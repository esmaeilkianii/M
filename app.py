import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
from datetime import timedelta # Import timedelta
import plotly.express as px
import plotly.graph_objects as go # For grouped bar chart
import os
from io import BytesIO
import requests # Needed for getThumbUrl download
import numpy as np # For calculations and handling potential NaNs

# --- Configuration ---
APP_TITLE = "Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

# --- File Paths (Relative to the script location in Hugging Face) ---
CSV_FILE_PATH = 'output (1).csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'

# --- GEE Authentication ---
@st.cache_resource # Cache the GEE initialization
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully using Service Account.")
        return True
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª ÙØ§ÛŒÙ„ Service Account Ùˆ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø¢Ù† Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ GEE Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.stop()

# --- Data Loading ---
@st.cache_data # Cache the loaded data
def load_data(csv_path):
    """Loads farm data from the CSV file."""
    try:
        df = pd.read_csv(csv_path)
        df.columns = df.columns.str.strip()
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        # Keep rows with missing coordinates for now, handle in functions needing geometry
        # df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], inplace=True)
        df['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª'] = pd.to_numeric(df['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª'], errors='coerce')
        df['Ù…Ø²Ø±Ø¹Ù‡'] = df['Ù…Ø²Ø±Ø¹Ù‡'].str.strip()
        for col in ['Ú©Ø§Ù†Ø§Ù„', 'Ø§Ø¯Ø§Ø±Ù‡', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù† ', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡']:
             if col in df.columns:
                # Convert to string first to handle mixed types before fillna
                df[col] = df[col].astype(str).fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
        # Ensure coordinates_missing is integer
        if 'coordinates_missing' in df.columns:
             df['coordinates_missing'] = pd.to_numeric(df['coordinates_missing'], errors='coerce').fillna(1).astype(int)

        print(f"Data loaded successfully. Shape: {df.shape}")
        return df
    except FileNotFoundError:
        st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ CSV Ø¯Ø± Ù…Ø³ÛŒØ± '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        st.stop()

# --- GEE Image Processing Functions ---

# Define common band names (used AFTER processing)
COMMON_BAND_NAMES = ['Blue', 'Green', 'Red', 'RedEdge1', 'NIR', 'SWIR1', 'SWIR2']

# --- Masking Functions ---
def mask_s2_clouds(image):
    img_ee = ee.Image(image) # Cast to image
    qa = img_ee.select('QA60')
    cloud_bit_mask = 1 << 10
    cirrus_bit_mask = 1 << 11
    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(
             qa.bitwiseAnd(cirrus_bit_mask).eq(0))
    data_bands = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12']
    return img_ee.select(data_bands).updateMask(mask).divide(10000.0)\
        .copyProperties(img_ee, ["system:time_start"])

def mask_landsat_clouds(image):
    img_ee = ee.Image(image) # Cast to image
    qa = img_ee.select('QA_PIXEL')
    cloud_shadow_bit = 1 << 3
    snow_bit = 1 << 4
    cloud_bit = 1 << 5
    mask = qa.bitwiseAnd(cloud_shadow_bit).eq(0)\
             .And(qa.bitwiseAnd(snow_bit).eq(0))\
             .And(qa.bitwiseAnd(cloud_bit).eq(0))
    sr_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']
    scaled_bands = img_ee.select(sr_bands).multiply(0.0000275).add(-0.2)
    return scaled_bands.updateMask(mask)\
        .copyProperties(img_ee, ["system:time_start"])


# --- Index Calculation Functions ---
# (Ensure they return the calculated index band correctly named)
def calculate_ndvi(image):
    img_ee = ee.Image(image)
    ndvi = img_ee.normalizedDifference(['NIR', 'Red'])
    return ndvi.rename('NDVI')

def calculate_evi(image):
    img_ee = ee.Image(image)
    evi = img_ee.expression(
        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {
            'NIR': img_ee.select('NIR'), 'RED': img_ee.select('Red'), 'BLUE': img_ee.select('Blue')
        })
    return evi.rename('EVI')

def calculate_ndmi(image):
    img_ee = ee.Image(image)
    ndmi = img_ee.normalizedDifference(['NIR', 'SWIR1'])
    return ndmi.rename('NDMI')

def calculate_msi(image):
    img_ee = ee.Image(image)
    msi = img_ee.expression('SWIR1 / NIR', { 'SWIR1': img_ee.select('SWIR1'), 'NIR': img_ee.select('NIR') })
    return msi.rename('MSI')

def calculate_lai_simple(image):
    img_ee = ee.Image(image)
    try:
        evi = img_ee.expression('2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',
                                {'NIR': img_ee.select('NIR'), 'RED': img_ee.select('Red'), 'BLUE': img_ee.select('Blue')})
        lai = evi.multiply(3.5).add(0.1)
    except Exception:
        # Warning is helpful, but avoid stopping execution if possible
        # st.warning("EVI failed for LAI, using NDVI.", icon="âš ï¸")
        ndvi = img_ee.normalizedDifference(['NIR', 'Red'])
        lai = ndvi.multiply(5.0).add(0.1)
    return lai.clamp(0, 8).rename('LAI')

def calculate_biomass_simple(image):
    img_ee = ee.Image(image)
    lai_image = calculate_lai_simple(img_ee) # Returns image named 'LAI'
    lai = lai_image.select('LAI')
    a = 1.5; b = 0.2 # Placeholder coefficients
    biomass = lai.multiply(a).add(b)
    return biomass.clamp(0, 50).rename('Biomass')

def calculate_chlorophyll_mcari(image):
    img_ee = ee.Image(image)
    try:
        img_ee.select('RedEdge1') # Check if band exists
        mcari = img_ee.expression('((RE1 - RED) - 0.2 * (RE1 - GREEN)) * (RE1 / RED)',
                                  {'RE1': img_ee.select('RedEdge1'), 'RED': img_ee.select('Red'), 'GREEN': img_ee.select('Green')})
        return mcari.rename('Chlorophyll')
    except ee.EEException:
         # st.warning("MCARI requires S2 Red Edge. Using NDVI as Chlorophyll proxy.", icon="âš ï¸")
         ndvi = img_ee.normalizedDifference(['NIR', 'Red'])
         return ndvi.rename('Chlorophyll')

def calculate_et_placeholder(image):
    # st.warning("Using NDMI as proxy for ET status.", icon="âš ï¸")
    img_ee = ee.Image(image)
    ndmi = img_ee.normalizedDifference(['NIR', 'SWIR1'])
    return ndmi.rename('ET_proxy')

# --- Index Definitions Dictionary (with descriptions) ---
INDEX_DEFINITIONS = {
    'NDVI': {
        'func': calculate_ndvi,
        'vis': {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']},
        'name_fa': "Ø´Ø§Ø®Øµ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ ØªÙØ§ÙˆØª Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ",
        'desc_fa': """
        **NDVI (Normalized Difference Vegetation Index)** Ø±Ø§ÛŒØ¬â€ŒØªØ±ÛŒÙ† Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø¬Ø´ Ø³Ù„Ø§Ù…Øª Ùˆ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø§Ø³Øª.
        - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** (NIR - Red) / (NIR + Red)
        - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û±
        - **ØªÙØ³ÛŒØ±:**
            - Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ +Û±: Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ø³ÛŒØ§Ø± Ù…ØªØ±Ø§Ú©Ù… Ùˆ Ø³Ø§Ù„Ù….
            - Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· (Û°.Û² ØªØ§ Û°.Ûµ): Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡ ÛŒØ§ ØªØ­Øª ØªÙ†Ø´.
            - Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ ØµÙØ± ÛŒØ§ Ù…Ù†ÙÛŒ: Ø®Ø§Ú©ØŒ Ø¢Ø¨ØŒ Ø§Ø¨Ø±ØŒ ÛŒØ§ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ø³ÛŒØ§Ø± Ú©Ù….
        """,
        'sort_ascending': False # Higher is better
    },
    'EVI': {
        'func': calculate_evi,
        'vis': {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']},
        'name_fa': "Ø´Ø§Ø®Øµ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ",
        'desc_fa': """
        **EVI (Enhanced Vegetation Index)** Ù…Ø´Ø§Ø¨Ù‡ NDVI Ø§Ø³Øª Ø§Ù…Ø§ Ø­Ø³Ø§Ø³ÛŒØª Ú©Ù…ØªØ±ÛŒ Ø¨Ù‡ Ø§Ø«Ø±Ø§Øª Ø§ØªÙ…Ø³ÙØ± Ùˆ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø®Ø§Ú© Ø¯Ø§Ø±Ø¯ Ùˆ Ø¯Ø± Ù…Ù†Ø§Ø·Ù‚ Ø¨Ø§ ØªØ±Ø§Ú©Ù… Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ø§Ù„Ø§ Ø¨Ù‡ØªØ± Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** 2.5 * (NIR - Red) / (NIR + 6*Red - 7.5*Blue + 1)
        - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û° ØªØ§ Û± (Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ú©Ù…ÛŒ Ø¨ÛŒØ´ØªØ± Ø´ÙˆØ¯).
        - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø³Ø§Ù„Ù…â€ŒØªØ± Ùˆ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ø§Ø³Øª.
        """,
        'sort_ascending': False
    },
    'NDMI': {
        'func': calculate_ndmi,
        'vis': {'min': -0.5, 'max': 0.8, 'palette': ['brown', 'white', 'blue']},
        'name_fa': "Ø´Ø§Ø®Øµ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ ØªÙØ§ÙˆØª Ø±Ø·ÙˆØ¨Øª",
        'desc_fa': """
        **NDMI (Normalized Difference Moisture Index)** Ù…ÛŒØ²Ø§Ù† Ø¢Ø¨ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¨Ø±Ú¯â€ŒÙ‡Ø§ÛŒ Ú¯ÛŒØ§Ù‡Ø§Ù† Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
        - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** (NIR - SWIR1) / (NIR + SWIR1)
        - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û±
        - **ØªÙØ³ÛŒØ±:**
            - Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§: Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ.
            - Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ†: Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø®Ø´Ú© ÛŒØ§ ØªØ­Øª ØªÙ†Ø´ Ø¢Ø¨ÛŒ.
        """,
        'sort_ascending': False
    },
    'MSI': {
        'func': calculate_msi,
        'vis': {'min': 0.4, 'max': 2.5, 'palette': ['darkgreen', 'yellow', 'red']}, # Lower MSI is less stressed
        'name_fa': "Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ",
        'desc_fa': """
        **MSI (Moisture Stress Index)** Ù†ÛŒØ² Ø¨Ù‡ Ø±Ø·ÙˆØ¨Øª Ú¯ÛŒØ§Ù‡ Ø­Ø³Ø§Ø³ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ø¨Ø±Ø®Ù„Ø§Ù NDMIØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± *Ø¨Ø§Ù„Ø§ØªØ±* Ø¢Ù† Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ *Ø¨ÛŒØ´ØªØ±* Ø§Ø³Øª.
        - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** SWIR1 / NIR
        - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨ÛŒØ´ØªØ± Ø§Ø² Û°.Û´.
        - **ØªÙØ³ÛŒØ±:**
            - Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±: ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ú©Ù…ØªØ±.
            - Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ±: ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø¨ÛŒØ´ØªØ±.
        """,
        'sort_ascending': True # Higher is worse
    },
    'LAI': {
        'func': calculate_lai_simple,
        'vis': {'min': 0, 'max': 8, 'palette': ['white', 'lightgreen', 'darkgreen']},
        'name_fa': "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
        'desc_fa': """
        **LAI (Leaf Area Index)** Ù†Ø³Ø¨Øª Ú©Ù„ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ú¯ Ø¨Ù‡ ÙˆØ§Ø­Ø¯ Ø³Ø·Ø­ Ø²Ù…ÛŒÙ† Ø§Ø³Øª (mÂ²/mÂ²). Ø§ÛŒÙ† ÛŒÚ© ØªØ®Ù…ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù…Ø§Ù†Ù†Ø¯ EVI ÛŒØ§ NDVI) Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ù…Ø­Ù„ÛŒ Ø¯Ø§Ø±Ø¯.
        - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** ØªÙ‚Ø±ÛŒØ¨ÛŒØŒ Ù…Ø«Ù„Ø§Ù‹ a * EVI + b
        - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û° ØªØ§ Û¸ ÛŒØ§ Ø¨ÛŒØ´ØªØ±.
        - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ø¨Ø§ Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.
        """,
        'sort_ascending': False
    },
    'Biomass': {
        'func': calculate_biomass_simple,
        'vis': {'min': 0, 'max': 30, 'palette': ['beige', 'yellow', 'brown']},
        'name_fa': "Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
        'desc_fa': """
        **Biomass** ÙˆØ²Ù† Ù…Ø§Ø¯Ù‡ Ø®Ø´Ú© Ú¯ÛŒØ§Ù‡ÛŒ Ø¯Ø± ÙˆØ§Ø­Ø¯ Ø³Ø·Ø­ (Ù…Ø«Ù„Ø§Ù‹ ØªÙ† Ø¨Ø± Ù‡Ú©ØªØ§Ø±) Ø§Ø³Øª. Ø§ÛŒÙ† Ù†ÛŒØ² ÛŒÚ© ØªØ®Ù…ÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ LAI ÛŒØ§ Ø³Ø§ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¯Ù‚ÛŒÙ‚ Ø¯Ø§Ø±Ø¯.
        - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** ØªÙ‚Ø±ÛŒØ¨ÛŒØŒ Ù…Ø«Ù„Ø§Ù‹ a * LAI + b
        - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** ÙˆØ§Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ù†ÙˆØ¹ Ú¯ÛŒØ§Ù‡ Ùˆ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† (Ù…Ø«Ù„Ø§Ù‹ Û° ØªØ§ ÛµÛ°+ ØªÙ†/Ù‡Ú©ØªØ§Ø±).
        - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.
        """,
        'sort_ascending': False
    },
    'Chlorophyll': {
        'func': calculate_chlorophyll_mcari,
        'vis': {'min': 0, 'max': 1, 'palette': ['yellow', 'lightgreen', 'darkgreen']},
        'name_fa': "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (MCARI/NDVI)",
        'desc_fa': """
        **Chlorophyll Index** Ø¨Ù‡ ØºÙ„Ø¸Øª Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¯Ø± Ø¨Ø±Ú¯â€ŒÙ‡Ø§ Ø­Ø³Ø§Ø³ Ø§Ø³Øª. Ø§Ø² Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ MCARI (Ú©Ù‡ Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ RedEdge Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯) ÛŒØ§ ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø¨Ø§ NDVI (Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ RedEdge) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** MCARI ÛŒØ§ NDVI
        - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…ØªØºÛŒØ±ØŒ Ø§Ù…Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ØªØ± Ø§Ø³Øª.
        - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ùˆ Ø³Ù„Ø§Ù…Øª Ø¨Ù‡ØªØ± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª.
        """,
        'sort_ascending': False
    },
    'ET_proxy': {
        'func': calculate_et_placeholder,
        'vis': {'min': -0.5, 'max': 0.8, 'palette': ['brown', 'white', 'blue']},
        'name_fa': "Ù¾Ø±Ø§Ú©Ø³ÛŒ ØªØ¨Ø®ÛŒØ±-ØªØ¹Ø±Ù‚ (Ø¨Ø± Ø§Ø³Ø§Ø³ NDMI)",
        'desc_fa': """
        **ET Proxy** ÛŒÚ© Ø´Ø§Ø®Øµ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª Ø±Ø·ÙˆØ¨ØªÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ØªØ¨Ø®ÛŒØ± Ùˆ ØªØ¹Ø±Ù‚ (ET) Ø§Ø³Øª. Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø² NDMI Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø±Ø§Ú©Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚ ET Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø§Ø³Øª.
        - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** NDMI
        - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û±
        - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± NDMI (Ø±Ø·ÙˆØ¨Øª Ø¨ÛŒØ´ØªØ±) Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ ET Ø¨Ø§Ù„Ø§ØªØ±ÛŒ Ø±Ø§ Ù†Ø´Ø§Ù† Ø¯Ù‡Ø¯ (Ø§Ú¯Ø± Ø¢Ø¨ Ø¹Ø§Ù…Ù„ Ù…Ø­Ø¯ÙˆØ¯Ú©Ù†Ù†Ø¯Ù‡ Ù†Ø¨Ø§Ø´Ø¯). Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ† Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ØªÙ†Ø´ Ø¢Ø¨ÛŒ Ùˆ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ ET Ú©Ù…ØªØ± Ø§Ø³Øª.
        """,
        'sort_ascending': False
    }
}


# --- GEE Data Retrieval ---
def get_image_collection(start_date, end_date, geometry=None, sensor='Sentinel-2'):
    """Gets, filters, masks, scales, and renames Sentinel-2 or Landsat images."""
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')

    bands_to_select_orig = []
    bands_to_rename_to = []
    mask_func = None
    collection = None

    if sensor == 'Sentinel-2':
        collection_id = 'COPERNICUS/S2_SR_HARMONIZED'
        mask_func = mask_s2_clouds
        bands_to_select_orig = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12', 'QA60']
        bands_to_rename_to = ['Blue', 'Green', 'Red', 'RedEdge1', 'NIR', 'SWIR1', 'SWIR2']
        collection = ee.ImageCollection(collection_id)
    elif sensor == 'Landsat':
        l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')
        l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')
        collection = l9.merge(l8)
        mask_func = mask_landsat_clouds
        bands_to_select_orig = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'QA_PIXEL']
        bands_to_rename_to = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2']
    else:
        st.error("Sensor not supported")
        return None

    # Basic Date Range Check
    if start_date > end_date:
         st.error("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø¹Ø¯ Ø§Ø² ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø´Ø¯.")
         return None

    collection = collection.filterDate(start_date_str, end_date_str)
    if geometry:
        # Add a check for valid geometry
        try:
            if geometry.type().getInfo() not in ['Point', 'Polygon', 'Rectangle', 'MultiPolygon']:
                 st.warning(f"Ù†ÙˆØ¹ Ù‡Ù†Ø¯Ø³ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ±: {geometry.type().getInfo()}", icon="âš ï¸")
                 geometry = None # Don't filter by invalid geometry
            else:
                 collection = collection.filterBounds(geometry)
        except Exception as e:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù…Ø±Ø²Ù‡Ø§ÛŒ Ù‡Ù†Ø¯Ø³ÛŒ: {e}")
            return None


    initial_count = collection.size().getInfo()
    if initial_count == 0:
        # Don't show warning if the reason might be the geometry filter failing silently
        if geometry is not None:
             st.warning(f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù…Ù†Ø·Ù‚Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ({sensor}) Ù‚Ø¨Ù„ Ø§Ø² Ù…Ø§Ø³Ú© Ø§Ø¨Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="â³")
        return None

    def process_image(image_element):
        image = ee.Image(image_element)
        img_selected_orig = image.select(bands_to_select_orig)
        img_processed = mask_func(img_selected_orig)
        img_processed_safe = ee.Image(img_processed) # Cast for safety
        # Handle potential mismatch in band counts after masking if needed
        expected_band_count = len(bands_to_rename_to)
        actual_bands = img_processed_safe.bandNames()
        # A more robust way might involve checking actual_bands length, but rename handles extra/missing okay
        img_renamed = img_processed_safe.rename(bands_to_rename_to)
        return img_renamed.copyProperties(image, ["system:time_start"])

    processed_collection = collection.map(process_image)

    count = processed_collection.size().getInfo()
    if count == 0:
        st.warning(f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù…Ù†Ø·Ù‚Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ({sensor}) ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="â˜ï¸")
        return None

    try:
        first_image = processed_collection.first()
        if first_image is None: return None # Empty after processing
        final_bands = ee.Image(first_image).bandNames().getInfo()
        print(f"Final bands in processed collection: {final_bands}")
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {e}")
        return None

    return processed_collection

# --- Function to calculate a single index for a collection ---
def calculate_single_index(collection, index_name):
    """Calculates a single index for the collection."""
    if collection is None: return None
    index_detail = INDEX_DEFINITIONS.get(index_name)
    if not index_detail:
        st.error(f"ØªØ¹Ø±ÛŒÙ Ø´Ø§Ø®Øµ '{index_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return None

    index_func = index_detail['func']
    try:
        # Map the function - it should return an image with the index band
        indexed_collection = collection.map(index_func)
        # Check if the index band was actually created
        first_img = indexed_collection.first()
        if first_img and index_name in ee.Image(first_img).bandNames().getInfo():
             return indexed_collection.select(index_name) # Return collection with only the index band
        else:
             st.warning(f"Ø¨Ø§Ù†Ø¯ Ø´Ø§Ø®Øµ '{index_name}' Ù¾Ø³ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯.", icon="âš ï¸")
             return None
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{index_name}': {e}")
        return None

# --- get_timeseries_for_farm ---
@st.cache_data(ttl=3600)
def get_timeseries_for_farm(_farm_geom_geojson, start_date, end_date, index_name, sensor):
    farm_geom = ee.Geometry(json.loads(_farm_geom_geojson))
    base_collection = get_image_collection(start_date, end_date, farm_geom, sensor)
    if base_collection is None: return pd.DataFrame(columns=['Date', index_name])

    indexed_collection = calculate_single_index(base_collection, index_name)
    if indexed_collection is None: return pd.DataFrame(columns=['Date', index_name])

    def extract_value(image):
        img_ee = ee.Image(image) # Ensure image type
        stats = img_ee.reduceRegion(
            reducer=ee.Reducer.mean(), geometry=farm_geom, scale=30, maxPixels=1e9, tileScale=4
        )
        val = stats.get(index_name)
        time_ms = img_ee.get('system:time_start') # Get time from the image object
        return ee.Feature(None, {'time': time_ms, index_name: ee.Algorithms.If(val, val, -9999)})

    try:
        ts_info = indexed_collection.map(extract_value).getInfo()
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ (reduceRegion): {e}")
        return pd.DataFrame(columns=['Date', index_name])

    data = []
    if 'features' in ts_info:
        for feature in ts_info['features']:
            props = feature.get('properties', {})
            value = props.get(index_name)
            time_ms = props.get('time')
            if value not in [None, -9999] and time_ms is not None:
                try:
                    dt = datetime.datetime.fromtimestamp(time_ms / 1000.0)
                    data.append([dt, value])
                except (TypeError, ValueError) as time_e:
                     st.warning(f"Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ† Ø²Ù…Ø§Ù† Ù†Ø§Ù…Ø¹ØªØ¨Ø± ({time_ms}): {time_e}", icon="âš ï¸")
    else:
        st.warning("Ú©Ù„ÛŒØ¯ 'features' Ø¯Ø± Ù†ØªØ§ÛŒØ¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

    if not data: return pd.DataFrame(columns=['Date', index_name])
    ts_df = pd.DataFrame(data, columns=['Date', index_name]).sort_values(by='Date')
    return ts_df

# --- Renamed Function for getting median index over a period for multiple farms ---
@st.cache_data(ttl=3600)
def get_median_index_for_period(_farms_df_json, start_date, end_date, index_name, sensor):
    """Gets the median index value over a period for multiple farms."""
    farms_df = pd.read_json(_farms_df_json)
    # Filter out farms with missing coordinates *before* creating features
    farms_df_valid_coords = farms_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']).copy()

    if farms_df_valid_coords.empty:
         st.warning("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="ğŸ“")
         return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    features = []
    for idx, row in farms_df_valid_coords.iterrows():
        try:
             geom = ee.Geometry.Point([row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']])
             buffered_geom = geom.buffer(50) # Buffer for reduction
             feature = ee.Feature(buffered_geom, {'farm_id': row['Ù…Ø²Ø±Ø¹Ù‡']})
             features.append(feature)
        except Exception as e:
             st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ù†Ø¯Ø³Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {row.get('Ù…Ø²Ø±Ø¹Ù‡', 'Unknown')}: {e}", icon="âš ï¸")

    if not features:
         st.warning("Ù‡ÛŒÚ† Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯.", icon="âš ï¸")
         return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    farm_fc = ee.FeatureCollection(features)

    base_collection = get_image_collection(start_date, end_date, farm_fc.geometry(), sensor)
    if base_collection is None:
        # Warning already shown in get_image_collection
        return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    indexed_collection = calculate_single_index(base_collection, index_name)
    if indexed_collection is None:
        return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    # Create a median composite over the period
    median_image = indexed_collection.median() # Already selected index band

    # Reduce the composite image over the farm geometries
    try:
        farm_values = median_image.reduceRegions(
            collection=farm_fc, reducer=ee.Reducer.mean(), scale=30, tileScale=8
        ).getInfo()
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø²Ø§Ø±Ø¹ (reduceRegions): {e}")
        return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    # Extract results
    results_data = []
    if 'features' in farm_values:
        for feature in farm_values['features']:
            props = feature.get('properties', {})
            farm_id = props.get('farm_id')
            value = props.get('mean') # Default output name is 'mean'
            if farm_id is not None and value is not None:
                results_data.append({'Ù…Ø²Ø±Ø¹Ù‡': farm_id, index_name: value})
    else:
        st.warning("Ú©Ù„ÛŒØ¯ 'features' Ø¯Ø± Ù†ØªØ§ÛŒØ¬ reduceRegions ÛŒØ§ÙØª Ù†Ø´Ø¯.")


    if not results_data:
         st.warning("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ GEE Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯.", icon="ğŸ“Š")
         return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    results_df = pd.DataFrame(results_data)
    return results_df

# --- Function for Weekly Comparison ---
@st.cache_data(ttl=3600)
def get_weekly_comparison(_filtered_df_json, start_date, end_date, index_name, sensor):
    """Compares the index values from the current week to the previous week."""
    # Define current and previous week date ranges
    current_start = start_date
    current_end = end_date
    prev_end = current_start - timedelta(days=1)
    prev_start = current_start - timedelta(days=7) # Assuming 7-day week

    st.write(f"Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ: {current_start} ØªØ§ {current_end}")
    st.write(f"Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„ÛŒ: {prev_start} ØªØ§ {prev_end}")


    # Get data for the current period
    df_current = get_median_index_for_period(_filtered_df_json, current_start, current_end, index_name, sensor)
    if df_current.empty:
        st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ ({current_start} ØªØ§ {current_end}) Ø¬Ù‡Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
        return pd.DataFrame()

    # Get data for the previous period
    df_previous = get_median_index_for_period(_filtered_df_json, prev_start, prev_end, index_name, sensor)
    if df_previous.empty:
        st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„ÛŒ ({prev_start} ØªØ§ {prev_end}) Ø¬Ù‡Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
        # Return current data only if previous is missing? Or empty? Let's return empty for comparison.
        return pd.DataFrame()

    # Merge the dataframes
    df_comparison = pd.merge(
        df_previous.rename(columns={index_name: f'{index_name}_prev'}),
        df_current.rename(columns={index_name: f'{index_name}_curr'}),
        on='Ù…Ø²Ø±Ø¹Ù‡',
        how='inner' # Only compare farms present in both periods
    )

    if df_comparison.empty:
        st.info("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø´ØªØ±Ú©ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ø¯ÙˆØ±Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return pd.DataFrame()

    # Calculate difference and percentage change
    df_comparison['ØªØºÛŒÛŒØ±'] = df_comparison[f'{index_name}_curr'] - df_comparison[f'{index_name}_prev']
    # Calculate percentage change carefully, handle division by zero or near-zero
    df_comparison['Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±'] = np.where(
        np.abs(df_comparison[f'{index_name}_prev']) > 1e-6, # Avoid division by zero/small numbers
       ((df_comparison['ØªØºÛŒÛŒØ±'] / df_comparison[f'{index_name}_prev']) * 100),
        np.nan # Assign NaN if previous value is too small
    )


    # Filter for farms with decrease
    df_decreased = df_comparison[df_comparison['ØªØºÛŒÛŒØ±'] < 0].copy()

    # Sort by percentage change (most negative first)
    df_decreased = df_decreased.sort_values(by='Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±', ascending=True)

    return df_decreased


# --- Streamlit App Layout ---
st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

# Initialize GEE
if initialize_gee():
    # Load data
    farm_data_df = load_data(CSV_FILE_PATH)

    # --- Sidebar ---
    st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")
    default_end_date = datetime.date.today()
    default_start_date = default_end_date - timedelta(days=6) # Default to last 7 days (inclusive)
    start_date = st.sidebar.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ", value=default_start_date, max_value=default_end_date)
    end_date = st.sidebar.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù† Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ", value=default_end_date, min_value=start_date, max_value=default_end_date)

    # --- Display Index Information ---
    st.sidebar.header("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§")
    selected_index_info = st.sidebar.selectbox(
        "Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­Ø§Øª:",
        options=list(INDEX_DEFINITIONS.keys()),
        format_func=lambda x: INDEX_DEFINITIONS[x]['name_fa'] # Show Persian name in dropdown
    )
    if selected_index_info:
        with st.sidebar.expander(f"ØªÙˆØ¶ÛŒØ­Ø§Øª Ø´Ø§Ø®Øµ {INDEX_DEFINITIONS[selected_index_info]['name_fa']}", expanded=False):
            st.markdown(INDEX_DEFINITIONS[selected_index_info]['desc_fa'], unsafe_allow_html=True)


    # --- Filters for Map/Ranking/Comparison ---
    st.sidebar.header("ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡")
    days_list = ["Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§"] + sorted(farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique().tolist())
    selected_day = st.sidebar.selectbox("ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ", options=days_list)

    # Filter DataFrame based on selected day *before* farm selection
    if selected_day == "Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§":
        filtered_df = farm_data_df.copy()
    else:
        filtered_df = farm_data_df[farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()

    # Allow selecting index for analysis
    available_indices = list(INDEX_DEFINITIONS.keys())
    selected_index = st.sidebar.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„", options=available_indices)

    # Sensor Selection
    selected_sensor = st.sidebar.radio("Ø§Ù†ØªØ®Ø§Ø¨ Ø³Ù†Ø³ÙˆØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡", ('Sentinel-2', 'Landsat'), index=0, key='sensor_select')

    # Farm Selection (applied AFTER day filter)
    farm_list = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + sorted(filtered_df['Ù…Ø²Ø±Ø¹Ù‡'].unique().tolist())
    selected_farm = st.sidebar.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ (ÛŒØ§ Ù‡Ù…Ù‡)", options=farm_list)


    # --- Main Panel ---
    tab1, tab2, tab3 = st.tabs(["Ù†Ù‚Ø´Ù‡ Ùˆ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡", "Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹", "Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ (Ú©Ø§Ù‡Ø´)"])

    # --- Tab 1: Map and Farm Details ---
    with tab1:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.subheader(f"Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø´Ø§Ø®Øµ: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
            map_placeholder = st.empty()
            m = geemap.Map(center=[INITIAL_LAT, INITIAL_LON], zoom=INITIAL_ZOOM, add_google_map=False)
            m.add_basemap('HYBRID')

            vis_params = INDEX_DEFINITIONS.get(selected_index, {}).get('vis')
            if not vis_params: vis_params = {'min': 0, 'max': 1, 'palette': ['white', 'gray']}

            # Determine display geometry
            display_geom = None
            target_object_for_map = None
            farm_info_for_popup = None
            # Use the filtered_df which respects the day filter
            display_df = filtered_df.copy() # Work with the day-filtered data

            if selected_farm == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                display_df_valid = display_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
                if not display_df_valid.empty:
                    min_lon, min_lat = display_df_valid['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), display_df_valid['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
                    max_lon, max_lat = display_df_valid['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(), display_df_valid['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
                    display_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])
                    target_object_for_map = display_geom
                else:
                    st.info("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ² Ù‡ÙØªÙ‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            else: # Single farm selected
                farm_info_rows = display_df[display_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm]
                if not farm_info_rows.empty:
                    farm_info_for_popup = farm_info_rows.iloc[0]
                    farm_lat = farm_info_for_popup['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
                    farm_lon = farm_info_for_popup['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
                    if pd.notna(farm_lat) and pd.notna(farm_lon):
                        farm_geom = ee.Geometry.Point([farm_lon, farm_lat])
                        display_geom = farm_geom.buffer(150)
                        target_object_for_map = farm_geom
                    else:
                        st.warning(f"Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm}.", icon="ğŸ“")
                        farm_info_for_popup = None
                else:
                    st.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ {selected_farm} Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")

            # Fetch data and display on map
            if display_geom:
                with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø´Ù‡ {selected_index}..."):
                    base_collection = get_image_collection(start_date, end_date, display_geom, selected_sensor)
                    if base_collection:
                        indexed_collection = calculate_single_index(base_collection, selected_index)
                        if indexed_collection:
                            median_image = indexed_collection.median()
                            layer_image = median_image.clip(display_geom) if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else median_image
                            m.addLayer(layer_image, vis_params, f'{selected_index} (Median)')
                            try:
                                m.add_legend(title=f'{selected_index}', builtin_legend=None, palette=vis_params['palette'], min=vis_params['min'], max=vis_params['max'])
                            except Exception as legend_e: pass # Ignore legend errors for now

                            # Add download button for map layer
                            try:
                                thumb_url = median_image.getThumbURL({'region': display_geom.toGeoJson(), 'bands': selected_index, 'palette': vis_params['palette'], 'min': vis_params['min'], 'max': vis_params['max'], 'dimensions': 512})
                                response = requests.get(thumb_url)
                                if response.status_code == 200:
                                    st.sidebar.download_button(label=f"Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ù‚Ø´Ù‡ ({selected_index})", data=BytesIO(response.content), file_name=f"map_{selected_farm if selected_farm != 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' else 'all'}_{selected_index}.png", mime="image/png", key=f"dl_map_{selected_index}_{selected_farm}")
                            except Exception as thumb_e: pass # Ignore thumb errors silently for now

                        else: st.warning(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{selected_index}' Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡ Ù…Ù…Ú©Ù† Ù†Ø¨ÙˆØ¯.", icon="âš ï¸")
                    else: st.warning(f"ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø´Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="â³")

                # Add markers
                if selected_farm == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                    df_to_mark = display_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
                    for idx, row in df_to_mark.iterrows():
                        popup_html = f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {row['Ù…Ø²Ø±Ø¹Ù‡']}<br><b>Ú©Ø§Ù†Ø§Ù„:</b> {row['Ú©Ø§Ù†Ø§Ù„']}<br><b>Ù…Ø³Ø§Ø­Øª:</b> {row['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}"
                        folium.Marker(location=[row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=folium.Popup(popup_html, max_width=200), tooltip=f"{row['Ù…Ø²Ø±Ø¹Ù‡']}", icon=folium.Icon(color='blue', icon='info-sign')).add_to(m)
                elif farm_info_for_popup is not None:
                    farm_info = farm_info_for_popup
                    popup_html = f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {farm_info['Ù…Ø²Ø±Ø¹Ù‡']}<br><b>Ú©Ø§Ù†Ø§Ù„:</b> {farm_info['Ú©Ø§Ù†Ø§Ù„']}<br><b>Ø§Ø¯Ø§Ø±Ù‡:</b> {farm_info['Ø§Ø¯Ø§Ø±Ù‡']}<br><b>Ù…Ø³Ø§Ø­Øª:</b> {farm_info['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}<br><b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {farm_info['ÙˆØ§Ø±ÛŒØªÙ‡']}<br><b>Ø³Ù†:</b> {farm_info['Ø³Ù† ']}"
                    folium.Marker(location=[farm_info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm_info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=folium.Popup(popup_html, max_width=250), tooltip=f"{farm_info['Ù…Ø²Ø±Ø¹Ù‡']}", icon=folium.Icon(color='red', icon='star')).add_to(m)

                # Center the map
                if target_object_for_map:
                    zoom_level = INITIAL_ZOOM + 2 if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else INITIAL_ZOOM
                    try: m.center_object(target_object_for_map, zoom=zoom_level)
                    except: m.set_center(INITIAL_LON, INITIAL_LAT, INITIAL_ZOOM) # Fallback center

            # Render the map
            with map_placeholder: m.to_streamlit(height=500)

        # --- Column 2: Details / Timeseries ---
        with col2:
            if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                st.subheader(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm}")
                if farm_info_for_popup is not None:
                    farm_info = farm_info_for_popup
                    st.metric("Ú©Ø§Ù†Ø§Ù„", str(farm_info['Ú©Ø§Ù†Ø§Ù„']))
                    st.metric("Ø§Ø¯Ø§Ø±Ù‡", str(farm_info['Ø§Ø¯Ø§Ø±Ù‡']))
                    st.metric("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", f"{farm_info['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}" if pd.notna(farm_info['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']) else "N/A")
                    st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", str(farm_info['ÙˆØ§Ø±ÛŒØªÙ‡']))
                    st.metric("Ø³Ù†", str(farm_info['Ø³Ù† ']))
                    st.metric("Ø±ÙˆØ² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", str(farm_info['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡']))

                    st.subheader(f"Ø±ÙˆÙ†Ø¯ Ø´Ø§Ø®Øµ: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
                    if pd.notna(farm_info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) and pd.notna(farm_info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']):
                        with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index}..."):
                            farm_geom = ee.Geometry.Point([farm_info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm_info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']])
                            ts_df = get_timeseries_for_farm(farm_geom.toGeoJsonString(), start_date, end_date, selected_index, selected_sensor)
                        if not ts_df.empty:
                            fig = px.line(ts_df, x='Date', y=selected_index, title=f"Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index}", markers=True)
                            fig.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title=selected_index)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    else:
                        st.warning("Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ.", icon="ğŸ“")
                else:
                    st.info("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ ÛŒØ§ Ø§Ù†ØªØ®Ø§Ø¨ ÙØ¹Ù„ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
            else:
                st.info("Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒØŒ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")


    # --- Tab 2: Ranking ---
    with tab2:
        st.subheader(f"Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
        st.info(f"Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ '{selected_index}' Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ {start_date} ØªØ§ {end_date} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÙØ¹Ø§Ù„ Ø¯Ø± '{selected_day}'.")

        with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹..."):
            # Use the day-filtered DataFrame for ranking
            ranking_df = get_median_index_for_period(filtered_df.to_json(), start_date, end_date, selected_index, sensor=selected_sensor)

        if not ranking_df.empty:
            # Determine sort order based on index definition
            ascending_sort = INDEX_DEFINITIONS[selected_index].get('sort_ascending', False)
            ranking_df_sorted = ranking_df.sort_values(by=selected_index, ascending=ascending_sort, na_position='last').reset_index(drop=True)

            if selected_index in ranking_df_sorted.columns:
                 st.dataframe(ranking_df_sorted.style.format({selected_index: "{:.3f}"}), use_container_width=True)
            else:
                 st.dataframe(ranking_df_sorted, use_container_width=True)

            csv = ranking_df_sorted.to_csv(index=False).encode('utf-8')
            st.download_button(
               label=f"Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ({selected_index})", data=csv,
               file_name=f'ranking_{selected_index}_{selected_day}.csv', mime='text/csv', key='dl_rank'
             )
        else:
            st.warning("Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="ğŸ“Š")

    # --- Tab 3: Weekly Comparison ---
    with tab3:
        st.subheader(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ: Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ ({INDEX_DEFINITIONS[selected_index]['name_fa']})")
        st.markdown(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø§Ø®Øµ **{selected_index}** Ø¨ÛŒÙ† Ø¯ÙˆØ±Ù‡ **{start_date} ØªØ§ {end_date}** (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ) Ùˆ Ø¯ÙˆØ±Ù‡ **{start_date - timedelta(days=7)} ØªØ§ {start_date - timedelta(days=1)}** (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„).")
        st.info("ÙÙ‚Ø· Ù…Ø²Ø§Ø±Ø¹ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ú©Ù‡ Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ú©Ø§Ù‡Ø´ Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.")

        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ..."):
            # Pass the day-filtered json for comparison relevant to the selected day
            comparison_df = get_weekly_comparison(filtered_df.to_json(), start_date, end_date, selected_index, selected_sensor)

        if not comparison_df.empty:
            st.markdown("##### Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ:")
            # Display table with relevant columns
            display_cols = ['Ù…Ø²Ø±Ø¹Ù‡', f'{index_name}_prev', f'{index_name}_curr', 'ØªØºÛŒÛŒØ±', 'Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±']
            st.dataframe(
                comparison_df[display_cols].style.format({
                    f'{index_name}_prev': "{:.3f}",
                    f'{index_name}_curr': "{:.3f}",
                    'ØªØºÛŒÛŒØ±': "{:.3f}",
                    'Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±': "{:.1f}%"
                }),
                use_container_width=True
            )

            st.markdown("##### Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ:")
            # Create grouped bar chart
            fig_comp = go.Figure()
            fig_comp.add_trace(go.Bar(
                x=comparison_df['Ù…Ø²Ø±Ø¹Ù‡'],
                y=comparison_df[f'{index_name}_prev'],
                name='Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„',
                marker_color='skyblue'
            ))
            fig_comp.add_trace(go.Bar(
                x=comparison_df['Ù…Ø²Ø±Ø¹Ù‡'],
                y=comparison_df[f'{index_name}_curr'],
                name='Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ',
                marker_color='salmon'
            ))

            fig_comp.update_layout(
                barmode='group',
                title=f'Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø§Ø®Øµ {selected_index} (Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´)',
                xaxis_title='Ù…Ø²Ø±Ø¹Ù‡',
                yaxis_title=f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}',
                legend_title='Ø¯ÙˆØ±Ù‡ Ø²Ù…Ø§Ù†ÛŒ'
            )
            st.plotly_chart(fig_comp, use_container_width=True)

            # Download comparison data
            csv_comp = comparison_df.to_csv(index=False).encode('utf-8')
            st.download_button(
               label=f"Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ ({selected_index})", data=csv_comp,
               file_name=f'comparison_decrease_{selected_index}_{selected_day}.csv', mime='text/csv', key='dl_comp'
             )

        else:
            st.success("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ø§Ù‡Ø´ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø´Ø§Ø®Øµ Ø¨ÛŒÙ† Ø¯Ùˆ Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ± Ù†Ø´Ø§Ù† Ù†Ø¯Ø§Ø¯.")

else:
    st.warning("Ù„Ø·ÙØ§ ØµØ¨Ø± Ú©Ù†ÛŒØ¯ ØªØ§ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´ÙˆØ¯ ÛŒØ§ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.", icon="â³")

# Footer
st.sidebar.markdown("---")
st.sidebar.info("Ø±Ø§Ù‡Ù†Ù…Ø§: Ø§Ø² Ù…Ù†ÙˆÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒØŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ØŒ Ù…Ø²Ø±Ø¹Ù‡ Ùˆ Ø´Ø§Ø®Øµ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")