import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
import plotly.express as px
import plotly.graph_objects as go # Add plotly graph objects
import os
# from io import BytesIO # Not strictly needed for this version
# import requests # Needed for getThumbUrl download (Not used currently)
import traceback  # Add missing traceback import
from streamlit_folium import st_folium  # Add missing st_folium import
# import base64 # Not strictly needed for this version
import google.generativeai as genai # Gemini API

# --- Custom CSS ---
st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±",
    page_icon="ğŸŒ¾",
    layout="wide"
)

# Modern CSS with dark mode and color palette
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');
        @import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css');
        html, body, .main, .stApp {
            font-family: 'Vazirmatn', sans-serif !important;
            background: linear-gradient(135deg, #e0f7fa 0%, #f8fafc 100%);
        }
        /* Modern card style */
        .modern-card {
            background: linear-gradient(135deg, #43cea2 0%, #185a9d 100%);
            color: white;
            border-radius: 18px;
            padding: 24px 18px;
            margin: 10px 0;
            box-shadow: 0 4px 16px rgba(30,60,114,0.08);
            text-align: center;
            transition: transform 0.2s;
        }
        .modern-card:hover {
            transform: translateY(-4px) scale(1.02);
        }
        /* Sidebar logo */
        .sidebar-logo {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 1.5rem;
        }
        .sidebar-logo img {
            width: 90px;
            height: 90px;
            border-radius: 18px;
            box-shadow: 0 2px 8px rgba(30,60,114,0.12);
        }
        /* Main header logo */
        .main-logo {
            width: 48px;
            height: 48px;
            border-radius: 12px;
            margin-left: 12px;
            vertical-align: middle;
        }
        /* Status Badges */
        .status-badge {
            padding: 4px 10px;
            border-radius: 12px;
            font-weight: bold;
            font-size: 0.9em;
            white-space: nowrap;
        }
        .status-positive {
            background-color: #d4edda; /* Light Green */
            color: #155724; /* Dark Green */
            border: 1px solid #c3e6cb;
        }
        .status-negative {
            background-color: #f8d7da; /* Light Red */
            color: #721c24; /* Dark Red */
            border: 1px solid #f5c6cb;
        }
        .status-neutral {
            background-color: #fff3cd; /* Light Yellow */
            color: #856404; /* Dark Yellow */
            border: 1px solid #ffeeba;
        }
        .status-nodata {
            background-color: #e2e3e5; /* Light Gray */
            color: #383d41; /* Dark Gray */
            border: 1px solid #d6d8db;
        }
        .status-unknown {
            background-color: #f0f0f0; /* Lighter Gray */
            color: #555;
            border: 1px solid #e0e0e0;
        }

        /* Dark mode support */
        @media (prefers-color-scheme: dark) {
            html, body, .main, .stApp {
                background: linear-gradient(135deg, #232526 0%, #414345 100%);
                color: #f8fafc;
            }
           .status-positive { background-color: #2a4d32; color: #c3e6cb; border-color: #446d50;}
           .status-negative { background-color: #582128; color: #f5c6cb; border-color: #8b3f46;}
           .status-neutral { background-color: #664d03; color: #ffeeba; border-color: #997404;}
           .status-nodata { background-color: #383d41; color: #d6d8db; border-color: #5a6268;}
           .status-unknown { background-color: #444; color: #ccc; border-color: #555;}
        }
    </style>
""", unsafe_allow_html=True)

# --- Sidebar Logo ---
# Assuming the logo path is relative to the app's root directory in deployment
logo_path = 'logo (1).png'
if os.path.exists(logo_path):
    st.sidebar.markdown(
        f"""
        <div class='sidebar-logo'>
            <img src='{logo_path}' alt='Ù„ÙˆÚ¯Ùˆ Ø³Ø§Ù…Ø§Ù†Ù‡' />
        </div>
        """,
        unsafe_allow_html=True
    )
else:
    st.sidebar.warning("Ù„ÙˆÚ¯Ùˆ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


# --- Main Header with Logo ---
if os.path.exists(logo_path):
    st.markdown(
        f"""
        <div style='display: flex; align-items: center; gap: 16px; margin-bottom: 0.5rem;'>
            <img src='{logo_path}' class='main-logo' alt='Ù„ÙˆÚ¯Ùˆ' />
            <h1 style='font-family: Vazirmatn, sans-serif; color: #185a9d; margin: 0;'>Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±</h1>
        </div>
        <h4 style='color: #43cea2; margin-top: 0;'>Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§</h4>
        """,
        unsafe_allow_html=True
    )
else:
     st.markdown(
        """
        <div style='display: flex; align-items: center; gap: 16px; margin-bottom: 0.5rem;'>
             <span style='font-size: 32px;'>ğŸŒ¾</span>
             <h1 style='font-family: Vazirmatn, sans-serif; color: #185a9d; margin: 0;'>Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±</h1>
        </div>
        <h4 style='color: #43cea2; margin-top: 0;'>Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§</h4>
        """,
        unsafe_allow_html=True
    )


# --- Configuration ---
APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±"
APP_SUBTITLE = "Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

# --- File Paths (Relative to the script location in Hugging Face) ---
CSV_FILE_PATH = 'Ø¨Ø±Ù†Ø§Ù…Ù‡_Ø±ÛŒØ²ÛŒ_Ø¨Ø§_Ù…Ø®ØªØµØ§Øª (1).csv' # Not used directly anymore? Check dependencies
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'

# --- GEE Authentication ---
@st.cache_resource # Cache the GEE initialization
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully using Service Account.")
        return True
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª ÙØ§ÛŒÙ„ Service Account Ùˆ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø¢Ù† Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ GEE Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.stop()


# --- Load Farm Data from GeoJSON ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...")
def load_farm_data_from_geojson(geojson_path='farm_geodata_fixed.geojson'):
    """Loads farm data from the specified GeoJSON file."""
    try:
        with open(geojson_path, 'r', encoding='utf-8') as f:
            gj = json.load(f)
        features = gj['features']
        # Extract properties and geometry
        records = []
        for feat in features:
            props = feat['properties']
            geom = feat['geometry']
            # For polygons, you may want centroid or all coordinates
            if geom and geom['type'] == 'Polygon' and geom['coordinates']:
                coords = geom['coordinates'][0]  # Outer ring
                # Calculate centroid for display/analysis
                lons = [pt[0] for pt in coords if isinstance(pt, (list, tuple)) and len(pt) >= 1]
                lats = [pt[1] for pt in coords if isinstance(pt, (list, tuple)) and len(pt) >= 2]
                if lons and lats:
                    centroid_lon = sum(lons) / len(lons)
                    centroid_lat = sum(lats) / len(lats)
                else:
                    centroid_lon, centroid_lat = None, None
            elif geom and geom['type'] == 'Point' and geom['coordinates']:
                 centroid_lon, centroid_lat = geom['coordinates'] # Use point coords directly
            else: # Handle other types or missing geometry
                centroid_lon, centroid_lat = None, None

            record = {
                **props,
                'geometry_type': geom['type'] if geom else None,
                'coordinates': geom['coordinates'] if geom else None,
                'centroid_lon': centroid_lon,
                'centroid_lat': centroid_lat
            }
            records.append(record)
        df = pd.DataFrame(records)
        # Basic validation
        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'centroid_lon', 'centroid_lat', 'Ø±ÙˆØ²', 'Ú¯Ø±ÙˆÙ‡']
        if not all(col in df.columns for col in required_cols):
            missing = [col for col in required_cols if col not in df.columns]
            st.error(f"âŒ ÙØ§ÛŒÙ„ GeoJSON Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø§Ø´Ø¯. Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØªâ€ŒÙ†Ø´Ø¯Ù‡: {', '.join(missing)}")
            st.stop()

        # Drop rows where essential coordinates or day are missing
        initial_count = len(df)
        df = df.dropna(subset=['centroid_lon', 'centroid_lat', 'Ø±ÙˆØ²'])
        dropped_count = initial_count - len(df)
        if dropped_count > 0:
            st.warning(f"âš ï¸ {dropped_count} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø¯Ø± Ù…Ø®ØªØµØ§Øª ÛŒØ§ Ø±ÙˆØ² Ø­Ø°Ù Ø´Ø¯Ù†Ø¯.")
        if df.empty:
            st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø®ØªØµØ§Øª ÛŒØ§ Ø±ÙˆØ²).")
            st.stop()
        df['Ø±ÙˆØ²'] = df['Ø±ÙˆØ²'].astype(str).str.replace(r'\s+', ' ', regex=True).str.strip()
        df['Ú¯Ø±ÙˆÙ‡'] = df['Ú¯Ø±ÙˆÙ‡'].astype(str).str.strip()
        # Convert area if it exists
        if 'Ù…Ø³Ø§Ø­Øª' in df.columns:
            df['Ù…Ø³Ø§Ø­Øª'] = pd.to_numeric(df['Ù…Ø³Ø§Ø­Øª'], errors='coerce')

        st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {len(df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² GeoJSON Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return df
    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{geojson_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ GeoJSON Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        st.stop()
    except json.JSONDecodeError as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ GeoJSON (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ ÙØ±Ù…Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±): {e}")
        st.stop()
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ GeoJSON: {e}")
        st.error(traceback.format_exc())
        st.stop()


# --- Load Analysis Data ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª...")
def load_analysis_data(csv_path='Ù…Ø­Ø§Ø³Ø¨Ø§Øª 2.csv'):
    """Loads and preprocesses data from the analysis CSV file."""
    try:
        # Read the raw lines to identify sections
        with open(csv_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # Find the headers and split points - Robust approach looking for keywords
        header1_indices = [i for i, line in enumerate(lines) if 'Ø§Ø¯Ø§Ø±Ù‡' in line and 'Ø³Ù†' in line and ('Ù…Ø³Ø§Ø­Øª' in line or 'area' in line.lower() or line.strip().startswith('Ø§Ø¯Ø§Ø±Ù‡,Ø³Ù†,'))] # More flexible header finding
        header2_indices = [i for i, line in enumerate(lines) if ('ØªÙˆÙ„ÛŒØ¯' in line or 'production' in line.lower()) and 'Ø³Ù†' in line and line.strip().startswith('ØªÙˆÙ„ÛŒØ¯,Ø³Ù†,')] # More specific for production

        if not header1_indices:
             st.error(f"âŒ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„ '{csv_path}' Ù‚Ø§Ø¨Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ³Øª. Ù‡Ø¯Ø± Ø¨Ø®Ø´ 'Ù…Ø³Ø§Ø­Øª' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
             st.stop()

        header1_idx = header1_indices[0]

        # Try to find the second header *after* the first one
        header2_idx = None
        potential_header2 = [i for i, line in enumerate(lines) if ('ØªÙˆÙ„ÛŒØ¯' in line or 'production' in line.lower()) and 'Ø³Ù†' in line and i > header1_idx]
        if potential_header2:
             header2_idx = potential_header2[0]

        section1_start = header1_idx + 1
        section2_start = header2_idx + 1 if header2_idx else None
        section1_end_guess = (header2_idx -1) if header2_idx else len(lines) # Read until next header or end

        # Find likely end of first section (e.g., line starting with 'Total' or 'Grand Total' before next header)
        for i in range(section1_start, section1_end_guess):
            if lines[i].strip().lower().startswith('total') or lines[i].strip().lower().startswith('grand total'):
                section1_end_guess = i
                break


        # Read the first section (Area)
        df_area = pd.read_csv(csv_path, skiprows=header1_idx, nrows=(section1_end_guess - header1_idx), encoding='utf-8')
        # The actual 'Ø§Ø¯Ø§Ø±Ù‡' column might be the first unnamed one or named 'Ø§Ø¯Ø§Ø±Ù‡'
        if df_area.columns[0].strip().lower() in ['Ø§Ø¯Ø§Ø±Ù‡','area']:
            df_area.rename(columns={df_area.columns[0]: 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)
        elif 'Ø§Ø¯Ø§Ø±Ù‡' not in df_area.columns and 'Unnamed: 0' in df_area.columns:
             df_area.rename(columns={'Unnamed: 0': 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)


        # Read the second section (Production) if found
        df_prod = None
        if section2_start:
            end_row_prod = None
            for i in range(section2_start, len(lines)):
                if lines[i].strip().lower().startswith("grand total"):
                    end_row_prod = i
                    break
            nrows_prod = (end_row_prod - section2_start) if end_row_prod else None # Read up to Grand Total

            df_prod = pd.read_csv(csv_path, skiprows=header2_idx, nrows=nrows_prod, encoding='utf-8') # Read including header
            # Rename production section's first column
            if df_prod.columns[0].strip().lower() in ['ØªÙˆÙ„ÛŒØ¯','production']:
                 df_prod.rename(columns={df_prod.columns[0]: 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)
            elif 'Ø§Ø¯Ø§Ø±Ù‡' not in df_prod.columns and 'Unnamed: 0' in df_prod.columns:
                 df_prod.rename(columns={'Unnamed: 0': 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)


        # --- Preprocessing Function ---
        def preprocess_df(df, section_name):
            if df is None:
                return None
            # Ensure 'Ø§Ø¯Ø§Ø±Ù‡' is the first column if it got misplaced
            if 'Ø§Ø¯Ø§Ø±Ù‡' not in df.columns and len(df.columns) > 0 and 'Unnamed: 0' in df.columns:
                 df.rename(columns={'Unnamed: 0': 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)
            elif 'Ø§Ø¯Ø§Ø±Ù‡' not in df.columns and len(df.columns) > 0 : # If first col is something else, assume it's Ø§Ø¯Ø§Ø±Ù‡
                 df.rename(columns={df.columns[0]: 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)

            # Check for required columns
            if not all(col in df.columns for col in ['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†']):
                 st.warning(f"âš ï¸ Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ 'Ø§Ø¯Ø§Ø±Ù‡' ÛŒØ§ 'Ø³Ù†' Ø¯Ø± Ø¨Ø®Ø´ '{section_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {list(df.columns)}")
                 return None

            # Forward fill 'Ø§Ø¯Ø§Ø±Ù‡' if it has NaNs (common in pivoted tables)
            if df['Ø§Ø¯Ø§Ø±Ù‡'].isnull().any():
                df['Ø§Ø¯Ø§Ø±Ù‡'] = df['Ø§Ø¯Ø§Ø±Ù‡'].ffill()

            # Filter out 'total' and 'Grand Total' rows in 'Ø³Ù†' and 'Ø§Ø¯Ø§Ø±Ù‡'
            df = df[~df['Ø³Ù†'].astype(str).str.contains('total', case=False, na=False)]
            df = df[~df['Ø§Ø¯Ø§Ø±Ù‡'].astype(str).str.contains('total|Ø¯Ù‡Ø®Ø¯Ø§', case=False, na=False)] # Filter Grand Total/summary rows in Ø§Ø¯Ø§Ø±Ù‡

            # Remove rows where 'Ø§Ø¯Ø§Ø±Ù‡' is NaN after ffill (usually header artifacts)
            df = df.dropna(subset=['Ø§Ø¯Ø§Ø±Ù‡'])

            # Convert 'Ø§Ø¯Ø§Ø±Ù‡' to integer where possible, handling potential non-numeric entries
            df['Ø§Ø¯Ø§Ø±Ù‡'] = pd.to_numeric(df['Ø§Ø¯Ø§Ø±Ù‡'], errors='coerce')
            df = df.dropna(subset=['Ø§Ø¯Ø§Ø±Ù‡']) # Drop if conversion failed
            df['Ø§Ø¯Ø§Ø±Ù‡'] = df['Ø§Ø¯Ø§Ø±Ù‡'].astype(int)

            # Convert numeric columns, coerce errors to NaN
            value_cols = [col for col in df.columns if col not in ['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†', 'Ø¯Ø±ØµØ¯', 'Grand Total']]
            for col in value_cols:
                # Attempt to clean strings (remove commas) before converting
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.replace(',', '', regex=False)
                df[col] = pd.to_numeric(df[col], errors='coerce')

            # Drop Grand Total and Ø¯Ø±ØµØ¯ columns if they exist
            df = df.drop(columns=['Grand Total', 'Ø¯Ø±ØµØ¯'], errors='ignore')

            # Remove rows where 'Ø³Ù†' is NaN
            df = df.dropna(subset=['Ø³Ù†'])

            # Set multi-index for easier access
            try:
                df = df.set_index(['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†'])
            except KeyError:
                 st.warning(f"âš ï¸ Ø§Ù…Ú©Ø§Ù† ØªÙ†Ø¸ÛŒÙ… Ø§ÛŒÙ†Ø¯Ú©Ø³ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡ Ø¯Ø± Ø¨Ø®Ø´ '{section_name}' ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ ÛŒØ§ Ø³Ù† ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù†Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ù‡Ø³ØªÙ†Ø¯).")
                 return None # Cannot proceed without index

            # Drop columns that are all NaN (often artifacts of parsing)
            df = df.dropna(axis=1, how='all')

            return df

        df_area_processed = preprocess_df(df_area, "Ù…Ø³Ø§Ø­Øª")
        df_prod_processed = preprocess_df(df_prod, "ØªÙˆÙ„ÛŒØ¯")


        st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯.")
        return df_area_processed, df_prod_processed

    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ CSV Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        return None, None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª CSV: {e}")
        st.error(traceback.format_exc()) # Print detailed error
        return None, None

# --- HTML Helper Functions ---

# --- Modern Progress Bar (HTML) --- Moved Definition Higher ---
def modern_progress_bar(progress: float) -> str:
    """
    Returns a modern styled HTML progress bar for Streamlit.
    :param progress: float between 0 and 1
    :return: HTML string
    """
    percent = int(progress * 100)
    # Dynamic color based on progress completion
    bar_color = '#185a9d' if percent >= 99 else '#43cea2' # Dark blue when near/at 100%
    bg_color = '#e0f7fa' # Light background

    # Unique ID for progress bar elements to avoid style conflicts if multiple exist
    import uuid
    bar_id = f"progress-bar-{uuid.uuid4()}"

    # Improved styling for better visibility and centering
    return f'''
    <div id="{bar_id}" style="position: relative; width: 100%; background: {bg_color}; border-radius: 12px; height: 22px; margin: 8px 0; box-shadow: inset 0 1px 3px rgba(0,0,0,0.1);">
      <div style="width: {percent}%; background: linear-gradient(90deg, {bar_color} 0%, #185a9d 100%); height: 100%; border-radius: 12px; transition: width 0.4s ease-in-out;"></div>
      <span style="position: absolute; width: 100%; top: 0; left: 0; text-align: center; color: #000; font-weight: bold; line-height: 22px; font-size: 0.85em;">{percent}%</span>
    </div>
    '''


# --- Modern Metric Card (HTML) --- Added Definition ---
def modern_metric_card(label, value, icon="fa-info-circle", color="#43cea2"):
    """Generates HTML for a modern metric card."""
    return f"""
    <div class="modern-card" style="background: linear-gradient(135deg, {color} 0%, #185a9d 100%);">
        <i class="fas {icon}" style="font-size: 1.8em; margin-bottom: 10px;"></i>
        <h5 style="color: white; margin-bottom: 5px;">{label}</h5>
        <h3 style="color: white; margin: 0;">{value}</h3>
    </div>
    """

# --- Status Badge (HTML) --- Added Definition ---
def status_badge(status_text):
    """Generates an HTML badge based on status text."""
    status_text_lower = status_text.lower()
    if "Ø¨Ù‡Ø¨ÙˆØ¯" in status_text_lower or "Ù…Ø«Ø¨Øª" in status_text_lower:
        css_class = "status-positive"
    elif "ØªÙ†Ø´" in status_text_lower or "Ú©Ø§Ù‡Ø´" in status_text_lower or "Ø¨Ø¯ØªØ±" in status_text_lower:
        css_class = "status-negative"
    elif "Ø«Ø§Ø¨Øª" in status_text_lower:
        css_class = "status-neutral"
    elif "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" in status_text_lower or "n/a" in status_text_lower:
         css_class = "status-nodata"
    else:
        css_class = "status-unknown"
    return f'<span class="status-badge {css_class}">{status_text}</span>'


# Initialize GEE and Load Data
if initialize_gee():
    # --- Use GeoJSON for farm data ---
    FARM_GEOJSON_PATH = 'farm_geodata_fixed.geojson'
    farm_data_df = load_farm_data_from_geojson(FARM_GEOJSON_PATH)

# Load Analysis Data only if the file exists
ANALYSIS_CSV_PATH = 'Ù…Ø­Ø§Ø³Ø¨Ø§Øª 2.csv'
analysis_area_df, analysis_prod_df = None, None
if os.path.exists(ANALYSIS_CSV_PATH):
    analysis_area_df, analysis_prod_df = load_analysis_data(ANALYSIS_CSV_PATH)
else:
    st.sidebar.warning(f"ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ '{ANALYSIS_CSV_PATH}' ÛŒØ§ÙØª Ù†Ø´Ø¯. ØªØ¨ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")


# ==============================================================================
# Sidebar Filters
# ==============================================================================
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

if 'farm_data_df' in locals() and not farm_data_df.empty: # Check if farm data loaded successfully

    # --- Day of the Week Selection ---
    available_days = sorted(farm_data_df['Ø±ÙˆØ²'].unique())
    selected_day = st.sidebar.selectbox(
        "ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        options=available_days,
        index=0, # Default to the first day
        help="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø±ÙˆØ² ÙÛŒÙ„ØªØ± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯."
    )

    # --- Filter Data Based on Selected Day ---
    filtered_farms_df = farm_data_df[farm_data_df['Ø±ÙˆØ²'] == selected_day].copy()

    if filtered_farms_df.empty:
        st.warning(f"âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()

    # --- Farm Selection ---
    available_farms = sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique())
    # Add an option for "All Farms"
    farm_options = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + available_farms
    selected_farm_name = st.sidebar.selectbox(
        "ğŸŒ¾ Ù…Ø²Ø±Ø¹Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        options=farm_options,
        index=0, # Default to "All Farms"
        help="Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¢Ù† Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯ ÛŒØ§ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ."
    )

    # --- Index Selection ---
    index_options = {
        "NDVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªÙØ§Ø¶Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡",
        "EVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡",
        "NDMI": "Ø´Ø§Ø®Øµ Ø±Ø·ÙˆØ¨Øª ØªÙØ§Ø¶Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡ (ÙˆØ¶Ø¹ÛŒØª Ø¢Ø¨ÛŒ)",
        "SAVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªØ¹Ø¯ÛŒÙ„ Ø´Ø¯Ù‡ Ø®Ø§Ú©",
        "LAI": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
        "MSI": "Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ",
        "CVI": "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
        # Add more indices if needed and implemented
        # "Biomass": "Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
        # "ET": "ØªØ¨Ø®ÛŒØ± Ùˆ ØªØ¹Ø±Ù‚ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
    }
    selected_index = st.sidebar.selectbox(
        "ğŸ“ˆ Ø´Ø§Ø®Øµ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡:",
        options=list(index_options.keys()),
        format_func=lambda x: f"{x} ({index_options[x]})",
        index=0 # Default to NDVI
    )

    # --- Date Range Calculation ---
    today = datetime.date.today()
    # Find the most recent date corresponding to the selected day of the week
    # Map Persian day names to Python's weekday() (Monday=0, Sunday=6) - Adjust if needed
    persian_to_weekday = {
        "Ø´Ù†Ø¨Ù‡": 5,
        "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6,
        "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0,
        "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1, # Handle potential space variations (normalized in loading)
        "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2,
        "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3,
        "Ø¬Ù…Ø¹Ù‡": 4,
    }
    try:
        target_weekday = persian_to_weekday[selected_day]
        days_ago = (today.weekday() - target_weekday + 7) % 7
        if days_ago == 0: # If today is the selected day, use today
             end_date_current = today
        else:
             end_date_current = today - datetime.timedelta(days=days_ago)

        start_date_current = end_date_current - datetime.timedelta(days=6)
        end_date_previous = start_date_current - datetime.timedelta(days=1)
        start_date_previous = end_date_previous - datetime.timedelta(days=6)

        # Convert to strings for GEE
        start_date_current_str = start_date_current.strftime('%Y-%m-%d')
        end_date_current_str = end_date_current.strftime('%Y-%m-%d')
        start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
        end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')

        st.sidebar.info(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÙØ¹Ù„ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
        st.sidebar.info(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")

    except KeyError:
        st.sidebar.error(f"Ù†Ø§Ù… Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ù‚Ø§Ø¨Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ³Øª.")
        st.stop()
    except Exception as e:
        st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}")
        st.stop()

else: # If farm data loading failed
    st.error("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ GeoJSON Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    st.stop() # Stop execution if no farm data


# ==============================================================================
# Google Earth Engine Functions
# ==============================================================================

# --- Cloud Masking Function for Sentinel-2 ---
def maskS2clouds(image):
    """Masks clouds in a Sentinel-2 SR image using QA band and SCL band."""
    qa = image.select('QA60')
    # Bits 10 and 11 are clouds and cirrus, respectively.
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    # Both flags should be set to zero, indicating clear conditions.
    clear_mask_qa = qa.bitwiseAnd(cloudBitMask).eq(0).And(
                   qa.bitwiseAnd(cirrusBitMask).eq(0))

    # Use SCL band for more robust cloud/shadow masking
    scl = image.select('SCL')
    # Keep 'Vegetation'(4), 'Not Vegetated'(5), 'Water'(6), 'Bare Soil'(11)
    # Mask out: 'Saturated/Defective'(1), 'Dark Area Pixels'(2), 'Cloud Shadows'(3),
    # 'Cloud Medium Probability'(8), 'Cloud High Probability'(9), 'Cirrus'(10), 'Snow/Ice'(7 - optional)
    # We choose to keep 7 (Snow/Ice) for broader applicability, mask if needed
    good_quality_scl = scl.remap([4, 5, 6, 11], [1, 1, 1, 1], 0) # Map good classes to 1, others to 0

    # Combine masks and apply scaling/offset
    combined_mask = clear_mask_qa.And(good_quality_scl)

    # Scale optical bands
    opticalBands = image.select('B.*').multiply(0.0001)

    # Return image with scaled bands and applied mask
    return image.addBands(opticalBands, None, True)\
                .updateMask(combined_mask)


# --- Index Calculation Functions ---
def add_indices(image):
    """Calculates and adds various indices as bands to an image."""
    # NDVI: (NIR - Red) / (NIR + Red) | Sentinel-2: (B8 - B4) / (B8 + B4)
    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')

    # EVI: 2.5 * (NIR - Red) / (NIR + 6 * Red - 7.5 * Blue + 1) | S2: 2.5 * (B8 - B4) / (B8 + 6 * B4 - 7.5 * B2 + 1)
    evi = image.expression(
        '2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1)', {
            'NIR': image.select('B8'),
            'RED': image.select('B4'),
            'BLUE': image.select('B2')
        }).rename('EVI')

    # NDMI (Normalized Difference Moisture Index): (NIR - SWIR1) / (NIR + SWIR1) | S2: (B8 - B11) / (B8 + B11)
    ndmi = image.normalizedDifference(['B8', 'B11']).rename('NDMI')

    # SAVI (Soil-Adjusted Vegetation Index): ((NIR - Red) / (NIR + Red + L)) * (1 + L) | L=0.5
    # S2: ((B8 - B4) / (B8 + B4 + 0.5)) * 1.5
    savi = image.expression(
        '((NIR - RED) / (NIR + RED + L)) * (1 + L)',
        {
            'NIR': image.select('B8'),
            'RED': image.select('B4'),
            'L': 0.5
        }
    ).rename('SAVI')

    # MSI (Moisture Stress Index): SWIR1 / NIR | S2: B11 / B8
    # Add small epsilon to NIR denominator to avoid division by zero potential
    msi = image.expression('SWIR1 / (NIR + 0.0001)', {
        'SWIR1': image.select('B11'),
        'NIR': image.select('B8')
    }).rename('MSI')

    # LAI (Leaf Area Index) - Simple estimation using NDVI (Needs calibration for accuracy)
    # Using a very basic placeholder - Requires proper calibration for reliable values
    lai = ndvi.multiply(3.5).max(0).rename('LAI') # Ensure non-negative

    # CVI (Chlorophyll Vegetation Index) - (NIR / Green) * (Red / Green) | S2: (B8 / B3) * (B4 / B3)
    # Handle potential division by zero if Green band is 0
    green_safe = image.select('B3').max(ee.Image(0.0001)) # Avoid division by zero
    cvi = image.expression('(NIR / GREEN_SAFE) * (RED / GREEN_SAFE)', {
        'NIR': image.select('B8'),
        'GREEN_SAFE': green_safe,
        'RED': image.select('B4')
    }).rename('CVI')

    return image.addBands([ndvi, evi, ndmi, msi, lai, cvi, savi]) # Add calculated indices, including SAVI

# --- Function to get processed image for a date range and geometry ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ...", persist=True)
def get_processed_image(_geometry, start_date, end_date, index_name):
    """
    Gets cloud-masked, index-calculated Sentinel-2 median composite for a given geometry and date range.
    _geometry: ee.Geometry (Point or Polygon)
    start_date, end_date: YYYY-MM-DD strings
    index_name: Name of the primary index band to return (e.g., 'NDVI')
    """
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_geometry)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds)) # Apply cloud masking

        # Check if any images are available after filtering and masking
        count = s2_sr_col.size().getInfo()
        if count == 0:
            return None, f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± Sentinel-2 Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø± Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start_date} ØªØ§ {end_date} Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯."

        # Calculate indices for each image in the collection
        indexed_col = s2_sr_col.map(add_indices)

        # Create a median composite image
        median_image = indexed_col.median() # Use median to reduce noise/outliers

        # Select the desired index band(s) - select all calculated indices initially
        output_image = median_image.select(index_name) # Select the specific index needed

        return output_image, None # Return the image and no error message
    except ee.EEException as e:
        # Handle GEE specific errors
        error_message = f"Ø®Ø·Ø§ÛŒ Google Earth Engine Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start_date}-{end_date}: {e}"
        # Try to extract more details if available
        try:
            error_details = e.args[0] if e.args else str(e)
            if isinstance(error_details, str):
                if 'computation timed out' in error_details.lower():
                     error_message += "\n(Ø¹Ù„Øª Ø§Ø­ØªÙ…Ø§Ù„ÛŒ: Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ)"
                elif 'user memory limit exceeded' in error_details.lower():
                     error_message += "\n(Ø¹Ù„Øª Ø§Ø­ØªÙ…Ø§Ù„ÛŒ: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø²Ø±Ú¯ ÛŒØ§ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡)"
                elif 'image.select' in error_details.lower() and 'band' in error_details.lower():
                     error_message += f"\n(Ø¹Ù„Øª Ø§Ø­ØªÙ…Ø§Ù„ÛŒ: Ø¨Ø§Ù†Ø¯ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² '{index_name}' Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± ØªØµØ§ÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª)"
        except Exception:
            pass # Ignore errors during error detail extraction
        return None, error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ GEE ({start_date}-{end_date}): {e}\n{traceback.format_exc()}"
        return None, error_message

# --- Function to get time series data for a point ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ...", persist=True)
def get_index_time_series(_point_geom, index_name, start_date='2023-01-01', end_date=today.strftime('%Y-%m-%d')):
    """Gets a time series of a specified index for a point geometry."""
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_point_geom)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds)
                     .map(add_indices)
                     .select(index_name)) # Select the index early

        def extract_value(image):
            # Extract the index value at the point
            # Use reduceRegion for points; scale should match sensor resolution
            value = image.reduceRegion(
                reducer=ee.Reducer.firstNonNull(), # Use first valid pixel at the point
                geometry=_point_geom,
                scale=10 # Scale in meters (10m for Sentinel-2 RGB/NIR/SWIR)
            ).get(index_name)
            # Return a feature with the value and the image date, only if value is not null
            return ee.Feature(None, {
                'date': image.date().format('YYYY-MM-dd'),
                index_name: value
            }).set('hasValue', value) # Set a property to filter by later

        # Map over the collection and remove features with null values
        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.neq('hasValue', None))

        # Convert the FeatureCollection to a list of dictionaries
        ts_info = ts_features.getInfo()['features']

        if not ts_info:
            return pd.DataFrame(columns=['date', index_name]), f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name} Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start_date}-{end_date} ÛŒØ§ÙØª Ù†Ø´Ø¯."

        # Convert to Pandas DataFrame
        ts_data = [{'date': f['properties']['date'], index_name: f['properties'][index_name]} for f in ts_info]
        ts_df = pd.DataFrame(ts_data)
        ts_df['date'] = pd.to_datetime(ts_df['date'])
        # Handle potential duplicates on the same date (take the mean or last)
        ts_df = ts_df.groupby('date').mean().reset_index()
        ts_df = ts_df.sort_values('date').set_index('date')

        return ts_df, None # Return DataFrame and no error
    except ee.EEException as e:
        error_message = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name}: {e}"
        return pd.DataFrame(columns=['date', index_name]), error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name}: {e}\n{traceback.format_exc()}"
        return pd.DataFrame(columns=['date', index_name]), error_message


# ==============================================================================
# Function to get all relevant indices for a farm point for two periods
# ==============================================================================
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ...", persist=True)
def get_farm_needs_data(_point_geom, start_curr, end_curr, start_prev, end_prev):
    """Calculates mean NDVI, NDMI, EVI, SAVI for current and previous periods."""
    results = {
        'NDVI_curr': None, 'NDMI_curr': None, 'EVI_curr': None, 'SAVI_curr': None,
        'NDVI_prev': None, 'NDMI_prev': None, 'EVI_prev': None, 'SAVI_prev': None,
        'error': None
    }
    indices_to_get = ['NDVI', 'NDMI', 'EVI', 'SAVI']

    def get_mean_values_for_period(start, end):
        period_values = {index: None for index in indices_to_get}
        error_msg = None
        try:
            # Get median composite image with all indices calculated
            s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                         .filterBounds(_point_geom)
                         .filterDate(start, end)
                         .map(maskS2clouds)
                         .map(add_indices))

            count = s2_sr_col.size().getInfo()
            if count == 0:
                return period_values, f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end} ÛŒØ§ÙØª Ù†Ø´Ø¯"

            # Calculate median composite from the indexed collection
            median_image = s2_sr_col.median() # Calculate median *after* adding indices

            # Reduce region to get the mean value at the point for all indices
            mean_dict = median_image.select(indices_to_get).reduceRegion(
                reducer=ee.Reducer.mean(), # Use mean for the period/point
                geometry=_point_geom,
                scale=10,  # Scale in meters
                maxPixels=1e9 # Allow potentially large computations if needed
            ).getInfo()

            if mean_dict:
                for index in indices_to_get:
                    period_values[index] = mean_dict.get(index) # Get value, defaults to None if key missing
            else:
                 # If reduceRegion returns empty or None
                 return period_values, f"Ù…Ù‚Ø¯Ø§Ø± Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end} Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¯Ø§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´)"

            return period_values, None # Success
        except ee.EEException as e:
            error_msg = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· ({start}-{end}): {e}"
            return period_values, error_msg
        except Exception as e:
            error_msg = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· ({start}-{end}): {e}"
            return period_values, error_msg

    # Get data for current period
    curr_values, err_curr = get_mean_values_for_period(start_curr, end_curr)
    if err_curr:
        results['error'] = err_curr
    else:
        results['NDVI_curr'] = curr_values['NDVI']
        results['NDMI_curr'] = curr_values['NDMI']
        results['EVI_curr'] = curr_values['EVI']
        results['SAVI_curr'] = curr_values['SAVI']

    # Get data for previous period
    prev_values, err_prev = get_mean_values_for_period(start_prev, end_prev)
    if err_prev:
        # Append previous period error if a current error already exists
        current_error = results.get('error')
        results['error'] = f"{current_error} | {err_prev}" if current_error else err_prev
    else:
        results['NDVI_prev'] = prev_values['NDVI']
        results['NDMI_prev'] = prev_values['NDMI']
        results['EVI_prev'] = prev_values['EVI']
        results['SAVI_prev'] = prev_values['SAVI']

    return results

# ==============================================================================
# Gemini AI Helper Functions
# ==============================================================================

# Configure Gemini API
@st.cache_resource
def configure_gemini():
    """Configures the Gemini API client using a hardcoded API key (NOT RECOMMENDED)."""
    try:
        # --- WARNING: Hardcoding API keys is insecure! Use Streamlit secrets instead. ---
        # Replace with st.secrets["GEMINI_API_KEY"] if using secrets.toml
        api_key = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ" # <-- HARDCODED API KEY
        # ---------------------------------------------------------------------------

        if not api_key:
             st.error("âŒ Ú©Ù„ÛŒØ¯ API Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø± Ú©Ø¯ ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
             return None

        genai.configure(api_key=api_key)
        # Optional: Add safety settings configuration here if needed
        # safety_settings = [...]
        # model = genai.GenerativeModel('gemini-pro', safety_settings=safety_settings)
        model = genai.GenerativeModel('gemini-1.5-flash') # Use the latest flash model
        print("Gemini Configured Successfully (using hardcoded key).")
        return model
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… Gemini API: {e}")
        return None

# Function to get AI analysis
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...", persist=True)
def get_ai_analysis(_model, farm_name, index_data, recommendations):
    """Generates AI analysis for the farm's condition."""
    if _model is None:
        return "Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    # Prepare data string, handling None values gracefully
    def format_value(val):
        return f"{val:.3f}" if val is not None else "N/A"

    data_str = ""
    data_str += f"NDVI ÙØ¹Ù„ÛŒ: {format_value(index_data.get('NDVI_curr'))} (Ù‚Ø¨Ù„ÛŒ: {format_value(index_data.get('NDVI_prev'))})\n"
    data_str += f"NDMI ÙØ¹Ù„ÛŒ: {format_value(index_data.get('NDMI_curr'))} (Ù‚Ø¨Ù„ÛŒ: {format_value(index_data.get('NDMI_prev'))})\n"
    data_str += f"EVI ÙØ¹Ù„ÛŒ: {format_value(index_data.get('EVI_curr'))} (Ù‚Ø¨Ù„ÛŒ: {format_value(index_data.get('EVI_prev'))})\n"
    data_str += f"SAVI ÙØ¹Ù„ÛŒ: {format_value(index_data.get('SAVI_curr'))} (Ù‚Ø¨Ù„ÛŒ: {format_value(index_data.get('SAVI_prev'))})\n"


    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ù†ÛŒØ´Ú©Ø± Ù‡Ø³ØªÛŒØ¯. Ù„Ø·ÙØ§Ù‹ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}' Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø²ÛŒØ± Ø¨Ù‡ Ø·ÙˆØ± Ø®Ù„Ø§ØµÙ‡ (Ø­Ø¯ÙˆØ¯ 3-5 Ø¬Ù…Ù„Ù‡) Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯. ØªÙ…Ø±Ú©Ø² Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ù†ÛŒØ§Ø² Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ Ø¨Ø§Ø´Ø¯ Ùˆ ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯ Ú†Ø±Ø§ Ø§ÛŒÙ† Ù†ÛŒØ§Ø²Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ù…Ø·Ø±Ø­ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.

    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ:
    {data_str}
    ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡:
    {', '.join(recommendations) if recommendations else 'Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡â€Œ Ø§ÙˆÙ„ÛŒÙ‡â€ŒØ§ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.'}

    ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ (Ú©ÙˆØªØ§Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ):
    """

    try:
        # Use specific generation config if needed (e.g., temperature)
        # generation_config = genai.types.GenerationConfig(temperature=0.7)
        response = _model.generate_content(prompt) #, generation_config=generation_config)

        # Accessing response text might differ slightly based on exact library version
        # Check response object structure if needed (e.g., response.candidates[0].content.parts[0].text)
        if response.parts:
             return response.parts[0].text
        else:
             # Fallback for older versions or different structures
             return response.text # Assuming response.text works

    except Exception as e:
        st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API: {e}")
        # Provide more detail if possible from the exception
        return f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ: {str(e)}"



# ==============================================================================
# Main Application Layout (Using Tabs)
# ==============================================================================

# Configure Gemini Model at the start
gemini_model = configure_gemini()

# Define Tabs - **Corrected to include tab2**
tab_titles = ["ğŸ“Š Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹"]
if analysis_area_df is not None or analysis_prod_df is not None:
    tab_titles.append("ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª") # Add analysis tab only if data loaded
else:
     tab_titles.append("ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª (ØºÛŒØ±ÙØ¹Ø§Ù„)") # Indicate disabled tab

tab_titles.append("ğŸ’§Ú©ÙˆØ¯ Ùˆ Ø¢Ø¨ÛŒØ§Ø±ÛŒ")

tabs = st.tabs(tab_titles)
tab1 = tabs[0]
tab2_idx = -1
if "ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª" in tab_titles:
    tab2_idx = tab_titles.index("ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª")
    tab2 = tabs[tab2_idx]
tab3 = tabs[-1] # Needs analysis is always the last tab


with tab1:
    # ==============================================================================
    # Main Panel Display (Monitoring)
    # ==============================================================================

    # --- Get Selected Farm Geometry and Details ---
    selected_farm_details = None
    selected_farm_geom = None
    map_center_lat = INITIAL_LAT
    map_center_lon = INITIAL_LON
    initial_zoom = INITIAL_ZOOM


    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        # Use the bounding box of all filtered farms for the map view
        if not filtered_farms_df.empty:
            min_lon, min_lat = filtered_farms_df['centroid_lon'].min(), filtered_farms_df['centroid_lat'].min()
            max_lon, max_lat = filtered_farms_df['centroid_lon'].max(), filtered_farms_df['centroid_lat'].max()
            # Create a bounding box geometry
            # Add a small buffer to ensure visibility if points are collinear
            buffer = 0.001
            selected_farm_geom = ee.Geometry.Rectangle([min_lon - buffer, min_lat - buffer, max_lon + buffer, max_lat + buffer])
            map_center_lat = (min_lat + max_lat) / 2
            map_center_lon = (min_lon + max_lon) / 2
            # Adjust zoom based on extent? (Optional - geemap often handles this)
            initial_zoom = 11 # Reset zoom for overview

            st.subheader(f"Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ²: {selected_day}")
            st.info(f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ²: {len(filtered_farms_df)}")
        else:
             st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ² ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
             # Optionally set a default geometry or stop
             selected_farm_geom = ee.Geometry.Point([INITIAL_LON, INITIAL_LAT]) # Default point

    else:
        selected_farm_details = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
        lat = selected_farm_details['centroid_lat']
        lon = selected_farm_details['centroid_lon']
        # Create geometry based on farm data (Point or Polygon centroid)
        selected_farm_geom = ee.Geometry.Point([lon, lat]) # Use centroid for map focus/calculations
        map_center_lat = lat
        map_center_lon = lon
        initial_zoom = 14 # Zoom closer for single farm


        st.subheader(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name} (Ø±ÙˆØ²: {selected_day})")
        # Display farm details using modern cards
        details_cols = st.columns([1, 1, 1, 1]) # Adjust column ratios if needed
        with details_cols[0]:
            area_val = selected_farm_details.get('Ù…Ø³Ø§Ø­Øª', 'N/A')
            area_display = f"{area_val:,.2f}" if pd.notna(area_val) and isinstance(area_val, (int, float)) else "N/A"
            st.markdown(modern_metric_card("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", area_display, icon="fa-ruler-combined"), unsafe_allow_html=True)
        with details_cols[1]:
            st.markdown(modern_metric_card("ÙˆØ§Ø±ÛŒØªÙ‡", f"{selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}", icon="fa-seedling"), unsafe_allow_html=True)
        with details_cols[2]:
            st.markdown(modern_metric_card("Ú¯Ø±ÙˆÙ‡", f"{selected_farm_details.get('Ú¯Ø±ÙˆÙ‡', 'N/A')}", icon="fa-users"), unsafe_allow_html=True)
        with details_cols[3]:
            st.markdown(modern_metric_card("Ø³Ù†", f"{selected_farm_details.get('Ø³Ù†', 'N/A')}", icon="fa-hourglass-half"), unsafe_allow_html=True)

        # Display coordinates separately or within a card
        # st.markdown(modern_metric_card("Ù…Ø®ØªØµØ§Øª", f"{lat:.5f}, {lon:.5f}", icon="fa-map-marker-alt"), unsafe_allow_html=True)

        st.write(f"**Ù…Ø®ØªØµØ§Øª (Ù…Ø±Ú©Ø²ÛŒ):** {lat:.5f}, {lon:.5f}")


    # --- Variety Distribution Chart (if multiple farms selected or showing all) ---
    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" and not filtered_farms_df.empty:
        st.markdown("---")
        st.subheader("ØªÙˆØ²ÛŒØ¹ ÙˆØ§Ø±ÛŒØªÙ‡â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø²Ø§Ø±Ø¹ Ø§ÛŒÙ† Ø±ÙˆØ²")
        if 'ÙˆØ§Ø±ÛŒØªÙ‡' in filtered_farms_df.columns:
            variety_counts = filtered_farms_df['ÙˆØ§Ø±ÛŒØªÙ‡'].value_counts().sort_values(ascending=False)
            if not variety_counts.empty:
                variety_percent = 100 * variety_counts / variety_counts.sum()
                # Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±
                pie_df = pd.DataFrame({
                    'ÙˆØ§Ø±ÛŒØªÙ‡': variety_percent.index,
                    'Ø¯Ø±ØµØ¯': variety_percent.values
                })
                # Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ (Pie Chart)
                fig_pie = px.pie(
                    pie_df,
                    names='ÙˆØ§Ø±ÛŒØªÙ‡',
                    values='Ø¯Ø±ØµØ¯',
                    title="Ø¯Ø±ØµØ¯ Ù‡Ø± ÙˆØ§Ø±ÛŒØªÙ‡ Ø¯Ø± Ù…Ø²Ø§Ø±Ø¹ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡",
                    hole=0.3,
                    color_discrete_sequence=px.colors.qualitative.Pastel
                )
                fig_pie.update_traces(textposition='inside', textinfo='percent+label', pull=[0.05]*len(pie_df))
                fig_pie.update_layout(
                    showlegend=True,
                    height=400,
                    margin=dict(l=20, r=20, t=60, b=20),
                    paper_bgcolor='rgba(0,0,0,0)',
                    plot_bgcolor='rgba(0,0,0,0)'
                )
                st.plotly_chart(fig_pie, use_container_width=True)
                # st.caption("Ø¯Ø±ØµØ¯ Ù‡Ø± ÙˆØ§Ø±ÛŒØªÙ‡ Ø§Ø² Ú©Ù„ Ù…Ø²Ø§Ø±Ø¹ Ø«Ø¨Øª Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ².")
            else:
                st.info("Ø¯Ø§Ø¯Ù‡ ÙˆØ§Ø±ÛŒØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø§ÛŒÙ† Ø±ÙˆØ² Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
        else:
            st.info("Ø³ØªÙˆÙ† 'ÙˆØ§Ø±ÛŒØªÙ‡' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ† Ø±ÙˆØ² ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")


    # --- Map Display ---
    st.markdown("---")
    st.subheader(" Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")

    # Define visualization parameters based on the selected index
    vis_params = {
        'NDVI': {'min': 0.0, 'max': 0.9, 'palette': ['#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901', '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01', '#012E01', '#011D01', '#011301']}, # Standard NDVI color ramp
        'EVI': {'min': 0.0, 'max': 0.9, 'palette': ['#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901', '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01', '#012E01', '#011D01', '#011301']}, # Similar to NDVI
        'NDMI': {'min': -0.5, 'max': 0.8, 'palette': ['#b2182b', '#d6604d', '#f4a582', '#fddbc7', '#f7f7f7', '#d1e5f0', '#92c5de', '#4393c3', '#2166ac']}, # Diverging red-blue for moisture
        'SAVI': {'min': 0.0, 'max': 0.9, 'palette': ['#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901', '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01', '#012E01', '#011D01', '#011301']}, # Similar to NDVI
        'LAI': {'min': 0, 'max': 7, 'palette': ['#EFEFEF', '#FFFFE5', '#FFF7BC', '#FEE391', '#FEC44F', '#FE9929', '#EC7014', '#CC4C02', '#993404', '#662506']}, # Sequential yellow-brown for LAI
        'MSI': {'min': 0, 'max': 3, 'palette': ['#2166ac', '#4393c3', '#92c5de', '#d1e5f0', '#f7f7f7', '#fddbc7', '#f4a582', '#d6604d', '#b2182b'][::-1]}, # Reversed NDMI palette: high MSI (dry) is red
        'CVI': {'min': 0, 'max': 25, 'palette': ['#FFFFE5', '#FFF7BC', '#FEE391', '#FEC44F', '#FE9929', '#EC7014', '#CC4C02', '#993404', '#662506']}, # Sequential yellow-brown for Chlorophyll proxy
    }

    # Create a geemap Map instance
    m = geemap.Map(
        location=[map_center_lat, map_center_lon],
        zoom=initial_zoom,
        add_google_map=True # Allow Google Maps baselayers
    )
    m.add_basemap("HYBRID") # Default to Google Satellite Hybrid

    # Get the processed image for the current week
    gee_image_current, error_msg_current = None, None
    if selected_farm_geom:
        gee_image_current, error_msg_current = get_processed_image(
            selected_farm_geom, start_date_current_str, end_date_current_str, selected_index
        )

        if gee_image_current:
            # Add the GEE layer to the map
            try:
                current_vis = vis_params.get(selected_index, {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']}) # Default vis
                m.addLayer(
                    gee_image_current,
                    current_vis,
                    f"{selected_index} ({start_date_current_str[-5:]} ØªØ§ {end_date_current_str[-5:]})" # Short date range
                )

                # Add a color bar legend
                m.add_colorbar(
                    current_vis,
                    label=f"{index_options[selected_index]} ({selected_index})",
                    layer_name=f"{selected_index} ({start_date_current_str[-5:]} ØªØ§ {end_date_current_str[-5:]})"
                 )

                 # Add markers for farms
                if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" and not filtered_farms_df.empty:
                     # Add markers for all filtered farms
                     for idx, farm in filtered_farms_df.iterrows():
                         folium.Marker(
                             location=[farm['centroid_lat'], farm['centroid_lon']],
                             popup=(f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {farm['Ù…Ø²Ø±Ø¹Ù‡']}<br>"
                                    f"<b>Ú¯Ø±ÙˆÙ‡:</b> {farm.get('Ú¯Ø±ÙˆÙ‡', 'N/A')}<br>"
                                    f"<b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {farm.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}"
                                   ),
                             tooltip=f"Ù…Ø²Ø±Ø¹Ù‡ {farm['Ù…Ø²Ø±Ø¹Ù‡']}",
                             icon=folium.Icon(color='blue', icon='info-sign')
                         ).add_to(m)
                     # Adjust map bounds if showing all farms
                     try:
                         m.center_object(selected_farm_geom, zoom=initial_zoom) # Center on the bounding box
                     except Exception as center_err:
                         print(f"Could not center map on geometry: {center_err}") # Non-critical error
                elif selected_farm_details is not None:
                     # Add marker for the single selected farm
                     folium.Marker(
                         location=[lat, lon],
                         popup=(f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {selected_farm_name}<br>"
                                f"<b>Ú¯Ø±ÙˆÙ‡:</b> {selected_farm_details.get('Ú¯Ø±ÙˆÙ‡', 'N/A')}<br>"
                                f"<b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}<br>"
                                f"<b>Ø³Ù†:</b> {selected_farm_details.get('Ø³Ù†', 'N/A')}"
                               ),
                         tooltip=f"Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}",
                         icon=folium.Icon(color='red', icon='star')
                     ).add_to(m)
                     m.set_center(lon, lat, zoom=14) # Zoom closer for a single farm

                m.add_layer_control() # Add layer control to toggle base maps and layers

            except Exception as map_err:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ ÛŒØ§ Ø¹Ù†Ø§ØµØ± Ø¨Ù‡ Ù†Ù‚Ø´Ù‡: {map_err}")
                st.error(traceback.format_exc())
        else:
            st.warning(f"ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ ({selected_index}) Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start_date_current_str} ØªØ§ {end_date_current_str} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            if error_msg_current:
                st.warning(f"Ø¹Ù„Øª: {error_msg_current}")
            # Still display the map with markers if no image
            if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" and not filtered_farms_df.empty:
                 for idx, farm in filtered_farms_df.iterrows():
                         folium.Marker(
                             location=[farm['centroid_lat'], farm['centroid_lon']],
                             popup=(f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {farm['Ù…Ø²Ø±Ø¹Ù‡']}<br>"
                                    f"<b>Ú¯Ø±ÙˆÙ‡:</b> {farm.get('Ú¯Ø±ÙˆÙ‡', 'N/A')}<br>"
                                    f"<b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {farm.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}"
                                   ),
                             tooltip=f"Ù…Ø²Ø±Ø¹Ù‡ {farm['Ù…Ø²Ø±Ø¹Ù‡']}",
                             icon=folium.Icon(color='gray', icon='info-sign') # Gray icon if no data
                         ).add_to(m)
                 try:
                     m.center_object(selected_farm_geom, zoom=initial_zoom)
                 except Exception as center_err:
                      print(f"Could not center map on geometry: {center_err}")
            elif selected_farm_details is not None:
                  folium.Marker(
                         location=[lat, lon],
                         popup=(f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {selected_farm_name}<br>"
                                f"<b>Ú¯Ø±ÙˆÙ‡:</b> {selected_farm_details.get('Ú¯Ø±ÙˆÙ‡', 'N/A')}<br>"
                                f"<b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}<br>"
                                f"<b>Ø³Ù†:</b> {selected_farm_details.get('Ø³Ù†', 'N/A')}"
                               ),
                         tooltip=f"Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name} (Ø¯Ø§Ø¯Ù‡ ØªØµÙˆÛŒØ±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯)",
                         icon=folium.Icon(color='gray', icon='star') # Gray icon if no data
                     ).add_to(m)
                  m.set_center(lon, lat, zoom=14)


    # Display the map in Streamlit
    try:
        # Use st_folium for better integration
        st_folium(m, width=None, height=500, use_container_width=True)
        st.caption("Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ø±ÙˆÛŒ Ù…Ø§Ø±Ú©Ø±Ù‡Ø§ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯. Ø§Ø² Ú©Ù†ØªØ±Ù„ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ (Ø¨Ø§Ù„Ø§ Ø³Ù…Øª Ø±Ø§Ø³Øª Ù†Ù‚Ø´Ù‡) Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ù†Ù‚Ø´Ù‡ Ù¾Ø§ÛŒÙ‡ ÛŒØ§ Ù†Ù…Ø§ÛŒØ´/Ø¹Ø¯Ù… Ù†Ù…Ø§ÛŒØ´ Ù„Ø§ÛŒÙ‡ Ø´Ø§Ø®Øµ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
    except Exception as display_err:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡: {display_err}")
        st.error(traceback.format_exc())

    # Note: Direct PNG download from st_folium/geemap isn't built-in easily.
    st.info("ğŸ’¡ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‚Ø´Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§Ø¨Ø²Ø§Ø± Ø¹Ú©Ø³ Ú¯Ø±ÙØªÙ† Ø§Ø² ØµÙØ­Ù‡ (Screenshot) Ù…Ø±ÙˆØ±Ú¯Ø± ÛŒØ§ Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„ Ø®ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")


    # --- Time Series Chart ---
    st.markdown("---")
    st.subheader(f"ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index}")

    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif selected_farm_geom and selected_farm_details is not None:
        # Check if the geometry is a Point for time series
        # A more robust check might involve inspecting selected_farm_details['geometry_type'] if loaded
        is_point = isinstance(selected_farm_geom, ee.geometry.Point)

        if is_point:
            # Define a longer period for the time series chart (e.g., last 6-12 months)
            timeseries_end_date = today.strftime('%Y-%m-%d')
            timeseries_start_date = (today - datetime.timedelta(days=365)).strftime('%Y-%m-%d') # Last year

            ts_df, ts_error = get_index_time_series(
                selected_farm_geom,
                selected_index,
                start_date=timeseries_start_date,
                end_date=timeseries_end_date
            )

            if ts_error:
                st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}")
            elif not ts_df.empty:
                # Create Plotly chart for better customization
                fig_ts = px.line(ts_df, x=ts_df.index, y=selected_index,
                                 title=f"Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}",
                                 labels={'date': 'ØªØ§Ø±ÛŒØ®', selected_index: f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                fig_ts.update_traces(mode='lines+markers')
                fig_ts.update_layout(hovermode="x unified")
                st.plotly_chart(fig_ts, use_container_width=True)
                st.caption(f"Ù†Ù…ÙˆØ¯Ø§Ø± ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name} Ø¯Ø± 12 Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡.")
            else:
                st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¯Ø± Ø¨Ø§Ø²Ù‡ {timeseries_start_date} ØªØ§ {timeseries_end_date} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        else:
            st.warning("Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ (Ø§Ù†ØªØ®Ø§Ø¨ ØªÚ© Ù…Ø²Ø±Ø¹Ù‡) Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª.")
    else:
        # This case might occur if 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' is selected but filtered_farms_df is empty,
        # or if selected_farm_name is specific but details couldn't be found (shouldn't happen with current logic)
        st.warning("Ù‡Ù†Ø¯Ø³Ù‡ ÛŒØ§ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")


    # ==============================================================================
    # Helper Function for Status Determination
    # ==============================================================================

    def determine_status(row, index_name):
        """Determines the status based on change in index value."""
        current_val_col = f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)'
        prev_val_col = f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)'
        change_col = 'ØªØºÛŒÛŒØ±'

        # Check if necessary columns exist and data is present
        if not all(col in row.index for col in [current_val_col, prev_val_col, change_col]):
            return "Ø®Ø·Ø§ Ø¯Ø± Ø³ØªÙˆÙ†" # Indicate missing columns
        if pd.isna(row[change_col]) or pd.isna(row[current_val_col]) or pd.isna(row[prev_val_col]):
            # Check if only one value is present
            if pd.notna(row[current_val_col]) and pd.isna(row[prev_val_col]):
                 return "Ø¬Ø¯ÛŒØ¯" # Data only for current week
            elif pd.isna(row[current_val_col]) and pd.notna(row[prev_val_col]):
                 return "Ø­Ø°Ù Ø´Ø¯Ù‡ØŸ" # Data only for previous week
            else:
                 return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" # Both missing or change couldn't be calculated


        change_val = row[change_col]
        # Threshold for significant change (relative or absolute)
        # Let's use a relative threshold for indices like NDVI/EVI
        # And an absolute threshold for indices like NDMI/MSI? Or keep it simple with absolute.
        absolute_threshold = 0.05 # e.g., 0.05 change in NDVI/NDMI
        # relative_threshold_percent = 5 # e.g., 5% change

        # Status based on index type and change direction
        higher_is_better = index_name in ['NDVI', 'EVI', 'LAI', 'CVI', 'NDMI', 'SAVI']
        lower_is_better = index_name in ['MSI']

        if higher_is_better:
            if change_val > absolute_threshold:
                return "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯"
            elif change_val < -absolute_threshold:
                return "ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´"
            else:
                return "Ø«Ø§Ø¨Øª"
        elif lower_is_better:
            if change_val < -absolute_threshold: # Negative change means improvement (less stress)
                return "Ø¨Ù‡Ø¨ÙˆØ¯ / Ú©Ø§Ù‡Ø´ ØªÙ†Ø´"
            elif change_val > absolute_threshold: # Positive change means deterioration (more stress)
                return "ØªÙ†Ø´ / Ø¨Ø¯ØªØ± Ø´Ø¯Ù†"
            else:
                return "Ø«Ø§Ø¨Øª"
        else:
            # Default case if index type is unknown
            # Check absolute change
             if abs(change_val) > absolute_threshold:
                 return f"ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡ ({change_val:+.2f})"
             else:
                 return "Ø«Ø§Ø¨Øª"

    # ==============================================================================
    # Ranking Table
    # ==============================================================================
    st.markdown("---")
    st.subheader(f"ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} (Ø±ÙˆØ²: {selected_day})")
    st.markdown(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ ({end_date_current_str}) Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ ({end_date_previous_str}).")

    # Use a placeholder for the progress bar display area
    progress_placeholder = st.empty()

    @st.cache_data(show_spinner=False, persist=True) # Show spinner handled manually
    def calculate_weekly_indices(_farms_df, index_name, start_curr, end_curr, start_prev, end_prev):
        """Calculates the average index value for the current and previous week for a list of farms."""
        results = []
        errors = []
        total_farms = len(_farms_df)
        # progress_bar = st.progress(0) # Use st.progress

        status_text = st.empty() # For text updates
        status_text.info(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ {index_name} Ø¨Ø±Ø§ÛŒ {total_farms} Ù…Ø²Ø±Ø¹Ù‡...")


        for i, (idx, farm) in enumerate(_farms_df.iterrows()):
            farm_name = farm['Ù…Ø²Ø±Ø¹Ù‡']
            lat = farm['centroid_lat']
            lon = farm['centroid_lon']
            point_geom = ee.Geometry.Point([lon, lat])

            current_val, previous_val = None, None
            err_curr, err_prev = None, None

            def get_mean_value_robust(start, end):
                """Wrapper to get mean value, handling potential errors gracefully."""
                try:
                    # Use the main processing function, select the specific index
                    image_period, error_img = get_processed_image(point_geom, start, end, index_name)

                    if image_period:
                        # Reduce region to get the mean value at the point
                        mean_dict = image_period.reduceRegion(
                            reducer=ee.Reducer.mean(), # Use mean over the period/point
                            geometry=point_geom,
                            scale=10,  # Scale in meters
                            maxPixels=1e9
                        ).getInfo()

                        val = mean_dict.get(index_name) if mean_dict else None
                        if val is not None:
                             return val, None # Success
                        else:
                             # If reduceRegion worked but returned no value for the index
                             return None, f"Ù…Ù‚Ø¯Ø§Ø± {index_name} Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end} ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ ØªÙ…Ø§Ù… Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ Ù…Ø§Ø³Ú© Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯)"
                    else:
                        # If get_processed_image failed
                         return None, error_img # Return the error from get_processed_image
                except ee.EEException as e:
                     return None, f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± reduceRegion ({start}-{end}): {e}"
                except Exception as e:
                     return None, f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø± ({start}-{end}): {e}"


            # Calculate for current week
            current_val, err_curr = get_mean_value_robust(start_curr, end_curr)
            if err_curr: errors.append(f"{farm_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ): {err_curr}")

            # Calculate for previous week
            previous_val, err_prev = get_mean_value_robust(start_prev, end_prev)
            if err_prev: errors.append(f"{farm_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„): {err_prev}")

            # Calculate change
            change = None
            if current_val is not None and previous_val is not None:
                try:
                    # Ensure both are numbers before subtracting
                    if isinstance(current_val, (int, float)) and isinstance(previous_val, (int, float)):
                        change = current_val - previous_val
                    else:
                         change = None # If types are wrong, cannot calculate change
                except TypeError:
                    change = None # Handle unexpected types

            results.append({
                'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
                'Ú¯Ø±ÙˆÙ‡': farm.get('Ú¯Ø±ÙˆÙ‡', 'N/A'),
                f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': current_val,
                f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': previous_val,
                'ØªØºÛŒÛŒØ±': change
            })

            # Update progress bar and status text
            progress_fraction = (i + 1) / total_farms
            # Update the placeholder with the progress bar HTML
            progress_placeholder.markdown(modern_progress_bar(progress_fraction), unsafe_allow_html=True)
            # Optionally update status text less frequently
            # if (i + 1) % 5 == 0 or (i + 1) == total_farms: # Update every 5 farms or at the end
            #     status_text.info(f"â³ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø²Ø±Ø¹Ù‡ {i+1} Ø§Ø² {total_farms}...")


        status_text.success(f"âœ… Ù…Ø­Ø§Ø³Ø¨Ù‡ {index_name} Ø¨Ø±Ø§ÛŒ {total_farms} Ù…Ø²Ø±Ø¹Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯.")
        progress_placeholder.empty() # Remove progress bar after completion
        return pd.DataFrame(results), errors

    # Calculate and display the ranking table
    ranking_df, calculation_errors = calculate_weekly_indices(
        filtered_farms_df,
        selected_index,
        start_date_current_str,
        end_date_current_str,
        start_date_previous_str,
        end_date_previous_str
    )

    # Display any errors that occurred during calculation
    if calculation_errors:
        with st.expander("Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ (Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯)", expanded=False):
            st.warning("âš ï¸ Ø¨Ø±Ø®ÛŒ Ø®Ø·Ø§Ù‡Ø§ Ø¯Ø± Ø­ÛŒÙ† Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø²ÛŒØ± Ø±Ø® Ø¯Ø§Ø¯:")
            # Show errors grouped by farm if possible, or just list them
            # Create a dictionary to group errors by farm
            error_dict = {}
            for error_str in calculation_errors:
                try:
                    farm_name_err = error_str.split(" (")[0]
                    if farm_name_err not in error_dict:
                        error_dict[farm_name_err] = []
                    error_dict[farm_name_err].append(error_str)
                except Exception:
                     if "Unknown" not in error_dict: error_dict["Unknown"] = []
                     error_dict["Unknown"].append(error_str) # Fallback

            for farm_name_err, err_list in error_dict.items():
                 st.error(f"**Ù…Ø²Ø±Ø¹Ù‡: {farm_name_err}**")
                 for err in err_list:
                      st.caption(f"- {err}")
            #for error in calculation_errors: # Simple list view
            #    st.warning(f"- {error}")

    if not ranking_df.empty:
        # Sort by the current week's index value
        # Higher is better for most indices, lower for MSI
        ascending_sort = selected_index in ['MSI'] # True if lower value is better
        ranking_df_sorted = ranking_df.sort_values(
            by=f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)',
            ascending=ascending_sort,
            na_position='last' # Put farms with no data at the bottom
        ).reset_index(drop=True)

        # Add rank number (starting from 1)
        ranking_df_sorted.index = ranking_df_sorted.index + 1
        ranking_df_sorted.index.name = 'Ø±ØªØ¨Ù‡'

        # Apply the determine_status function to get status text
        ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†'] = ranking_df_sorted.apply(
            lambda row: determine_status(row, selected_index), axis=1
        )
        # Apply the status_badge function to generate HTML badges
        ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†'].apply(status_badge)


        # Format numeric columns for better readability, handle N/A
        cols_to_format = [f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±']
        for col in cols_to_format:
            if col in ranking_df_sorted.columns:
                 # Check if column exists before formatting
                 ranking_df_sorted[col] = ranking_df_sorted[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) and isinstance(x, (int, float)) else ("N/A" if pd.isna(x) else x))

        # Select and order columns to display
        display_columns_order = [
            'Ù…Ø²Ø±Ø¹Ù‡', 'Ú¯Ø±ÙˆÙ‡',
             f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)',
             f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)',
             'ØªØºÛŒÛŒØ±',
             'ÙˆØ¶Ø¹ÛŒØª' # The HTML badge column
             ]
        # Ensure only existing columns are selected
        display_columns = [col for col in display_columns_order if col in ranking_df_sorted.columns]

        # Display the table using st.dataframe for interactivity or st.write(html) for static badges
        st.markdown("<style> td, th { text-align: right !important; } </style>", unsafe_allow_html=True) # Ensure right alignment for Farsi
        # Use st.write with HTML to render badges correctly
        st.write(ranking_df_sorted[display_columns].to_html(escape=False, index=True, classes='dataframe table table-striped', justify='right'), unsafe_allow_html=True)


        # --- Summary Metrics ---
        st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
        status_counts_text = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†'].value_counts()

        # Define categories based on expected status text
        positive_terms = ["Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯", "Ø¨Ù‡Ø¨ÙˆØ¯ / Ú©Ø§Ù‡Ø´ ØªÙ†Ø´", "Ø¬Ø¯ÛŒØ¯"]
        negative_terms = ["ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´", "ØªÙ†Ø´ / Ø¨Ø¯ØªØ± Ø´Ø¯Ù†", "Ø­Ø°Ù Ø´Ø¯Ù‡?"]
        neutral_terms = ["Ø«Ø§Ø¨Øª"]
        nodata_terms = ["Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", "Ø®Ø·Ø§ Ø¯Ø± Ø³ØªÙˆÙ†"]

        # Calculate counts for each category
        positive_count = sum(status_counts_text.get(term, 0) for term in positive_terms)
        negative_count = sum(status_counts_text.get(term, 0) for term in negative_terms)
        neutral_count = sum(status_counts_text.get(term, 0) for term in neutral_terms)
        nodata_count = sum(status_counts_text.get(term, 0) for term in nodata_terms)
        unknown_count = len(ranking_df_sorted) - (positive_count + negative_count + neutral_count + nodata_count)

        summary_cols = st.columns(4)
        with summary_cols[0]:
            st.metric("ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯/Ø¬Ø¯ÛŒØ¯", positive_count)
        with summary_cols[1]:
            st.metric("ğŸ”´ ØªÙ†Ø´/Ú©Ø§Ù‡Ø´", negative_count)
        with summary_cols[2]:
            st.metric("âšª Ø«Ø§Ø¨Øª", neutral_count)
        with summary_cols[3]:
            st.metric("âš« Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡/Ø®Ø·Ø§", nodata_count + unknown_count)


        # Add explanation of status terms
        st.info(f"""
        **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª:**
        - **ğŸŸ¢ Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯ / Ú©Ø§Ù‡Ø´ ØªÙ†Ø´ / Ø¬Ø¯ÛŒØ¯**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª.
        - **âšª Ø«Ø§Ø¨Øª**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ ØªØºÛŒÛŒØ± Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯.
        - **ğŸ”´ ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´ / Ø¨Ø¯ØªØ± Ø´Ø¯Ù† / Ø­Ø°Ù Ø´Ø¯Ù‡?**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ ÙˆØ¶Ø¹ÛŒØª Ù†Ø§Ù…Ø·Ù„ÙˆØ¨â€ŒØªØ±ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª.
        - **âš« Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ / Ø®Ø·Ø§**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± Ù‡Ø± Ø¯Ùˆ Ù‡ÙØªÙ‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ ÛŒØ§ Ø¯Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ù…Ø´Ú©Ù„ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.
        """)

        # Add download button for the table (including the raw status text)
        csv_df = ranking_df_sorted.drop(columns=['ÙˆØ¶Ø¹ÛŒØª']) # Drop HTML badge column for CSV
        csv_data = csv_df.to_csv(index=True, encoding='utf-8-sig') # Use utf-8-sig for Excel compatibility
        st.download_button(
            label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (CSV)",
            data=csv_data,
            file_name=f'ranking_{selected_index}_{selected_day}_{end_date_current_str}.csv',
            mime='text/csv',
        )
    else:
        st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")


# --- Tab 2: Analysis Data Visualization (Conditional) ---
# Check if the tab exists before trying to use it
if tab2_idx != -1:
    with tab2: # Use the correct tab variable
        st.header("ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª")
        st.markdown("Ù†Ù…Ø§ÛŒØ´ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³Ø§Ø­Øª Ùˆ ØªÙˆÙ„ÛŒØ¯ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ø§Ø¯Ø§Ø±Ù‡ Ùˆ Ø³Ù†.")

        if analysis_area_df is not None or analysis_prod_df is not None:

            # Get unique 'Ø§Ø¯Ø§Ø±Ù‡' values from both dataframes if they exist
            available_edareh = []
            if analysis_area_df is not None and 'Ø§Ø¯Ø§Ø±Ù‡' in analysis_area_df.index.names:
                try:
                    available_edareh.extend(analysis_area_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique().tolist())
                except KeyError:
                    st.warning("Ø³Ø·Ø­ 'Ø§Ø¯Ø§Ø±Ù‡' Ø¯Ø± Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            if analysis_prod_df is not None and 'Ø§Ø¯Ø§Ø±Ù‡' in analysis_prod_df.index.names:
                 try:
                    available_edareh.extend(analysis_prod_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique().tolist())
                 except KeyError:
                     st.warning("Ø³Ø·Ø­ 'Ø§Ø¯Ø§Ø±Ù‡' Ø¯Ø± Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


            # Ensure unique and sorted list of integers
            try:
                available_edareh = sorted(list(set(map(int, filter(lambda x: isinstance(x, (int, float)) and pd.notna(x), available_edareh)))))
            except Exception:
                 available_edareh = sorted(list(set(filter(pd.notna, available_edareh)))) # Keep as is if conversion fails


            if not available_edareh:
                st.warning("Ù‡ÛŒÚ† Ø§Ø¯Ø§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            else:
                selected_edareh = st.selectbox(
                    "Ø§Ø¯Ø§Ø±Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
                    options=available_edareh,
                    key='analysis_edareh_select'
                )

                # --- Display Data for Selected Edareh ---
                st.subheader(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡: {selected_edareh}")

                col1, col2 = st.columns(2)

                # --- Area Data Visualization ---
                with col1:
                    st.markdown("#### Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)")
                    df_area_selected = None
                    if analysis_area_df is not None:
                         try:
                            if selected_edareh in analysis_area_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡'):
                                df_area_selected = analysis_area_df.loc[selected_edareh].copy()
                                # Drop rows/cols that are entirely NaN before plotting
                                df_area_selected = df_area_selected.dropna(axis=0, how='all').dropna(axis=1, how='all')
                            else:
                                st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                         except KeyError:
                                st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø®Ø·Ø§ÛŒ Key).")
                         except Exception as e:
                                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}: {e}")


                    if df_area_selected is not None and not df_area_selected.empty:
                        # Prepare data for plots
                        varieties = df_area_selected.columns.tolist()
                        ages = df_area_selected.index.tolist()
                        z_data = df_area_selected.fillna(0).values # Fill NA with 0 for surface plot

                        # Surface Plot (if enough data)
                        if len(ages) > 1 and len(varieties) > 1 :
                             try:
                                 fig_3d_area = go.Figure(data=[go.Surface(z=z_data, x=ages, y=varieties, colorscale='Viridis', showscale=True)])
                                 fig_3d_area.update_layout(
                                     title=f'Surface Plot Ù…Ø³Ø§Ø­Øª - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                     scene=dict(
                                         xaxis_title='Ø³Ù†',
                                         yaxis_title='ÙˆØ§Ø±ÛŒØªÙ‡',
                                         zaxis_title='Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)'),
                                     autosize=True, height=500, margin=dict(l=40, r=40, b=40, t=80))
                                 st.plotly_chart(fig_3d_area, use_container_width=True)
                             except Exception as e:
                                 st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot Ù…Ø³Ø§Ø­Øª: {e}")
                                 st.dataframe(df_area_selected) # Show table as fallback
                        else:
                             st.info("Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot Ù…Ø³Ø§Ø­Øª ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨ÛŒØ´ Ø§Ø² ÛŒÚ© Ø³Ù† Ùˆ ÛŒÚ© ÙˆØ§Ø±ÛŒØªÙ‡).")
                             st.dataframe(df_area_selected.fillna("N/A")) # Show table if not enough data for 3D

                        # Bar Chart of Area per Variety (Summed over Ages)
                        area_by_variety = df_area_selected.sum(axis=0) # Sum area for each variety
                        if not area_by_variety.empty:
                            fig_bar_area = px.bar(area_by_variety, x=area_by_variety.index, y=area_by_variety.values,
                                                   title=f'Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø³Ø§Ø­Øª Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ø±ÛŒØªÙ‡ - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                   labels={'index':'ÙˆØ§Ø±ÛŒØªÙ‡', 'y':'Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)'})
                            st.plotly_chart(fig_bar_area, use_container_width=True)

                        # Bar Chart of Area per Age (Summed over Varieties)
                        area_by_age = df_area_selected.sum(axis=1) # Sum area for each age
                        if not area_by_age.empty:
                             fig_bar_age_area = px.bar(area_by_age, x=area_by_age.index, y=area_by_age.values,
                                                    title=f'Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø³Ø§Ø­Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù† - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                    labels={'index':'Ø³Ù†', 'y':'Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)'})
                             st.plotly_chart(fig_bar_age_area, use_container_width=True)


                    elif analysis_area_df is not None: # If df exists but no data for selected edareh
                        st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
                    # else: analysis_area_df is None - warning already shown

                # --- Production Data Visualization ---
                with col2:
                    st.markdown("#### ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)")
                    df_prod_selected = None
                    if analysis_prod_df is not None:
                         try:
                            if selected_edareh in analysis_prod_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡'):
                                df_prod_selected = analysis_prod_df.loc[selected_edareh].copy()
                                # Drop rows/cols that are entirely NaN before plotting
                                df_prod_selected = df_prod_selected.dropna(axis=0, how='all').dropna(axis=1, how='all')
                            else:
                                st.info(f"Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                         except KeyError:
                             st.info(f"Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø®Ø·Ø§ÛŒ Key).")
                         except Exception as e:
                             st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}: {e}")

                    if df_prod_selected is not None and not df_prod_selected.empty:
                        # Prepare data for plots
                        varieties_prod = df_prod_selected.columns.tolist()
                        ages_prod = df_prod_selected.index.tolist()
                        z_data_prod = df_prod_selected.fillna(0).values # Fill NA with 0 for surface plot

                        # Surface Plot (if enough data)
                        if len(ages_prod) > 1 and len(varieties_prod) > 1:
                             try:
                                 fig_3d_prod = go.Figure(data=[go.Surface(z=z_data_prod, x=ages_prod, y=varieties_prod, colorscale='Plasma', showscale=True)])
                                 fig_3d_prod.update_layout(
                                     title=f'Surface Plot ØªÙˆÙ„ÛŒØ¯ - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                     scene=dict(
                                         xaxis_title='Ø³Ù†',
                                         yaxis_title='ÙˆØ§Ø±ÛŒØªÙ‡',
                                         zaxis_title='ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)'),
                                     autosize=True, height=500, margin=dict(l=40, r=40, b=40, t=80))
                                 st.plotly_chart(fig_3d_prod, use_container_width=True)
                             except Exception as e:
                                  st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot ØªÙˆÙ„ÛŒØ¯: {e}")
                                  st.dataframe(df_prod_selected) # Show table as fallback
                        else:
                             st.info("Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot ØªÙˆÙ„ÛŒØ¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨ÛŒØ´ Ø§Ø² ÛŒÚ© Ø³Ù† Ùˆ ÛŒÚ© ÙˆØ§Ø±ÛŒØªÙ‡).")
                             st.dataframe(df_prod_selected.fillna("N/A")) # Show table if not enough data for 3D

                        # Bar Chart of Production per Variety (Summed over Ages)
                        prod_by_variety = df_prod_selected.sum(axis=0)
                        if not prod_by_variety.empty:
                            fig_bar_prod = px.bar(prod_by_variety, x=prod_by_variety.index, y=prod_by_variety.values,
                                                  title=f'Ù…Ø¬Ù…ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ø±ÛŒØªÙ‡ - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                  labels={'index':'ÙˆØ§Ø±ÛŒØªÙ‡', 'y':'Ù…Ø¬Ù…ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)'})
                            st.plotly_chart(fig_bar_prod, use_container_width=True)

                         # Bar Chart of Production per Age (Summed over Varieties)
                        prod_by_age = df_prod_selected.sum(axis=1)
                        if not prod_by_age.empty:
                             fig_bar_age_prod = px.bar(prod_by_age, x=prod_by_age.index, y=prod_by_age.values,
                                                    title=f'Ù…Ø¬Ù…ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù† - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                    labels={'index':'Ø³Ù†', 'y':'Ù…Ø¬Ù…ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)'})
                             st.plotly_chart(fig_bar_age_prod, use_container_width=True)

                    elif analysis_prod_df is not None: # If df exists but no data for selected edareh
                        st.info(f"Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
                    # else: analysis_prod_df is None - warning already shown

        else: # If analysis dataframes failed to load
            st.error("Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„. Ø§ÛŒÙ† ØªØ¨ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")

# --- New Tab for Needs Analysis ---
with tab3:
    st.header("ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ")

    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø¯Ø± ØªØ¨ 'Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹' Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¢Ù† Ø¯Ø± Ø§ÛŒÙ† ØªØ¨ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif selected_farm_geom and selected_farm_details is not None: # Ensure details are available
        # Check if it's a point geometry for analysis (using centroid)
        is_point = isinstance(selected_farm_geom, ee.geometry.Point) # Check the geometry used
        if not is_point:
            st.warning("ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ù…Ø®ØªØµØ§Øª Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ (Ø§Ù†ØªØ®Ø§Ø¨ ØªÚ© Ù…Ø²Ø±Ø¹Ù‡) Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª.")
        else:
            st.subheader(f"ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")

            # --- Define thresholds (allow user adjustment in sidebar or here) ---
            st.markdown("**ØªÙ†Ø¸ÛŒÙ… Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ø´Ø¯Ø§Ø±:**")
            thresh_cols = st.columns(2)
            with thresh_cols[0]:
                ndmi_threshold = st.slider("Ø¢Ø³ØªØ§Ù†Ù‡ NDMI Ø¨Ø±Ø§ÛŒ Ù‡Ø´Ø¯Ø§Ø± Ú©Ù… Ø¢Ø¨ÛŒ:", -0.2, 0.5, 0.25, 0.01, format="%.2f",
                                         help="Ø§Ú¯Ø± NDMI Ú©Ù…ØªØ± Ø§Ø² Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø­ØªÙ…Ø§Ù„ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.")
            with thresh_cols[1]:
                ndvi_drop_threshold = st.slider("Ø¢Ø³ØªØ§Ù†Ù‡ Ø§ÙØª NDVI Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ ØªØºØ°ÛŒÙ‡ (%):", 0.0, 20.0, 7.0, 0.5, format="%.1f%%",
                                            help="Ø§Ú¯Ø± NDVI Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† Ø¯Ø±ØµØ¯ Ø§ÙØª Ú©Ù†Ø¯ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ ÛŒØ§ Ø¹ÙˆØ§Ù…Ù„ Ø¯ÛŒÚ¯Ø± Ø¨Ø§Ø´Ø¯.")

            # --- Get the required index data for the selected farm's centroid ---
            farm_needs_data = get_farm_needs_data(
                selected_farm_geom, # Use the Point geometry
                start_date_current_str, end_date_current_str,
                start_date_previous_str, end_date_previous_str
            )

            if farm_needs_data['error']:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§:")
                st.error(farm_needs_data['error']) # Show specific GEE/calculation error
            elif farm_needs_data['NDMI_curr'] is None or farm_needs_data['NDVI_curr'] is None:
                st.warning("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ù„Ø§Ø²Ù… (NDMI Ùˆ/ÛŒØ§ NDVI) Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾ÙˆØ´Ø´ Ø§Ø¨Ø± ÛŒØ§ Ù†Ø¨ÙˆØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§Ø´Ø¯.")
                # Display available data if any
                st.markdown("**Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ - Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯):**")
                idx_cols_partial = st.columns(4)
                with idx_cols_partial[0]: st.metric("NDVI", format_value(farm_needs_data.get('NDVI_curr')))
                with idx_cols_partial[1]: st.metric("NDMI", format_value(farm_needs_data.get('NDMI_curr')))
                with idx_cols_partial[2]: st.metric("EVI", format_value(farm_needs_data.get('EVI_curr')))
                with idx_cols_partial[3]: st.metric("SAVI", format_value(farm_needs_data.get('SAVI_curr')))

            else: # Data is available
                # --- Display Current Indices ---
                st.markdown("**Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ):**")
                idx_cols = st.columns(4)
                with idx_cols[0]: st.metric("NDVI", f"{farm_needs_data['NDVI_curr']:.3f}", f"{farm_needs_data['NDVI_curr'] - farm_needs_data.get('NDVI_prev', farm_needs_data['NDVI_curr']):+.3f}" if farm_needs_data.get('NDVI_prev') is not None else "N/A")
                with idx_cols[1]: st.metric("NDMI", f"{farm_needs_data['NDMI_curr']:.3f}", f"{farm_needs_data['NDMI_curr'] - farm_needs_data.get('NDMI_prev', farm_needs_data['NDMI_curr']):+.3f}" if farm_needs_data.get('NDMI_prev') is not None else "N/A")
                with idx_cols[2]: st.metric("EVI", f"{farm_needs_data.get('EVI_curr', 'N/A'):.3f}" if farm_needs_data.get('EVI_curr') is not None else "N/A", f"{farm_needs_data['EVI_curr'] - farm_needs_data.get('EVI_prev', farm_needs_data['EVI_curr']):+.3f}" if farm_needs_data.get('EVI_curr') is not None and farm_needs_data.get('EVI_prev') is not None else "N/A" )
                with idx_cols[3]: st.metric("SAVI", f"{farm_needs_data.get('SAVI_curr', 'N/A'):.3f}" if farm_needs_data.get('SAVI_curr') is not None else "N/A", f"{farm_needs_data['SAVI_curr'] - farm_needs_data.get('SAVI_prev', farm_needs_data['SAVI_curr']):+.3f}" if farm_needs_data.get('SAVI_curr') is not None and farm_needs_data.get('SAVI_prev') is not None else "N/A")
                st.caption("Ù…Ù‚Ø¯Ø§Ø± Ø§ØµÙ„ÛŒ Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¯Ù„ØªØ§ (ØªØºÛŒÛŒØ± Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„) Ø¯Ø± Ø²ÛŒØ± Ø¢Ù† Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„).")


                # --- Generate Recommendations ---
                recommendations = []
                issues_found = False # Flag to track if any negative condition is met

                # 1. Irrigation Check (Low NDMI)
                if farm_needs_data['NDMI_curr'] < ndmi_threshold:
                    recommendations.append(f"ğŸ’§ **Ù†ÛŒØ§Ø² Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** Ù…Ù‚Ø¯Ø§Ø± NDMI ({farm_needs_data['NDMI_curr']:.3f}) Ú©Ù…ØªØ± Ø§Ø² Ø¢Ø³ØªØ§Ù†Ù‡ ({ndmi_threshold:.2f}) Ø§Ø³Øª Ú©Ù‡ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø±Ø·ÙˆØ¨Øª Ù¾Ø§ÛŒÛŒÙ† Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø§Ø³Øª.")
                    issues_found = True

                # 2. Fertilization/Stress Check (Significant NDVI drop)
                if farm_needs_data.get('NDVI_prev') is not None and farm_needs_data['NDVI_curr'] < farm_needs_data['NDVI_prev']:
                     # Calculate relative change percentage
                     try: # Avoid division by zero if NDVI_prev is very small or zero
                         if abs(farm_needs_data['NDVI_prev']) > 1e-6:
                             ndvi_change_percent = ((farm_needs_data['NDVI_curr'] - farm_needs_data['NDVI_prev']) / abs(farm_needs_data['NDVI_prev'])) * 100
                             # Check if the drop exceeds the threshold (change is negative, so compare absolute value)
                             if abs(ndvi_change_percent) > ndvi_drop_threshold:
                                 recommendations.append(f"âš ï¸ **Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´:** Ø§ÙØª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ NDVI ({ndvi_change_percent:.1f}%) Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯. Ø§ÛŒÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù†Ø§Ø´ÛŒ Ø§Ø² Ú©Ù…Ø¨ÙˆØ¯ Ù…ÙˆØ§Ø¯ Ù…ØºØ°ÛŒØŒ ØªÙ†Ø´ Ø¢Ø¨ÛŒØŒ Ø¢ÙØª ÛŒØ§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø§Ø´Ø¯. Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒØ¯Ø§Ù†ÛŒ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
                                 issues_found = True
                         else: # NDVI previous was zero or near-zero
                             if farm_needs_data['NDVI_curr'] > 0.1: # If current NDVI is reasonably positive
                                 recommendations.append(f"ğŸ“ˆ **Ø±Ø´Ø¯ NDVI:** Ù…Ù‚Ø¯Ø§Ø± NDVI Ø§Ø² Ù†Ø²Ø¯ÛŒÚ© ØµÙØ± Ø¨Ù‡ {farm_needs_data['NDVI_curr']:.3f} Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØªÙ‡ Ø§Ø³Øª.")
                             # Else: still near zero, no significant change comment needed

                     except Exception as e:
                         st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ± NDVI: {e}")

                elif farm_needs_data.get('NDVI_prev') is None:
                     st.caption("Ø¯Ø§Ø¯Ù‡ NDVI Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

                # 3. General Health check (Low NDVI) - Add an absolute check
                if farm_needs_data['NDVI_curr'] < 0.3: # Example threshold for very low vegetation cover
                    # Avoid duplicating stress message if already triggered by drop
                    if not any("ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´" in rec for rec in recommendations):
                        recommendations.append(f"ğŸ“‰ **Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¶Ø¹ÛŒÙ:** Ù…Ù‚Ø¯Ø§Ø± NDVI ({farm_needs_data['NDVI_curr']:.3f}) Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª. ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø±Ø¯.")
                        issues_found = True


                # 4. Default if no specific issues flagged
                if not issues_found and not recommendations: # Ensure no recommendations were added for other reasons (like NDVI increase)
                    recommendations.append("âœ… **ÙˆØ¶Ø¹ÛŒØª Ù…Ø·Ù„ÙˆØ¨:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ NDMI Ùˆ Ø±ÙˆÙ†Ø¯ NDVIØŒ ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù…Ø·Ù„ÙˆØ¨ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ùˆ Ù‡Ø´Ø¯Ø§Ø±ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.")

                # Display Recommendations Clearly
                st.markdown("**ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡:**")
                if recommendations:
                    for rec in recommendations:
                        if "Ø¢Ø¨ÛŒØ§Ø±ÛŒ" in rec: st.error(rec)
                        elif "ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´" in rec: st.warning(rec)
                        elif "Ø¶Ø¹ÛŒÙ" in rec: st.warning(rec)
                        else: st.success(rec) # For positive/neutral messages
                else:
                    # Should not happen due to default message, but as a fallback:
                    st.info("Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡ Ø®Ø§ØµÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯.")


                # --- Get and Display AI Analysis ---
                st.markdown("---")
                st.markdown("**ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (Gemini):**")
                if gemini_model:
                    ai_explanation = get_ai_analysis(gemini_model, selected_farm_name, farm_needs_data, [rec.split(':')[0].strip() for rec in recommendations]) # Pass concise recommendations
                    st.markdown(ai_explanation)
                else:
                    st.info("Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

    else:
         st.info("Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø¹ØªØ¨Ø± Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø¯Ø± ØªØ¨ 'Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹' Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")


st.markdown("---")
st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ ğŸ’š ØªÙˆØ³Ø· [Ù†Ø§Ù… Ø´Ù…Ø§ ÛŒØ§ ØªÛŒÙ… Ø´Ù…Ø§]") # Add credit
st.sidebar.markdown("[Ù¾ÛŒÙˆÙ†Ø¯ Ø¨Ù‡ GitHub ÛŒØ§ Ù…Ø³ØªÙ†Ø¯Ø§Øª](https://your-link-here)") # Optional link