# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
from datetime import timedelta # Import timedelta
import plotly.express as px
import plotly.graph_objects as go # For grouped bar chart
import os
from io import BytesIO
import requests # Needed for getThumbUrl download
import numpy as np # For calculations and handling potential NaNs

# --- Configuration ---
APP_TITLE = "Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

# --- File Paths (Relative to the script location) ---
CSV_FILE_PATH = 'output (1).csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'

# --- GEE Authentication ---
@st.cache_resource
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully.")
        return True
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.stop()

# --- Data Loading ---
@st.cache_data
def load_data(csv_path):
    """Loads and preprocesses farm data from the CSV file."""
    try:
        df = pd.read_csv(csv_path)
        df.columns = df.columns.str.strip()
        print(f"Original columns: {df.columns.tolist()}")

        if 'Ø³Ù† ' in df.columns and 'Ø³Ù†' not in df.columns:
             df.rename(columns={'Ø³Ù† ': 'Ø³Ù†'}, inplace=True) # Rename if space exists

        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª'] = pd.to_numeric(df['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª'], errors='coerce')
        df['Ù…Ø²Ø±Ø¹Ù‡'] = df['Ù…Ø²Ø±Ø¹Ù‡'].str.strip()

        for col in ['Ú©Ø§Ù†Ø§Ù„', 'Ø§Ø¯Ø§Ø±Ù‡', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡']:
             if col in df.columns:
                df[col] = df[col].astype(str).fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
             else:
                 print(f"Warning: Column '{col}' not found during loading.")
                 df[col] = 'Ù†Ø§Ù…Ø´Ø®Øµ' # Add default if missing

        if 'coordinates_missing' in df.columns:
             df['coordinates_missing'] = pd.to_numeric(df['coordinates_missing'], errors='coerce').fillna(1).astype(int)
        else:
             print("Warning: Column 'coordinates_missing' not found. Inferring.")
             df['coordinates_missing'] = df.apply(lambda row: 1 if pd.isna(row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) or pd.isna(row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) else 0, axis=1)

        print(f"Data loaded. Shape: {df.shape}. Cleaned columns: {df.columns.tolist()}")
        return df
    except FileNotFoundError: st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ CSV '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯."); st.stop()
    except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ CSV: {e}"); st.exception(e); st.stop()

# --- GEE Image Processing Functions ---
COMMON_BAND_NAMES = ['Blue', 'Green', 'Red', 'RedEdge1', 'NIR', 'SWIR1', 'SWIR2']

def mask_s2_clouds(image):
    # ... (masking logic remains the same) ...
    img_ee = ee.Image(image)
    qa = img_ee.select('QA60')
    cloud_mask = 1 << 10; cirrus_mask = 1 << 11
    mask = qa.bitwiseAnd(cloud_mask).eq(0).And(qa.bitwiseAnd(cirrus_mask).eq(0))
    data_bands = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12']
    return img_ee.select(data_bands).updateMask(mask).divide(10000.0).copyProperties(img_ee, ["system:time_start"])

def mask_landsat_clouds(image):
    # ... (masking logic remains the same) ...
    img_ee = ee.Image(image)
    qa = img_ee.select('QA_PIXEL')
    cloud_shadow_mask = 1 << 3; snow_mask = 1 << 4; cloud_mask = 1 << 5
    mask = qa.bitwiseAnd(cloud_shadow_mask).eq(0).And(qa.bitwiseAnd(snow_mask).eq(0)).And(qa.bitwiseAnd(cloud_mask).eq(0))
    sr_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']
    scale = 0.0000275; offset = -0.2
    scaled_bands = img_ee.select(sr_bands).multiply(scale).add(offset)
    return scaled_bands.updateMask(mask).copyProperties(img_ee, ["system:time_start"])

# --- Index Calculation Functions ---
# (Defined as before - calculate_ndvi, calculate_evi, etc.)
# Ensure they return ee.Image().rename(...) on error
def calculate_ndvi(image):
    img_ee = ee.Image(image); try: return img_ee.normalizedDifference(['NIR', 'Red']).rename('NDVI'); except: return ee.Image().rename('NDVI')
def calculate_evi(image):
    img_ee = ee.Image(image); try: img_ee.select(['NIR', 'Red', 'Blue']); evi = img_ee.expression('2.5*((NIR-RED)/(NIR+6*RED-7.5*BLUE+1))',{'NIR':img_ee.select('NIR'),'RED':img_ee.select('Red'),'BLUE':img_ee.select('Blue')}); return evi.rename('EVI'); except: return ee.Image().rename('EVI')
def calculate_ndmi(image):
    img_ee = ee.Image(image); try: return img_ee.normalizedDifference(['NIR', 'SWIR1']).rename('NDMI'); except: return ee.Image().rename('NDMI')
def calculate_msi(image):
    img_ee = ee.Image(image); try: return img_ee.expression('SWIR1/NIR',{'SWIR1':img_ee.select('SWIR1'),'NIR':img_ee.select('NIR')}).rename('MSI'); except: return ee.Image().rename('MSI')
def calculate_lai_simple(image):
    img_ee = ee.Image(image); lai=None
    try: evi_img = calculate_evi(img_ee); lai = evi_img.select('EVI').multiply(3.5).add(0.1)
    except:
        try: ndvi = img_ee.normalizedDifference(['NIR','Red']); lai = ndvi.multiply(5.0).add(0.1)
        except: return ee.Image().rename('LAI')
    return lai.clamp(0,8).rename('LAI') if lai else ee.Image().rename('LAI')
def calculate_biomass_simple(image):
    img_ee = ee.Image(image); lai_image = calculate_lai_simple(img_ee)
    try: lai=lai_image.select('LAI'); a=1.5; b=0.2; biomass=lai.multiply(a).add(b); return biomass.clamp(0,50).rename('Biomass')
    except: return ee.Image().rename('Biomass')
def calculate_chlorophyll_mcari(image):
    img_ee = ee.Image(image)
    try: img_ee.select('RedEdge1'); mcari = img_ee.expression('((RE1-RED)-0.2*(RE1-GREEN))*(RE1/RED)',{'RE1':img_ee.select('RedEdge1'),'RED':img_ee.select('Red'),'GREEN':img_ee.select('Green')}); return mcari.rename('Chlorophyll')
    except:
        try: ndvi = img_ee.normalizedDifference(['NIR','Red']); return ndvi.rename('Chlorophyll')
        except: return ee.Image().rename('Chlorophyll')
def calculate_et_placeholder(image):
    img_ee = ee.Image(image); try: ndmi = img_ee.normalizedDifference(['NIR', 'SWIR1']); return ndmi.rename('ET_proxy'); except: return ee.Image().rename('ET_proxy')


# --- Index Definitions Dictionary ---
# (Defined as before)
INDEX_DEFINITIONS = {
    'NDVI': { 'func': calculate_ndvi, 'vis': {'min': 0, 'max': 1, 'palette': ['#d73027', '#fee08b', '#1a9850']}, 'name_fa': "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ (NDVI)", 'desc_fa': """**NDVI:** Ø±Ø§ÛŒØ¬â€ŒØªØ±ÛŒÙ† Ø´Ø§Ø®Øµ Ø³Ù„Ø§Ù…Øª Ùˆ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ. Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ØªØ± Ø§Ø³Øª.<br>- **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û± (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û°.Û± ØªØ§ Û°.Û¹ Ø¨Ø±Ø§ÛŒ Ú¯ÛŒØ§Ù‡)<br>- **ØªÙØ³ÛŒØ±:** < Û°.Û² (Ø®Ø§Ú©/Ø¢Ø¨), Û°.Û²-Û°.Ûµ (Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡/ØªÙ†Ø´), > Û°.Ûµ (Ø³Ø§Ù„Ù…/Ù…ØªØ±Ø§Ú©Ù…)""", 'sort_ascending': False},
    'EVI': { 'func': calculate_evi, 'vis': {'min': 0, 'max': 1, 'palette': ['#d73027', '#fee08b', '#1a9850']}, 'name_fa': "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ (EVI)", 'desc_fa': """**EVI:** Ù…Ø´Ø§Ø¨Ù‡ NDVI Ø¨Ø§ Ø­Ø³Ø§Ø³ÛŒØª Ú©Ù…ØªØ± Ø¨Ù‡ Ø§Ø«Ø±Ø§Øª Ø¬Ùˆ Ùˆ Ø®Ø§Ú©ØŒ Ø¨Ù‡ØªØ± Ø¯Ø± ØªØ±Ø§Ú©Ù… Ø¨Ø§Ù„Ø§.<br>- **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Û° ØªØ§ Û±<br>- **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ØªØ± Ø§Ø³Øª.""", 'sort_ascending': False},
    'NDMI': { 'func': calculate_ndmi, 'vis': {'min': -0.5, 'max': 0.8, 'palette': ['#a50026', '#ffffbf', '#313695']}, 'name_fa': "Ø´Ø§Ø®Øµ Ø±Ø·ÙˆØ¨Øª (NDMI)", 'desc_fa': """**NDMI:** Ù…ÛŒØ²Ø§Ù† Ø¢Ø¨ Ø¯Ø± Ø¨Ø±Ú¯â€ŒÙ‡Ø§.<br>- **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û±<br>- **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± (Ø¢Ø¨ÛŒ) Ø±Ø·ÙˆØ¨Øª Ø¨ÛŒØ´ØªØ±ØŒ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ) Ø®Ø´Ú©ÛŒ/ØªÙ†Ø´ Ø¢Ø¨ÛŒ.""", 'sort_ascending': False},
    'MSI': { 'func': calculate_msi, 'vis': {'min': 0.4, 'max': 2.5, 'palette': ['#1a9641', '#ffffbf', '#d7191c']}, 'name_fa': "Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ (MSI)", 'desc_fa': """**MSI:** Ø­Ø³Ø§Ø³ Ø¨Ù‡ Ø±Ø·ÙˆØ¨ØªØŒ Ø§Ù…Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± **Ø¨Ø§Ù„Ø§ØªØ±** Ù†Ø´Ø§Ù†Ù‡ ØªÙ†Ø´ **Ø¨ÛŒØ´ØªØ±** Ø§Ø³Øª (Ø¨Ø±Ø¹Ú©Ø³ NDMI).<br>- **Ù…Ø­Ø§Ø³Ø¨Ù‡:** SWIR1 / NIR<br>- **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** > Û°.Û´<br>- **ØªÙØ³ÛŒØ±:** Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Ø³Ø¨Ø²) Ø¨Ù‡ØªØ±ØŒ Ø¨Ø§Ù„Ø§ØªØ± (Ù‚Ø±Ù…Ø²) ØªÙ†Ø´ Ø¨ÛŒØ´ØªØ±.""", 'sort_ascending': True},
    'LAI': { 'func': calculate_lai_simple, 'vis': {'min': 0, 'max': 8, 'palette': ['#fff5f0', '#fdcdb9', '#e34a33']}, 'name_fa': "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (LAI - ØªØ®Ù…ÛŒÙ†ÛŒ)", 'desc_fa': """**LAI:** Ù†Ø³Ø¨Øª Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¨Ù‡ Ø³Ø·Ø­ Ø²Ù…ÛŒÙ† (mÂ²/mÂ²). **ØªØ®Ù…ÛŒÙ†ÛŒ** Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¯Ø§Ø±Ø¯.<br>- **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Û° ØªØ§ Û¸+<br>- **ØªÙØ³ÛŒØ±:** Ø¨Ø§Ù„Ø§ØªØ± ÛŒØ¹Ù†ÛŒ ØªØ±Ø§Ú©Ù… Ø¨Ø±Ú¯ Ø¨ÛŒØ´ØªØ±.""", 'sort_ascending': False},
    'Biomass': { 'func': calculate_biomass_simple, 'vis': {'min': 0, 'max': 30, 'palette': ['#f7fcb9', '#addd8e', '#31a354']}, 'name_fa': "Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ (Biomass - ØªØ®Ù…ÛŒÙ†ÛŒ)", 'desc_fa': """**Biomass:** ÙˆØ²Ù† Ù…Ø§Ø¯Ù‡ Ø®Ø´Ú© Ú¯ÛŒØ§Ù‡ÛŒ (ØªÙ†/Ù‡Ú©ØªØ§Ø±). **ØªØ®Ù…ÛŒÙ†ÛŒ** Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¯Ø§Ø±Ø¯.<br>- **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** ÙˆØ§Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ†.<br>- **ØªÙØ³ÛŒØ±:** Ø¨Ø§Ù„Ø§ØªØ± ÛŒØ¹Ù†ÛŒ Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ Ø¨ÛŒØ´ØªØ±.""", 'sort_ascending': False},
    'Chlorophyll': { 'func': calculate_chlorophyll_mcari, 'vis': {'min': 0, 'max': 1, 'palette': ['#ffffcc', '#a1dab4', '#253494']}, 'name_fa': "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (MCARI/NDVI)", 'desc_fa': """**Chlorophyll:** Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ØºÙ„Ø¸Øª Ú©Ù„Ø±ÙˆÙÛŒÙ„ (Ø³Ù„Ø§Ù…Øª). Ø§Ø² MCARI (Ù†ÛŒØ§Ø² Ø¨Ù‡ RedEdge) ÛŒØ§ NDVI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.<br>- **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…ØªØºÛŒØ±.<br>- **ØªÙØ³ÛŒØ±:** Ø¨Ø§Ù„Ø§ØªØ± Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ØªØ± Ø§Ø³Øª.""", 'sort_ascending': False},
    'ET_proxy': { 'func': calculate_et_placeholder, 'vis': {'min': -0.5, 'max': 0.8, 'palette': ['#a50026', '#ffffbf', '#313695']}, 'name_fa': "Ù¾Ø±Ø§Ú©Ø³ÛŒ ØªØ¨Ø®ÛŒØ±-ØªØ¹Ø±Ù‚ (ET)", 'desc_fa': """**ET Proxy:** Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø±Ø·ÙˆØ¨ØªÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ØªØ¨Ø®ÛŒØ±-ØªØ¹Ø±Ù‚ (ET). Ø§Ø² NDMI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.<br>- **ØªÙØ³ÛŒØ±:** Ø¨Ø§Ù„Ø§ØªØ± ÛŒØ¹Ù†ÛŒ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø·ÙˆØ¨ØªÛŒ Ø¨ÛŒØ´ØªØ±.""", 'sort_ascending': False}
}


# --- GEE Data Retrieval ---
def get_image_collection(start_date, end_date, geometry=None, sensor='Sentinel-2'):
    start_date_str = start_date.strftime('%Y-%m-%d'); end_date_str = end_date.strftime('%Y-%m-%d')
    collection_id = None; bands_to_select_orig = []; bands_to_rename_to = []; mask_func = None

    if sensor == 'Sentinel-2':
        collection_id = 'COPERNICUS/S2_SR_HARMONIZED'; mask_func = mask_s2_clouds
        bands_to_select_orig = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12', 'QA60']
        bands_to_rename_to = COMMON_BAND_NAMES
    elif sensor == 'Landsat':
        l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2'); l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')
        collection_id = l9.merge(l8); mask_func = mask_landsat_clouds
        bands_to_select_orig = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'QA_PIXEL']
        bands_to_rename_to = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2']
    else: st.error(f"Ø³Ù†Ø³ÙˆØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {sensor}"); return None

    if start_date > end_date: st.error("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ø¨Ø¹Ø¯ Ø§Ø² Ù¾Ø§ÛŒØ§Ù† Ø§Ø³Øª."); return None

    collection = ee.ImageCollection(collection_id) if isinstance(collection_id, str) else collection_id
    collection = collection.filterDate(start_date_str, end_date_str)
    if geometry:
        try: collection = collection.filterBounds(geometry)
        except: st.error("Ø®Ø·Ø§ Ø¯Ø± ÙÛŒÙ„ØªØ± Ù‡Ù†Ø¯Ø³ÛŒ."); return None

    try:
        initial_count = collection.size().getInfo()
        if initial_count == 0: print(f"No initial images for {sensor} in period."); return collection
    except: st.error("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ‡ ØªØµØ§ÙˆÛŒØ±."); return None

    # --- Processing Function (Mapped) ---
    # **MODIFIED:** Ensure it always returns an ee.Image
    def process_image(image_element):
        image = ee.Image(image_element)
        try:
            img_selected_orig = image.select(bands_to_select_orig)
            img_processed = mask_func(img_selected_orig)
            img_processed_safe = ee.Image(img_processed)
            actual_band_names = img_processed_safe.bandNames()
            # Return empty image if band count doesn't match expected common names for renaming
            if actual_band_names.size().getInfo() != len(bands_to_rename_to):
                 print(f"Band count mismatch after masking/scaling. Skipping.")
                 # Return an empty image instead of None
                 return ee.Image().set('process_error', 1) # Set a property to potentially filter later

            img_renamed = img_processed_safe.rename(bands_to_rename_to)
            return img_renamed.copyProperties(image, ["system:time_start"])
        except Exception as proc_e:
            print(f"Error processing image: {proc_e}. Skipping.")
            # Return an empty image instead of None
            return ee.Image().set('process_error', 1) # Mark as errored

    # Map processing, then filter out images marked with process_error
    processed_collection = collection.map(process_image).filter(ee.Filter.eq('process_error', None))

    try:
        count = processed_collection.size().getInfo()
        print(f"Processed collection size: {count}")
        if count == 0: st.info(f"Ù‡Ø´Ø¯Ø§Ø±: Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ø§Ø¨Ø±Ù‡Ø§ØŒ ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯ ({sensor}).", icon="â˜ï¸")
    except: st.error("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡.")

    return processed_collection

# --- Function to calculate a single index ---
def calculate_single_index(collection, index_name):
    if collection is None: return None
    try:
        if collection.size().getInfo() == 0: print(f"Input collection for '{index_name}' is empty."); return None
    except: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§Ù„Ú©Ø´Ù† Ø¨Ø±Ø§ÛŒ '{index_name}'."); return None

    index_detail = INDEX_DEFINITIONS.get(index_name);
    if not index_detail: st.error(f"ØªØ¹Ø±ÛŒÙ Ø´Ø§Ø®Øµ '{index_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯."); return None
    index_func = index_detail['func']

    # Define a safe mapping function that checks the result
    def calculate_and_check(image):
        img = ee.Image(image)
        calculated_index_image = index_func(img) # This should return an image named index_name or empty
        # Return the result directly, downstream will check bands
        return calculated_index_image.copyProperties(img, ['system:time_start']) # Preserve time

    try:
        indexed_collection = collection.map(calculate_and_check)

        # Check the first image *after* mapping to ensure the band exists and filter if needed
        first_img = indexed_collection.first()
        if first_img is None or index_name not in ee.Image(first_img).bandNames().getInfo():
             st.warning(f"Ø¨Ø§Ù†Ø¯ Ø´Ø§Ø®Øµ '{index_name}' Ù¾Ø³ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯.", icon="âš ï¸")
             return None
        # Filter collection to ensure all images have the required band? (Could be slow)
        # indexed_collection = indexed_collection.filter(ee.Filter.listContains('system:band_names', index_name))
        # if indexed_collection.size().getInfo() == 0:
        #     st.warning(f"No images remained after ensuring '{index_name}' band exists.", icon="âš ï¸")
        #     return None

        return indexed_collection.select(index_name) # Select only the index band

    except ee.EEException as e: st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{index_name}': {e}"); return None
    except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ± GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{index_name}': {e}"); return None


# --- get_timeseries_for_farm ---
@st.cache_data(ttl=1800)
def get_timeseries_for_farm(_farm_geom_geojson, start_date, end_date, index_name, sensor):
    try: farm_geom = ee.Geometry(json.loads(_farm_geom_geojson))
    except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø±Ø¹Ù‡: {e}"); return pd.DataFrame()

    base_collection = get_image_collection(start_date, end_date, farm_geom, sensor)
    if base_collection is None: return pd.DataFrame()
    try:
        if base_collection.size().getInfo() == 0: st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ '{index_name}' Ù†ÛŒØ³Øª (Ø¨ÛŒ Ø§Ø¨Ø±).", icon="ğŸ“ˆ"); return pd.DataFrame()
    except: st.error("Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§Ù„Ú©Ø´Ù† Ù¾Ø§ÛŒÙ‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ."); return pd.DataFrame()

    indexed_collection = calculate_single_index(base_collection, index_name)
    if indexed_collection is None: return pd.DataFrame()
    try:
        if indexed_collection.size().getInfo() == 0: st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ '{index_name}' Ù†ÛŒØ³Øª (Ù¾Ø³ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ).", icon="ğŸ“ˆ"); return pd.DataFrame()
    except: st.error("Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§Ù„Ú©Ø´Ù† Ø´Ø§Ø®Øµ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ."); return pd.DataFrame()

    # **MODIFIED:** Ensure extract_value always returns a Feature
    def extract_value(image):
        img_ee = ee.Image(image)
        time_ms = img_ee.get('system:time_start') # Get time first
        try:
            stats = img_ee.reduceRegion(reducer=ee.Reducer.mean(), geometry=farm_geom, scale=30, maxPixels=1e9, tileScale=4)
            val = stats.get(index_name)
            # Return feature with value or placeholder -9999
            return ee.Feature(None, {'time': time_ms, index_name: ee.Algorithms.If(val, val, -9999)})
        except ee.EEException as reduce_e:
            print(f"Warning: reduceRegion failed: {reduce_e}")
            # Return feature with placeholder value and error flag
            return ee.Feature(None, {'time': time_ms, index_name: -9999, 'reduce_error': 1})

    try:
        # Map extraction. Filter client-side later.
        ts_info = indexed_collection.map(extract_value).getInfo()
    except ee.EEException as e: st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"); return pd.DataFrame()
    except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"); return pd.DataFrame()

    data = []
    if 'features' in ts_info:
        for feature in ts_info['features']:
            props = feature.get('properties', {})
            # Skip if reduction failed for this image
            if props.get('reduce_error') == 1: continue
            value = props.get(index_name)
            time_ms = props.get('time')
            if value not in [None, -9999] and time_ms is not None:
                try: dt = datetime.datetime.fromtimestamp(time_ms / 1000.0); data.append([dt, value])
                except: pass # Ignore time conversion errors
    if not data: return pd.DataFrame(columns=['Date', index_name])
    return pd.DataFrame(data, columns=['Date', index_name]).sort_values(by='Date').reset_index(drop=True)


# --- get_median_index_for_period ---
@st.cache_data(ttl=1800)
def get_median_index_for_period(_farms_df_json, start_date, end_date, index_name, sensor):
    farms_df = pd.read_json(_farms_df_json); farms_df_valid = farms_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
    if farms_df_valid.empty: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    features = []
    for idx, row in farms_df_valid.iterrows():
        try: geom = ee.Geometry.Point([row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']]).buffer(50); features.append(ee.Feature(geom, {'farm_id': row['Ù…Ø²Ø±Ø¹Ù‡']}))
        except Exception as e: print(f"Skipping farm {row.get('Ù…Ø²Ø±Ø¹Ù‡')} geom error: {e}")
    if not features: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    farm_fc = ee.FeatureCollection(features)

    base_collection = get_image_collection(start_date, end_date, farm_fc.geometry(), sensor)
    if base_collection is None: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    try:
         if base_collection.size().getInfo() == 0: print(f"No base images for median ({index_name})."); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    except: st.error("Error checking base collection size for median."); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    indexed_collection = calculate_single_index(base_collection, index_name)
    if indexed_collection is None: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    try:
         if indexed_collection.size().getInfo() == 0: print(f"No indexed images for median ({index_name})."); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    except: st.error("Error checking indexed collection size for median."); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])


    try:
        median_image = indexed_collection.median()
        if not median_image.bandNames().getInfo(): st.warning(f"Median calc failed for '{index_name}'.", icon="âš ï¸"); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    except ee.EEException as median_e: st.error(f"GEE Median error for '{index_name}': {median_e}"); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    except Exception as e: st.error(f"Median error for '{index_name}': {e}"); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    try:
        farm_values = median_image.reduceRegions(collection=farm_fc, reducer=ee.Reducer.mean(), scale=30, tileScale=8).getInfo()
    except ee.EEException as e: st.error(f"GEE reduceRegions error: {e}"); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    except Exception as e: st.error(f"reduceRegions error: {e}"); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    results_data = []
    if 'features' in farm_values:
        for feature in farm_values['features']:
            props = feature.get('properties', {}); farm_id = props.get('farm_id'); value = props.get('mean')
            if farm_id is not None and value is not None: results_data.append({'Ù…Ø²Ø±Ø¹Ù‡': farm_id, index_name: value})
    if not results_data: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    return pd.DataFrame(results_data)


# --- get_weekly_comparison ---
@st.cache_data(ttl=1800)
def get_weekly_comparison(_filtered_df_json, start_date, end_date, index_name, sensor):
    if not isinstance(start_date, datetime.date) or not isinstance(end_date, datetime.date): st.error("ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±."); return pd.DataFrame()
    current_start = start_date; current_end = end_date
    prev_end = current_start - timedelta(days=1); prev_start = prev_end - timedelta(days=(end_date-start_date).days)
    print(f"Comparing Period: {current_start} to {current_end} vs {prev_start} to {prev_end}")

    df_current = get_median_index_for_period(_filtered_df_json, current_start, current_end, index_name, sensor)
    if df_current.empty: st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ÛŒØ³Øª.", icon="âš ï¸"); return pd.DataFrame()
    df_previous = get_median_index_for_period(_filtered_df_json, prev_start, prev_end, index_name, sensor)
    if df_previous.empty: st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ÛŒØ³Øª.", icon="âš ï¸"); return pd.DataFrame()

    df_comparison = pd.merge(df_previous.rename(columns={index_name: f'{index_name}_prev'}),
                           df_current.rename(columns={index_name: f'{index_name}_curr'}), on='Ù…Ø²Ø±Ø¹Ù‡', how='inner')
    if df_comparison.empty: st.info("Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø´ØªØ±Ú©ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ø¯ÙˆØ±Ù‡ Ù†ÛŒØ³Øª."); return pd.DataFrame()

    df_comparison['ØªØºÛŒÛŒØ±'] = df_comparison[f'{index_name}_curr'] - df_comparison[f'{index_name}_prev']
    df_comparison['Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±'] = np.where(np.abs(df_comparison[f'{index_name}_prev']) > 1e-9, ((df_comparison['ØªØºÛŒÛŒØ±']/df_comparison[f'{index_name}_prev'])*100.0), np.nan)
    df_decreased = df_comparison[df_comparison['ØªØºÛŒÛŒØ±'] < 0].copy()
    df_decreased = df_decreased.sort_values(by='Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±', ascending=True, na_position='last')
    return df_decreased


# --- Streamlit App Layout ---
# (Layout remains largely the same as the previous version, using tabs, columns, etc.)
# Ensure it uses the updated function names and handles potential empty dataframes.
st.set_page_config(page_title=APP_TITLE, layout="wide", initial_sidebar_state="expanded")
st.title(f"ğŸŒ¾ {APP_TITLE}")
st.markdown("Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ùˆ Google Earth Engine")
st.divider()

if initialize_gee():
    farm_data_df = load_data(CSV_FILE_PATH)
    with st.sidebar:
        # Sidebar controls... (same as before)
        st.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ ÙÛŒÙ„ØªØ±Ù‡Ø§"); st.divider()
        st.subheader("ğŸ—“ï¸ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ"); today = datetime.date.today(); default_start = today - timedelta(days=6)
        start_date = st.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", value=default_start, max_value=today); end_date = st.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", value=today, min_value=start_date, max_value=today)
        st.info(f"Ù…Ø¯Øª Ø¯ÙˆØ±Ù‡: {(end_date - start_date).days + 1} Ø±ÙˆØ²", icon="â³"); st.divider()
        st.subheader("ğŸ” ÙÛŒÙ„ØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
        days_list = ["Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§"] + sorted(farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique().tolist())
        selected_day = st.selectbox("Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ", options=days_list)
        if selected_day == "Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§": filtered_df = farm_data_df.copy()
        else: filtered_df = farm_data_df[farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()
        st.caption(f"{len(filtered_df)} Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯.")
        available_indices = list(INDEX_DEFINITIONS.keys())
        selected_index = st.selectbox("Ø´Ø§Ø®Øµ Ù…ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„", options=available_indices, format_func=lambda x: INDEX_DEFINITIONS[x]['name_fa'])
        selected_sensor = st.radio("Ø³Ù†Ø³ÙˆØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡", ('Sentinel-2', 'Landsat'), index=0, horizontal=True); st.divider()
        st.subheader("ğŸšœ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡")
        farm_list = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + sorted(filtered_df['Ù…Ø²Ø±Ø¹Ù‡'].unique().tolist())
        selected_farm = st.selectbox("Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ (ÛŒØ§ Ù‡Ù…Ù‡)", options=farm_list); st.divider()
        st.header("â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§")
        index_to_explain = st.selectbox("Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø´Ø§Ø®Øµ:", options=list(INDEX_DEFINITIONS.keys()), index=available_indices.index(selected_index), format_func=lambda x: INDEX_DEFINITIONS[x]['name_fa'])
        if index_to_explain:
            with st.expander(f"Ø¬Ø²Ø¦ÛŒØ§Øª: {INDEX_DEFINITIONS[index_to_explain]['name_fa']}", expanded=False): st.markdown(INDEX_DEFINITIONS[index_to_explain]['desc_fa'], unsafe_allow_html=True)
        st.divider(); st.caption("v1.2 - GEE Dashboard")

    tab1, tab2, tab3 = st.tabs(["ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ Ùˆ Ø¬Ø²Ø¦ÛŒØ§Øª", "ğŸ“Š Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹", "ğŸ“‰ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ"])

    with tab1: # Map and Details
        col_map, col_detail = st.columns([2, 1])
        with col_map:
            st.subheader(f"Ù†Ù‚Ø´Ù‡: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
            st.caption(f"{start_date.strftime('%Y-%m-%d')} ØªØ§ {end_date.strftime('%Y-%m-%d')} | {selected_sensor}")
            map_placeholder = st.empty()
            m = geemap.Map(center=[INITIAL_LAT, INITIAL_LON], zoom=INITIAL_ZOOM); m.add_basemap('HYBRID')
            vis_params = INDEX_DEFINITIONS[selected_index]['vis']

            display_geom = None; target_object_for_map = None; farm_info_for_display = None
            display_df = filtered_df.copy()

            if selected_farm == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                display_df_valid = display_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
                if not display_df_valid.empty:
                    try: min_lon, min_lat, max_lon, max_lat = display_df_valid['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), display_df_valid['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), display_df_valid['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(), display_df_valid['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(); display_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat]); target_object_for_map = display_geom
                    except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø±Ø²: {e}")
                else: st.info("Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª.", icon="ğŸ“")
            else: # Single farm
                farm_info_rows = display_df[display_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm]
                if not farm_info_rows.empty:
                    farm_info_for_display = farm_info_rows.iloc[0]; farm_lat = farm_info_for_display['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']; farm_lon = farm_info_for_display['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
                    if pd.notna(farm_lat) and pd.notna(farm_lon):
                        try: farm_geom = ee.Geometry.Point([farm_lon, farm_lat]); display_geom = farm_geom.buffer(150); target_object_for_map = farm_geom
                        except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ù‚Ø·Ù‡: {e}"); farm_info_for_display = None
                    else: st.warning(f"Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {selected_farm}.", icon="ğŸ“"); farm_info_for_display = None
                else: st.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ {selected_farm} Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' Ù†ÛŒØ³Øª.", icon="âš ï¸")

            # Display Map Layer using Median Composite
            layer_added = False
            if display_geom:
                with st.spinner(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø´Ù‡ '{selected_index}'..."):
                    base_collection = get_image_collection(start_date, end_date, display_geom, selected_sensor)
                    if base_collection is not None: # Collection object exists
                         indexed_collection = calculate_single_index(base_collection, selected_index)
                         if indexed_collection is not None: # Index calculation succeeded
                             try:
                                 # **Use median composite**
                                 median_image = indexed_collection.median()
                                 if median_image.bandNames().getInfo(): # Check if median has bands
                                     layer_image = median_image.clip(display_geom) if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else median_image
                                     m.addLayer(layer_image, vis_params, f'{selected_index} (Median)')
                                     layer_added = True
                                     try: m.add_legend(title=f'{selected_index}', builtin_legend=None, **vis_params) # Use **vis_params
                                     except: pass # Ignore legend errors
                                     # Download button... (add if needed)
                                 else: st.warning(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Median Ø¨Ø±Ø§ÛŒ '{selected_index}' Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ù†Ø¯Ø§Ø´Øª.", icon="âš ï¸")
                             except ee.EEException as ee_err: st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø´Ù‡: {ee_err}")
                             except Exception as err: st.error(f"Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø´Ù‡: {err}")
                         # else: Warning from calculate_single_index
                    # else: Warning/Error from get_image_collection

            # Add markers if layer was added
            if layer_added:
                 if selected_farm == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                    df_to_mark = display_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
                    for idx, row in df_to_mark.iterrows():
                        popup_html = f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {row['Ù…Ø²Ø±Ø¹Ù‡']}<br><b>Ú©Ø§Ù†Ø§Ù„:</b> {row['Ú©Ø§Ù†Ø§Ù„']} | <b>Ø§Ø¯Ø§Ø±Ù‡:</b> {row['Ø§Ø¯Ø§Ø±Ù‡']}<br><b>Ù…Ø³Ø§Ø­Øª:</b> {row.get('Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª', 'N/A'):.2f}<br><b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {row['ÙˆØ§Ø±ÛŒØªÙ‡']} | <b>Ø³Ù†:</b> {row['Ø³Ù†']}"
                        folium.Marker([row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'],row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=popup_html, tooltip=f"{row['Ù…Ø²Ø±Ø¹Ù‡']}", icon=folium.Icon(color='blue', icon='info-sign', prefix='fa')).add_to(m)
                 elif farm_info_for_display is not None:
                    info = farm_info_for_display
                    popup_html = f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {info['Ù…Ø²Ø±Ø¹Ù‡']}<br><b>Ú©Ø§Ù†Ø§Ù„:</b> {info['Ú©Ø§Ù†Ø§Ù„']} | <b>Ø§Ø¯Ø§Ø±Ù‡:</b> {info['Ø§Ø¯Ø§Ø±Ù‡']}<br><b>Ù…Ø³Ø§Ø­Øª:</b> {info.get('Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª', 'N/A'):.2f}<br><b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {info['ÙˆØ§Ø±ÛŒØªÙ‡']} | <b>Ø³Ù†:</b> {info['Ø³Ù†']}"
                    folium.Marker([info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'],info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=popup_html, tooltip=f"{info['Ù…Ø²Ø±Ø¹Ù‡']}", icon=folium.Icon(color='red', icon='star', prefix='fa')).add_to(m)

            if target_object_for_map:
                 zoom = INITIAL_ZOOM + 2 if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else INITIAL_ZOOM
                 try: m.center_object(target_object_for_map, zoom=zoom)
                 except: m.set_center(INITIAL_LON, INITIAL_LAT, INITIAL_ZOOM)
            else: st.info("Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ù†ÛŒØ³Øª.", icon="ğŸ—ºï¸")

            with map_placeholder: m.to_streamlit(height=550)

        with col_detail: # Farm Details & Timeseries
            if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                st.subheader(f" Ø¬Ø²Ø¦ÛŒØ§Øª: {selected_farm}"); st.divider()
                if farm_info_for_display is not None:
                    info = farm_info_for_display
                    st.metric("Ú©Ø§Ù†Ø§Ù„", str(info.get('Ú©Ø§Ù†Ø§Ù„','N/A'))); st.metric("Ø§Ø¯Ø§Ø±Ù‡", str(info.get('Ø§Ø¯Ø§Ø±Ù‡','N/A')))
                    st.metric("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", f"{info['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}" if pd.notna(info.get('Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª')) else "N/A")
                    st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", str(info.get('ÙˆØ§Ø±ÛŒØªÙ‡','N/A'))); st.metric("Ø³Ù†", str(info.get('Ø³Ù†','N/A')))
                    st.metric("Ø±ÙˆØ² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", str(info.get('Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡','N/A'))); st.divider()

                    st.subheader(f"ğŸ“ˆ Ø±ÙˆÙ†Ø¯: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
                    if pd.notna(info.get('Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ')) and pd.notna(info.get('Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ')):
                        with st.spinner(f"Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ..."):
                            try: farm_geom_ts = ee.Geometry.Point([info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']]); ts_df = get_timeseries_for_farm(farm_geom_ts.toGeoJsonString(), start_date, end_date, selected_index, selected_sensor)
                            except: ts_df = pd.DataFrame() # Handle geometry error
                        if not ts_df.empty:
                            fig_ts = px.line(ts_df, x='Date', y=selected_index, title=f"Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index}", markers=True, labels={'Date':'ØªØ§Ø±ÛŒØ®', selected_index:f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                            fig_ts.update_layout(title_x=0.5); fig_ts.update_traces(line={'color':'royalblue'}, marker={'color':'salmon'})
                            st.plotly_chart(fig_ts, use_container_width=True)
                        # else: Info/Warning shown inside get_timeseries
                    else: st.warning("Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±.", icon="ğŸ“")
                else: st.info("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ³Øª.")
            else: st.subheader("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª"); st.info("ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.", icon="ğŸ‘ˆ")

    with tab2: # Ranking
        st.subheader(f"ğŸ“Š Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
        st.caption(f"{start_date.strftime('%Y-%m-%d')} ØªØ§ {end_date.strftime('%Y-%m-%d')} | Ø±ÙˆØ²: '{selected_day}' | {selected_sensor}"); st.divider()
        if filtered_df.empty: st.warning(f"Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' Ù†ÛŒØ³Øª.", icon="âš ï¸")
        else:
            with st.spinner(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ..."):
                ranking_df = get_median_index_for_period(filtered_df.to_json(), start_date, end_date, selected_index, sensor=selected_sensor)
            if not ranking_df.empty:
                ascending_sort = INDEX_DEFINITIONS[selected_index].get('sort_ascending', False)
                ranking_df_sorted = ranking_df.sort_values(by=selected_index, ascending=ascending_sort, na_position='last').reset_index(drop=True)
                st.dataframe(ranking_df_sorted.style.format({selected_index: "{:.3f}"}).bar(subset=[selected_index], color='lightcoral' if ascending_sort else 'lightgreen', align='zero'), use_container_width=True)
                csv_rank = ranking_df_sorted.to_csv(index=False).encode('utf-8'); st.download_button(label=f"ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ", data=csv_rank, file_name=f'ranking_{selected_index}_{selected_day}.csv', mime='text/csv', key='dl_rank')
            else: st.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="ğŸ“Š")
        st.divider()

    with tab3: # Weekly Comparison
        st.subheader(f"ğŸ“‰ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ (Ú©Ø§Ù‡Ø´): {INDEX_DEFINITIONS[selected_index]['name_fa']}")
        st.caption(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯ÙˆØ±Ù‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ | Ø±ÙˆØ²: '{selected_day}' | {selected_sensor}"); st.divider()
        if filtered_df.empty: st.warning(f"Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' Ù†ÛŒØ³Øª.", icon="âš ï¸")
        else:
            with st.spinner(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ..."):
                comparison_df_decreased = get_weekly_comparison(filtered_df.to_json(), start_date, end_date, selected_index, selected_sensor)
            if not comparison_df_decreased.empty:
                st.markdown("##### Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ:"); display_cols = ['Ù…Ø²Ø±Ø¹Ù‡', f'{index_name}_prev', f'{index_name}_curr', 'ØªØºÛŒÛŒØ±', 'Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±']
                st.dataframe(comparison_df_decreased[display_cols].style.format({f'{index_name}_prev': "{:.3f}", f'{index_name}_curr': "{:.3f}", 'ØªØºÛŒÛŒØ±': "{:+.3f}", 'Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±': "{:+.1f}%"})
                                     .applymap(lambda x: 'color: red' if isinstance(x,(int,float)) and x<0 else ('color: green' if isinstance(x,(int,float)) and x>0 else 'color: black'), subset=['ØªØºÛŒÛŒØ±','Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±']), use_container_width=True)
                st.divider(); st.markdown("##### Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ:")
                fig_comp = go.Figure(); fig_comp.add_trace(go.Bar(x=comparison_df_decreased['Ù…Ø²Ø±Ø¹Ù‡'], y=comparison_df_decreased[f'{index_name}_prev'], name='Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„', marker_color='dodgerblue', text=comparison_df_decreased[f'{index_name}_prev'].round(3), textposition='auto'))
                fig_comp.add_trace(go.Bar(x=comparison_df_decreased['Ù…Ø²Ø±Ø¹Ù‡'], y=comparison_df_decreased[f'{index_name}_curr'], name='Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ', marker_color='lightcoral', text=comparison_df_decreased[f'{index_name}_curr'].round(3), textposition='auto'))
                fig_comp.update_layout(barmode='group', title=f'Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø§Ø®Øµ {selected_index} (Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´)', xaxis_title='Ù…Ø²Ø±Ø¹Ù‡', yaxis_title=f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}', legend_title='Ø¯ÙˆØ±Ù‡', hovermode="x unified", title_x=0.5)
                st.plotly_chart(fig_comp, use_container_width=True); st.divider()
                csv_comp = comparison_df_decreased.to_csv(index=False).encode('utf-8'); st.download_button(label=f"ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù‚Ø§ÛŒØ³Ù‡", data=csv_comp, file_name=f'comparison_decrease_{selected_index}_{selected_day}.csv', mime='text/csv', key='dl_comp')
            else: st.success(f"âœ… Ø¹Ø¯Ù… Ú©Ø§Ù‡Ø´: Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ '{selected_index}' Ø±Ø§ Ù†Ø´Ø§Ù† Ù†Ø¯Ø§Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†Ø¨ÙˆØ¯.")

else: st.error("Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.", icon="ğŸš¨")