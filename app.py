import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
import plotly.express as px
import plotly.graph_objects as go
import os
from io import BytesIO
import requests
import traceback
from streamlit_folium import st_folium
import base64
import google.generativeai as genai
from shapely.geometry import Polygon
import pyproj
import numpy as np # Import numpy for np.nan

# Define the source CRS (likely UTM Zone 39N for Khuzestan)
# Assuming WGS 84 / UTM zone 39N based on typical data format and region
SOURCE_CRS = "EPSG:32639"
TARGET_CRS = "EPSG:4326" # WGS 84 geographic 2D

transformer = None
try:
    transformer = pyproj.Transformer.from_crs(SOURCE_CRS, TARGET_CRS, always_xy=True)
    print(f"Coordinate transformer created: {SOURCE_CRS} to {TARGET_CRS}")
except pyproj.exceptions.CRSError as e:
    st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª: {e}. Ù„Ø·ÙØ§Ù‹ Ú©Ø¯Ù‡Ø§ÛŒ EPSG {SOURCE_CRS} Ùˆ {TARGET_CRS} Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
except Exception as e:
     st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ù†Ø¯Ù‡ Ù…Ø®ØªØµØ§Øª: {e}")


# --- HARDCODED GEMINI API KEY (SECURITY RISK - NOT RECOMMENDED) ---
# As requested, the API key is hardcoded here.
# !!! WARNING: This is a security vulnerability. Anyone with access to this code
# !!! can use your API key and potentially incur costs on your account.
# !!! It is strongly recommended to use Streamlit Secrets for API keys.
# !!! https://docs.streamlit.io/develop/concepts/secrets
GEMINI_API_KEY_HARDCODED = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ"
# --- END OF HARDCODED API KEY ---


# --- Custom CSS for an Amazing and User-Friendly UI ---
st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±",
    page_icon="ğŸŒ¾",
    layout="wide",
    initial_sidebar_state="expanded" # Keep sidebar expanded by default
)

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700;900&display=swap');
        @import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css');
        @import url('https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css');

        html, body, .main, .stApp {
            font-family: 'Vazirmatn', sans-serif !important;
            background: linear-gradient(135deg, #e0f7fa 0%, #f8fafc 100%);
            color: #333;
        }

        /* Header styling with animations */
        header {
            position: sticky;
            top: 0;
            z-index: 999;
            animation: fadeIn 0.8s ease-in-out;
            backdrop-filter: blur(8px);
            -webkit-backdrop-filter: blur(8px);
            background: rgba(255, 255, 255, 0.8);
            border-bottom: 1px solid rgba(0, 0, 0, 0.1);
            padding: 0.5rem 0;
            transition: all 0.3s ease;
        }
        
        header:hover {
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        }

        /* Dark Mode Enhancements */
        @media (prefers-color-scheme: dark) {
            html, body, .main, .stApp {
                background: linear-gradient(135deg, #1a1f36 0%, #2d3748 100%);
                color: #f8f8f8;
            }
            header {
                background: rgba(30, 41, 59, 0.8);
                border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            }
            .stTabs [data-baseweb="tab-list"] button [data-baseweb="tab"] {
                color: #bbb !important;
            }
            .stTabs [data-baseweb="tab-list"] button:hover {
                color: #f8f8f8 !important;
            }
            .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
                color: #43cea2 !important;
                border-bottom-color: #43cea2 !important;
            }
            .modern-card {
                background: linear-gradient(135deg, #1a435a 0%, #2a2a2a 100%);
                color: #f8f8f8;
                box-shadow: 0 4px 16px rgba(0,0,0,0.3);
            }
            .status-positive { background-color: #218838; }
            .status-negative { background-color: #c82333; }
            .status-neutral { background-color: #5a6268; color: #fff; }
            .status-nodata { background-color: #d39e00; color: #f8f8f8;}
        }

        h1, h2, h3, h4, h5, h6 {
            color: #185a9d;
            font-weight: 700;
        }
        .stMarkdown h1 {
            color: #185a9d !important;
            animation: fadeInDown 0.5s ease-in-out;
        }

        /* Modern animated cards */
        .modern-card {
            background: linear-gradient(135deg, #43cea2 0%, #185a9d 100%);
            color: white;
            border-radius: 18px;
            padding: 20px;
            margin: 15px 0;
            box-shadow: 0 6px 20px rgba(30,60,114,0.1);
            text-align: center;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            overflow: hidden;
            position: relative;
            animation: fadeIn 0.6s ease-in-out;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .modern-card:hover {
            transform: translateY(-8px) scale(1.02);
            box-shadow: 0 15px 30px rgba(30,60,114,0.2);
        }
        .modern-card::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: linear-gradient(45deg, transparent, rgba(255,255,255,0.1), transparent);
            transform: rotate(45deg);
            transition: all 1s ease;
            opacity: 0;
        }
        .modern-card:hover::before {
            opacity: 1;
            animation: shine 1.5s ease-in-out;
        }
        .modern-card div:first-child {
            font-size: 1em;
            opacity: 0.9;
            margin-bottom: 8px;
        }
        .modern-card div:last-child {
            font-size: 2em;
            font-weight: 900;
        }

        /* Sidebar enhancements */
        .sidebar-logo {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 2rem;
            padding-top: 1rem;
            animation: pulse 2s infinite;
        }
        .sidebar-logo img {
            width: 100px;
            height: 100px;
            border-radius: 20px;
            box-shadow: 0 4px 12px rgba(30,60,114,0.15);
            transition: all 0.3s ease;
        }
        .sidebar-logo img:hover {
            transform: rotate(5deg) scale(1.05);
        }
        
        [data-testid="stSidebar"] {
            background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
            border-right: 1px solid rgba(0,0,0,0.1);
            box-shadow: 5px 0 10px rgba(0,0,0,0.05);
        }
        
        @media (prefers-color-scheme: dark) {
            [data-testid="stSidebar"] {
                background: linear-gradient(180deg, #1e2937 0%, #111827 100%);
                border-right: 1px solid rgba(255,255,255,0.1);
            }
        }

        /* Main logo animation */
        .main-logo {
            width: 55px;
            height: 55px;
            border-radius: 15px;
            margin-left: 15px;
            vertical-align: middle;
            box-shadow: 0 2px 8px rgba(30,60,114,0.1);
            transition: all 0.3s ease;
            animation: bounceIn 1s;
        }
        .main-logo:hover {
            transform: rotate(10deg) scale(1.1);
        }

        /* Tab styling enhancements */
        .stTabs [data-baseweb="tab-list"] {
            gap: 20px;
            border-bottom: 1px solid rgba(0,0,0,0.1);
            padding-bottom: 0;
            margin-bottom: 20px;
        }
        .stTabs [data-baseweb="tab-list"] button {
            background-color: transparent;
            padding: 12px 20px;
            border-radius: 8px 8px 0 0;
            border-bottom: 3px solid transparent;
            transition: all 0.3s ease;
            font-weight: 700;
            color: #555;
            position: relative;
            overflow: hidden;
        }
        .stTabs [data-baseweb="tab-list"] button:hover {
            background-color: rgba(67, 206, 162, 0.1);
            color: #185a9d;
            border-bottom-color: rgba(67, 206, 162, 0.5);
        }
        .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
            background-color: rgba(67, 206, 162, 0.15);
            border-bottom-color: #43cea2;
            color: #185a9d;
            box-shadow: 0 -2px 8px rgba(30,60,114,0.05);
        }
        .stTabs [data-baseweb="tab-list"] button[aria-selected="true"]::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 100%;
            height: 3px;
            background: linear-gradient(90deg, #43cea2, #185a9d);
            animation: slideInRight 0.3s ease-out;
        }
        .stTabs [data-baseweb="tab-panel"] {
            padding: 25px 5px;
            animation: fadeIn 0.5s ease-in-out;
        }

        /* Status badges enhancements */
        .status-badge {
            display: inline-block;
            padding: 0.4em 0.8em;
            font-size: 0.85em;
            font-weight: bold;
            line-height: 1.2;
            text-align: center;
            white-space: nowrap;
            vertical-align: middle;
            border-radius: 0.5rem;
            color: #fff;
            margin: 3px;
            transition: all 0.3s ease;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            animation: fadeIn 0.5s ease-in-out;
        }
        .status-badge:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.15);
        }
        .status-positive { 
            background: linear-gradient(90deg, #28a745, #1e7e34);
        }
        .status-negative { 
            background: linear-gradient(90deg, #dc3545, #bd2130);
        }
        .status-neutral { 
            background: linear-gradient(90deg, #6c757d, #5a6268);
            color: #fff;
        }
        .status-nodata { 
            background: linear-gradient(90deg, #ffc107, #d39e00);
            color: #212529;
        }

        /* Table enhancements */
        table {
            border-collapse: separate;
            border-spacing: 0;
            width: 100%;
            margin: 20px 0;
            box-shadow: 0 4px 15px rgba(0,0,0,0.05);
            border-radius: 10px;
            overflow: hidden;
            animation: fadeIn 0.5s ease-in-out;
        }
        
        table thead tr {
            background: linear-gradient(90deg, #43cea2, #185a9d);
            color: white;
        }
        
        table th {
            padding: 12px 15px;
            text-align: right;
            font-weight: bold;
        }
        
        table td {
            padding: 10px 15px;
            border-bottom: 1px solid rgba(0,0,0,0.05);
        }
        
        table tbody tr {
            transition: all 0.3s ease;
        }
        
        table tbody tr:hover {
            background-color: rgba(67, 206, 162, 0.05);
            transform: scale(1.005);
        }
        
        table tbody tr:last-child td {
            border-bottom: none;
        }
        
        /* Button enhancements */
        .stButton > button {
            border-radius: 8px;
            padding: 0.5rem 1rem;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(50, 50, 93, 0.11), 0 1px 3px rgba(0, 0, 0, 0.08);
            border: none;
            background: linear-gradient(135deg, #43cea2 0%, #185a9d 100%);
            color: white;
            position: relative;
            overflow: hidden;
        }
        
        .stButton > button:hover {
            transform: translateY(-2px);
            box-shadow: 0 7px 14px rgba(50, 50, 93, 0.1), 0 3px 6px rgba(0, 0, 0, 0.08);
        }
        
        .stButton > button:active {
            transform: translateY(1px);
        }
        
        .stButton > button::after {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 5px;
            height: 5px;
            background: rgba(255, 255, 255, 0.5);
            opacity: 0;
            border-radius: 100%;
            transform: scale(1, 1) translate(-50%, -50%);
            transform-origin: 50% 50%;
        }
        
        .stButton > button:hover::after {
            animation: ripple 1s ease-out;
            opacity: 0;
        }
        
        /* Select box enhancements */
        .stSelectbox {
            border-radius: 8px;
            overflow: hidden;
        }
        
        .stSelectbox > div > div[data-baseweb="select"] {
            transition: all 0.3s ease;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }
        
        .stSelectbox > div > div[data-baseweb="select"]:hover {
            box-shadow: 0 4px 10px rgba(0,0,0,0.1);
            transform: translateY(-1px);
        }
        
        /* Animation keyframes */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        
        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        @keyframes slideInRight {
            from { 
                width: 0;
            }
            to {
                width: 100%;
            }
        }
        
        @keyframes bounceIn {
            0% {
                opacity: 0;
                transform: scale(0.3);
            }
            50% {
                opacity: 1;
                transform: scale(1.05);
            }
            70% { transform: scale(0.9); }
            100% { transform: scale(1); }
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        @keyframes ripple {
            0% {
                transform: scale(0, 0);
                opacity: 0.5;
            }
            100% {
                transform: scale(100, 100);
                opacity: 0;
            }
        }
        
        @keyframes shine {
            0% {
                left: -100%;
                opacity: 0;
            }
            100% {
                left: 100%;
                opacity: 0.3;
            }
        }
    </style>
""", unsafe_allow_html=True)


def status_badge(status: str) -> str:
    """Returns HTML for a status badge with color."""
    if "Ø¨Ù‡Ø¨ÙˆØ¯" in status or "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª" in status or "Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª" in status: # Added NDMI positive
        badge_class = "status-positive"
    elif "ØªÙ†Ø´" in status or "Ú©Ø§Ù‡Ø´" in status or "Ø¨Ø¯ØªØ± Ø´Ø¯Ù†" in status or "Ù†ÛŒØ§Ø²" in status: # Added NDMI negative
        badge_class = "status-negative"
    elif "Ø«Ø§Ø¨Øª" in status or "Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª" in status or "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ†" in status or "Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡" in status: # Added NDMI neutral/warning
        badge_class = "status-neutral"
    elif "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" in status or "N/A" in status:
         badge_class = "status-nodata"
    else:
        badge_class = "status-neutral"

    return f'<span class="status-badge {badge_class}">{status}</span>'

def modern_metric_card(title: str, value: str, icon: str, color: str) -> str:
    """
    Returns a modern styled HTML card for displaying a metric.
    :param title: Title of the metric
    :param value: Value of the metric
    :param icon: FontAwesome icon class (e.g., 'fa-leaf')
    :param color: Accent color for the card background gradient
    :return: HTML string
    """
    return f'''
    <div class="modern-card" style="background: linear-gradient(135deg, {color} 0%, #185a9d 100%);">
        <div>{title} <i class="fa {icon}"></i></div>
        <div>{value}</div>
    </div>
    '''

def modern_progress_bar(progress: float) -> str:
    """
    Returns a modern styled HTML progress bar for Streamlit.
    :param progress: float between 0 and 1
    :return: HTML string
    """
    percent = max(0, min(100, int(progress * 100)))
    color_start = '#dc3545'
    color_mid = '#ffc107'
    color_end = '#28a745'

    if percent <= 50:
        r = int(0xdc + (0xff - 0xdc) * (percent / 50))
        g = int(0x35 + (0xc1 - 0x35) * (percent / 50))
        b = int(0x45 + (0x07 - 0x45) * (percent / 50))
        current_color = f"#{r:02x}{g:02x}{b:02x}"
        background_gradient = f"linear-gradient(90deg, {color_start} 0%, {current_color} 100%)"
    else:
        r = int(0xff + (0x28 - 0xff) * ((percent - 50) / 50))
        g = int(0xc1 + (0xa7 - 0xc1) * ((percent - 50) / 50))
        b = int(0x07 + (0x45 - 0x07) * ((percent - 50) / 50))
        current_color = f"#{r:02x}{g:02x}{b:02x}"
        background_gradient = f"linear-gradient(90deg, {color_mid} 0%, {current_color} 100%)"

    if percent == 100:
        background_gradient = f"linear-gradient(90deg, {color_end} 0%, #1a9850 100%)"


    return f'''
    <div style="width: 100%; background: #e0f7fa; border-radius: 12px; height: 22px; margin: 8px 0; box-shadow: 0 2px 8px rgba(30,60,114,0.08); overflow: hidden; position: relative;">
      <div style="width: {percent}%; background: {background_gradient}; height: 100%; border-radius: 12px; transition: width 0.3s ease-in-out;"></div>
      <span style="position: absolute; left: 50%; top: 0; transform: translateX(-50%); color: #185a9d; font-weight: bold; line-height: 22px; text-shadow: 0 0 2px rgba(255,255,255,0.5); /* Add subtle text shadow for readability */">
          {percent}%
      </span>
    </div>
    '''

st.sidebar.markdown(
    """
    <div class='sidebar-logo'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' alt='Ù„ÙˆÚ¯Ùˆ Ø³Ø§Ù…Ø§Ù†Ù‡' />
    </div>
    """,
    unsafe_allow_html=True
)

st.markdown(
    """
    <div style='display: flex; align-items: center; gap: 16px; margin-bottom: 0.5rem;'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' class='main-logo' alt='Ù„ÙˆÚ¯Ùˆ' />
        <h1 style='font-family: Vazirmatn, sans-serif; color: #185a9d; margin: 0;'>Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±</h1>
    </div>
    <h4 style='color: #43cea2; margin-top: 0;'>Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§</h4>
    """,
    unsafe_allow_html=True
)

APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±"
APP_SUBTITLE = "Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

FARM_DATA_CSV_PATH = 'merged_farm_data_renamed (1).csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'
ANALYSIS_CSV_PATH = 'Ù…Ø­Ø§Ø³Ø¨Ø§Øª 2.csv'


@st.cache_resource(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine...")
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if os.path.exists(SERVICE_ACCOUNT_FILE):
            credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
            print("GEE Initialized Successfully using Service Account File.")
        else:
            try:
                if "gee_auth_json" in st.secrets:
                    auth_info = json.loads(st.secrets["gee_auth_json"])
                    credentials = ee.ServiceAccountCredentials(auth_info['client_email'], None, private_key_id=auth_info['private_key_id'], private_key=auth_info['private_key'], token_uri=auth_info['token_uri'])
                    print("GEE Initialized Successfully using Streamlit Secrets JSON.")
                else:
                     raise ValueError("GEE credentials not found in secrets ('gee_auth_json').")

            except Exception as e:
                 st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Service Account Ø§Ø² Secrets: {e}")
                 st.info("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØªÙ†Ø¸ÛŒÙ… ØµØ­ÛŒØ­ Secrets Ø¨Ø±Ø§ÛŒ Google Earth Engine Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯. (Ø¨Ù‡ Ø®ØµÙˆØµ secret 'gee_auth_json').")
                 return None

        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully.")
        return True
    except ee.EEException as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª ÙØ§ÛŒÙ„ Service Account ÛŒØ§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Secrets Ùˆ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø¢Ù† Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ GEE Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        return None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.error(traceback.format_exc())
        return None


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...", persist="disk") # Corrected persist option
def load_farm_data_from_csv(csv_path=FARM_DATA_CSV_PATH):
    """Loads farm data from the specified CSV file and processes coordinates."""
    if transformer is None:
         st.error("âŒ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ù†Ø¯Ù‡ Ù…Ø®ØªØµØ§Øª Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.")
         return pd.DataFrame()

    try:
        df = None
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path, encoding='utf-8')
            print(f"Loaded Farm data from local CSV: {csv_path}")
        else:
            github_raw_url = f'https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/{csv_path}'
            try:
                response = requests.get(github_raw_url)
                response.raise_for_status()
                df = pd.read_csv(BytesIO(response.content), encoding='utf-8')
                print(f"Loaded Farm data from URL: {github_raw_url}")
            except requests.exceptions.RequestException as e:
                 st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' Ø¯Ø± Ù…Ø³ÛŒØ± Ù…Ø­Ù„ÛŒ ÛŒØ§ Ø§Ø² URL Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ '{github_raw_url}' ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ù†ÛŒØ³Øª: {e}")
                 return pd.DataFrame()
            except Exception as e:
                 st.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ CSV Ø§Ø² URL: {e}")
                 return pd.DataFrame()


        if df is None or df.empty:
             st.error("âŒ ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª ÛŒØ§ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù†Ø´Ø¯.")
             return pd.DataFrame()


        df.columns = df.columns.str.strip().str.replace('\ufeff', '')

        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø±ÙˆØ²', 'lat1', 'lon1', 'lat2', 'lon2', 'lat3', 'lon3', 'lat4', 'lon4']
        if not all(col in df.columns for col in required_cols):
            missing_cols = [col for col in required_cols if col not in df.columns]
            st.error(f"âŒ ÙØ§ÛŒÙ„ CSV Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø§Ø´Ø¯. Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯: {', '.join(missing_cols)}")
            return pd.DataFrame()

        df['wgs84_centroid_lon'] = None
        df['wgs84_centroid_lat'] = None
        df['ee_geometry'] = None
        df['wgs84_polygon_coords'] = None

        processed_records = []
        skipped_farms = []

        for index, row in df.iterrows():
            farm_name = row.get('Ù…Ø²Ø±Ø¹Ù‡', f'Ù…Ø²Ø±Ø¹Ù‡ Ù†Ø§Ø´Ù†Ø§Ø³ Ø±Ø¯ÛŒÙ {index+1}')
            try:
                points_utm = []
                valid_points = True
                for i in range(1, 5):
                    lat_col = f'lat{i}'
                    lon_col = f'lon{i}'
                    if pd.notna(row.get(lat_col)) and pd.notna(row.get(lon_col)):
                        try:
                            easting = float(row[lon_col])
                            northing = float(row[lat_col])
                            points_utm.append((easting, northing))
                        except ValueError:
                            valid_points = False
                            break
                    else:
                        valid_points = False
                        break


                if not valid_points or len(points_utm) < 4:
                    skipped_farms.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}': Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± ÛŒØ§ Ù†Ø§Ù‚Øµ (Ù†ÛŒØ§Ø² Ø¨Ù‡ Û´ Ù†Ù‚Ø·Ù‡).")
                    continue


                points_wgs84 = []
                try:
                    for easting, northing in points_utm:
                         lon_wgs84, lat_wgs84 = transformer.transform(easting, northing)
                         points_wgs84.append((lon_wgs84, lat_wgs84))
                except pyproj.exceptions.TransformerError as te:
                     skipped_farms.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}': Ø®Ø·Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…Ø®ØªØµØ§Øª UTM Ø¨Ù‡ WGS84: {te}")
                     continue
                except Exception as e:
                     skipped_farms.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}': Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù…Ø®ØªØµØ§Øª: {e}")
                     continue


                if points_wgs84[-1] != points_wgs84[0]:
                     polygon_coords_wgs84 = points_wgs84 + [points_wgs84[0]]
                else:
                     polygon_coords_wgs84 = points_wgs84

                try:
                    shapely_polygon = Polygon(polygon_coords_wgs84)
                    if not shapely_polygon.is_valid:
                         shapely_polygon = shapely_polygon.buffer(0)
                         if not shapely_polygon.is_valid:
                             skipped_farms.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}': Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ† WGS84 Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯ Ù¾Ø³ Ø§Ø² buffer(0).")
                             continue

                    ee_polygon = ee.Geometry.Polygon(list(shapely_polygon.exterior.coords))

                    centroid_ee = ee_polygon.centroid(maxError=1)
                    centroid_coords_wgs84 = centroid_ee.getInfo()['coordinates']
                    centroid_lon_wgs84, centroid_lat_wgs84 = centroid_coords_wgs84[0], centroid_coords_wgs84[1]

                    processed_row = row.copy()
                    processed_row['wgs84_centroid_lon'] = centroid_lon_wgs84
                    processed_row['wgs84_centroid_lat'] = centroid_lat_wgs84
                    processed_row['ee_geometry'] = ee_polygon
                    processed_row['wgs84_polygon_coords'] = [list(coord) for coord in shapely_polygon.exterior.coords]

                    processed_records.append(processed_row)

                except ee.EEException as ee_geom_e:
                    skipped_farms.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}': Ø®Ø·Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ù†Ø¯Ø³Ù‡ GEE ÛŒØ§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Centroid: {ee_geom_e}")
                    continue
                except Exception as e:
                    skipped_farms.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}': Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù†Ø¯Ø³Ù‡: {e}")
                    continue


            except Exception as e:
                skipped_farms.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}': Ø®Ø·Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø¯ÛŒÙ: {e}")
                continue

        processed_df = pd.DataFrame(processed_records)

        if skipped_farms:
            st.warning("âš ï¸ Ø¨Ø±Ø®ÛŒ Ø§Ø² Ù…Ø²Ø§Ø±Ø¹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø®ØªØµØ§Øª ÛŒØ§ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù†Ø¯:")
            for msg in skipped_farms[:10]:
                 st.warning(f"- {msg}")
            if len(skipped_farms) > 10:
                 st.warning(f"... Ùˆ {len(skipped_farms) - 10} Ø®Ø·Ø§ÛŒ Ø¯ÛŒÚ¯Ø±.")


        if processed_df.empty:
            st.error("âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯.")
            return pd.DataFrame()


        for col in ['Ø±ÙˆØ²', 'Ú¯Ø±ÙˆÙ‡', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†']:
            if col in processed_df.columns:
                processed_df[col] = processed_df[col].astype(str).str.replace(r'\s+', ' ', regex=True).str.strip()
                processed_df[col] = processed_df[col].replace(['nan', ''], 'Ù†Ø§Ù…Ø´Ø®Øµ')
            else:
                 processed_df[col] = 'Ù†Ø§Ù…Ø´Ø®Øµ'

        if 'Ù…Ø³Ø§Ø­Øª' in processed_df.columns:
             processed_df['Ù…Ø³Ø§Ø­Øª'] = pd.to_numeric(processed_df['Ù…Ø³Ø§Ø­Øª'], errors='coerce')
             processed_df['Ù…Ø³Ø§Ø­Øª'] = processed_df['Ù…Ø³Ø§Ø­Øª'].fillna(0)
        else:
            processed_df['Ù…Ø³Ø§Ø­Øª'] = 0


        st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {len(processed_df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² CSV Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯.")
        return processed_df
    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ CSV Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        st.error(traceback.format_exc())
        return pd.DataFrame()


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª...", persist="disk") # Corrected persist option
def load_analysis_data(csv_path=ANALYSIS_CSV_PATH):
    """Loads and preprocesses data from the analysis CSV file."""
    try:
        lines = None
        if os.path.exists(csv_path):
            with open(csv_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            print(f"Loaded Analysis CSV from local path: {csv_path}")
        else:
             github_raw_url = f'https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/{csv_path}'
             try:
                 response = requests.get(github_raw_url)
                 response.raise_for_status()
                 lines = response.text.splitlines()
                 print(f"Loaded Analysis CSV from URL: {github_raw_url}")
             except requests.exceptions.RequestException as e:
                 st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' Ø¯Ø± Ù…Ø³ÛŒØ± Ù…Ø­Ù„ÛŒ ÛŒØ§ Ø§Ø² URL Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ '{github_raw_url}' ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ù†ÛŒØ³Øª: {e}")
                 return None, None
             except Exception as e:
                 st.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ CSV Ø§Ø² URL: {e}")
                 return None, None


        if lines is None:
             return None, None


        headers_indices = [i for i, line in enumerate(lines) if line.strip().lstrip('\ufeff').startswith('Ø§Ø¯Ø§Ø±Ù‡,Ø³Ù†,') or line.strip().lstrip('\ufeff').startswith('ØªÙˆÙ„ÛŒØ¯,Ø³Ù†,')]

        if len(headers_indices) < 1:
            st.error(f"âŒ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„ '{csv_path}' Ù‚Ø§Ø¨Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ³Øª. Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± ('Ø§Ø¯Ø§Ø±Ù‡,Ø³Ù†,' ÛŒØ§ 'ØªÙˆÙ„ÛŒØ¯,Ø³Ù†,') ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return None, None

        section1_start_line_num = headers_indices[0]
        section2_start_line_num = len(lines)

        if len(headers_indices) > 1:
            section2_start_line_num = headers_indices[1]

        end_row_area_line_num = section2_start_line_num

        try:
            area_section_io = BytesIO("\n".join(lines[section1_start_line_num : end_row_area_line_num]).encode('utf-8'))
            df_area = pd.read_csv(area_section_io, encoding='utf-8')
        except Exception as e:
             st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ø®Ø´ Ù…Ø³Ø§Ø­Øª Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª: {e}")
             df_area = pd.DataFrame()


        df_prod = pd.DataFrame()
        if len(headers_indices) > 1:
             end_row_prod_line_num = len(lines)
             for i in range(section2_start_line_num + 1, len(lines)):
                 if "Grand Total" in lines[i] or len(lines[i].strip()) < 5:
                     end_row_prod_line_num = i
                     break

             try:
                  prod_section_io = BytesIO("\n".join(lines[section2_start_line_num : end_row_prod_line_num]).encode('utf-8'))
                  df_prod = pd.read_csv(prod_section_io, encoding='utf-8')
             except Exception as e:
                  st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ø®Ø´ ØªÙˆÙ„ÛŒØ¯ Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª: {e}")
                  df_prod = pd.DataFrame()


        def preprocess_df(df, section_name):
            if df is None or df.empty:
                return None

            df.columns = df.columns.str.strip().str.replace('\ufeff', '')

            if df.columns.tolist() and 'Ø§Ø¯Ø§Ø±Ù‡' not in df.columns:
                df.rename(columns={df.columns[0]: 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)


            if not all(col in df.columns for col in ['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†']):
                 st.warning(f"âš ï¸ Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ 'Ø§Ø¯Ø§Ø±Ù‡' ÛŒØ§ 'Ø³Ù†' Ø¯Ø± Ø¨Ø®Ø´ '{section_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                 return None

            df['Ø§Ø¯Ø§Ø±Ù‡'] = df['Ø§Ø¯Ø§Ø±Ù‡'].ffill()

            df = df[~df['Ø³Ù†'].astype(str).str.contains('total', case=False, na=False)].copy()
            df = df[~df['Ø§Ø¯Ø§Ø±Ù‡'].astype(str).str.contains('total|Ø¯Ù‡Ø®Ø¯Ø§', case=False, na=False)].copy()

            df = df.dropna(subset=['Ø§Ø¯Ø§Ø±Ù‡']).copy()

            df['Ø§Ø¯Ø§Ø±Ù‡'] = pd.to_numeric(df['Ø§Ø¯Ø§Ø±Ù‡'], errors='coerce').astype('Int64')
            df = df.dropna(subset=['Ø§Ø¯Ø§Ø±Ù‡']).copy()

            value_cols = [col for col in df.columns if col not in ['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†', 'Ø¯Ø±ØµØ¯', 'Grand Total']]
            for col in value_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            df = df.dropna(axis=1, how='all').copy()

            df = df.drop(columns=['Grand Total', 'Ø¯Ø±ØµØ¯'], errors='ignore')

            if 'Ø§Ø¯Ø§Ø±Ù‡' in df.columns and 'Ø³Ù†' in df.columns:
                try:
                    df = df.set_index(['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†']).copy()
                except ValueError as e:
                     st.warning(f"âš ï¸ Ø®Ø·Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø§ÛŒÙ†Ø¯Ú©Ø³ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡ Ø¯Ø± Ø¨Ø®Ø´ '{section_name}': {e}. Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ø§ÛŒÙ†Ø¯Ú©Ø³.")

            return df

        df_area_processed = preprocess_df(df_area, "Ù…Ø³Ø§Ø­Øª")
        df_prod_processed = preprocess_df(df_prod, "ØªÙˆÙ„ÛŒØ¯")

        if df_area_processed is not None or df_prod_processed is not None:
             st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯.")
        else:
             st.warning("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„ 'Ù…Ø­Ø§Ø³Ø¨Ø§Øª 2.csv' Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")

        return df_area_processed, df_prod_processed

    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ CSV Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        return None, None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª CSV: {e}")
        st.error(traceback.format_exc())
        return None, None


gee_initialized = initialize_gee()

farm_data_df = pd.DataFrame()
if transformer is not None:
    farm_data_df = load_farm_data_from_csv()
else:
     st.error("âŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.")


analysis_area_df, analysis_prod_df = load_analysis_data()


@st.cache_resource(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
def configure_gemini(api_key): # Accept API key as parameter
    """Configures the Gemini API client."""
    try:
        if not api_key:
             st.error("âŒ Ú©Ù„ÛŒØ¯ API Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
             st.info("Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯ API Ø±Ø§ Ø¯Ø± Ú©Ø¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ ÛŒØ§ Ø¯Ø± Streamlit Secrets ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.")
             return None

        genai.configure(api_key=api_key)

        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings)
        print("Gemini Configured Successfully.")
        return model
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… Gemini API: {e}")
        st.error(traceback.format_exc())
        return None


# Initialize Gemini model AFTER its definition
gemini_model = None
if gee_initialized:
    # Use the hardcoded API key
    gemini_model = configure_gemini(GEMINI_API_KEY_HARDCODED)
    if gemini_model is None:
         st.warning("âš ï¸ Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
    # Add a prominent warning about hardcoding the API key
    st.warning("âš ï¸ **Ù‡Ø´Ø¯Ø§Ø± Ø§Ù…Ù†ÛŒØªÛŒ:** Ú©Ù„ÛŒØ¯ API Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¯Ø± Ú©Ø¯ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø§ÛŒÙ† Ø±ÙˆØ´ **Ù†Ø§Ø§Ù…Ù†** Ø§Ø³Øª Ùˆ Ø¨Ù‡ Ø´Ø¯Øª ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§Ø² Streamlit Secrets Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù…Ù† Ú©Ù„ÛŒØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.", icon="ğŸ”’")


# --- Sidebar Logo ---
st.sidebar.markdown(
    """
    <div class='sidebar-logo'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' alt='Ù„ÙˆÚ¯Ùˆ Ø³Ø§Ù…Ø§Ù†Ù‡' />
    </div>
    """,
    unsafe_allow_html=True
)

# --- Main Header with Logo ---
st.markdown(
    """
    <div style='display: flex; align-items: center; gap: 16px; margin-bottom: 0.5rem;'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' class='main-logo' alt='Ù„ÙˆÚ¯Ùˆ' />
        <h1 style='font-family: Vazirmatn, sans-serif; color: #185a9d; margin: 0;'>Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±</h1>
    </div>
    <h4 style='color: #43cea2; margin-top: 0;'>Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§</h4>
    """,
    unsafe_allow_html=True
)

# ==============================================================================
# Sidebar Filters (Moved here, after data loading)
# ==============================================================================
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

selected_day = None
if not farm_data_df.empty and 'Ø±ÙˆØ²' in farm_data_df.columns:
    available_days = sorted(farm_data_df['Ø±ÙˆØ²'].unique())
    if not available_days or (len(available_days) == 1 and available_days[0] == 'Ù†Ø§Ù…Ø´Ø®Øµ'):
         st.sidebar.warning("Ù‡ÛŒÚ† Ø±ÙˆØ² Ù‡ÙØªÙ‡â€ŒØ§ÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
         selected_day = None
    else:
         valid_days = [d for d in available_days if d != 'Ù†Ø§Ù…Ø´Ø®Øµ']
         if not valid_days:
              st.sidebar.warning("Ù‡ÛŒÚ† Ø±ÙˆØ² Ù‡ÙØªÙ‡â€ŒØ§ÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
              selected_day = None
         else:
            selected_day = st.sidebar.selectbox(
                "ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
                options=valid_days,
                index=0,
                help="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø±ÙˆØ² ÙÛŒÙ„ØªØ± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯."
            )
else:
     st.sidebar.info("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
     selected_day = None


filtered_farms_df = pd.DataFrame()
if selected_day and not farm_data_df.empty:
    filtered_farms_df = farm_data_df[farm_data_df['Ø±ÙˆØ²'] == selected_day].copy()

selected_farm_name = "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"
available_farms = []
if not filtered_farms_df.empty:
    available_farms = sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique())
    farm_options = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + available_farms
    selected_farm_name = st.sidebar.selectbox(
        "ğŸŒ¾ Ù…Ø²Ø±Ø¹Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        options=farm_options,
        index=0,
        help="Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¢Ù† Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯ ÛŒØ§ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ."
    )
else:
    st.sidebar.info("â„¹ï¸ Ù…Ø²Ø§Ø±Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


index_options = {
    "NDVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªÙØ§Ø¶Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡",
    "EVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡",
    "NDMI": "Ø´Ø§Ø®Øµ Ø±Ø·ÙˆØ¨ØªÛŒ ØªÙØ§Ø¶Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡",
    "LAI": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
    "MSI": "Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ",
    "CVI": "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
    "SAVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªØ¹Ø¯ÛŒÙ„ Ø´Ø¯Ù‡ Ø¨Ø§ Ø®Ø§Ú©",
}
selected_index = st.sidebar.selectbox(
    "ğŸ“ˆ Ø´Ø§Ø®Øµ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ùˆ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:",
    options=list(index_options.keys()),
    format_func=lambda x: f"{x} ({index_options[x]})",
    index=0
)

today = datetime.date.today()
start_date_current_str = None
end_date_current_str = None
start_date_previous_str = None
end_date_previous_str = None

if selected_day:
    try:
        persian_to_weekday = {
            "Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1,
            "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4,
        }
        target_weekday = persian_to_weekday[selected_day.strip()]
        today_weekday = today.weekday()

        days_ago = (today_weekday - target_weekday + 7) % 7
        end_date_current = today - datetime.timedelta(days=days_ago)

        start_date_current = end_date_current - datetime.timedelta(days=6)

        end_date_previous = start_date_current - datetime.timedelta(days=1)
        start_date_previous = end_date_previous - datetime.timedelta(days=6)

        # Ensure previous start date is not too far back if needed
        one_year_ago = today - datetime.timedelta(days=365)
        if start_date_previous < one_year_ago:
             start_date_previous = one_year_ago
             st.sidebar.info(f"âš ï¸ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ù‡ ÛŒÚ© Ø³Ø§Ù„ Ù‚Ø¨Ù„ Ù…Ø­Ø¯ÙˆØ¯ Ø´Ø¯: {start_date_previous.strftime('%Y-%m-%d')}")


        start_date_current_str = start_date_current.strftime('%Y-%m-%d')
        end_date_current_str = end_date_current.strftime('%Y-%m-%d')
        start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
        end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')

        st.sidebar.info(f"**Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÙØ¹Ù„ÛŒ:** {start_date_current_str} ØªØ§ {end_date_current_str}")
        st.sidebar.info(f"**Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù‚Ø¨Ù„ÛŒ:** {start_date_previous_str} ØªØ§ {end_date_previous_str}")

    except KeyError:
        st.sidebar.error(f"âŒ Ù†Ø§Ù… Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ù‚Ø§Ø¨Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø±ÙˆØ² Ù…Ø¹ØªØ¨Ø±ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
    except Exception as e:
        st.sidebar.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}")
        st.error(traceback.format_exc())

st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ â¤ï¸ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Streamlit, Google Earth Engine, Ùˆ geemap")


def maskS2clouds(image):
    qa = image.select('QA60')
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    mask_qa = qa.bitwiseAnd(cloudBitMask).eq(0).And(
             qa.bitwiseAnd(cirrusBitMask).eq(0))

    scl = image.select('SCL')
    # Sentinel-2 SCL band values:
    # 0: No Data (Mask)
    # 1: Saturated or defective pixel
    # 2: Dark Area Pixels
    # 3: Cloud Shadows
    # 4: Vegetation
    # 5: Not Vegetated
    # 6: Water
    # 7: Unclassified
    # 8: Cloud Medium Probability
    # 9: Cloud High Probability
    # 10: Thin Cirrus
    # 11: Snow/Ice
    # Masking out: No Data, Saturated, Dark Area, Cloud Shadows, Cloud High Probability, Thin Cirrus, Snow/Ice
    masked_classes_scl = [0, 1, 2, 3, 9, 10, 11]
    mask_scl = scl.remap(masked_classes_scl, [0] * len(masked_classes_scl), 1).eq(1)


    final_mask = mask_qa.And(mask_scl)
    opticalBands = image.select('B.*').multiply(0.0001)

    return image.addBands(opticalBands, None, True)\
                .updateMask(final_mask)

def add_indices(image):
    red = image.select('B4')
    nir = image.select('B8')
    blue = image.select('B2')
    green = image.select('B3')
    swir1 = image.select('B11')

    epsilon = 1e-9

    ndvi_denominator = nir.add(red)
    ndvi = image.expression(
        '(NIR - RED) / (NIR + RED)',
        {'NIR': nir, 'RED': red}
    ).rename('NDVI').updateMask(ndvi_denominator.gt(epsilon))

    evi_denominator = nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)
    evi = image.expression(
        '2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1)',
        {'NIR': nir, 'RED': red, 'BLUE': blue}
    ).rename('EVI').updateMask(evi_denominator.abs().gt(epsilon))

    ndmi_denominator = nir.add(swir1)
    ndmi = image.normalizedDifference(['B8', 'B11']).rename('NDMI').updateMask(ndmi_denominator.gt(epsilon))

    savi_denominator = nir.add(red).add(0.5)
    savi = image.expression(
        '((NIR - RED) / (NIR + RED + L)) * (1 + L)',
        {'NIR': nir, 'RED': red, 'L': 0.5}
    ).rename('SAVI').updateMask(savi_denominator.gt(epsilon))

    nir_safe = nir.max(ee.Image(epsilon))
    msi = image.expression('SWIR1 / NIR', {'SWIR1': swir1, 'NIR': nir_safe}).rename('MSI')

    lai = evi.multiply(3.618).subtract(0.118).rename('LAI').reproject(crs=image.projection().crs(), scale=10)
    lai = lai.updateMask(lai.gt(0))

    green_safe = green.max(ee.Image(epsilon))
    cvi = image.expression('(NIR / GREEN) * (RED / GREEN)',
                         {'NIR': nir, 'GREEN': green_safe, 'RED': red}
    ).rename('CVI').reproject(crs=image.projection().crs(), scale=10)

    return image.addBands([ndvi, evi, ndmi, msi, lai, cvi, savi])

@st.cache_data(show_spinner=False, persist="disk")
def get_processed_image(_geometry, start_date, end_date, index_name):
    """
    Gets cloud-masked, index-calculated Sentinel-2 median composite for a given geometry and date range.
    Includes fallback date range logic if no images are found initially.
    Ensures a non-None error message is returned if the image is None.
    """
    if not gee_initialized:
        return None, "Google Earth Engine Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."
    if _geometry is None:
        return None, "Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ GEE ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."

    initial_start_date = start_date
    initial_end_date = end_date
    fallback_days = 30 # Increased fallback period


    def filter_and_process_collection(s_date, e_date):
        try:
            s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                         .filterBounds(_geometry)
                         .filterDate(s_date, e_date)
                         .map(maskS2clouds))

            count = s2_sr_col.size().getInfo()
            if count == 0:
                return None, 0, f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± Sentinel-2 Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø± Ø¯Ø± Ø¨Ø§Ø²Ù‡ {s_date} ØªØ§ {e_date} ÛŒØ§ÙØª Ù†Ø´Ø¯."

            indexed_col = s2_sr_col.map(add_indices)
            median_image = indexed_col.median()

            available_bands = median_image.bandNames().getInfo()
            if index_name not in available_bands:
                 # Attempt to select another common band to see if the image is valid otherwise
                 test_band = 'B4' if 'B4' in available_bands else (available_bands[0] if available_bands else None)
                 if test_band:
                     try:
                         # Test reducing a small region with the available band
                          test_region = _geometry.centroid(1).buffer(10) # Small buffer around centroid
                          median_image.select(test_band).reduceRegion(ee.Reducer.first(), test_region, 10).getInfo()
                          # If above works, the issue is band calculation/availability
                          return None, count, f"Ø´Ø§Ø®Øµ '{index_name}' Ø¯Ø± ØªØµØ§ÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ø´Ø¯). Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {', '.join(available_bands)}"
                     except Exception as band_test_e:
                          # If even testing another band fails, likely a broader issue
                          return None, count, f"Ø´Ø§Ø®Øµ '{index_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯ Ùˆ Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ù†ÛŒØ² ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯: {band_test_e}. Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {', '.join(available_bands)}"
                 else: # No bands available at all
                     return None, count, f"Ø´Ø§Ø®Øµ '{index_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯ Ùˆ Ù‡ÛŒÚ† Ø¨Ø§Ù†Ø¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± ØªØµÙˆÛŒØ± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."


            # Select the band before returning
            output_image = median_image.select(index_name)

            # Final validity check: Ensure the selected band has data over the geometry
            try:
                test_reduction = output_image.reduceRegion(
                    reducer=ee.Reducer.firstNonNull(), # Check if there's any non-null pixel
                    geometry=_geometry,
                    scale=30, # Use slightly coarser scale for faster check
                    bestEffort=True
                ).get(index_name).getInfo()
                if test_reduction is None:
                     return None, count, f"ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{index_name}' Ø¯Ø± Ø¨Ø§Ø²Ù‡ {s_date}-{e_date} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯ Ø§Ù…Ø§ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø±ÙˆÛŒ Ù‡Ù†Ø¯Ø³Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ù†Ø¯Ø§Ø±Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù‡Ù…Ù‡ Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ Mask Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯)."
            except ee.EEException as reduce_err:
                 # If reduction itself fails, report it
                 return None, count, f"Ø®Ø·Ø§ Ø¯Ø± ØªØ£ÛŒÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{index_name}' Ø¯Ø± Ø¨Ø§Ø²Ù‡ {s_date}-{e_date}: {reduce_err}"


            return output_image, count, None

        except ee.EEException as e:
            error_message = f"Ø®Ø·Ø§ÛŒ Google Earth Engine Ø¯Ø± Ø¨Ø§Ø²Ù‡ {s_date}-{e_date}: {e}"
            try:
                error_details = e.args[0] if e.args else str(e)
                if isinstance(error_details, str):
                     if 'computation timed out' in error_details.lower():
                         error_message += "\\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ)"
                     elif 'user memory limit exceeded' in error_details.lower():
                         error_message += "\\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø²Ø±Ú¯ ÛŒØ§ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡)"
                     elif 'image.projection' in error_details.lower() and 'different projections' in error_details.lower():
                        error_message += "\\n(Ø®Ø·Ø§ÛŒ Ù¾Ø±ÙˆØ¬Ú©Ø´Ù† Ø¯Ø§Ø®Ù„ÛŒ Ø¯Ø± GEE. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ ÛŒØ§ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…ØªÙØ§ÙˆØª Ø¨Ø±Ø·Ø±Ù Ø´ÙˆØ¯.)"
                     elif 'geometryconstructors' in error_details.lower() or 'invalid polygon' in error_details.lower():
                         error_message += "\\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ù‡Ù†Ø¯Ø³Ù‡ ÙˆØ±ÙˆØ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)"

            except Exception:
                pass # Ignore errors during error message enhancement
            return None, 0, error_message
        except Exception as e:
            error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ GEE Ø¯Ø± Ø¨Ø§Ø²Ù‡ {s_date}-{e_date}: {e}\\n{traceback.format_exc()}"
            return None, 0, error_message


    # --- Main Logic with Improved Error Handling ---
    image, count, error_msg = filter_and_process_collection(initial_start_date, initial_end_date)
    initial_error_msg = error_msg # Store the initial error message

    if image is None:
        # Attempt 2: Fallback with extended end date
        try:
            # Ensure dates are valid datetime objects before manipulation
            start_dt_obj = datetime.datetime.strptime(initial_start_date, '%Y-%m-%d')
            end_dt_obj = datetime.datetime.strptime(initial_end_date, '%Y-%m-%d')

            fallback_end_date = (end_dt_obj + datetime.timedelta(days=fallback_days)).strftime('%Y-%m-%d')
            # Use original start date for fallback range
            fallback_start_date = initial_start_date

            print(f"Attempt 1 failed for {initial_start_date}-{initial_end_date}. Error: '{initial_error_msg}'. Trying fallback range: {fallback_start_date} to {fallback_end_date}")

            # Call fallback, store result in separate variables
            fallback_image, fallback_count, fallback_error_msg = filter_and_process_collection(fallback_start_date, fallback_end_date)

            if fallback_image is not None:
                 image = fallback_image # Use fallback image if successful
                 error_msg = None # Clear error message if fallback succeeded
                 print(f"Found {fallback_count} images in fallback range {fallback_start_date}-{fallback_end_date}.")
                 # Optionally add info message: st.info(f"â„¹ï¸ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ±ÛŒ ØªØ§ ØªØ§Ø±ÛŒØ® {fallback_end_date} Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯.")
            else:
                 # Fallback also failed. Prioritize the fallback error message if it exists and is informative, otherwise use the initial error message.
                 if fallback_error_msg and "Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±" not in fallback_error_msg: # Prioritize specific errors from fallback
                      error_msg = f"ØªÙ„Ø§Ø´ Ø§ÙˆÙ„ Ù†Ø§Ù…ÙˆÙÙ‚ ({initial_error_msg}). ØªÙ„Ø§Ø´ Ø¯ÙˆÙ… ({fallback_start_date}-{fallback_end_date}) Ù†ÛŒØ² Ù†Ø§Ù…ÙˆÙÙ‚: {fallback_error_msg}"
                 else: # Use initial error if fallback error is generic "no image" or None
                      error_msg = initial_error_msg if initial_error_msg else fallback_error_msg # Fallback error only if initial was None

                 # Ensure error_msg is never None if image is None at this stage
                 if image is None and not error_msg:
                     error_msg = f"Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ {initial_start_date}-{initial_end_date} Ùˆ Ø¨Ø§Ø²Ù‡ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† {fallback_start_date}-{fallback_end_date} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ (Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ)."
                 print(f"Attempt 2 also failed for {fallback_start_date}-{fallback_end_date}. Final Error: {error_msg}")

        except ValueError as date_err:
            # Handle potential errors converting date strings
            error_msg = f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†: {date_err}. Ø®Ø·Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡: {initial_error_msg}"
            image = None # Ensure image remains None
            print(f"Error processing fallback dates: {date_err}")
        except Exception as e:
            # Error during the fallback *attempt* itself
            error_msg = f"Ø®Ø·Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† ({fallback_start_date}-{fallback_end_date}): {e}\\n{traceback.format_exc()}. Ø®Ø·Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡: {initial_error_msg}"
            image = None # Ensure image remains None
            print(f"Error during fallback attempt: {e}")

    # Final check: if image is None, ensure there's an error message
    if image is None and not error_msg:
        error_msg = f"Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ {initial_start_date}-{initial_end_date} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ (Ø¯Ù„ÛŒÙ„ Ù†Ø§Ù…Ø´Ø®Øµ)."


    # --- Return Value ---
    return image, error_msg


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ...", persist="disk")
def get_index_time_series(_point_geom, index_name, start_date='2023-01-01', end_date=today.strftime('%Y-%m-%d')):
    if not gee_initialized:
        return pd.DataFrame(columns=['date', index_name]), "Google Earth Engine Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."
    if _point_geom is None:
        return pd.DataFrame(columns=['date', index_name]), "Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_point_geom)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds)
                     .map(add_indices))

        # Select the band explicitly before proceeding
        s2_sr_col = s2_sr_col.select([index_name])

        def extract_value(image):
            try:
                # Select the band again before reducing to be extra safe with projections
                value = image.select(index_name).reduceRegion(
                    reducer=ee.Reducer.first(),
                    geometry=_point_geom,
                    scale=10,
                    bestEffort=True
                ).get(index_name)
                return ee.Feature(None, {
                    'date': image.date().format('YYYY-MM-dd'),
                    index_name: value
                })
            except Exception as e:
                 # Log the error internally or print for debugging
                 print(f"Error extracting value for date {image.date().format('YYYY-MM-dd')} and index {index_name}: {e}")
                 return ee.Feature(None, {
                    'date': image.date().format('YYYY-MM-dd'),
                    index_name: None
                })

        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.notNull([index_name]))

        try:
            # Using aggregate_array might be more robust than getInfo() on features for large collections
            dates_list = ts_features.aggregate_array('date').getInfo()
            values_list = ts_features.aggregate_array(index_name).getInfo()

            if not dates_list or not values_list:
                 return pd.DataFrame(columns=['date', index_name]), "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾ÙˆØ´Ø´ Ø§Ø¨Ø±ÛŒ ÛŒØ§ Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§Ø´Ø¯)."


            ts_df = pd.DataFrame({
                'date': dates_list,
                index_name: values_list
            })

        except ee.EEException as e:
            return pd.DataFrame(columns=['date', index_name]), f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"
        except Exception as e:
            return pd.DataFrame(columns=['date', index_name]), f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"


        if ts_df.empty:
             return pd.DataFrame(columns=['date', index_name]), "Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù„ÛŒ)."

        ts_df['date'] = pd.to_datetime(ts_df['date'])
        ts_df = ts_df.sort_values('date').set_index('date')

        return ts_df, None
    except ee.EEException as e:
        error_message = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"
        st.error(error_message)
        return pd.DataFrame(columns=['date', index_name]), error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}\n{traceback.format_exc()}"
        st.error(error_message)
        return pd.DataFrame(columns=['date', index_name]), error_message

@st.cache_data(show_spinner=False, persist="disk")
def get_farm_needs_data(_farm_geometry, start_curr, end_curr, start_prev, end_prev):
    if not gee_initialized:
        results = {'error': "Google Earth Engine Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."}
        return results
    if _farm_geometry is None:
        results = {'error': "Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."}
        return results

    results = {
        'NDVI_curr': None, 'NDMI_curr': None, 'EVI_curr': None, 'SAVI_curr': None,
        'NDVI_prev': None, 'NDMI_prev': None, 'EVI_prev': None, 'SAVI_prev': None,
        'error': None
    }
    indices_to_get = ['NDVI', 'NDMI', 'EVI', 'SAVI']

    def get_mean_values_for_period(start, end):
        period_values = {index: None for index in indices_to_get}
        error_msg = None
        try:
            s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                         .filterBounds(_farm_geometry)
                         .filterDate(start, end)
                         .map(maskS2clouds))

            count = s2_sr_col.size().getInfo()
            if count == 0:
                # Fallback logic (similar to get_processed_image)
                fallback_days_needs = 30 # Fallback for needs data as well
                fallback_end_date = (datetime.datetime.strptime(end, '%Y-%m-%d') + datetime.timedelta(days=fallback_days_needs)).strftime('%Y-%m-%d')
                s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                             .filterBounds(_farm_geometry)
                             .filterDate(start, fallback_end_date)
                             .map(maskS2clouds))
                count = s2_sr_col.size().getInfo()
                if count == 0:
                    return period_values, f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end} (Ùˆ Ø¨Ø§Ø²Ù‡ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† ØªØ§ {fallback_end_date}) ÛŒØ§ÙØª Ù†Ø´Ø¯"


            indexed_col = s2_sr_col.map(add_indices)
            median_image = indexed_col.median()

            available_bands = median_image.bandNames().getInfo()
            indices_to_reduce = [idx for idx in indices_to_get if idx in available_bands]

            if not indices_to_reduce:
                 return period_values, f"Ù‡ÛŒÚ† ÛŒÚ© Ø§Ø² Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ({', '.join(indices_to_get)}) Ø¯Ø± ØªØµØ§ÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ {start}-{end} ÛŒØ§ÙØª Ù†Ø´Ø¯."

            # Calculate mean for each index separately to avoid projection issues with multi-band image reduction
            mean_dict = {}
            for idx in indices_to_reduce:
                try:
                    mean_value = median_image.select(idx).reduceRegion( # Select band before reduceRegion
                        reducer=ee.Reducer.mean(),
                        geometry=_farm_geometry,
                        scale=10,
                        bestEffort=True,
                        maxPixels=1e8
                    ).get(idx).getInfo()
                    mean_dict[idx] = mean_value
                except Exception as e:
                     print(f"Error calculating mean for index {idx} in period {start}-{end}: {e}") # Log error per index


            if mean_dict:
                for index in indices_to_get:
                    if index in mean_dict and mean_dict[index] is not None:
                         period_values[index] = mean_dict[index]

            return period_values, None
        except ee.EEException as e:
            error_msg = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end}: {e}"
            return period_values, error_msg
        except Exception as e:
            error_msg = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end}: {e}\n{traceback.format_exc()}"
            return period_values, error_msg

    curr_values, err_curr = get_mean_values_for_period(start_curr, end_curr)
    if err_curr:
        results['error'] = f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø¬Ø§Ø±ÛŒ: {err_curr}"
    results['NDVI_curr'] = curr_values.get('NDVI')
    results['NDMI_curr'] = curr_values.get('NDMI')
    results['EVI_curr'] = curr_values.get('EVI')
    results['SAVI_curr'] = curr_values.get('SAVI')


    prev_values, err_prev = get_mean_values_for_period(start_prev, end_prev)
    if err_prev:
        if results.get('error'):
             results['error'] += f"\nØ®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù‚Ø¨Ù„ÛŒ: {err_prev}"
        else:
             results['error'] = f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù‚Ø¨Ù„ÛŒ: {err_prev}"

    # Consolidate error message if both periods failed
    if results.get('error') and 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø¬Ø§Ø±ÛŒ:' in results['error'] and 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù‚Ø¨Ù„ÛŒ:' in results['error']:
         results['error'] = "Ø®Ø·Ø§ Ø¯Ø± Ù‡Ø± Ø¯Ùˆ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù‡Ù†Ú¯Ø§Ù… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ."
    elif results.get('error'):
         pass # Keep the specific error if only one period failed
    elif pd.isna(results['NDVI_curr']) and pd.isna(results['NDMI_curr']) and pd.isna(results['EVI_curr']) and pd.isna(results['SAVI_curr']) and \
         pd.isna(results['NDVI_prev']) and pd.isna(results['NDMI_prev']) and pd.isna(results['EVI_prev']) and pd.isna(results['SAVI_prev']):
         results['error'] = "Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ø´Ø§Ø®ØµÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯."

    results['NDVI_prev'] = prev_values.get('NDVI')
    results['NDMI_prev'] = prev_values.get('NDMI')
    results['EVI_prev'] = prev_values.get('EVI')
    results['SAVI_prev'] = prev_values.get('SAVI')


    return results


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...", persist="disk")
def get_ai_needs_analysis(_model, farm_name, index_data, recommendations):
    """Generates AI analysis for the farm's condition related to needs."""
    if _model is None:
        return "Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    data_str_parts = []
    indices_to_display = ['NDVI', 'NDMI', 'EVI', 'SAVI']
    for idx in indices_to_display:
         curr_val = index_data.get(f'{idx}_curr')
         prev_val = index_data.get(f'{idx}_prev')

         if pd.notna(curr_val):
              line = f"- {idx} ÙØ¹Ù„ÛŒ: {curr_val:.3f}"
              if pd.notna(prev_val):
                  line += f" (Ù‚Ø¨Ù„ÛŒ: {prev_val:.3f}"
                  change_percent = None
                  if pd.notna(prev_val) and prev_val != 0:
                      try:
                         change_percent = ((curr_val - prev_val) / prev_val) * 100
                      except Exception:
                         change_percent = None # Handle division by zero

                  if change_percent is not None:
                      line += f", ØªØºÛŒÛŒØ±: {change_percent:.1f}%)"
                      # Provide context for change based on index type
                      change_status_desc = ""
                      if idx in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI']: # Higher is better
                           if change_percent > 3: change_status_desc = "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"
                           elif change_percent > 0: change_status_desc = "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª"
                           elif change_percent < -5: change_status_desc = "Ø§ÙØª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"
                           elif change_percent < 0: change_status_desc = "Ú©Ø§Ù‡Ø´"
                           else: change_status_desc = "Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±" # Added "Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±"
                      elif idx == 'MSI': # Lower is better
                           if change_percent < -3: change_status_desc = "Ø¨Ù‡Ø¨ÙˆØ¯ (Ú©Ø§Ù‡Ø´ ØªÙ†Ø´ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡)"
                           elif change_percent < 0: change_status_desc = "Ø¨Ù‡Ø¨ÙˆØ¯ (Ú©Ø§Ù‡Ø´ ØªÙ†Ø´)"
                           elif change_percent > 5: change_status_desc = "Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†Ø´ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"
                           elif change_percent > 0: change_status_desc = "Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†Ø´"
                           else: change_status_desc = "Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±"
                      elif idx == 'NDMI': # Higher is better
                           if change_percent > 3: change_status_desc = "Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"
                           elif change_percent > 0: change_status_desc = "Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª"
                           elif change_percent < -5: change_status_desc = "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"
                           elif change_percent < 0: change_status_desc = "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª"
                           else: change_status_desc = "Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª"

                      if change_status_desc:
                           line += f" - {change_status_desc}"
                  else:
                      line += ")" # Close parenthesis if percentage change couldn't be calculated
              data_str_parts.append(line)
         elif pd.notna(prev_val):
              data_str_parts.append(f"- {idx} Ù‚Ø¨Ù„ÛŒ: {prev_val:.3f} (Ø¯Ø§Ø¯Ù‡ ÙØ¹Ù„ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª)")


    data_str = "\n".join(data_str_parts) if data_str_parts else "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    recommendations_str = "\n".join([f"- {rec}" for rec in recommendations]) if recommendations else 'Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§ÙˆÙ„ÛŒÙ‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.'


    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ø¨Ø§ØªØ¬Ø±Ø¨Ù‡ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ù¾Ø§ÛŒØ´ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ ØªØ®ØµØµ Ø¯Ø§Ø±ÛŒØ¯. Ù„Ø·ÙØ§Ù‹ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}' Ø±Ø§ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø²ÛŒØ± ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯. ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ø¬Ø§Ù…Ø¹ØŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø±Ø§Ø¦Ù‡ Ø¨Ù‡ Ù…Ø¯ÛŒØ±Ø§Ù† ÛŒØ§ Ú©Ø§Ø±Ø´Ù†Ø§Ø³Ø§Ù† Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ø¨Ø§Ø´Ø¯. Ø¨Ù‡ Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÛŒÙ† Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù…Ø«Ù„Ø§Ù‹ NDMI Ùˆ NDVI) Ùˆ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ù…Ø²Ø±Ø¹Ù‡ (Ø¢Ø¨ÛŒØ§Ø±ÛŒØŒ Ú©ÙˆØ¯Ø¯Ù‡ÛŒØŒ ÛŒØ§ Ø³Ø§ÛŒØ± Ø¹ÙˆØ§Ù…Ù„ ØªÙ†Ø´â€ŒØ²Ø§) Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†ÛŒØ¯. ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:

    1.  **Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ:** ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…Øª Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ùˆ Ø±Ø·ÙˆØ¨Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ (NDVI, NDMI, EVI, SAVI). Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†ÛŒØ´Ú©Ø± (Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø±ÛŒØ¯) Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ø¯.
    2.  **ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯:** Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ùˆ ØªÙˆØ¶ÛŒØ­ Ù…Ø¹Ø§Ù†ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯Ù‡ (Ø±Ø´Ø¯ Ù…Ø«Ø¨ØªØŒ Ú©Ø§Ù‡Ø´ØŒ ØªÙ†Ø´ØŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø·ÙˆØ¨ØªØŒ Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†Ø´ Ùˆ...). Ø¨Ù‡ Ø¨Ø²Ø±Ú¯ÛŒ ØªØºÛŒÛŒØ±Ø§Øª (Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ ÛŒØ§ Ø¬Ø²Ø¦ÛŒ) Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†ÛŒØ¯.
    3.  **Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ§Ø²Ù‡Ø§ Ùˆ Ø¹ÙˆØ§Ù…Ù„ ØªÙ†Ø´â€ŒØ²Ø§:** Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ùˆ Ø±ÙˆÙ†Ø¯ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ØŒ Ø¨Ù‡ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ (Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ø§Ú¯Ø± NDMI Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª ÛŒØ§ Ú©Ø§Ù‡Ø´ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¯Ø§Ø´ØªÙ‡ØŒ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ Ø§Ú¯Ø± NDVI/EVI Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ø¨Ø§ ÙˆØ¬ÙˆØ¯ Ø±Ø·ÙˆØ¨Øª Ú©Ø§ÙÛŒØŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÙØ§Øª ÛŒØ§ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø§Ú¯Ø± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø³Ù„Ø§Ù…Øª Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ùˆ Ø±Ø·ÙˆØ¨Øª Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª Ùˆ...) Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†ÛŒØ¯. ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ (Ø³ÛŒØ³ØªÙ… Ù‚ÙˆØ§Ù†ÛŒÙ† Ø³Ø§Ø¯Ù‡) Ø±Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯ Ù„Ø­Ø§Ø¸ Ú©Ù†ÛŒØ¯ Ùˆ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø³Ø· Ø¯Ù‡ÛŒØ¯.
    4.  **ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ:** Ø§Ø±Ø§Ø¦Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ú©Ù„ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø¨Ø¹Ø¯ÛŒ (Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ù…ÛŒØ¯Ø§Ù†ÛŒ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ù†Ù‚Ø§Ø· Ù…Ø´Ú©Ù„â€ŒØ¯Ø§Ø±ØŒ ØªÙ†Ø¸ÛŒÙ… Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ/Ú©ÙˆØ¯Ø¯Ù‡ÛŒØŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø­ÛŒØ·ÛŒ).
    5.  **ÛŒØ§Ø¯Ø¯Ø§Ø´Øª Ù…Ù‡Ù…:** Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§ÙÛŒ (Ù…Ø«Ù„Ø§Ù‹ Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ ÛŒØ§ Ø¬Ø§Ø±ÛŒ) Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ù‡ Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ Ø°Ú©Ø± Ú©Ù†ÛŒØ¯ Ú©Ù‡ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ Ø¯Ù‚ÛŒÙ‚ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.

    Ø²Ø¨Ø§Ù† ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÛŒØ¯ ÙØ§Ø±Ø³ÛŒØŒ ØªØ®ØµØµÛŒ Ø§Ù…Ø§ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ø¨Ø§Ø´Ø¯.

    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ:
{data_str}

    ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ (Ø³ÛŒØ³ØªÙ… Ù‚ÙˆØ§Ù†ÛŒÙ† Ø³Ø§Ø¯Ù‡):
{recommendations_str}

    ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø´Ù…Ø§:
    """

    try:
        response = _model.generate_content(prompt)
        if response.candidates and response.candidates[0].content.parts:
            return "".join([part.text for part in response.candidates[0].content.parts])
        elif response.prompt_feedback and response.prompt_feedback.block_reason:
             block_reason = response.prompt_feedback.block_reason.name
             st.warning(f"âš ï¸ Ù¾Ø§Ø³Ø® Gemini Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ '{block_reason}' Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯. Ù¾Ø±Ø§Ù…Ù¾Øª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.")
             return "Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯."
        else:
             st.warning("âš ï¸ Ù¾Ø§Ø³Ø® Ù…Ø¹ØªØ¨Ø±ÛŒ Ø§Ø² Gemini Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
             return "Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    except Exception as e:
        st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API Ù‡Ù†Ú¯Ø§Ù… ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§: {e}")
        st.warning(traceback.format_exc())
        return "Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ."


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù†Ù‚Ø´Ù‡...", persist="disk")
def get_ai_map_summary(_model, ranking_df_sorted, selected_index, selected_day):
    """Generates AI summary for the overall map/ranking status."""
    if _model is None:
        return "Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    if ranking_df_sorted.empty:
        return "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ² ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."

    # Ensure these temporary copies are made if modifications are planned, though none are here
    negative_status_farms = ranking_df_sorted[ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].astype(str).str.contains("ØªÙ†Ø´|Ú©Ø§Ù‡Ø´|Ø¨Ø¯ØªØ±|Ù†ÛŒØ§Ø²", case=False, na=False)]
    positive_status_farms = ranking_df_sorted[ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].astype(str).str.contains("Ø¨Ù‡Ø¨ÙˆØ¯|Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª", case=False, na=False)]
    nodata_farms = ranking_df_sorted[ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].astype(str).str.contains("Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", case=False, na=False)]
    neutral_terms_list = ["Ø«Ø§Ø¨Øª", "Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª", "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ†", "Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"] # Define list for neutral terms
    neutral_farms = ranking_df_sorted[ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].astype(str).str.contains("|".join(neutral_terms_list), case=False, na=False)] # Use list here


    summary_text = f"Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² {selected_day} Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ {selected_index}:\n"
    summary_text += f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {len(ranking_df_sorted)}\n"
    summary_text += f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ ÙˆØ¶Ø¹ÛŒØª 'ØªÙ†Ø´/Ú©Ø§Ù‡Ø´/Ù†ÛŒØ§Ø²': {len(negative_status_farms)}\n"
    summary_text += f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ ÙˆØ¶Ø¹ÛŒØª 'Ø¨Ù‡Ø¨ÙˆØ¯/Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª': {len(positive_status_farms)}\n"
    summary_text += f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ ÙˆØ¶Ø¹ÛŒØª 'Ø«Ø§Ø¨Øª/Ø®Ù†Ø«ÛŒ': {len(neutral_farms)}\n"
    summary_text += f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ 'Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡': {len(nodata_farms)}\n\n"

    if not negative_status_farms.empty:
        summary_text += "Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙˆØ¬Ù‡ ÙÙˆØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ (Ø¨ÛŒØ´ØªØ±ÛŒÙ† ØªÙ†Ø´ ÛŒØ§ Ú©Ø§Ù‡Ø´ØŒ ØªØ§ Ûµ Ù…Ø²Ø±Ø¹Ù‡ Ø§ÙˆÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ØªØ¨Ù‡):\n"
        # Sort negative farms by rank to get the "top" problem farms
        top_problem_farms = negative_status_farms.sort_index().head(5) # Assuming index is rank

        for idx, row in top_problem_farms.iterrows():
            farm_name_ai = row.get('Ù…Ø²Ø±Ø¹Ù‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')
            status_html_ai = row.get('ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´', 'Ù†Ø§Ù…Ø´Ø®Øµ')
            # Clean HTML tags from status for AI prompt
            status_text_ai = status_html_ai.replace('<span class="status-badge status-positive">', '').replace('<span class="status-badge status-negative">', '').replace('<span class="status-badge status-neutral">', '').replace('<span class="status-badge status-nodata">', '').replace('</span>', '')

            current_index_val_ai = row.get(f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', 'N/A')
            change_val_ai = row.get('ØªØºÛŒÛŒØ±', 'N/A')

            current_index_display = f"{float(str(current_index_val_ai).replace('N/A', 'nan')):.3f}" if pd.notna(current_index_val_ai) and str(current_index_val_ai) != 'N/A' else 'N/A'
            change_display = f"{float(str(change_val_ai).replace('N/A', 'nan')):.3f}" if pd.notna(change_val_ai) and str(change_val_ai) != 'N/A' else 'N/A'


            summary_text += f"- Ø±ØªØ¨Ù‡ {idx}: Ù…Ø²Ø±Ø¹Ù‡ {farm_name_ai}, ÙˆØ¶Ø¹ÛŒØª {status_text_ai}, Ø´Ø§Ø®Øµ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ: {current_index_display}, ØªØºÛŒÛŒØ±: {change_display}\n"


    if not positive_status_farms.empty and len(positive_status_farms) > 0:
         summary_text += "\nÙ…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ ÛŒØ§ Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ (ØªØ§ Ûµ Ù…Ø²Ø±Ø¹Ù‡ Ø§ÙˆÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ØªØ¨Ù‡):\n"
         # Sort positive farms by rank to get the "top" improving farms
         top_improving_farms = positive_status_farms.sort_index().head(5) # Assuming index is rank

         for idx, row in top_improving_farms.iterrows():
             farm_name_ai = row.get('Ù…Ø²Ø±Ø¹Ù‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')
             status_html_ai = row.get('ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´', 'Ù†Ø§Ù…Ø´Ø®Øµ')
             status_text_ai = status_html_ai.replace('<span class="status-badge status-positive">', '').replace('<span class="status-badge status-negative">', '').replace('<span class="status-badge status-neutral">', '').replace('<span class="status-badge status-nodata">', '').replace('</span>', '')

             current_index_val_ai = row.get(f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', 'N/A')
             change_val_ai = row.get('ØªØºÛŒÛŒØ±', 'N/A')

             current_index_display = f"{float(str(current_index_val_ai).replace('N/A', 'nan')):.3f}" if pd.notna(current_index_val_ai) and str(current_index_val_ai) != 'N/A' else 'N/A'
             change_display = f"{float(str(change_val_ai).replace('N/A', 'nan')):.3f}" if pd.notna(change_val_ai) and str(change_val_ai) != 'N/A' else 'N/A'

             summary_text += f"- Ø±ØªØ¨Ù‡ {idx}: Ù…Ø²Ø±Ø¹Ù‡ {farm_name_ai}, ÙˆØ¶Ø¹ÛŒØª {status_text_ai}, Ø´Ø§Ø®Øµ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ: {current_index_display}, ØªØºÛŒÛŒØ±: {change_display}\n"


    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ù‡Ø³ØªÛŒØ¯ Ùˆ ÙˆØ¸ÛŒÙÙ‡ Ø¯Ø§Ø±ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯. Ø§ÛŒÙ† Ø®Ù„Ø§ØµÙ‡ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ù…Ø¯ÛŒØ±Ø§Ù† ÛŒØ§ Ú©Ø§Ø±Ø´Ù†Ø§Ø³Ø§Ù† Ú©Ù…Ú© Ú©Ù†Ø¯ ØªØ§ Ø¨Ù‡ Ø³Ø±Ø¹Øª ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ø±Ø§ Ø¯Ø±Ú© Ú©Ø±Ø¯Ù‡ Ùˆ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ Ø§Ù‚Ø¯Ø§Ù… Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†Ù†Ø¯.

    Ø®Ù„Ø§ØµÙ‡ Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
    1.  **ØªØµÙˆÛŒØ± Ú©Ù„ÛŒ:** ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ù‡Ø± Ø¯Ø³ØªÙ‡ ÙˆØ¶Ø¹ÛŒØª (ØªÙ†Ø´/Ú©Ø§Ù‡Ø´ØŒ Ø¨Ù‡Ø¨ÙˆØ¯/Ø±Ø´Ø¯ Ù…Ø«Ø¨ØªØŒ Ø«Ø§Ø¨ØªØŒ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡) Ùˆ Ù…Ø¹Ù†ÛŒ Ú©Ù„ÛŒ Ø§ÛŒÙ† ØªÙˆØ²ÛŒØ¹ Ú†ÛŒØ³ØªØŸ
    2.  **Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø­Ø±Ø§Ù†ÛŒ:** Ø§Ø´Ø§Ø±Ù‡ Ø¨Ù‡ Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒÙ† ØªÙ†Ø´ ÛŒØ§ Ú©Ø§Ù‡Ø´ Ø±Ø§ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù„ÛŒØ³Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡). Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø´Ø§Ø®Øµ {selected_index}ØŒ Ú†Ù‡ Ù†ÙˆØ¹ ØªÙ†Ø´ÛŒ (Ù…Ø«Ù„Ø§Ù‹ Ø±Ø·ÙˆØ¨ØªÛŒØŒ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ) Ù…Ø­ØªÙ…Ù„ Ø§Ø³Øª Ùˆ Ú†Ù‡ Ø§Ù‚Ø¯Ø§Ù…Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø²Ø§Ø±Ø¹ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ (Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ù…ÛŒØ¯Ø§Ù†ÛŒ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ù†Ù‚Ø§Ø· Ù…Ø´Ú©Ù„â€ŒØ¯Ø§Ø±ØŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¹ÙˆØ§Ù…Ù„ ØªÙ†Ø´â€ŒØ²Ø§ØŒ Ø¢Ø²Ù…Ø§ÛŒØ´ Ø®Ø§Ú©ØŒ ØªÙ†Ø¸ÛŒÙ… Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ/Ú©ÙˆØ¯Ø¯Ù‡ÛŒ).
    3.  **Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¨:** Ø§Ø´Ø§Ø±Ù‡ Ø¨Ù‡ Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù„ÛŒØ³Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡). Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² Ø¯Ù„Ø§ÛŒÙ„ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒÙ† Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ø³Ø§ÛŒØ± Ù†Ù‚Ø§Ø· Ø§Ù„Ú¯ÙˆØ¨Ø±Ø¯Ø§Ø±ÛŒ Ú©Ø±Ø¯ØŸ (Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø²Ø±Ø§Ø¹ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…Ø²Ø§Ø±Ø¹).
    4.  **Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯:** ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ùˆ Ù„Ø²ÙˆÙ… Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªÛŒ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø¨Ø±Ø§ÛŒ Ø¢Ù†â€ŒÙ‡Ø§.
    5.  **Ø§Ù‡Ù…ÛŒØª Ø´Ø§Ø®Øµ:** ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ú©ÙˆØªØ§Ù‡ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø§ÛŒÙ†Ú©Ù‡ Ø´Ø§Ø®Øµ {selected_index} Ú†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¨Ù‡ Ù…Ø§ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ú†Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ´ Ù…Ù‡Ù… Ø§Ø³Øª.

    Ø²Ø¨Ø§Ù† ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÛŒØ¯ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§Ø´Ø¯.

    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:
{summary_text}

    Ø®Ù„Ø§ØµÙ‡ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø´Ù…Ø§:
    """
    try:
        response = _model.generate_content(prompt)
        if response.candidates and response.candidates[0].content.parts:
            return "".join([part.text for part in response.candidates[0].content.parts])
        elif response.prompt_feedback and response.prompt_feedback.block_reason:
             block_reason = response.prompt_feedback.block_reason.name
             st.warning(f"âš ï¸ Ù¾Ø§Ø³Ø® Gemini Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ '{block_reason}' Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯.")
             return "Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯."
        else:
             st.warning("âš ï¸ Ù¾Ø§Ø³Ø® Ù…Ø¹ØªØ¨Ø±ÛŒ Ø§Ø² Gemini Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ù†Ù‚Ø´Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
             return "Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
    except Exception as e:
        st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API Ù‡Ù†Ú¯Ø§Ù… Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ù‚Ø´Ù‡: {e}")
        st.warning(traceback.format_exc())
        return "Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù†Ù‚Ø´Ù‡."


def determine_status(row, index_name):
    """Determines the status based on change in index value using fixed thresholds."""
    # Fixed Thresholds (Not visible to the user)
    NDMI_IRRIGATION_THRESHOLD = 0.25 # Example threshold for low NDMI
    NDVI_DROP_PERCENT_THRESHOLD = 5.0 # Example threshold for significant NDVI drop
    # General thresholds for change significance
    ABSOLUTE_CHANGE_THRESHOLD = 0.02 # Example absolute change for significance
    PERCENT_CHANGE_THRESHOLD = 3.0 # Example percentage change for positive significance
    NEGATIVE_PERCENT_CHANGE_THRESHOLD = 5.0 # Example percentage change for negative significance (can be different)


    current_val = row.get(f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)')
    previous_val = row.get(f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)')
    change_val = row.get('ØªØºÛŒÛŒØ±')

    # Ensure values are floats, handling possible string representations of None or N/A
    try:
        current_val_float = float(str(current_val).replace('N/A', 'nan').replace('None', 'nan'))
    except ValueError:
        current_val_float = np.nan
    try:
        previous_val_float = float(str(previous_val).replace('N/A', 'nan').replace('None', 'nan'))
    except ValueError:
        previous_val_float = np.nan
    try:
        change_val_float = float(str(change_val).replace('N/A', 'nan').replace('None', 'nan'))
    except ValueError:
         # Recalculate change_val_float if needed, based on raw floats
         if pd.notna(current_val_float) and pd.notna(previous_val_float):
              change_val_float = current_val_float - previous_val_float
         else:
              change_val_float = np.nan


    if pd.notna(current_val_float) and pd.notna(previous_val_float) and pd.notna(change_val_float):
        percentage_change = None
        if pd.notna(previous_val_float) and previous_val_float != 0:
            try:
                 percentage_change = (change_val_float / previous_val_float) * 100
            except Exception: # Handle division by zero or other issues
                 percentage_change = None


        is_significant_positive = change_val_float > ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change > PERCENT_CHANGE_THRESHOLD)
        is_significant_negative = change_val_float < -ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change < -NEGATIVE_PERCENT_CHANGE_THRESHOLD) # Use negative threshold

        if index_name in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI']:
            if is_significant_positive:
                return "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯"
            elif is_significant_negative:
                return "ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´"
            else:
                 return "Ø«Ø§Ø¨Øª"
        elif index_name in ['MSI']: # Lower MSI is better
             is_significant_improvement = change_val_float < -ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change < -NEGATIVE_PERCENT_CHANGE_THRESHOLD) # Negative change in MSI is improvement
             is_significant_deterioration = change_val_float > ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change > PERCENT_CHANGE_THRESHOLD) # Positive change in MSI is deterioration

             if is_significant_improvement:
                return "Ø¨Ù‡Ø¨ÙˆØ¯ (Ú©Ø§Ù‡Ø´ ØªÙ†Ø´)"
             elif is_significant_deterioration:
                return "ØªÙ†Ø´ (Ø§ÙØ²Ø§ÛŒØ´ MSI)"
             else:
                return "Ø«Ø§Ø¨Øª"
        elif index_name == 'NDMI': # Higher NDMI is better (more moisture)
             is_low_ndmi = pd.notna(current_val_float) and current_val_float <= NDMI_IRRIGATION_THRESHOLD
             is_significant_decrease = change_val_float < -ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change < -NEGATIVE_PERCENT_CHANGE_THRESHOLD)


             if is_low_ndmi and is_significant_decrease:
                  return "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø´Ø¯ÛŒØ¯ / Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ"
             elif is_low_ndmi:
                  return "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ / Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ"
             elif is_significant_decrease:
                  return "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"
             elif is_significant_positive: # Significant increase in NDMI
                 return "Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯"
             else:
                  return "Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª" # Within thresholds or slight non-significant change


        else:
            return "Ù†Ø§Ù…Ø´Ø®Øµ"
    elif pd.notna(current_val_float) and pd.isna(previous_val_float):
         # If current data exists but previous doesn't, check current against a fixed threshold if applicable
         if index_name == 'NDMI' and pd.notna(current_val_float) and current_val_float <= NDMI_IRRIGATION_THRESHOLD:
              return "Ø§Ø­ØªÙ…Ø§Ù„ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„)"
         # Add similar checks for low values of other indices if they indicate potential issues
         elif index_name in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI'] and pd.notna(current_val_float) and current_val_float <= 0.3: # Example low threshold for these indices
              return "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ† (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„)"
         else:
              return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„"

    elif pd.isna(current_val_float) and pd.notna(previous_val_float):
         return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ"
    else:
        return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"


# ==============================================================================
# Main Application Layout (Using Tabs)
# ==============================================================================

tab1, tab2, tab3 = st.tabs(["ğŸ“Š Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹ (Ù†Ù‚Ø´Ù‡ Ùˆ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ)", "ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª", "ğŸ’§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ"])

with tab1:
    st.header("ğŸ“Š Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹ (Ù†Ù‚Ø´Ù‡ Ùˆ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ)")
    st.markdown("""
    <div style="text-align: justify; margin-bottom: 20px;">
    Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…Øª Ùˆ Ø±Ø·ÙˆØ¨Øª Ù…Ø²Ø§Ø±Ø¹ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯. Ù†Ù‚Ø´Ù‡ØŒ ØªÙˆØ²ÛŒØ¹ Ù…Ú©Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø±Ø§ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒØŒ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ ØªØ§ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ ØªÙˆØ¬Ù‡ Ø¨ÛŒØ´ØªØ± Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯.
    </div>
    """, unsafe_allow_html=True)


    if farm_data_df.empty:
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ CSV Ù…Ø²Ø§Ø±Ø¹ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    elif filtered_farms_df.empty:
        st.warning("âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ùˆ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ùˆ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    elif not gee_initialized:
         st.warning("âš ï¸ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª. Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ùˆ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.")
    else:
        selected_farm_details = None
        selected_farm_gee_geom = None
        center_lat = INITIAL_LAT
        center_lon = INITIAL_LON
        zoom_level = INITIAL_ZOOM
        is_single_farm = (selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹")

        if is_single_farm:
            selected_farm_details_list = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name]
            if not selected_farm_details_list.empty:
                 selected_farm_details = selected_farm_details_list.iloc[0]
                 lat = selected_farm_details.get('wgs84_centroid_lat')
                 lon = selected_farm_details.get('wgs84_centroid_lon')
                 selected_farm_gee_geom = selected_farm_details.get('ee_geometry')

                 if pd.notna(lat) and pd.notna(lon) and selected_farm_gee_geom is not None:
                     center_lat = lat
                     center_lon = lon
                     zoom_level = 14
                 else:
                      st.warning(f"âš ï¸ Ù…Ø®ØªØµØ§Øª WGS84 ÛŒØ§ Ù‡Ù†Ø¯Ø³Ù‡ GEE Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ø®ÙˆØ§Ù‡Ø¯ Ø¨Ø§Ø´Ø¯.")
                      selected_farm_gee_geom = None


                 st.subheader(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name} (Ø±ÙˆØ²: {selected_day})")
                 details_cols = st.columns(3)
                 with details_cols[0]:
                     st.markdown(modern_metric_card("Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª (Ù‡Ú©ØªØ§Ø±)", f"{selected_farm_details.get('Ù…Ø³Ø§Ø­Øª', 'N/A'):,.2f}" if pd.notna(selected_farm_details.get('Ù…Ø³Ø§Ø­Øª')) else "N/A", icon="fa-ruler-combined", color="#43cea2"), unsafe_allow_html=True)
                     st.markdown(modern_metric_card("ÙˆØ§Ø±ÛŒØªÙ‡", f"{selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')}", icon="fa-seedling", color="#43cea2"), unsafe_allow_html=True)
                 with details_cols[1]:
                     st.markdown(modern_metric_card("Ú¯Ø±ÙˆÙ‡", f"{selected_farm_details.get('Ú¯Ø±ÙˆÙ‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')}", icon="fa-users", color="#43cea2"), unsafe_allow_html=True)
                     st.markdown(modern_metric_card("Ø³Ù†", f"{selected_farm_details.get('Ø³Ù†', 'Ù†Ø§Ù…Ø´Ø®Øµ')}", icon="fa-hourglass-half", color="#43cea2"), unsafe_allow_html=True)
                 with details_cols[2]:
                     st.markdown(modern_metric_card("Ù…Ø®ØªØµØ§Øª", f"{lat:.5f}, {lon:.5f}" if pd.notna(lat) and pd.notna(lon) else "N/A", icon="fa-map-marker-alt", color="#43cea2"), unsafe_allow_html=True)
            else:
                 st.error(f"âŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                 is_single_farm = False


        if not is_single_farm:
            all_farm_geometries = [geom for geom in filtered_farms_df['ee_geometry'] if geom is not None]
            if all_farm_geometries:
                try:
                    selected_farm_gee_geom = ee.Geometry.MultiPolygon(all_farm_geometries)
                    center = selected_farm_gee_geom.centroid(maxError=1).getInfo()['coordinates']
                    center_lon, center_lat = center[0], center[1]
                    bounds = selected_farm_gee_geom.bounds().getInfo()
                    
                    # Fix for bounds coordinates access
                    if 'coordinates' in bounds:
                        # New GEE API format uses 'coordinates'
                        coordinates = bounds['coordinates'][0]  # First polygon's coordinates
                        # Find min/max coordinates
                        lon_vals = [coord[0] for coord in coordinates]
                        lat_vals = [coord[1] for coord in coordinates]
                        lon_min, lon_max = min(lon_vals), max(lon_vals)
                        lat_min, lat_max = min(lat_vals), max(lat_vals)
                        lon_diff = lon_max - lon_min
                        lat_diff = lat_max - lat_min
                    elif 'even' in bounds:
                        # Old format
                        lon_diff = bounds['even'][2] - bounds['even'][0]
                        lat_diff = bounds['even'][3] - bounds['even'][1]
                    else:
                        # If both formats fail, extract coordinates differently
                        bbox = selected_farm_gee_geom.bounds().getInfo()
                        if isinstance(bbox, dict) and 'type' in bbox and bbox['type'] == 'Polygon':
                            coordinates = bbox['coordinates'][0]  # First polygon's coordinates
                            lon_vals = [coord[0] for coord in coordinates]
                            lat_vals = [coord[1] for coord in coordinates]
                            lon_min, lon_max = min(lon_vals), max(lon_vals)
                            lat_min, lat_max = min(lat_vals), max(lat_vals)
                            lon_diff = lon_max - lon_min
                            lat_diff = lat_max - lat_min
                        else:
                            # If we can't determine bounds, use default values
                            lon_diff = 1.0
                            lat_diff = 1.0
                            st.info("â„¹ï¸ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²ÙˆÙ… Ù†Ù‚Ø´Ù‡.")
                    
                    # Set zoom level based on the geographic extent
                    if max(lon_diff, lat_diff) > 10: zoom_level = 6
                    elif max(lon_diff, lat_diff) > 5: zoom_level = 8
                    elif max(lon_diff, lat_diff) > 2: zoom_level = 10
                    elif max(lon_diff, lat_diff) > 0.5: zoom_level = 12
                    else: zoom_level = 13

                except Exception as e:
                     st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ù†Ø¯Ø³Ù‡ GEE Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹: {e}. Ù†Ù‚Ø´Ù‡ Ø¨Ø§ Ù…Ø±Ú©Ø² Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
                     selected_farm_gee_geom = None
            else:
                st.warning("âš ï¸ Ù‡ÛŒÚ† Ù‡Ù†Ø¯Ø³Ù‡ GEE Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")
                selected_farm_gee_geom = None


            st.subheader(f"Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ²: {selected_day}")
            st.markdown(modern_metric_card("ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ²", f"{len(filtered_farms_df):,}", icon="fa-leaf", color="#185a9d"), unsafe_allow_html=True)
            st.caption("ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø²Ø§Ø±Ø¹ Ø«Ø¨Øª Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡.")

            if 'ÙˆØ§Ø±ÛŒØªÙ‡' in filtered_farms_df.columns and not filtered_farms_df['ÙˆØ§Ø±ÛŒØªÙ‡'].isna().all():
                variety_counts = filtered_farms_df[filtered_farms_df['ÙˆØ§Ø±ÛŒØªÙ‡'].astype(str).str.lower() != 'Ù†Ø§Ù…Ø´Ø®Øµ']['ÙˆØ§Ø±ÛŒØªÙ‡'].value_counts().sort_values(ascending=False)
                if not variety_counts.empty:
                     pie_df = pd.DataFrame({
                         'ÙˆØ§Ø±ÛŒØªÙ‡': variety_counts.index,
                         'ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø±Ø¹Ù‡': variety_counts.values
                     })
                     fig_pie = px.pie(pie_df, values='ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø±Ø¹Ù‡', names='ÙˆØ§Ø±ÛŒØªÙ‡',
                                       title=f'Ø¯Ø±ØµØ¯ ÙˆØ§Ø±ÛŒØªÙ‡â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø²Ø§Ø±Ø¹ Ø±ÙˆØ² {selected_day}',
                                       hole=0.3)
                     fig_pie.update_traces(textposition='inside', textinfo='percent+label', insidetextorientation='radial')
                     fig_pie.update_layout(
                         showlegend=True,
                         height=400,
                         margin=dict(l=20, r=20, t=40, b=20),
                         paper_bgcolor='rgba(0,0,0,0)',
                         plot_bgcolor='rgba(0,0,0,0)'
                     )
                     st.plotly_chart(fig_pie, use_container_width=True)
                     st.caption("Ø¯Ø±ØµØ¯ Ù‡Ø± ÙˆØ§Ø±ÛŒØªÙ‡ Ø§Ø² Ú©Ù„ Ù…Ø²Ø§Ø±Ø¹ Ø«Ø¨Øª Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ².")
                else:
                    st.info("âš ï¸ Ø¯Ø§Ø¯Ù‡ ÙˆØ§Ø±ÛŒØªÙ‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ² ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            else:
                st.info("âš ï¸ Ø³ØªÙˆÙ† ÙˆØ§Ø±ÛŒØªÙ‡ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ† Ø±ÙˆØ² ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")


        st.markdown("---")
        st.subheader("ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
        st.markdown("Ù†Ù‚Ø´Ù‡ØŒ Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø±Ø§ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.")

        vis_params = {
            'NDVI': {'min': 0.1, 'max': 0.9, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
            'EVI': {'min': 0.1, 'max': 0.8, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
            'NDMI': {'min': -0.6, 'max': 0.6, 'palette': ['#b2182b', '#ef8a62', '#fddbc7', '#f7f7f7', '#d1e5f0', '#67a9cf', '#2166ac']},
            'LAI': {'min': 0, 'max': 6, 'palette': ['#f7f7f7', '#dcdcdc', '#babcba', '#8aae8b', '#5a9c5a', '#2a8a2a', '#006400']},
            'MSI': {'min': 0.6, 'max': 2.5, 'palette': ['#2166ac', '#67a9cf', '#d1e5f0', '#f7f7f7', '#fddbc7', '#ef8a62', '#b2182b']},
            'CVI_corrected_palette': {'min': 0, 'max': 20, 'palette': ['#ffffb2', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
            'SAVI': {'min': 0.1, 'max': 0.8, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
        }

        if selected_index == 'CVI':
            index_vis_params = vis_params['CVI_corrected_palette']
        else:
             index_vis_params = vis_params.get(selected_index, {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']})


        m = geemap.Map(
            location=[center_lat, center_lon],
            zoom=zoom_level,
            add_google_map=False
        )
        m.add_basemap("HYBRID")

        gee_image_current = None
        error_msg_current = None
        if gee_initialized and selected_farm_gee_geom is not None and start_date_current_str and end_date_current_str:
             with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø´Ø§Ø®Øµ {selected_index}..."):
                 gee_image_current, error_msg_current = get_processed_image(
                     selected_farm_gee_geom, start_date_current_str, end_date_current_str, selected_index
                 )

        if gee_image_current:
            try:
                m.addLayer(
                    gee_image_current,
                    index_vis_params,
                    f"{selected_index} ({start_date_current_str} ØªØ§ {end_date_current_str})"
                )

                farm_boundary_collection = ee.FeatureCollection([ee.Feature(geom) for geom in filtered_farms_df['ee_geometry'] if geom is not None])
                if not farm_boundary_collection.size().getInfo() == 0:
                     m.addLayer(
                         farm_boundary_collection,
                         {'color': 'yellow', 'fillColor': '00000000'},
                         'Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…Ø²Ø§Ø±Ø¹'
                     )
                else:
                     st.warning("âš ï¸ Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù„Ø§ÛŒÙ‡ Ù…Ø±Ø²ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


                legend_title = f"Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø´Ø§Ø®Øµ {selected_index}"
                legend_description = ""

                if selected_index in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI']:
                     legend_description = "(Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ/Ø³Ù„Ø§Ù…ØªØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ØªØ± Ø§Ø³Øª)"
                     palette_colors = index_vis_params.get('palette', ['red', 'yellow', 'green'])
                     color_low = palette_colors[0] if palette_colors else 'red'
                     color_mid = palette_colors[len(palette_colors)//2] if palette_colors else 'yellow'
                     color_high = palette_colors[-1] if palette_colors else 'green'
                     legend_text = f'''
                     <p style="margin: 0;"><span style="color: {color_low};">Ù…Ù‚Ø¯Ø§Ø± Ú©Ù…</span> / <span style="color: {color_mid};">Ù…ØªÙˆØ³Ø·</span> / <span style="color: {color_high};">Ù…Ù‚Ø¯Ø§Ø± Ø²ÛŒØ§Ø¯</span></p>
                     '''
                elif selected_index in ['NDMI']:
                     legend_description = "(Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø±Ø·ÙˆØ¨Øª Ø®Ø§Ú©ØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ØªØ± Ø§Ø³Øª)"
                     palette_colors = index_vis_params.get('palette', ['brown', 'white', 'blue'])
                     color_low = palette_colors[0] if palette_colors else 'brown'
                     color_mid = palette_colors[len(palette_colors)//2] if palette_colors else 'white'
                     color_high = palette_colors[-1] if palette_colors else 'blue'
                     legend_text = f'''
                     <p style="margin: 0;"><span style="color: {color_low};">Ø®Ø´Ú© (Ú©Ù…)</span> / <span style="color: {color_mid};">Ù…ØªÙˆØ³Ø·</span> / <span style="color: {color_high};">Ù…Ø±Ø·ÙˆØ¨ (Ø²ÛŒØ§Ø¯)</span></p>
                     '''
                elif selected_index in ['MSI']:
                     legend_description = "(Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø¨Ù‡ØªØ± Ø§Ø³Øª)"
                     palette_colors = index_vis_params.get('palette', ['blue', 'white', 'brown'])
                     color_low = palette_colors[0] if palette_colors else 'blue'
                     color_mid = palette_colors[len(palette_colors)//2] if palette_colors else 'white'
                     color_high = palette_colors[-1] if palette_colors else 'brown'
                     legend_text = f'''
                     <p style="margin: 0;"><span style="color: {color_low};">Ù…Ø±Ø·ÙˆØ¨ (Ú©Ù…)</span> / <span style="color: {color_mid};">Ù…ØªÙˆØ³Ø·</span> / <span style="color: {color_high};">Ø®Ø´Ú© (Ø²ÛŒØ§Ø¯)</span></p>
                     '''
                else:
                    legend_text = '''
                    <p style="margin: 0;">Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµ</p>
                    '''

                legend_html = f'''
                <div style="position: fixed; bottom: 50px; right: 10px; z-index: 1000; background-color: rgba(255, 255, 255, 0.9); padding: 10px; border: 1px solid grey; border-radius: 8px; font-family: Vazirmatn, sans-serif; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                    <p style="margin: 0;"><strong>{legend_title}</strong></p>
                    {legend_text}
                    <p style="margin: 0; font-size: 0.8em; opacity: 0.8;">{legend_description}</p>
                </div>
                '''
                m.get_root().html.add_child(folium.Element(legend_html))

                ranking_df_map_popups = pd.DataFrame()
                if not is_single_farm and start_date_current_str and end_date_current_str and start_date_previous_str and end_date_previous_str:
                     with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ù¾Ø§Ù¾â€ŒØ¢Ù¾â€ŒÙ‡Ø§ÛŒ Ù†Ù‚Ø´Ù‡..."):
                         # Re-calculate indices for popups only if not single farm, to save computation
                         # This calculation is parallelized within the function if possible
                         ranking_df_map_popups, popup_calculation_errors = calculate_weekly_indices_for_table(
                              filtered_farms_df,
                              selected_index,
                              start_date_current_str,
                              end_date_current_str,
                              start_date_previous_str,
                              end_date_previous_str
                         )
                         if popup_calculation_errors:
                             st.warning("âš ï¸ Ø¨Ø±Ø®ÛŒ Ø®Ø·Ø§Ù‡Ø§ Ø¯Ø± Ø­ÛŒÙ† Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ù¾â€ŒØ¢Ù¾â€ŒÙ‡Ø§ÛŒ Ù†Ù‚Ø´Ù‡ Ø±Ø® Ø¯Ø§Ø¯ (ØªØ§ Ûµ Ø®Ø·Ø§):")
                             for error in popup_calculation_errors[:5]: st.warning(f"- {error}")


                if not filtered_farms_df.empty:
                     for idx, farm in filtered_farms_df.iterrows():
                          lat = farm.get('wgs84_centroid_lat')
                          lon = farm.get('wgs84_centroid_lon')

                          if pd.notna(lat) and pd.notna(lon):
                               farm_name = farm.get('Ù…Ø²Ø±Ø¹Ù‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')
                               group = farm.get('Ú¯Ø±ÙˆÙ‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')
                               age = farm.get('Ø³Ù†', 'Ù†Ø§Ù…Ø´Ø®Øµ')
                               variety = farm.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'Ù†Ø§Ù…Ø´Ø®Øµ')

                               current_index_val = 'N/A'
                               previous_index_val = 'N/A'
                               change_val_display = 'N/A'
                               status_text = "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"

                               # Get data for popup: use ranking_df if single farm, or ranking_df_map_popups if all farms
                               farm_data_for_popup = None
                               if is_single_farm and 'ranking_df' in locals() and not ranking_df.empty:
                                    farm_data_for_popup_list = ranking_df[ranking_df['Ù…Ø²Ø±Ø¹Ù‡'] == farm_name]
                                    if not farm_data_for_popup_list.empty:
                                         farm_data_for_popup = farm_data_for_popup_list.iloc[0]
                               elif not is_single_farm and not ranking_df_map_popups.empty:
                                    farm_data_for_popup_list = ranking_df_map_popups[ranking_df_map_popups['Ù…Ø²Ø±Ø¹Ù‡'] == farm_name]
                                    if not farm_data_for_popup_list.empty:
                                        farm_data_for_popup = farm_data_for_popup_list.iloc[0]


                               if farm_data_for_popup is not None:
                                    current_index_val_raw = farm_data_for_popup.get(f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)')
                                    previous_index_val_raw = farm_data_for_popup.get(f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)')
                                    change_val_raw = farm_data_for_popup.get('ØªØºÛŒÛŒØ±')

                                    # Format for display, handling None/N/A/nan
                                    current_index_val = f"{float(str(current_index_val_raw).replace('N/A', 'nan').replace('None', 'nan')):.3f}" if pd.notna(current_index_val_raw) and str(current_index_val_raw) != 'N/A' and str(current_index_val_raw) != 'None' else 'N/A'
                                    previous_index_val = f"{float(str(previous_index_val_raw).replace('N/A', 'nan').replace('None', 'nan')):.3f}" if pd.notna(previous_index_val_raw) and str(previous_index_val_raw) != 'N/A' and str(previous_index_val_raw) != 'None' else 'N/A'
                                    change_val_display = f"{float(str(change_val_raw).replace('N/A', 'nan').replace('None', 'nan')):.3f}" if pd.notna(change_val_raw) and str(change_val_raw) != 'N/A' and str(change_val_raw) != 'None' else 'N/A'

                                    status_text = determine_status(farm_data_for_popup, selected_index)
                               else:
                                   # If no data found for this farm in the ranking/popup df, try getting just the current value
                                   try:
                                       point_geom_single = ee.Geometry.Point([lon, lat])
                                       current_img_single, err_single = get_processed_image(point_geom_single, start_date_current_str, end_date_current_str, selected_index)
                                       if current_img_single:
                                           current_val_single = current_img_single.reduceRegion(
                                               reducer=ee.Reducer.first(),
                                               geometry=point_geom_single,
                                               scale=10,
                                               bestEffort=True
                                           ).get(selected_index).getInfo()
                                           current_index_val = f"{float(str(current_val_single).replace('None', 'nan')):.3f}" if pd.notna(current_val_single) and str(current_val_single) != 'None' else 'N/A'
                                           status_text = "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„" if pd.notna(current_val_single) else "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
                                       else:
                                            status_text = "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
                                            if err_single: print(f"Error getting single farm current index for popup ({farm_name}): {err_single}")
                                   except Exception as e:
                                       print(f"Error getting single farm current index for popup ({farm_name}): {e}")
                                       status_text = "Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ø¯Ù‡"


                               popup_html = f"""
                               <strong>Ù…Ø²Ø±Ø¹Ù‡:</strong> {farm_name}<br>
                               <strong>Ú¯Ø±ÙˆÙ‡:</strong> {group}<br>
                               <strong>Ø³Ù†:</strong> {age}<br>
                               <strong>ÙˆØ§Ø±ÛŒØªÙ‡:</strong> {variety}<br>
                               ---<br>
                               <strong>{selected_index} (Ø¬Ø§Ø±ÛŒ):</strong> {current_index_val} <br>
                               <strong>{selected_index} (Ù‚Ø¨Ù„ÛŒ):</strong> {previous_index_val} <br>
                               <strong>ØªØºÛŒÛŒØ±:</strong> {change_val_display} <br>
                               <strong>ÙˆØ¶Ø¹ÛŒØª:</strong> {status_text}
                               """

                               marker_icon = 'info-sign'
                               marker_color = 'blue'
                               if is_single_farm:
                                    marker_icon = 'star'
                                    marker_color = 'red'

                               folium.Marker(
                                   location=[lat, lon],
                                   popup=folium.Popup(popup_html, max_width=300),
                                   tooltip=farm_name,
                                   icon=folium.Icon(color=marker_color, icon=marker_icon, prefix='fa')
                               ).add_to(m)


                m.add_layer_control()

            except Exception as map_err:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ GEE Ø¨Ù‡ Ù†Ù‚Ø´Ù‡: {map_err}")
                st.error(traceback.format_exc())
        else:
            st.warning(f"âš ï¸ ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø´Ø§Ø®Øµ {selected_index} Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ Ø¯Ø± Ø¨Ø§Ø²Ù‡ ÙØ¹Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. ({error_msg_current})")


        map_placeholder = st.empty()
        with map_placeholder:
             st_folium(m, width=None, height=500, use_container_width=True)

        st.caption("Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ø±ÙˆÛŒ Ù…Ø§Ø±Ú©Ø±Ù‡Ø§ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯. Ø§Ø² Ú©Ù†ØªØ±Ù„ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± Ø³Ù…Øª Ø±Ø§Ø³Øª Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ù†Ù‚Ø´Ù‡ Ù¾Ø§ÛŒÙ‡ Ùˆ Ù„Ø§ÛŒÙ‡ Ø´Ø§Ø®Øµ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
        st.info("ğŸ’¡ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‚Ø´Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§Ø¨Ø²Ø§Ø± Ø¹Ú©Ø³ Ú¯Ø±ÙØªÙ† Ø§Ø² ØµÙØ­Ù‡ (Screenshot) Ù…Ø±ÙˆØ±Ú¯Ø± ÛŒØ§ Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„ Ø®ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")


        st.markdown("---")
        st.subheader(f"ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index}")
        st.markdown("Ø±ÙˆÙ†Ø¯ ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø± ÛŒÚ© Ø³Ø§Ù„ Ú¯Ø°Ø´ØªÙ‡ (Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø±).")

        if not is_single_farm:
            st.info("â„¹ï¸ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
        elif not gee_initialized:
             st.warning("âš ï¸ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª. Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.")
        elif selected_farm_details is None or pd.isna(selected_farm_details.get('wgs84_centroid_lat')) or pd.isna(selected_farm_details.get('wgs84_centroid_lon')):
             st.warning(f"âš ï¸ Ù…Ø®ØªØµØ§Øª WGS84 Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.")
        else:
             point_geom_ts = ee.Geometry.Point([selected_farm_details['wgs84_centroid_lon'], selected_farm_details['wgs84_centroid_lat']])

             timeseries_end_date = today.strftime('%Y-%m-%d')
             timeseries_start_date = (today - datetime.timedelta(days=365)).strftime('%Y-%m-%d')

             ts_df, ts_error = get_index_time_series(
                 point_geom_ts,
                 selected_index,
                 start_date=timeseries_start_date,
                 end_date=timeseries_end_date
             )

             if ts_error:
                 st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}")
             elif not ts_df.empty:
                 fig_ts = px.line(ts_df, y=selected_index, title=f'Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}')
                 fig_ts.update_layout(
                     xaxis_title="ØªØ§Ø±ÛŒØ®",
                     yaxis_title=selected_index,
                     hovermode="x unified",
                     margin=dict(l=20, r=20, t=40, b=20),
                     paper_bgcolor='rgba(0,0,0,0)',
                     plot_bgcolor='rgba(0,0,0,0)'
                 )
                 st.plotly_chart(fig_ts, use_container_width=True)
                 st.caption(f"Ù†Ù…ÙˆØ¯Ø§Ø± ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name} Ø¯Ø± ÛŒÚ© Ø³Ø§Ù„ Ú¯Ø°Ø´ØªÙ‡ (Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø±).")
             else:
                 st.info(f"â„¹ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾ÙˆØ´Ø´ Ø§Ø¨Ø±ÛŒ Ù…Ø¯Ø§ÙˆÙ…).")


        st.markdown("---")
        st.subheader(f"ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} (Ø±ÙˆØ²: {selected_day})")
        st.markdown("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ùˆ ØªØ¹ÛŒÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ù‡Ø± Ù…Ø²Ø±Ø¹Ù‡.")

        @st.cache_data(show_spinner=False, persist="disk")
        def calculate_weekly_indices_for_table(
            _farms_df, index_name, start_curr, end_curr, start_prev, end_prev
        ):
            results = []
            errors = []
            total_farms = len(_farms_df)
            progress_placeholder = st.empty()


            for i, (idx, farm) in enumerate(_farms_df.iterrows()):
                farm_name = farm.get('Ù…Ø²Ø±Ø¹Ù‡', f'Ù…Ø²Ø±Ø¹Ù‡ Ù†Ø§Ø´Ù†Ø§Ø³ Ø±Ø¯ÛŒÙ {i+1}')
                farm_gee_geom = farm.get('ee_geometry')

                if farm_gee_geom is None:
                    errors.append(f"Ù‡Ù†Ø¯Ø³Ù‡ GEE Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}'. Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
                    results.append({
                         'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
                         'Ú¯Ø±ÙˆÙ‡': farm.get('Ú¯Ø±ÙˆÙ‡', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                         f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': None,
                         f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': None,
                         'ØªØºÛŒÛŒØ±': None,
                         'Ø³Ù†': farm.get('Ø³Ù†', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                         'ÙˆØ§Ø±ÛŒØªÙ‡': farm.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                     })
                    progress = (i + 1) / total_farms
                    progress_placeholder.markdown(modern_progress_bar(progress), unsafe_allow_html=True)
                    continue

                def get_mean_value_single_index(start, end, index):
                     try:
                          image, error = get_processed_image(farm_gee_geom, start, end, index)
                          if image:
                              # Select the band explicitly before reducing to avoid projection issues
                              mean_dict = image.select(index).reduceRegion(
                                  reducer=ee.Reducer.mean(),
                                  geometry=farm_gee_geom,
                                  scale=10,
                                  bestEffort=True,
                                  maxPixels=1e8
                              ).get(index).getInfo()
                              return mean_dict, None
                          else:
                              return None, error
                     except ee.EEException as e:
                          # Check for common errors and provide more specific messages
                          error_message = f"GEE Error for {farm_name} ({start}-{end}): {e}"
                          try:
                               error_details = e.args[0] if e.args else str(e)
                               if isinstance(error_details, str) and 'computation timed out' in error_details.lower():
                                   error_message += "\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ)"
                               elif isinstance(error_details, str) and 'user memory limit exceeded' in error_details.lower():
                                   error_message += "\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø²Ø±Ú¯ ÛŒØ§ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡)"
                               elif isinstance(error_details, str) and 'Image.projection: The bands of the specified image contains different projections' in error_details:
                                    error_message += "\n(Ø®Ø·Ø§ÛŒ Ù¾Ø±ÙˆØ¬Ú©Ø´Ù† Ø¯Ø§Ø®Ù„ÛŒ Ø¯Ø± GEE. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ ÛŒØ§ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…ØªÙØ§ÙˆØª Ø¨Ø±Ø·Ø±Ù Ø´ÙˆØ¯.)"
                          except Exception:
                               pass
                          return None, error_message
                     except Exception as e:
                          return None, f"Unknown Error for {farm_name} ({start}-{end}): {e}"


                current_val, err_curr = get_mean_value_single_index(start_curr, end_curr, index_name)
                if err_curr: errors.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}' (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ): {err_curr}")

                previous_val, err_prev = get_mean_value_single_index(start_prev, end_prev, index_name)
                if err_prev: errors.append(f"Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}' (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„): {err_prev}")

                change = None
                if pd.notna(current_val) and pd.notna(previous_val):
                    try:
                        change = current_val - previous_val
                    except TypeError:
                        change = None


                results.append({
                    'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
                    'Ú¯Ø±ÙˆÙ‡': farm.get('Ú¯Ø±ÙˆÙ‡', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                    f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': current_val, # Store raw numerical value here
                    f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': previous_val, # Store raw numerical value here
                    'ØªØºÛŒÛŒØ±': change, # Store raw numerical value here
                    'Ø³Ù†': farm.get('Ø³Ù†', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                    'ÙˆØ§Ø±ÛŒØªÙ‡': farm.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                })

                progress = (i + 1) / total_farms
                progress_placeholder.markdown(modern_progress_bar(progress), unsafe_allow_html=True)

            progress_placeholder.empty()
            return pd.DataFrame(results), errors

        ranking_df = pd.DataFrame()
        calculation_errors = []

        if gee_initialized and start_date_current_str and end_date_current_str and start_date_previous_str and end_date_previous_str and not filtered_farms_df.empty:
             ranking_df, calculation_errors = calculate_weekly_indices_for_table(
                 filtered_farms_df,
                 selected_index,
                 start_date_current_str,
                 end_date_current_str,
                 start_date_previous_str,
                 end_date_previous_str
             )
        elif not gee_initialized:
             st.warning("âš ï¸ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª. Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.")
        elif filtered_farms_df.empty:
             st.warning("âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        else:
             st.warning("âš ï¸ Ø¨Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")


        if calculation_errors:
            st.warning("âš ï¸ Ø¨Ø±Ø®ÛŒ Ø®Ø·Ø§Ù‡Ø§ Ø¯Ø± Ø­ÛŒÙ† Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø±Ø® Ø¯Ø§Ø¯ (ØªØ§ Û±Û° Ø®Ø·Ø§):")
            for error in calculation_errors[:10]:
                st.warning(f"- {error}")
            if len(calculation_errors) > 10:
                st.warning(f"... Ùˆ {len(calculation_errors) - 10} Ø®Ø·Ø§ÛŒ Ø¯ÛŒÚ¯Ø±.")


        if not ranking_df.empty:
            ascending_sort = selected_index == 'MSI'

            sort_col_name_raw = f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)'

            if sort_col_name_raw in ranking_df.columns:
                # Sort directly on the raw numerical column (which might have None/NaN)
                # Use 'na_position' to control where missing values appear
                ranking_df_sorted = ranking_df.sort_values(
                    by=sort_col_name_raw,
                    ascending=ascending_sort,
                    na_position='last' # Place missing values at the end
                ).reset_index(drop=True)
            else:
                 st.warning(f"âš ï¸ Ø³ØªÙˆÙ† '{sort_col_name_raw}' Ø¨Ø±Ø§ÛŒ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø¯ÙˆÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                 ranking_df_sorted = ranking_df.copy()


            if not ranking_df_sorted.empty:
                 ranking_df_sorted.index = ranking_df_sorted.index + 1
                 ranking_df_sorted.index.name = 'Ø±ØªØ¨Ù‡'

                 # Calculate status AFTER sorting, based on the sorted data (which has raw numbers)
                 ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_sorted.apply(
                     lambda row: determine_status(row, selected_index), axis=1
                 )

                 ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´'] = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].apply(lambda s: status_badge(s))

                 # Format the numerical columns for display AFTER status calculation and sorting
                 cols_to_format = [f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±']
                 for col in cols_to_format:
                     if col in ranking_df_sorted.columns:
                          # Convert numerical values to formatted strings, leaving None/NaN as N/A
                          ranking_df_sorted[col] = ranking_df_sorted[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")


                 display_columns = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ú¯Ø±ÙˆÙ‡', 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡'] + cols_to_format + ['ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´']
                 final_display_columns = [col for col in display_columns if col in ranking_df_sorted.columns]

                 ranking_df_display = ranking_df_sorted[final_display_columns].rename(columns={'ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´': 'ÙˆØ¶Ø¹ÛŒØª'})

                 st.write("<style>td {vertical-align: middle !important;}</style>", unsafe_allow_html=True)
                 st.write(ranking_df_display.to_html(escape=False, index=True), unsafe_allow_html=True)

                 st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ)")

                 status_counts = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].value_counts()

                 # Define groups based on keywords
                 positive_terms = [s for s in status_counts.index if "Ø¨Ù‡Ø¨ÙˆØ¯" in s or "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª" in s or "Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª" in s]
                 negative_terms = [s for s in status_counts.index if any(sub in s for sub in ["ØªÙ†Ø´", "Ú©Ø§Ù‡Ø´", "Ø¨Ø¯ØªØ±", "Ù†ÛŒØ§Ø²"])]
                 neutral_terms = [s for s in status_counts.index if any(sub in s for sub in ["Ø«Ø§Ø¨Øª", "Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª", "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ†", "Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"])] # Added 'Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡' for NDMI decrease
                 nodata_terms = [s for s in status_counts.index if "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" in s or "N/A" in s] # Added N/A for completeness

                 col1, col2, col3, col4 = st.columns(4)

                 with col1:
                     pos_count = sum(status_counts.get(term, 0) for term in positive_terms)
                     st.metric("ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯", pos_count)

                 with col2:
                     neutral_count = sum(status_counts.get(term, 0) for term in neutral_terms)
                     st.metric("âšª Ø«Ø§Ø¨Øª", neutral_count)

                 with col3:
                     neg_count = sum(status_counts.get(term, 0) for term in negative_terms)
                     st.metric("ğŸ”´ ØªÙ†Ø´", neg_count)

                 with col4:
                      nodata_count = sum(status_counts.get(term, 0) for term in nodata_terms)
                      st.metric("ğŸŸ¡ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", nodata_count)

                 st.info(f"""
                 **ØªÙˆØ¶ÛŒØ­Ø§Øª ÙˆØ¶Ø¹ÛŒØª:**
                 - **ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯/Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ (Ø§ÙØ²Ø§ÛŒØ´ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ NDVI ÛŒØ§ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ MSI) ÛŒØ§ Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯.
                 - **âšª Ø«Ø§Ø¨Øª**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ ØªØºÛŒÛŒØ± Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ø¯Ø± Ø´Ø§Ø®Øµ Ù†Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ (Ø¯Ø±ÙˆÙ† Ø¢Ø³ØªØ§Ù†Ù‡ ØªØºÛŒÛŒØ±) ÛŒØ§ ÙˆØ¶Ø¹ÛŒØª Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ (Ù…Ø«Ù„ Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª ÛŒØ§ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ† Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±). Ø´Ø§Ù…Ù„ Ú©Ø§Ù‡Ø´â€ŒÙ‡Ø§ÛŒ Ø±Ø·ÙˆØ¨Øª Ú©Ù‡ Ø¨Ù‡ Ø­Ø¯ ØªÙ†Ø´ Ù†Ø±Ø³ÛŒØ¯Ù‡â€ŒØ§Ù†Ø¯.
                 - **ğŸ”´ ØªÙ†Ø´/Ú©Ø§Ù‡Ø´/Ø¨Ø¯ØªØ± Ø´Ø¯Ù†**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ ÙˆØ¶Ø¹ÛŒØª Ù†Ø§Ù…Ø·Ù„ÙˆØ¨â€ŒØªØ±ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ (Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ NDVI ÛŒØ§ Ø§ÙØ²Ø§ÛŒØ´ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ MSI) ÛŒØ§ Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ/Ú©ÙˆØ¯ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø´Ø§Ù…Ù„ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ ÛŒØ§ Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡.
                 - **ğŸŸ¡ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø± Ø¯Ø± ÛŒÚ© ÛŒØ§ Ù‡Ø± Ø¯Ùˆ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒØŒ Ø§Ù…Ú©Ø§Ù† Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.
                 """)

                 st.markdown("---")
                 st.subheader("ğŸ¤– Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
                 if gemini_model:
                      with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ..."):
                          ai_map_summary = get_ai_map_summary(gemini_model, ranking_df_sorted, selected_index, selected_day)
                      st.markdown(ai_map_summary)
                 else:
                      st.info("âš ï¸ Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

                 ranking_df_clean = ranking_df_sorted.drop(columns=['ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´'], errors='ignore')
                 # Format numerical columns back to string for CSV export if desired, or keep as numbers
                 # Let's keep them as numbers for potential further analysis outside the app
                 csv_data = ranking_df_clean.to_csv(index=True).encode('utf-8')
                 st.download_button(
                     label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (CSV)",
                     data=csv_data,
                     file_name=f'ranking_{selected_index}_{selected_day}_{end_date_current_str}.csv',
                     mime='text/csv',
                 )
            else:
                 st.info("âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù¾Ø³ Ø§Ø² Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ ÛŒØ§ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.")
        else:
            st.info(f"â„¹ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ {selected_index} Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø±).")


    st.markdown("---")


with tab2:
    st.header("ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª")
    st.markdown("""
    <div style="text-align: justify; margin-bottom: 20px;">
    Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù…Ø³Ø§Ø­Øª Ùˆ ØªÙˆÙ„ÛŒØ¯ Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯. Ø§ÛŒÙ† Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ ØªÙˆØ²ÛŒØ¹ Ù…Ø³Ø§Ø­Øª Ùˆ ØªÙˆÙ„ÛŒØ¯ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø¯Ø§Ø±Ù‡ØŒ Ø³Ù† Ùˆ ÙˆØ§Ø±ÛŒØªÙ‡ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯.
    </div>
    """, unsafe_allow_html=True)


    if analysis_area_df is None and analysis_prod_df is None:
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø² ÙØ§ÛŒÙ„ 'Ù…Ø­Ø§Ø³Ø¨Ø§Øª 2.csv' Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯Ù†Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    else:
        available_edareh = []
        if analysis_area_df is not None and 'Ø§Ø¯Ø§Ø±Ù‡' in analysis_area_df.index.names:
            available_edareh.extend(analysis_area_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique().tolist())
        if analysis_prod_df is not None and 'Ø§Ø¯Ø§Ø±Ù‡' in analysis_prod_df.index.names:
            available_edareh.extend(analysis_prod_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique().tolist())

        available_edareh = sorted(list(set(e for e in available_edareh if e is not None)))

        if not available_edareh:
            st.warning("âš ï¸ Ù‡ÛŒÚ† Ø§Ø¯Ø§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„ 'Ù…Ø­Ø§Ø³Ø¨Ø§Øª 2.csv' Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
        else:
            selected_edareh = st.selectbox(
                "Ø§Ø¯Ø§Ø±Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
                options=available_edareh,
                key='analysis_edareh_select'
            )

            st.subheader(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡: {selected_edareh}")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)")
                if analysis_area_df is not None and selected_edareh in analysis_area_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique():
                    try:
                        df_area_selected = analysis_area_df.loc[selected_edareh].copy()

                        ages = df_area_selected.index.tolist()
                        varieties = df_area_selected.columns.tolist()
                        z_data = df_area_selected.values

                        if len(ages) > 1 and len(varieties) > 1 and z_data.shape[0] > 1 and z_data.shape[1] > 1:
                             try:
                                 fig_3d_area = go.Figure(data=[go.Surface(z=z_data, x=ages, y=varieties, colorscale='Viridis')])
                                 fig_3d_area.update_layout(
                                     title=f'Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø·Ø­ Ù…Ø³Ø§Ø­Øª - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                     scene=dict(
                                         xaxis_title='Ø³Ù†',
                                         yaxis_title='ÙˆØ§Ø±ÛŒØªÙ‡',
                                         zaxis_title='Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)'),
                                     autosize=True, height=500,
                                     margin=dict(l=0, r=0, t=40, b=0),
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
                                 )
                                 st.plotly_chart(fig_3d_area, use_container_width=True)
                                 st.caption("Ù†Ù…Ø§ÛŒØ´ ØªÙˆØ²ÛŒØ¹ Ù…Ø³Ø§Ø­Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù† Ùˆ ÙˆØ§Ø±ÛŒØªÙ‡ Ø¯Ø± ÛŒÚ© Ø³Ø·Ø­ Ø³Ù‡ Ø¨Ø¹Ø¯ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ.")
                             except Exception as e:
                                 st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot Ù…Ø³Ø§Ø­Øª: {e}")
                                 st.dataframe(df_area_selected)
                        else:
                             st.info("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot Ù…Ø³Ø§Ø­Øª ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨ÛŒØ´ Ø§Ø² ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ø³Ù† Ùˆ ÛŒÚ© ÙˆØ§Ø±ÛŒØªÙ‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡).")
                             st.dataframe(df_area_selected)


                        if 'Ø³Ù†' in df_area_selected.index.names:
                             df_area_melt = df_area_selected.reset_index().melt(id_vars='Ø³Ù†', var_name='ÙˆØ§Ø±ÛŒØªÙ‡', value_name='Ù…Ø³Ø§Ø­Øª')
                        else:
                              st.warning("âš ï¸ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø§Ø³Øª. Ù†Ù…Ø§ÛŒØ´ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.")
                              df_area_melt = pd.DataFrame()

                        df_area_melt = df_area_melt.dropna(subset=['Ù…Ø³Ø§Ø­Øª', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†'])
                        df_area_melt = df_area_melt[pd.to_numeric(df_area_melt['Ø³Ù†'], errors='coerce').notna()]


                        if not df_area_melt.empty:
                            try:
                                fig_hist_area = px.histogram(df_area_melt, x='ÙˆØ§Ø±ÛŒØªÙ‡', y='Ù…Ø³Ø§Ø­Øª', color='Ø³Ù†',
                                                           title=f'Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù…Ø³Ø§Ø­Øª Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ø±ÛŒØªÙ‡ Ùˆ Ø³Ù† - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                           labels={'Ù…Ø³Ø§Ø­Øª':'Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)'},
                                                           barmode='group',
                                                           text_auto=True)
                                fig_hist_area.update_layout(
                                     margin=dict(l=0, r=0, t=40, b=0),
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
                                )
                                st.plotly_chart(fig_hist_area, use_container_width=True)
                                st.caption("ØªÙˆØ²ÛŒØ¹ Ù…Ø³Ø§Ø­Øª Ù‡Ø± ÙˆØ§Ø±ÛŒØªÙ‡ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ø³Ù†.")
                            except Exception as e:
                                 st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù…Ø³Ø§Ø­Øª: {e}")
                                 st.dataframe(df_area_selected)
                        else:
                             st.info(f"â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù…Ø³Ø§Ø­Øª Ø¯Ø± Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯.")

                    except KeyError:
                        st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø¯Ø§Ø±Ù‡ '{selected_edareh}' Ø¯Ø± Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª. Ù„Ø·ÙØ§Ù‹ Ø³ØªÙˆÙ† 'Ø§Ø¯Ø§Ø±Ù‡' Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
                    except Exception as e:
                         st.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ '{selected_edareh}': {e}")
                         st.error(traceback.format_exc())

                else:
                    st.info(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")

            with col2:
                st.markdown("#### ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)")
                if analysis_prod_df is not None and selected_edareh in analysis_prod_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique():
                    try:
                        df_prod_selected = analysis_prod_df.loc[selected_edareh].copy()

                        ages_prod = df_prod_selected.index.tolist()
                        varieties_prod = df_prod_selected.columns.tolist()
                        z_data_prod = df_prod_selected.values

                        if len(ages_prod) > 1 and len(varieties_prod) > 1 and z_data_prod.shape[0] > 1 and z_data_prod.shape[1] > 1:
                             try:
                                 fig_3d_prod = go.Figure(data=[go.Surface(z=z_data_prod, x=ages_prod, y=varieties_prod, colorscale='Plasma')])
                                 fig_3d_prod.update_layout(
                                     title=f'Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø·Ø­ ØªÙˆÙ„ÛŒØ¯ - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                     scene=dict(
                                         xaxis_title='Ø³Ù†',
                                         yaxis_title='ÙˆØ§Ø±ÛŒØªÙ‡',
                                         zaxis_title='ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)'),
                                     autosize=True, height=500,
                                     margin=dict(l=0, r=0, t=40, b=0),
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
                                 )
                                 st.plotly_chart(fig_3d_prod, use_container_width=True)
                                 st.caption("Ù†Ù…Ø§ÛŒØ´ ØªÙˆØ²ÛŒØ¹ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù† Ùˆ ÙˆØ§Ø±ÛŒØªÙ‡ Ø¯Ø± ÛŒÚ© Ø³Ø·Ø­ Ø³Ù‡ Ø¨Ø¹Ø¯ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ.")
                             except Exception as e:
                                  st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot ØªÙˆÙ„ÛŒØ¯: {e}")
                                  st.dataframe(df_prod_selected)
                        else:
                             st.info("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot ØªÙˆÙ„ÛŒØ¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨ÛŒØ´ Ø§Ø² ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ø³Ù† Ùˆ ÛŒÚ© ÙˆØ§Ø±ÛŒØªÙ‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡).")
                             st.dataframe(df_prod_selected)


                        if 'Ø³Ù†' in df_prod_selected.index.names:
                            df_prod_melt = df_prod_selected.reset_index().melt(id_vars='Ø³Ù†', var_name='ÙˆØ§Ø±ÛŒØªÙ‡', value_name='ØªÙˆÙ„ÛŒØ¯')
                        else:
                             st.warning("âš ï¸ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø§Ø³Øª. Ù†Ù…Ø§ÛŒØ´ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.")
                             df_prod_melt = pd.DataFrame()

                        df_prod_melt = df_prod_melt.dropna(subset=['ØªÙˆÙ„ÛŒØ¯', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†'])
                        df_prod_melt = df_prod_melt[pd.to_numeric(df_prod_melt['Ø³Ù†'], errors='coerce').notna()]


                        if not df_prod_melt.empty:
                            try:
                                fig_hist_prod = px.histogram(df_prod_melt, x='ÙˆØ§Ø±ÛŒØªÙ‡', y='ØªÙˆÙ„ÛŒØ¯', color='Ø³Ù†',
                                                           title=f'Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆÙ„ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ø±ÛŒØªÙ‡ Ùˆ Ø³Ù† - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                           labels={'ØªÙˆÙ„ÛŒØ¯':'Ù…Ø¬Ù…ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)'},
                                                           barmode='group',
                                                           text_auto=True)
                                fig_hist_prod.update_layout(
                                     margin=dict(l=0, r=0, t=40, b=0),
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
                                )
                                st.plotly_chart(fig_hist_prod, use_container_width=True)
                                st.caption("ØªÙˆØ²ÛŒØ¹ ØªÙˆÙ„ÛŒØ¯ Ù‡Ø± ÙˆØ§Ø±ÛŒØªÙ‡ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ø³Ù†.")
                            except Exception as e:
                                 st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆÙ„ÛŒØ¯: {e}")
                                 st.dataframe(df_prod_selected)
                        else:
                             st.info(f"â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆÙ„ÛŒØ¯ Ø¯Ø± Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯.")

                    except KeyError:
                         st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø¯Ø§Ø±Ù‡ '{selected_edareh}' Ø¯Ø± Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯. Ù„Ø·ÙØ§Ù‹ Ø³ØªÙˆÙ† 'Ø§Ø¯Ø§Ø±Ù‡' Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
                    except Exception as e:
                         st.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ '{selected_edareh}': {e}")
                         st.error(traceback.format_exc())
                else:
                    st.info(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")

    st.markdown("---")


with tab3:
    st.header("ğŸ’§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ")
    st.markdown("""
    <div style="text-align: justify; margin-bottom: 20px;">
    Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù…Ø§Ù†Ù†Ø¯ NDMI (Ø±Ø·ÙˆØ¨Øª) Ùˆ NDVI (Ø³Ù„Ø§Ù…Øª Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ)ØŒ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø±Ø§ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù†ÛŒØ¯. ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù¾ÛŒØ´ ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ùˆ Ø³Ù¾Ø³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯ÛŒØ¯Ú¯Ø§Ù‡ Ø¬Ø§Ù…Ø¹â€ŒØªØ±ÛŒ Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    </div>
    """, unsafe_allow_html=True)


    is_single_farm = (selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹")

    # Need to get farm needs data only if a single farm is selected and GEE is initialized
    farm_needs_data = {'error': "Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯."}
    if is_single_farm and gee_initialized and selected_farm_details is not None and selected_farm_details.get('ee_geometry') is not None and start_date_current_str and end_date_current_str and start_date_previous_str and end_date_previous_str:
         with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§..."):
             farm_needs_data = get_farm_needs_data(selected_farm_details.get('ee_geometry'), start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str)
    elif is_single_farm and gee_initialized and (selected_farm_details is None or selected_farm_details.get('ee_geometry') is None):
         farm_needs_data = {'error': f"Ù‡Ù†Ø¯Ø³Ù‡ GEE Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯."}
    elif is_single_farm and not gee_initialized:
         farm_needs_data = {'error': "Google Earth Engine Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."}
    elif is_single_farm and (not start_date_current_str or not end_date_current_str or not start_date_previous_str or not end_date_previous_str):
         farm_needs_data = {'error': "Ø¨Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."}


    if not is_single_farm:
        st.info("âš ï¸ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ (Ø³Ù…Øª Ú†Ù¾) Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif farm_needs_data.get('error'):
         st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§: {farm_needs_data['error']}")
    elif pd.isna(farm_needs_data.get('NDMI_curr')) and pd.isna(farm_needs_data.get('NDVI_curr')):
        st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ù„Ø§Ø²Ù… (NDMI Ùˆ NDVI) Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾ÙˆØ´Ø´ Ø§Ø¨Ø±ÛŒ ÛŒØ§ Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§Ø´Ø¯).")
        st.markdown("---")
        st.markdown("#### ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ")
        st.info("âš ï¸ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®ØµØŒ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.")

    else:
        st.subheader(f"ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")

        st.markdown("---")
        st.markdown("#### Ù†ØªØ§ÛŒØ¬ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ùˆ Ù‚Ø¨Ù„)")

        st.markdown("**Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§:**")
        idx_cols = st.columns(4)
        with idx_cols[0]:
            display_val = f"{farm_needs_data['NDVI_curr']:.3f}" if pd.notna(farm_needs_data.get('NDVI_curr')) else "N/A"
            st.metric("NDVI (Ø¬Ø§Ø±ÛŒ)", display_val)
        with idx_cols[1]:
            display_val = f"{farm_needs_data['NDMI_curr']:.3f}" if pd.notna(farm_needs_data.get('NDMI_curr')) else "N/A"
            st.metric("NDMI (Ø¬Ø§Ø±ÛŒ)", display_val)
        with idx_cols[2]:
            display_val = f"{farm_needs_data.get('EVI_curr', 'N/A'):.3f}" if pd.notna(farm_needs_data.get('EVI_curr')) else "N/A"
            st.metric("EVI (Ø¬Ø§Ø±ÛŒ)", display_val)
        with idx_cols[3]:
            display_val = f"{farm_needs_data.get('SAVI_curr', 'N/A'):.3f}" if pd.notna(farm_needs_data.get('SAVI_curr')) else "N/A"
            st.metric("SAVI (Ø¬Ø§Ø±ÛŒ)", display_val)


        idx_prev_cols = st.columns(4)
        with idx_prev_cols[0]:
             display_val_prev = f"{farm_needs_data['NDVI_prev']:.3f}" if pd.notna(farm_needs_data.get('NDVI_prev')) else "N/A"
             st.metric("NDVI (Ù‚Ø¨Ù„ÛŒ)", display_val_prev)
        with idx_prev_cols[1]:
             display_val_prev = f"{farm_needs_data['NDMI_prev']:.3f}" if pd.notna(farm_needs_data.get('NDMI_prev')) else "N/A"
             st.metric("NDMI (Ù‚Ø¨Ù„ÛŒ)", display_val_prev)
        with idx_prev_cols[2]:
             display_val_prev = f"{farm_needs_data.get('EVI_prev', 'N/A'):.3f}" if pd.notna(farm_needs_data.get('EVI_prev')) else "N/A"
             st.metric("EVI (Ù‚Ø¨Ù„ÛŒ)", display_val_prev)
        with idx_prev_cols[3]:
             display_val_prev = f"{farm_needs_data.get('SAVI_prev', 'N/A'):.3f}" if pd.notna(farm_needs_data.get('SAVI_prev')) else "N/A"
             st.metric("SAVI (Ù‚Ø¨Ù„ÛŒ)", display_val_prev)


        st.markdown("---")
        st.markdown("#### ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§)")
        st.markdown("Ø§ÛŒÙ† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµ Ùˆ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø³ÛŒØ³ØªÙ…ØŒ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯:")
        recommendations = []

        NDMI_IRRIGATION_THRESHOLD = 0.25
        NDVI_DROP_PERCENT_THRESHOLD = 5.0

        # Get status using the determine_status logic for consistency
        # We need the raw numerical values for determine_status
        farm_row_for_status = {
            f'{idx} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': farm_needs_data.get(f'{idx}_curr') for idx in ['NDVI', 'NDMI', 'EVI', 'SAVI']
        }
        farm_row_for_status.update({
             f'{idx} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': farm_needs_data.get(f'{idx}_prev') for idx in ['NDVI', 'NDMI', 'EVI', 'SAVI']
        })

        # Calculate change for status determination based on raw numerical values
        current_ndvi_raw = farm_needs_data.get('NDVI_curr')
        previous_ndvi_raw = farm_needs_data.get('NDVI_prev')
        ndvi_change_raw = current_ndvi_raw - previous_ndvi_raw if pd.notna(current_ndvi_raw) and pd.notna(previous_ndvi_raw) else np.nan
        farm_row_for_status['ØªØºÛŒÛŒØ±'] = ndvi_change_raw # Add change for NDVI status check


        # Use determine_status for specific recommendations
        ndmi_status = determine_status(farm_row_for_status, 'NDMI')
        ndvi_status = determine_status(farm_row_for_status, 'NDVI')


        if "Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ ÙÙˆØ±ÛŒ" in ndmi_status or "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø´Ø¯ÛŒØ¯" in ndmi_status:
             recommendations.append(f"ğŸ’§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ ÙÙˆØ±ÛŒ ({ndmi_status})")
        elif "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡" in ndmi_status:
             recommendations.append(f"â— Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ ({ndmi_status})")
        elif "Ø§Ø­ØªÙ…Ø§Ù„ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„)" in ndmi_status:
             recommendations.append(f"âš ï¸ Ø§Ø­ØªÙ…Ø§Ù„ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ Ø¬Ø§Ø±ÛŒ. (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡)")


        if "ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´" in ndvi_status:
             recommendations.append(f"âš ï¸ Ú©Ø§Ù‡Ø´ Ø¯Ø± Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ/Ø³Ù„Ø§Ù…Øª Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø±Ø±Ø³ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ ÛŒØ§ Ø³Ø§ÛŒØ± Ø¹ÙˆØ§Ù…Ù„ ØªÙ†Ø´â€ŒØ²Ø§ ({ndvi_status})")
        # Check if NDVI is low when previous data is missing
        elif pd.notna(farm_needs_data.get('NDVI_curr')) and pd.isna(farm_needs_data.get('NDVI_prev')):
             LOW_NDVI_THRESHOLD = 0.3 # Example low threshold for NDVI
             if farm_needs_data['NDVI_curr'] <= LOW_NDVI_THRESHOLD:
                 recommendations.append(f"âš ï¸ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ Ø¬Ø§Ø±ÛŒ ({farm_needs_data['NDVI_curr']:.3f}). (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡). Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ù…Ø²Ø±Ø¹Ù‡.")

        # Handle cases where data is missing for NDMI or NDVI specifically
        if pd.isna(farm_needs_data.get('NDMI_curr')) and pd.notna(farm_needs_data.get('NDMI_prev')):
             recommendations.append("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ø±Ø·ÙˆØ¨Øª (NDMI) Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
        elif pd.notna(farm_needs_data.get('NDMI_curr')) and pd.isna(farm_needs_data.get('NDMI_prev')) and "Ø§Ø­ØªÙ…Ø§Ù„ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„)" not in recommendations:
             # If current NDMI exists but previous doesn't, and no other NDMI warning was added
              recommendations.append("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ø±Ø·ÙˆØ¨Øª (NDMI) Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")


        if pd.isna(farm_needs_data.get('NDVI_curr')) and pd.notna(farm_needs_data.get('NDVI_prev')):
             recommendations.append("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ (NDVI) Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
        elif pd.notna(farm_needs_data.get('NDVI_curr')) and pd.isna(farm_needs_data.get('NDVI_prev')) and "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ† (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„)" not in recommendations:
             # If current NDVI exists but previous doesn't, and no other NDVI warning was added
              recommendations.append("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ (NDVI) Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")


        if not recommendations:
             recommendations.append("âœ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ Ùˆ ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ØŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø·Ù„ÙˆØ¨ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„ ÙˆØ§Ø¶Ø­ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")


        for rec in recommendations:
            if "Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ ÙÙˆØ±ÛŒ" in rec or "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø´Ø¯ÛŒØ¯" in rec or "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡" in rec or "Ø§Ø­ØªÙ…Ø§Ù„ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ" in rec: st.error(rec)
            elif "Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ" in rec or "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ†" in rec: st.warning(rec)
            else: st.success(rec)

        st.markdown("---")
        st.markdown("#### ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ")
        if gemini_model:
             with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ..."):
                 ai_explanation = get_ai_needs_analysis(gemini_model, selected_farm_name, farm_needs_data, recommendations)
             st.markdown(ai_explanation)
        else:
             st.info("âš ï¸ Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

    st.markdown("---")