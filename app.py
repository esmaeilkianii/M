# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
from datetime import timedelta # Import timedelta
import plotly.express as px
import plotly.graph_objects as go # For grouped bar chart
import os
from io import BytesIO
import requests # Needed for getThumbUrl download
import numpy as np # For calculations and handling potential NaNs

# --- Configuration ---
APP_TITLE = "Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

# --- File Paths (Relative to the script location) ---
CSV_FILE_PATH = 'output (1).csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'

# --- GEE Authentication ---
@st.cache_resource
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully.")
        return True
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.stop()

# --- Data Loading ---
@st.cache_data
def load_data(csv_path):
    """Loads and preprocesses farm data from the CSV file."""
    try:
        df = pd.read_csv(csv_path)
        df.columns = df.columns.str.strip()
        print(f"Original columns: {df.columns.tolist()}")

        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª'] = pd.to_numeric(df['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª'], errors='coerce')
        df['Ù…Ø²Ø±Ø¹Ù‡'] = df['Ù…Ø²Ø±Ø¹Ù‡'].str.strip()

        # Ensure 'Ø³Ù†' column exists before accessing (handle potential CSV variations)
        if 'Ø³Ù†' not in df.columns:
            if 'Ø³Ù† ' in df.columns: # Check for the version with space
                 df.rename(columns={'Ø³Ù† ': 'Ø³Ù†'}, inplace=True) # Rename it
            else:
                 print("Warning: 'Ø³Ù†' column not found. Adding default.")
                 df['Ø³Ù†'] = 'Ù†Ø§Ù…Ø´Ø®Øµ' # Add default if completely missing

        for col in ['Ú©Ø§Ù†Ø§Ù„', 'Ø§Ø¯Ø§Ø±Ù‡', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡']:
             if col in df.columns:
                df[col] = df[col].astype(str).fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
             else:
                 print(f"Warning: Column '{col}' not found.")

        if 'coordinates_missing' in df.columns:
             df['coordinates_missing'] = pd.to_numeric(df['coordinates_missing'], errors='coerce').fillna(1).astype(int)
        else:
             print("Warning: Column 'coordinates_missing' not found.")
             df['coordinates_missing'] = df.apply(lambda row: 1 if pd.isna(row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) or pd.isna(row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) else 0, axis=1)


        print(f"Data loaded. Shape: {df.shape}. Cleaned columns: {df.columns.tolist()}")
        return df
    except FileNotFoundError:
        st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ CSV '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ CSV: {e}")
        st.exception(e)
        st.stop()

# --- GEE Image Processing Functions ---
COMMON_BAND_NAMES = ['Blue', 'Green', 'Red', 'RedEdge1', 'NIR', 'SWIR1', 'SWIR2']

def mask_s2_clouds(image):
    img_ee = ee.Image(image)
    qa = img_ee.select('QA60')
    cloud_mask = 1 << 10
    cirrus_mask = 1 << 11
    mask = qa.bitwiseAnd(cloud_mask).eq(0).And(qa.bitwiseAnd(cirrus_mask).eq(0))
    data_bands = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12']
    return img_ee.select(data_bands).updateMask(mask).divide(10000.0)\
        .copyProperties(img_ee, ["system:time_start"])

def mask_landsat_clouds(image):
    img_ee = ee.Image(image)
    qa = img_ee.select('QA_PIXEL')
    cloud_shadow_mask = 1 << 3; snow_mask = 1 << 4; cloud_mask = 1 << 5
    mask = qa.bitwiseAnd(cloud_shadow_mask).eq(0).And(qa.bitwiseAnd(snow_mask).eq(0)).And(qa.bitwiseAnd(cloud_mask).eq(0))
    sr_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']
    scale = 0.0000275; offset = -0.2
    scaled_bands = img_ee.select(sr_bands).multiply(scale).add(offset)
    return scaled_bands.updateMask(mask).copyProperties(img_ee, ["system:time_start"])

# --- Index Calculation Functions ---
# (Defined as before - calculate_ndvi, calculate_evi, etc.)
def calculate_ndvi(image):
    img_ee = ee.Image(image)
    return img_ee.normalizedDifference(['NIR', 'Red']).rename('NDVI')

def calculate_evi(image):
    img_ee = ee.Image(image)
    try:
        img_ee.select(['NIR', 'Red', 'Blue'])
        evi = img_ee.expression('2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',
                                {'NIR': img_ee.select('NIR'), 'RED': img_ee.select('Red'), 'BLUE': img_ee.select('Blue')})
        return evi.rename('EVI')
    except: return ee.Image().rename('EVI')

def calculate_ndmi(image):
    img_ee = ee.Image(image)
    return img_ee.normalizedDifference(['NIR', 'SWIR1']).rename('NDMI')

def calculate_msi(image):
    img_ee = ee.Image(image)
    return img_ee.expression('SWIR1 / NIR', {'SWIR1': img_ee.select('SWIR1'), 'NIR': img_ee.select('NIR')}).rename('MSI')

def calculate_lai_simple(image):
    img_ee = ee.Image(image)
    lai = None
    try:
        evi_img = calculate_evi(img_ee)
        if 'EVI' in evi_img.bandNames().getInfo(): lai = evi_img.select('EVI').multiply(3.5).add(0.1)
        else: raise ee.EEException("EVI failed")
    except:
        try:
            ndvi = img_ee.normalizedDifference(['NIR', 'Red'])
            lai = ndvi.multiply(5.0).add(0.1)
        except: return ee.Image().rename('LAI') # Failed both
    return lai.clamp(0, 8).rename('LAI') if lai else ee.Image().rename('LAI')

def calculate_biomass_simple(image):
    img_ee = ee.Image(image)
    lai_image = calculate_lai_simple(img_ee)
    if 'LAI' in lai_image.bandNames().getInfo():
        lai = lai_image.select('LAI')
        a = 1.5; b = 0.2
        biomass = lai.multiply(a).add(b)
        return biomass.clamp(0, 50).rename('Biomass')
    else: return ee.Image().rename('Biomass')

def calculate_chlorophyll_mcari(image):
    img_ee = ee.Image(image)
    try:
        img_ee.select('RedEdge1')
        mcari = img_ee.expression('((RE1 - RED) - 0.2 * (RE1 - GREEN)) * (RE1 / RED)',
                                  {'RE1': img_ee.select('RedEdge1'), 'RED': img_ee.select('Red'), 'GREEN': img_ee.select('Green')})
        return mcari.rename('Chlorophyll')
    except:
        ndvi = img_ee.normalizedDifference(['NIR', 'Red'])
        return ndvi.rename('Chlorophyll')

def calculate_et_placeholder(image):
    img_ee = ee.Image(image)
    ndmi = img_ee.normalizedDifference(['NIR', 'SWIR1'])
    return ndmi.rename('ET_proxy')

# --- Index Definitions Dictionary ---
# (Defined as before, with 'func', 'vis', 'name_fa', 'desc_fa', 'sort_ascending')
INDEX_DEFINITIONS = {
    'NDVI': {
        'func': calculate_ndvi, 'vis': {'min': 0, 'max': 1, 'palette': ['#d73027', '#fee08b', '#1a9850']}, # Red-Yellow-Green
        'name_fa': "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ (NDVI)",
        'desc_fa': """**NDVI (Ø´Ø§Ø®Øµ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ ØªÙØ§ÙˆØª Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ):** Ø±Ø§ÛŒØ¬â€ŒØªØ±ÛŒÙ† Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø¬Ø´ Ø³Ù„Ø§Ù…Øª Ùˆ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø³Ø¨Ø². Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø³Ø§Ù„Ù…â€ŒØªØ± Ùˆ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ø§Ø³Øª.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û± (Ø¨Ø±Ø§ÛŒ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û°.Û± ØªØ§ Û°.Û¹)
                    - **ØªÙØ³ÛŒØ±:** < Û°.Û² (Ø®Ø§Ú©ØŒ Ø¢Ø¨)ØŒ Û°.Û²-Û°.Ûµ (Ú¯ÛŒØ§Ù‡ Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡/ØªÙ†Ø´)ØŒ > Û°.Ûµ (Ú¯ÛŒØ§Ù‡ Ø³Ø§Ù„Ù… Ùˆ Ù…ØªØ±Ø§Ú©Ù…)""",
        'sort_ascending': False # Higher is better
    },
    'EVI': {
        'func': calculate_evi, 'vis': {'min': 0, 'max': 1, 'palette': ['#d73027', '#fee08b', '#1a9850']},
        'name_fa': "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ (EVI)",
        'desc_fa': """**EVI (Ø´Ø§Ø®Øµ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ):** Ù…Ø´Ø§Ø¨Ù‡ NDVI Ø§Ù…Ø§ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø§Ø«Ø±Ø§Øª Ø¬ÙˆÛŒ Ùˆ Ø®Ø§Ú© Ø²Ù…ÛŒÙ†Ù‡ØŒ Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ Ø¯Ø± Ù…Ù†Ø§Ø·Ù‚ Ø¨Ø§ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù…ØªØ±Ø§Ú©Ù….
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û° ØªØ§ Û±
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø³Ø§Ù„Ù…â€ŒØªØ± Ùˆ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'NDMI': {
        'func': calculate_ndmi, 'vis': {'min': -0.5, 'max': 0.8, 'palette': ['#a50026', '#ffffbf', '#313695']}, # Brown-Yellow-Blue
        'name_fa': "Ø´Ø§Ø®Øµ Ø±Ø·ÙˆØ¨Øª (NDMI)",
        'desc_fa': """**NDMI (Ø´Ø§Ø®Øµ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ ØªÙØ§ÙˆØª Ø±Ø·ÙˆØ¨Øª):** Ù…ÛŒØ²Ø§Ù† Ø¢Ø¨ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¨Ø±Ú¯â€ŒÙ‡Ø§ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û±
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± (Ø¢Ø¨ÛŒ) Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø±Ø·ÙˆØ¨Øª Ø¨ÛŒØ´ØªØ±ØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ) Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø®Ø´Ú©ÛŒ ÛŒØ§ ØªÙ†Ø´ Ø¢Ø¨ÛŒ Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'MSI': {
        'func': calculate_msi, 'vis': {'min': 0.4, 'max': 2.5, 'palette': ['#1a9641', '#ffffbf', '#d7191c']}, # Green-Yellow-Red
        'name_fa': "Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ (MSI)",
        'desc_fa': """**MSI (Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ):** Ù†ÛŒØ² Ø¨Ù‡ Ø±Ø·ÙˆØ¨Øª Ú¯ÛŒØ§Ù‡ Ø­Ø³Ø§Ø³ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± **Ø¨Ø§Ù„Ø§ØªØ±** Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ **Ø¨ÛŒØ´ØªØ±** Ø§Ø³Øª (Ø¨Ø±Ø¹Ú©Ø³ NDMI).
                    - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** SWIR1 / NIR
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ > Û°.Û´
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Ø³Ø¨Ø²) Ø¨Ù‡ØªØ± Ø§Ø³ØªØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± (Ù‚Ø±Ù…Ø²) Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ØªÙ†Ø´ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.""",
        'sort_ascending': True # Higher is worse (more stress)
    },
    'LAI': {
        'func': calculate_lai_simple, 'vis': {'min': 0, 'max': 8, 'palette': ['#fff5f0', '#fdcdb9', '#e34a33']}, # Light Orange to Red
        'name_fa': "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (LAI - ØªØ®Ù…ÛŒÙ†ÛŒ)",
        'desc_fa': """**LAI (Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯):** Ù†Ø³Ø¨Øª Ú©Ù„ Ù…Ø³Ø§Ø­Øª ÛŒÚ© Ø·Ø±ÙÙ‡ Ø¨Ø±Ú¯ Ø¨Ù‡ ÙˆØ§Ø­Ø¯ Ø³Ø·Ø­ Ø²Ù…ÛŒÙ† (mÂ²/mÂ²). Ø§ÛŒÙ† ÛŒÚ© **ØªØ®Ù…ÛŒÙ†** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¯Ø§Ø±Ø¯.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û° ØªØ§ Û¸+
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ø¨Ø§ Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'Biomass': {
        'func': calculate_biomass_simple, 'vis': {'min': 0, 'max': 30, 'palette': ['#f7fcb9', '#addd8e', '#31a354']}, # Yellow-LightGreen-DarkGreen
        'name_fa': "Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ (Biomass - ØªØ®Ù…ÛŒÙ†ÛŒ)",
        'desc_fa': """**Biomass:** ÙˆØ²Ù† Ù…Ø§Ø¯Ù‡ Ø®Ø´Ú© Ú¯ÛŒØ§Ù‡ÛŒ Ø¯Ø± ÙˆØ§Ø­Ø¯ Ø³Ø·Ø­ (Ù…Ø«Ù„Ø§Ù‹ ØªÙ† Ø¨Ø± Ù‡Ú©ØªØ§Ø±). Ø§ÛŒÙ† Ù†ÛŒØ² ÛŒÚ© **ØªØ®Ù…ÛŒÙ†** Ø¨Ø± Ø§Ø³Ø§Ø³ LAI ÛŒØ§ Ø³Ø§ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¯Ù‚ÛŒÙ‚ Ø¯Ø§Ø±Ø¯.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** ÙˆØ§Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ù†ÙˆØ¹ Ú¯ÛŒØ§Ù‡ Ùˆ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ†.
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'Chlorophyll': {
        'func': calculate_chlorophyll_mcari, 'vis': {'min': 0, 'max': 1, 'palette': ['#ffffcc', '#a1dab4', '#253494']}, # Yellow-Green-Blue
        'name_fa': "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (MCARI/NDVI)",
        'desc_fa': """**Chlorophyll Index:** Ø¨Ù‡ ØºÙ„Ø¸Øª Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¯Ø± Ø¨Ø±Ú¯â€ŒÙ‡Ø§ Ø­Ø³Ø§Ø³ Ø§Ø³Øª (Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ÙØªÙˆØ³Ù†ØªØ² Ùˆ Ø³Ù„Ø§Ù…Øª). Ø§Ø² Ø´Ø§Ø®Øµ MCARI (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ RedEdge Ø¯Ø± Sentinel-2) ÛŒØ§ NDVI (Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªÙ‚Ø±ÛŒØ¨ÛŒ) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…ØªØºÛŒØ±.
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ùˆ Ø³Ù„Ø§Ù…Øª Ø¨Ù‡ØªØ± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'ET_proxy': {
        'func': calculate_et_placeholder, 'vis': {'min': -0.5, 'max': 0.8, 'palette': ['#a50026', '#ffffbf', '#313695']}, # Same as NDMI
        'name_fa': "Ù¾Ø±Ø§Ú©Ø³ÛŒ ØªØ¨Ø®ÛŒØ±-ØªØ¹Ø±Ù‚ (ET - Ø¨Ø± Ø§Ø³Ø§Ø³ NDMI)",
        'desc_fa': """**ET Proxy:** ÛŒÚ© Ø´Ø§Ø®Øµ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª Ø±Ø·ÙˆØ¨ØªÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ØªØ¨Ø®ÛŒØ± Ùˆ ØªØ¹Ø±Ù‚ (ET). Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø² NDMI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚ ET Ø¨Ø³ÛŒØ§Ø± Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø§Ø³Øª.
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± NDMI (Ø±Ø·ÙˆØ¨Øª Ø¨ÛŒØ´ØªØ±) Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ ET Ø¨Ø§Ù„Ø§ØªØ±ÛŒ Ø±Ø§ Ù†Ø´Ø§Ù† Ø¯Ù‡Ø¯.""",
        'sort_ascending': False
    }
}

# --- GEE Data Retrieval ---
# **MODIFIED:** Returns the processed collection, even if empty after masking.
def get_image_collection(start_date, end_date, geometry=None, sensor='Sentinel-2'):
    """Gets, filters, masks, scales, and renames image collection. Returns collection."""
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')
    collection_id = None; bands_to_select_orig = []; bands_to_rename_to = []; mask_func = None

    if sensor == 'Sentinel-2':
        collection_id = 'COPERNICUS/S2_SR_HARMONIZED'
        mask_func = mask_s2_clouds
        bands_to_select_orig = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12', 'QA60']
        bands_to_rename_to = COMMON_BAND_NAMES
    elif sensor == 'Landsat':
        l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2'); l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')
        collection_id = l9.merge(l8)
        mask_func = mask_landsat_clouds
        bands_to_select_orig = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'QA_PIXEL']
        bands_to_rename_to = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2']
    else: st.error(f"Ø³Ù†Ø³ÙˆØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {sensor}"); return None

    if start_date > end_date: st.error("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø¹Ø¯ Ø§Ø² Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø´Ø¯."); return None

    collection = ee.ImageCollection(collection_id) if isinstance(collection_id, str) else collection_id
    collection = collection.filterDate(start_date_str, end_date_str)
    if geometry:
        try: collection = collection.filterBounds(geometry)
        except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙÛŒÙ„ØªØ± Ù‡Ù†Ø¯Ø³ÛŒ: {e}"); return None

    try:
        initial_count = collection.size().getInfo()
        if initial_count == 0:
            print(f"No initial images found for {sensor} in period/region.")
            # Return the empty collection, let caller handle it
            return collection
    except ee.EEException as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ‡ ØªØµØ§ÙˆÛŒØ±: {e}"); return None

    def process_image(image_element):
        image = ee.Image(image_element)
        try:
            img_selected_orig = image.select(bands_to_select_orig)
            img_processed = mask_func(img_selected_orig)
            img_processed_safe = ee.Image(img_processed)
            # Check if bands_to_rename_to length matches actual bands in processed image
            actual_band_names = img_processed_safe.bandNames()
            if actual_band_names.size().getInfo() == len(bands_to_rename_to):
                img_renamed = img_processed_safe.rename(bands_to_rename_to)
                return img_renamed.copyProperties(image, ["system:time_start"])
            else:
                 print(f"Warning: Band count mismatch after processing. Expected {len(bands_to_rename_to)}, got {actual_band_names.size().getInfo()}. Skipping image.")
                 return None # Skip if band count doesn't match expected common names
        except Exception as proc_e:
            print(f"Error processing single image: {proc_e}. Skipping.")
            return None # Skip image if processing fails

    processed_collection = collection.map(process_image).filter(ee.Filter.neq('item', None))

    # **CHANGE:** Do not return None here if count is 0. Just provide info.
    try:
        count = processed_collection.size().getInfo()
        print(f"Processed collection size: {count}")
        if count == 0:
            st.info(f"Ù‡Ø´Ø¯Ø§Ø±: Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ø§Ø¨Ø±Ù‡Ø§ØŒ ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù…Ù†Ø·Ù‚Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ({sensor}) Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø§Ø´Ø¯.", icon="â˜ï¸")
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {e}")
        # Return the collection anyway, maybe subsequent steps can handle it
        # return None

    return processed_collection # Return the collection, even if empty

# --- Function to calculate a single index ---
# **MODIFIED:** Handles empty input collection more gracefully.
def calculate_single_index(collection, index_name):
    """Calculates a single specified index for the collection."""
    if collection is None: return None
    # Check if collection is empty *before* trying to calculate
    try:
        collection_size = collection.size().getInfo()
        if collection_size == 0:
            print(f"Input collection for '{index_name}' calculation is empty.")
            return None # Return None if input is empty
    except ee.EEException as e:
         st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§Ù„Ú©Ø´Ù† Ø¨Ø±Ø§ÛŒ '{index_name}': {e}")
         return None


    index_detail = INDEX_DEFINITIONS.get(index_name)
    if not index_detail: st.error(f"ØªØ¹Ø±ÛŒÙ Ø´Ø§Ø®Øµ '{index_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯."); return None

    index_func = index_detail['func']
    try:
        indexed_collection = collection.map(index_func)
        # Verify the index band exists in the *first* image of the result
        first_img = indexed_collection.first()
        # Check if first_img is None (if map failed on all images) OR if band is missing
        if first_img is None or index_name not in ee.Image(first_img).bandNames().getInfo():
             available_bands = ee.Image(first_img).bandNames().getInfo() if first_img else "None"
             st.warning(f"Ø¨Ø§Ù†Ø¯ Ø´Ø§Ø®Øµ '{index_name}' Ù¾Ø³ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯. Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {available_bands}", icon="âš ï¸")
             return None
        # Select only the calculated index band for consistency
        return indexed_collection.select(index_name)
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{index_name}': {e}")
        return None
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ± GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{index_name}': {e}")
        return None

# --- get_timeseries_for_farm ---
@st.cache_data(ttl=1800)
def get_timeseries_for_farm(_farm_geom_geojson, start_date, end_date, index_name, sensor):
    """Retrieves and calculates the time series for a specific index and farm geometry."""
    try: farm_geom = ee.Geometry(json.loads(_farm_geom_geojson))
    except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø±Ø¹Ù‡: {e}"); return pd.DataFrame()

    base_collection = get_image_collection(start_date, end_date, farm_geom, sensor)
    # Base collection might be empty but not None
    if base_collection is None: return pd.DataFrame() # Error occurred in get_image_collection
    if base_collection.size().getInfo() == 0:
         st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ '{index_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ØªØµÙˆÛŒØ± Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø±). Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯.", icon="ğŸ“ˆ")
         return pd.DataFrame() # Empty df if no images after masking


    indexed_collection = calculate_single_index(base_collection, index_name)
    if indexed_collection is None: return pd.DataFrame() # Index calculation failed

    def extract_value(image):
        img_ee = ee.Image(image)
        try:
            stats = img_ee.reduceRegion(reducer=ee.Reducer.mean(), geometry=farm_geom, scale=30, maxPixels=1e9, tileScale=4)
            val = stats.get(index_name)
            time_ms = img_ee.get('system:time_start')
            return ee.Feature(None, {'time': time_ms, index_name: ee.Algorithms.If(val, val, -9999)})
        except ee.EEException as reduce_e:
            print(f"Warning: reduceRegion failed for one image in timeseries: {reduce_e}")
            return None # Return None if reduction fails for this image

    try:
        # Map extraction and filter out nulls from failed reductions
        ts_info = indexed_collection.map(extract_value).filter(ee.Filter.neq('item', None)).getInfo()
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"); return pd.DataFrame()
    except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"); return pd.DataFrame()

    data = []
    # ... (rest of the data processing remains the same)
    if 'features' in ts_info:
        for feature in ts_info['features']:
            props = feature.get('properties', {})
            value = props.get(index_name)
            time_ms = props.get('time')
            if value not in [None, -9999] and time_ms is not None:
                try:
                    dt = datetime.datetime.fromtimestamp(time_ms / 1000.0)
                    data.append([dt, value])
                except (TypeError, ValueError) as time_e: pass # Ignore invalid time silently
    if not data: return pd.DataFrame(columns=['Date', index_name])
    return pd.DataFrame(data, columns=['Date', index_name]).sort_values(by='Date').reset_index(drop=True)


# --- Function for getting median index over a period for multiple farms ---
@st.cache_data(ttl=1800)
def get_median_index_for_period(_farms_df_json, start_date, end_date, index_name, sensor):
    """Gets the median index value over a period for multiple farms."""
    farms_df = pd.read_json(_farms_df_json)
    farms_df_valid = farms_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
    if farms_df_valid.empty: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    features = []
    for idx, row in farms_df_valid.iterrows():
        try:
             geom = ee.Geometry.Point([row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']]).buffer(50)
             features.append(ee.Feature(geom, {'farm_id': row['Ù…Ø²Ø±Ø¹Ù‡']}))
        except Exception as e: print(f"Skipping farm {row.get('Ù…Ø²Ø±Ø¹Ù‡')} due to geom error: {e}")
    if not features: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    farm_fc = ee.FeatureCollection(features)

    base_collection = get_image_collection(start_date, end_date, farm_fc.geometry(), sensor)
    if base_collection is None or base_collection.size().getInfo() == 0:
         print(f"No base images for period median calculation ({index_name}).")
         return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name]) # Return empty if no images

    indexed_collection = calculate_single_index(base_collection, index_name)
    if indexed_collection is None: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    try:
        # Calculate median *after* calculating index for the collection
        median_image = indexed_collection.median()
        # Check if median calculation resulted in a valid image with bands
        if not median_image.bandNames().getInfo():
             st.warning(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Median Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{index_name}' ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ù†Ø¯ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø±Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯).", icon="âš ï¸")
             return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    except ee.EEException as median_e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Median Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{index_name}': {median_e}")
        return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])


    try:
        farm_values = median_image.reduceRegions(collection=farm_fc, reducer=ee.Reducer.mean(), scale=30, tileScale=8).getInfo()
    except ee.EEException as e: st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± reduceRegions: {e}"); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± reduceRegions: {e}"); return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    results_data = []
    # ... (rest of data extraction remains the same)
    if 'features' in farm_values:
        for feature in farm_values['features']:
            props = feature.get('properties', {})
            farm_id = props.get('farm_id'); value = props.get('mean')
            if farm_id is not None and value is not None: results_data.append({'Ù…Ø²Ø±Ø¹Ù‡': farm_id, index_name: value})
    if not results_data: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    return pd.DataFrame(results_data)


# --- Function for Weekly Comparison ---
@st.cache_data(ttl=1800)
def get_weekly_comparison(_filtered_df_json, start_date, end_date, index_name, sensor):
    """Compares the index values from the current week to the previous week."""
    if not isinstance(start_date, datetime.date) or not isinstance(end_date, datetime.date):
        st.error("ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡."); return pd.DataFrame()

    current_start = start_date; current_end = end_date
    prev_end = current_start - timedelta(days=1)
    prev_start = prev_end - timedelta(days=(end_date-start_date).days)

    print(f"Comparing Period: {current_start} to {current_end}")
    print(f"Previous Period: {prev_start} to {prev_end}")

    # Get data for the current period
    df_current = get_median_index_for_period(_filtered_df_json, current_start, current_end, index_name, sensor)
    if df_current.empty: st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ Ø¬Ù‡Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸"); return pd.DataFrame()

    # Get data for the previous period
    df_previous = get_median_index_for_period(_filtered_df_json, prev_start, prev_end, index_name, sensor)
    if df_previous.empty: st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„ÛŒ Ø¬Ù‡Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸"); return pd.DataFrame() # Cannot compare

    df_comparison = pd.merge(df_previous.rename(columns={index_name: f'{index_name}_prev'}),
                           df_current.rename(columns={index_name: f'{index_name}_curr'}),
                           on='Ù…Ø²Ø±Ø¹Ù‡', how='inner')
    if df_comparison.empty: st.info("Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø´ØªØ±Ú©ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ø¯ÙˆØ±Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯."); return pd.DataFrame()

    df_comparison['ØªØºÛŒÛŒØ±'] = df_comparison[f'{index_name}_curr'] - df_comparison[f'{index_name}_prev']
    df_comparison['Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±'] = np.where(np.abs(df_comparison[f'{index_name}_prev']) > 1e-9,
                                       ((df_comparison['ØªØºÛŒÛŒØ±'] / df_comparison[f'{index_name}_prev']) * 100.0), np.nan)
    df_decreased = df_comparison[df_comparison['ØªØºÛŒÛŒØ±'] < 0].copy()
    df_decreased = df_decreased.sort_values(by='Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±', ascending=True, na_position='last')
    return df_decreased


# --- Streamlit App Layout ---
st.set_page_config(page_title=APP_TITLE, layout="wide", initial_sidebar_state="expanded")
st.title(f"ğŸŒ¾ {APP_TITLE}")
st.markdown("Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ùˆ Google Earth Engine")
st.divider()

# Initialize GEE
if initialize_gee():
    # Load data
    farm_data_df = load_data(CSV_FILE_PATH)

    # --- Sidebar Controls ---
    with st.sidebar:
        st.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ ÙÛŒÙ„ØªØ±Ù‡Ø§")
        st.divider()
        st.subheader("ğŸ—“ï¸ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ")
        today = datetime.date.today()
        default_start = today - timedelta(days=6)
        start_date = st.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", value=default_start, max_value=today, help="ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ø¯ÙˆØ±Ù‡ ØªØ­Ù„ÛŒÙ„ Ø§ØµÙ„ÛŒ")
        end_date = st.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", value=today, min_value=start_date, max_value=today, help="ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù† Ø¯ÙˆØ±Ù‡ ØªØ­Ù„ÛŒÙ„ Ø§ØµÙ„ÛŒ")
        st.info(f"Ù…Ø¯Øª Ø¯ÙˆØ±Ù‡: {(end_date - start_date).days + 1} Ø±ÙˆØ²", icon="â³")
        st.divider()

        st.subheader("ğŸ” ÙÛŒÙ„ØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
        days_list = ["Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§"] + sorted(farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique().tolist())
        selected_day = st.selectbox("Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ", options=days_list, help="ÙÛŒÙ„ØªØ± Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ² Ù‡ÙØªÙ‡")
        if selected_day == "Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§": filtered_df = farm_data_df.copy()
        else: filtered_df = farm_data_df[farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()
        st.caption(f"{len(filtered_df)} Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯.")

        available_indices = list(INDEX_DEFINITIONS.keys())
        selected_index = st.selectbox("Ø´Ø§Ø®Øµ Ù…ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„", options=available_indices, format_func=lambda x: INDEX_DEFINITIONS[x]['name_fa'], help="Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡ØŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡")
        selected_sensor = st.radio("Ø³Ù†Ø³ÙˆØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡", ('Sentinel-2', 'Landsat'), index=0, horizontal=True, help="Sentinel-2 (10m, RedEdge), Landsat (30m)")
        st.divider()

        st.subheader("ğŸšœ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡")
        farm_list = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + sorted(filtered_df['Ù…Ø²Ø±Ø¹Ù‡'].unique().tolist())
        selected_farm = st.selectbox("Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ (ÛŒØ§ Ù‡Ù…Ù‡)", options=farm_list, help="Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ")
        st.divider()

        st.header("â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§")
        index_to_explain = st.selectbox("Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø´Ø§Ø®Øµ:", options=list(INDEX_DEFINITIONS.keys()), index=available_indices.index(selected_index), format_func=lambda x: INDEX_DEFINITIONS[x]['name_fa'])
        if index_to_explain:
            with st.expander(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ø´Ø§Ø®Øµ {INDEX_DEFINITIONS[index_to_explain]['name_fa']}", expanded=False):
                st.markdown(INDEX_DEFINITIONS[index_to_explain]['desc_fa'], unsafe_allow_html=True)
        st.divider()
        st.caption("v1.1 - Dehkhoda Sugarcane Monitoring")

    # --- Main Panel with Tabs ---
    tab1, tab2, tab3 = st.tabs(["ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ Ùˆ Ø¬Ø²Ø¦ÛŒØ§Øª", "ğŸ“Š Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹", "ğŸ“‰ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ"])

    with tab1:
        col_map, col_detail = st.columns([2, 1])
        with col_map:
            st.subheader(f"Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
            st.caption(f"Ø¯ÙˆØ±Ù‡: {start_date.strftime('%Y-%m-%d')} ØªØ§ {end_date.strftime('%Y-%m-%d')} | Ø³Ù†Ø³ÙˆØ±: {selected_sensor}")
            map_placeholder = st.empty()
            m = geemap.Map(center=[INITIAL_LAT, INITIAL_LON], zoom=INITIAL_ZOOM, add_google_map=False)
            m.add_basemap('HYBRID')
            vis_params = INDEX_DEFINITIONS.get(selected_index, {}).get('vis', {'min': 0, 'max': 1, 'palette': ['white', 'gray']})

            display_geom = None; target_object_for_map = None; farm_info_for_display = None
            display_df = filtered_df.copy() # Use day-filtered data

            if selected_farm == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                display_df_valid = display_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
                if not display_df_valid.empty:
                    try:
                        min_lon, min_lat = display_df_valid['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), display_df_valid['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
                        max_lon, max_lat = display_df_valid['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(), display_df_valid['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
                        display_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])
                        target_object_for_map = display_geom
                    except Exception as bounds_e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø±Ø²Ù‡Ø§: {bounds_e}")
                else: st.info("Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ² ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="ğŸ“")
            else: # Single farm
                farm_info_rows = display_df[display_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm]
                if not farm_info_rows.empty:
                    farm_info_for_display = farm_info_rows.iloc[0]
                    farm_lat = farm_info_for_display['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']; farm_lon = farm_info_for_display['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
                    if pd.notna(farm_lat) and pd.notna(farm_lon):
                        try:
                            farm_geom = ee.Geometry.Point([farm_lon, farm_lat])
                            display_geom = farm_geom.buffer(150); target_object_for_map = farm_geom
                        except Exception as point_e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ù‚Ø·Ù‡: {point_e}"); farm_info_for_display = None
                    else: st.warning(f"Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {selected_farm}.", icon="ğŸ“"); farm_info_for_display = None
                else: st.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ {selected_farm} Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")

            # --- Display Map Layer ---
            layer_added = False
            if display_geom:
                with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø´Ù‡ '{selected_index}'... (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù…ÛŒ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯)"):
                    base_collection = get_image_collection(start_date, end_date, display_geom, selected_sensor)
                    # Base collection might be empty but not None
                    if base_collection is not None:
                        indexed_collection = calculate_single_index(base_collection, selected_index)
                        if indexed_collection is not None:
                            try:
                                # **CRUCIAL CHANGE:** Use median composite for map display
                                median_image = indexed_collection.median()
                                # Check if median calculation resulted in a valid image
                                if median_image.bandNames().getInfo():
                                    layer_image = median_image.clip(display_geom) if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else median_image
                                    m.addLayer(layer_image, vis_params, f'{selected_index} (Median)')
                                    layer_added = True
                                    try: m.add_legend(title=f'{selected_index}', builtin_legend=None, palette=vis_params['palette'], min=vis_params['min'], max=vis_params['max'])
                                    except Exception as legend_e: print(f"Legend error: {legend_e}")

                                    # Add download button
                                    # ... (download button logic remains same)

                                else:
                                     st.warning(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Median Ø¨Ø±Ø§ÛŒ '{selected_index}' ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ù†Ø¯ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø±Ø¯. Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.", icon="âš ï¸")

                            except ee.EEException as ee_err: st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§ÛŒÙ‡ Ù†Ù‚Ø´Ù‡: {ee_err}")
                            except Exception as err: st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§ÛŒÙ‡ Ù†Ù‚Ø´Ù‡: {err}")
                        # else: Warning shown in calculate_single_index
                    # else: Warning shown in get_image_collection

                # --- Add markers ---
                if layer_added: # Only add markers if layer exists
                    # ... (marker adding logic remains same, uses cleaned 'Ø³Ù†')
                    if selected_farm == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                        df_to_mark = display_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
                        for idx, row in df_to_mark.iterrows():
                            popup_html = f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {row['Ù…Ø²Ø±Ø¹Ù‡']}<br><b>Ú©Ø§Ù†Ø§Ù„:</b> {row['Ú©Ø§Ù†Ø§Ù„']} | <b>Ø§Ø¯Ø§Ø±Ù‡:</b> {row['Ø§Ø¯Ø§Ø±Ù‡']}<br><b>Ù…Ø³Ø§Ø­Øª:</b> {row['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}<br><b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {row['ÙˆØ§Ø±ÛŒØªÙ‡']} | <b>Ø³Ù†:</b> {row['Ø³Ù†']}" # Use 'Ø³Ù†'
                            folium.Marker(location=[row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=folium.Popup(popup_html, max_width=250), tooltip=f"{row['Ù…Ø²Ø±Ø¹Ù‡']}", icon=folium.Icon(color='blue', icon='info-sign', prefix='fa')).add_to(m)
                    elif farm_info_for_display is not None:
                        farm_info = farm_info_for_display
                        popup_html = f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {farm_info['Ù…Ø²Ø±Ø¹Ù‡']}<br><b>Ú©Ø§Ù†Ø§Ù„:</b> {farm_info['Ú©Ø§Ù†Ø§Ù„']} | <b>Ø§Ø¯Ø§Ø±Ù‡:</b> {farm_info['Ø§Ø¯Ø§Ø±Ù‡']}<br><b>Ù…Ø³Ø§Ø­Øª:</b> {farm_info['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}<br><b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {farm_info['ÙˆØ§Ø±ÛŒØªÙ‡']} | <b>Ø³Ù†:</b> {farm_info['Ø³Ù†']}" # Use 'Ø³Ù†'
                        folium.Marker(location=[farm_info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm_info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=folium.Popup(popup_html, max_width=250), tooltip=f"{farm_info['Ù…Ø²Ø±Ø¹Ù‡']} (Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡)", icon=folium.Icon(color='red', icon='star', prefix='fa')).add_to(m)

                # Center map
                if target_object_for_map:
                    zoom = INITIAL_ZOOM + 2 if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else INITIAL_ZOOM
                    try: m.center_object(target_object_for_map, zoom=zoom)
                    except: m.set_center(INITIAL_LON, INITIAL_LAT, INITIAL_ZOOM)

            else: st.info("Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ ØªØ¹ÛŒÛŒÙ† Ù†Ø´Ø¯.", icon="ğŸ—ºï¸")

            with map_placeholder: m.to_streamlit(height=550)

        # --- Column 2: Details / Timeseries ---
        with col_detail:
            if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                st.subheader(f" Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm}")
                st.divider()
                if farm_info_for_display is not None:
                    farm_info = farm_info_for_display
                    st.metric("Ú©Ø§Ù†Ø§Ù„", str(farm_info.get('Ú©Ø§Ù†Ø§Ù„', 'N/A')), help="Ø´Ù…Ø§Ø±Ù‡ Ú©Ø§Ù†Ø§Ù„")
                    st.metric("Ø§Ø¯Ø§Ø±Ù‡", str(farm_info.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')), help="Ø´Ù…Ø§Ø±Ù‡ Ø§Ø¯Ø§Ø±Ù‡")
                    st.metric("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", f"{farm_info['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}" if pd.notna(farm_info.get('Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª')) else "N/A", help="Ù…Ø³Ø§Ø­Øª Ø«Ø¨Øª Ø´Ø¯Ù‡")
                    st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", str(farm_info.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')))
                    st.metric("Ø³Ù†", str(farm_info.get('Ø³Ù†', 'N/A'))) # Use cleaned name
                    st.metric("Ø±ÙˆØ² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", str(farm_info.get('Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'N/A')))
                    st.divider()

                    st.subheader(f"ğŸ“ˆ Ø±ÙˆÙ†Ø¯ Ø´Ø§Ø®Øµ: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
                    if pd.notna(farm_info.get('Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ')) and pd.notna(farm_info.get('Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ')):
                        with st.spinner(f"Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ '{selected_index}'..."):
                            try:
                                farm_geom_ts = ee.Geometry.Point([farm_info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm_info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']])
                                ts_df = get_timeseries_for_farm(farm_geom_ts.toGeoJsonString(), start_date, end_date, selected_index, selected_sensor)
                            except Exception as ts_geom_e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù‡Ù†Ø¯Ø³Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_geom_e}"); ts_df = pd.DataFrame()

                        if not ts_df.empty:
                            fig_ts = px.line(ts_df, x='Date', y=selected_index, title=f"Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index}", markers=True, labels={'Date': 'ØªØ§Ø±ÛŒØ®', selected_index: f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                            fig_ts.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}", title_x=0.5)
                            fig_ts.update_traces(line=dict(color='royalblue', width=2), marker=dict(color='salmon', size=6))
                            st.plotly_chart(fig_ts, use_container_width=True)
                        # else: Warning/Info shown in get_timeseries_for_farm if empty
                    else: st.warning("Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ.", icon="ğŸ“")
                else: st.info("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
            else:
                 st.subheader("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø±ÙˆÙ†Ø¯")
                 st.info("Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ØŒ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.", icon="ğŸ‘ˆ")


    with tab2:
        st.subheader(f"ğŸ“Š Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
        st.caption(f"Ø¯ÙˆØ±Ù‡: {start_date.strftime('%Y-%m-%d')} ØªØ§ {end_date.strftime('%Y-%m-%d')} | Ø±ÙˆØ² Ù‡ÙØªÙ‡: '{selected_day}' | Ø³Ù†Ø³ÙˆØ±: {selected_sensor}")
        st.divider()
        if filtered_df.empty: st.warning(f"Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
        else:
            with st.spinner(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ '{selected_index}'..."):
                ranking_df = get_median_index_for_period(filtered_df.to_json(), start_date, end_date, selected_index, sensor=selected_sensor)

            if not ranking_df.empty:
                ascending_sort = INDEX_DEFINITIONS[selected_index].get('sort_ascending', False)
                ranking_df_sorted = ranking_df.sort_values(by=selected_index, ascending=ascending_sort, na_position='last').reset_index(drop=True)
                st.dataframe(ranking_df_sorted.style.format({selected_index: "{:.3f}"})
                                     .bar(subset=[selected_index], color='lightcoral' if ascending_sort else 'lightgreen', align='zero'), # Align bars at zero
                                     use_container_width=True)
                csv_rank = ranking_df_sorted.to_csv(index=False).encode('utf-8')
                st.download_button(label=f"ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ", data=csv_rank, file_name=f'ranking_{selected_index}_{selected_day}.csv', mime='text/csv', key='dl_rank')
            else: st.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ø¯.", icon="ğŸ“Š")
        st.divider()


    with tab3:
        st.subheader(f"ğŸ“‰ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ: Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ ({INDEX_DEFINITIONS[selected_index]['name_fa']})")
        st.caption(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯ÙˆØ±Ù‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ | Ø±ÙˆØ² Ù‡ÙØªÙ‡: '{selected_day}' | Ø³Ù†Ø³ÙˆØ±: {selected_sensor}")
        st.divider()
        if filtered_df.empty: st.warning(f"Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ø¬Ù‡Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
        else:
            with st.spinner(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ '{selected_index}'..."):
                comparison_df_decreased = get_weekly_comparison(filtered_df.to_json(), start_date, end_date, selected_index, selected_sensor)

            if not comparison_df_decreased.empty:
                st.markdown("##### Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ:")
                display_cols = ['Ù…Ø²Ø±Ø¹Ù‡', f'{index_name}_prev', f'{index_name}_curr', 'ØªØºÛŒÛŒØ±', 'Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±']
                st.dataframe(comparison_df_decreased[display_cols].style.format({
                                f'{index_name}_prev': "{:.3f}", f'{index_name}_curr': "{:.3f}",
                                'ØªØºÛŒÛŒØ±': "{:+.3f}", 'Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±': "{:+.1f}%"
                            }).applymap(lambda x: 'color: red' if isinstance(x, (int, float)) and x < 0 else ('color: green' if isinstance(x, (int, float)) and x > 0 else 'color: black'), subset=['ØªØºÛŒÛŒØ±','Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±']),
                            use_container_width=True)
                st.divider()
                st.markdown("##### Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ:")
                fig_comp = go.Figure()
                fig_comp.add_trace(go.Bar(x=comparison_df_decreased['Ù…Ø²Ø±Ø¹Ù‡'], y=comparison_df_decreased[f'{index_name}_prev'], name='Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„', marker_color='dodgerblue', text=comparison_df_decreased[f'{index_name}_prev'].round(3), textposition='auto'))
                fig_comp.add_trace(go.Bar(x=comparison_df_decreased['Ù…Ø²Ø±Ø¹Ù‡'], y=comparison_df_decreased[f'{index_name}_curr'], name='Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ', marker_color='lightcoral', text=comparison_df_decreased[f'{index_name}_curr'].round(3), textposition='auto'))
                fig_comp.update_layout(barmode='group', title=f'Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø§Ø®Øµ {selected_index} (Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´)', xaxis_title='Ù…Ø²Ø±Ø¹Ù‡', yaxis_title=f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}', legend_title='Ø¯ÙˆØ±Ù‡', hovermode="x unified", title_x=0.5)
                st.plotly_chart(fig_comp, use_container_width=True)
                st.divider()
                csv_comp = comparison_df_decreased.to_csv(index=False).encode('utf-8')
                st.download_button(label=f"ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡", data=csv_comp, file_name=f'comparison_decrease_{selected_index}_{selected_day}.csv', mime='text/csv', key='dl_comp')
            else:
                 # Check if comparison failed due to lack of data in *either* period (based on warnings from get_median_index_for_period)
                 # This requires passing status back or checking df validity more carefully.
                 # For now, assume if comparison_df is empty, either no decrease or no data.
                 st.success(f"âœ… Ø¹Ø¯Ù… Ú©Ø§Ù‡Ø´: Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ '{selected_index}' Ø±Ø§ Ø¨ÛŒÙ† Ø¯Ùˆ Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ± Ù†Ø´Ø§Ù† Ù†Ø¯Ø§Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª.")

else:
    st.error("Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§ Ùˆ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.", icon="ğŸš¨")