import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
from folium import plugins
import datetime
import time
import json
import os
import plotly.express as px
from dateutil.relativedelta import relativedelta

# ==============================================================================
# Configuration and Initialization
# ==============================================================================

# --- Streamlit Page Configuration ---
st.set_page_config(
    page_title="Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§",
    page_icon="ğŸŒ¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Constants ---
CSV_FILE_PATH = 'output (1).csv'  # Path to your CSV file
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json' # Path to your GEE Service Account JSON file
DEFAULT_LATITUDE = 31.534442
DEFAULT_LONGITUDE = 48.724416
INITIAL_ZOOM = 11
DATE_FORMAT = "%Y-%m-%d"

# --- GEE Authentication ---
@st.cache_resource(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine...")
def authenticate_gee(service_account_file):
    """Authenticates to Google Earth Engine using a service account."""
    try:
        # Check if the service account file exists
        if not os.path.exists(service_account_file):
            st.error(f"ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{service_account_file}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()

        # Load credentials from the file
        with open(service_account_file) as f:
            credentials_dict = json.load(f)

        credentials = ee.ServiceAccountCredentials(
            email=credentials_dict['client_email'],
            key_data=json.dumps(credentials_dict) # Pass the whole dict as key_data
        )
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Authenticated Successfully using Service Account.")
        return True # Indicate success
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª ÙØ§ÛŒÙ„ Service Account Ùˆ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø¢Ù† Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        return False
    except FileNotFoundError:
        st.error(f"ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{service_account_file}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return False
    except json.JSONDecodeError:
        st.error(f"ÙØ§ÛŒÙ„ Service Account ('{service_account_file}') Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª ÛŒØ§ ÙØ±Ù…Øª JSON ØµØ­ÛŒØ­ÛŒ Ù†Ø¯Ø§Ø±Ø¯.")
        return False
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        return False

# Perform authentication
if not authenticate_gee(SERVICE_ACCOUNT_FILE):
    st.stop() # Stop execution if authentication fails

# --- Load Data ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...")
def load_farm_data(csv_path):
    """Loads farm data from the CSV file."""
    try:
        df = pd.read_csv(csv_path)
        # Basic validation
        required_columns = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'coordinates_missing']
        if not all(col in df.columns for col in required_columns):
            st.error(f"ÙØ§ÛŒÙ„ CSV Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ {required_columns} Ø¨Ø§Ø´Ø¯.")
            st.stop()
        # Convert coordinate columns to numeric, coercing errors
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        # Handle missing coordinates flag more robustly
        df['coordinates_missing'] = df['coordinates_missing'].fillna(False).astype(bool) | df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].isna() | df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].isna()

        # Filter out farms with missing coordinates for mapping/GEE analysis
        df_valid_coords = df[~df['coordinates_missing']].copy()
        df_valid_coords['geometry'] = df_valid_coords.apply(
            lambda row: ee.Geometry.Point([row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']]), axis=1
        )
        return df, df_valid_coords
    except FileNotFoundError:
        st.error(f"ÙØ§ÛŒÙ„ CSV Ø¯Ø± Ù…Ø³ÛŒØ± '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        st.stop()

farm_data_full, farm_data_valid = load_farm_data(CSV_FILE_PATH)

# ==============================================================================
# GEE Functions
# ==============================================================================

# --- Cloud Masking ---
def mask_s2_clouds(image):
    """Masks clouds in Sentinel-2 images."""
    qa = image.select('QA60')
    cloud_bit_mask = 1 << 10
    cirrus_bit_mask = 1 << 11
    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0) \
             .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))
    return image.updateMask(mask).divide(10000) # Scale factor for S2

def mask_landsat_clouds(image):
    """Masks clouds in Landsat 8/9 images using the QA_PIXEL band."""
    qa_pixel = image.select('QA_PIXEL')
    # Bits 3 and 4 are cloud shadow and cloud, respectively.
    cloud_shadow_bit = 1 << 3
    cloud_bit = 1 << 4
    # Mask is clear if both bits are 0.
    mask = qa_pixel.bitwiseAnd(cloud_shadow_bit).eq(0) \
                   .And(qa_pixel.bitwiseAnd(cloud_bit).eq(0))
    return image.updateMask(mask).select("SR_B.*").multiply(0.0000275).add(-0.2) # Apply scale factors for Landsat Collection 2 SR


# --- Image Collection Retrieval ---
def get_image_collection(aoi, start_date, end_date, source='Sentinel-2'):
    """Gets a cloud-masked image collection for a given AOI and date range."""
    if source == 'Sentinel-2':
        collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
                       .filterBounds(aoi) \
                       .filterDate(start_date, end_date) \
                       .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \
                       .map(mask_s2_clouds)
    elif source == 'Landsat': # Combine Landsat 8 and 9
         collection_l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2') \
            .filterBounds(aoi) \
            .filterDate(start_date, end_date) \
            .map(mask_landsat_clouds)
         collection_l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \
            .filterBounds(aoi) \
            .filterDate(start_date, end_date) \
            .map(mask_landsat_clouds)
         collection = collection_l8.merge(collection_l9).sort('system:time_start')
    else:
        raise ValueError("Ù…Ù†Ø¨Ø¹ ØªØµÙˆÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª. 'Sentinel-2' ÛŒØ§ 'Landsat' Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")

    return collection

# --- Index Calculation Functions ---
def calculate_ndvi(image, source='Sentinel-2'):
    if source == 'Sentinel-2':
        nir = image.select('B8')
        red = image.select('B4')
    elif source == 'Landsat':
        nir = image.select('SR_B5')
        red = image.select('SR_B4')
    else:
        raise ValueError("Ù…Ù†Ø¨Ø¹ Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
    return image.addBands(nir.subtract(red).divide(nir.add(red)).rename('NDVI'))

def calculate_ndmi(image, source='Sentinel-2'):
    if source == 'Sentinel-2':
        nir = image.select('B8')
        swir1 = image.select('B11')
    elif source == 'Landsat':
        nir = image.select('SR_B5')
        swir1 = image.select('SR_B6')
    else:
        raise ValueError("Ù…Ù†Ø¨Ø¹ Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
    return image.addBands(nir.subtract(swir1).divide(nir.add(swir1)).rename('NDMI'))

def calculate_evi(image, source='Sentinel-2'):
    if source == 'Sentinel-2':
        nir = image.select('B8')
        red = image.select('B4')
        blue = image.select('B2')
        evi = image.expression(
            '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {
                'NIR': nir, 'RED': red, 'BLUE': blue
            }).rename('EVI')
    elif source == 'Landsat':
        nir = image.select('SR_B5')
        red = image.select('SR_B4')
        blue = image.select('SR_B2')
        evi = image.expression(
            '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {
                'NIR': nir, 'RED': red, 'BLUE': blue
            }).rename('EVI')
    else:
        raise ValueError("Ù…Ù†Ø¨Ø¹ Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
    return image.addBands(evi)

def calculate_msi(image, source='Sentinel-2'):
    # Moisture Stress Index
    if source == 'Sentinel-2':
        swir1 = image.select('B11')
        nir = image.select('B8')
    elif source == 'Landsat':
        swir1 = image.select('SR_B6')
        nir = image.select('SR_B5')
    else:
        raise ValueError("Ù…Ù†Ø¨Ø¹ Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
    return image.addBands(swir1.divide(nir).rename('MSI'))

# Placeholder functions for complex indices - require more specific algorithms/data
def calculate_lai(image, source='Sentinel-2'):
    # Simple LAI estimation using NDVI (needs calibration)
    # Example: LAI = a * exp(b * NDVI) - adjust coefficients a, b
    # Or use established GEE LAI products if available (e.g., MODIS)
    ndvi = calculate_ndvi(image.select([]).addBands(image), source).select('NDVI') # Ensure NDVI is calculated first
    # Using a generic formula for demonstration - replace with a calibrated one
    lai = ndvi.multiply(5.0).exp().multiply(0.1).rename('LAI') # Example: 0.1 * exp(5.0 * NDVI)
    return image.addBands(lai)

def calculate_biomass(image, source='Sentinel-2'):
    # Simple Biomass estimation using LAI (needs calibration)
    # Example: Biomass = a * LAI + b - adjust coefficients a, b
    lai = calculate_lai(image.select([]).addBands(image), source).select('LAI') # Ensure LAI is calculated first
    # Using generic coefficients for demonstration
    a = 1.5 # Example coefficient
    b = 0.5 # Example coefficient
    biomass = lai.multiply(a).add(b).rename('Biomass')
    return image.addBands(biomass)

def calculate_et(image, source='Sentinel-2'):
    # Evapotranspiration - Very complex. Using NDVI as a proxy indicator for demonstration.
    # Real ET requires meteorological data and models (e.g., Penman-Monteith, SSEBop).
    # Consider using MODIS ET product ('MODIS/061/MOD16A2') if temporal/spatial resolution fits.
    ndvi = calculate_ndvi(image.select([]).addBands(image), source).select('NDVI')
    # Simple proxy: Higher NDVI often correlates with higher ET in vegetated areas
    et_proxy = ndvi.multiply(10).rename('ET_Proxy') # Scale NDVI to an arbitrary ET range
    return image.addBands(et_proxy)

def calculate_chlorophyll(image, source='Sentinel-2'):
    # Chlorophyll Index - Example using MCARI (Modified Chlorophyll Absorption Ratio Index)
    # MCARI = ((REdge - Red) - 0.2 * (REdge - Green)) * (REdge / Red)
    # Requires Red Edge bands (available in Sentinel-2)
    if source == 'Sentinel-2':
        red = image.select('B4')
        green = image.select('B3')
        red_edge = image.select('B5') # Using B5 as a representative Red Edge band
        mcari = ((red_edge.subtract(red)).subtract(red_edge.subtract(green).multiply(0.2))).multiply(red_edge.divide(red))
        return image.addBands(mcari.rename('Chlorophyll'))
    elif source == 'Landsat':
        # Landsat doesn't have the same Red Edge bands. Use a different index or proxy.
        # Example: Using NDVI as a simple proxy for chlorophyll content
        ndvi = calculate_ndvi(image.select([]).addBands(image), source).select('NDVI')
        return image.addBands(ndvi.rename('Chlorophyll_Proxy'))
    else:
        raise ValueError("Ù…Ù†Ø¨Ø¹ Ù†Ø§Ù…Ø¹ØªØ¨Ø±")

# --- Index Dictionary ---
INDEX_FUNCTIONS = {
    'NDVI': calculate_ndvi,
    'NDMI': calculate_ndmi,
    'EVI': calculate_evi,
    'MSI': calculate_msi,
    'LAI': calculate_lai,          # Placeholder/Simple Estimation
    'Biomass': calculate_biomass,  # Placeholder/Simple Estimation
    'ET': calculate_et,            # Placeholder/Proxy
    'Chlorophyll': calculate_chlorophyll # Placeholder/Proxy for Landsat
}

INDEX_PALETTES = {
    'NDVI': '006400, FFFF00, FF0000', # Green, Yellow, Red
    'NDMI': '0000FF, FFFF00, FF0000', # Blue, Yellow, Red (Wet to Dry)
    'EVI': '006400, FFFF00, FF0000', # Green, Yellow, Red
    'MSI': 'FF0000, FFFF00, 0000FF', # Red, Yellow, Blue (Stressed to Wet)
    'LAI': 'F0FFF0, 00FF00, 006400', # Honeydew, Green, DarkGreen (Low to High LAI)
    'Biomass': 'F5DEB3, 90EE90, 008000', # Wheat, LightGreen, Green (Low to High Biomass)
    'ET_Proxy': 'ADD8E6, FFFF00, FF4500', # LightBlue, Yellow, OrangeRed (Low to High ET Proxy)
    'Chlorophyll': 'FFFFE0, 90EE90, 006400', # LightYellow, LightGreen, DarkGreen (Low to High Chlorophyll)
    'Chlorophyll_Proxy': 'FFFFE0, 90EE90, 006400' # Same as above
}

INDEX_RANGES = { # Approximate ranges for visualization, adjust as needed
    'NDVI': {'min': 0, 'max': 1},
    'NDMI': {'min': -1, 'max': 1},
    'EVI': {'min': 0, 'max': 1},
    'MSI': {'min': 0, 'max': 3}, # Higher values indicate more moisture stress
    'LAI': {'min': 0, 'max': 8},
    'Biomass': {'min': 0, 'max': 15}, # Units depend on calibration (e.g., t/ha)
    'ET_Proxy': {'min': 0, 'max': 10}, # Arbitrary units based on NDVI proxy
    'Chlorophyll': {'min': 0, 'max': 1}, # MCARI range can vary
    'Chlorophyll_Proxy': {'min': 0, 'max': 1} # NDVI range
}

# --- Get Time Series Data ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ...", ttl=3600) # Cache for 1 hour
def get_time_series_for_farm(_farm_name, farm_geometry, index_name, start_date, end_date, source):
    """Calculates the time series for a given index and farm."""
    try:
        collection = get_image_collection(farm_geometry.buffer(100), start_date, end_date, source) # Buffer slightly

        if index_name not in INDEX_FUNCTIONS:
            st.error(f"ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{index_name}' ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            return None

        index_func = INDEX_FUNCTIONS[index_name]

        def calculate_index_stat(image):
            # Calculate the specific index
            img_with_index = index_func(image, source)
            # Select the band corresponding to the index name (handle proxy names)
            index_band_name = index_name
            if index_name == 'ET' and source == 'Sentinel-2': index_band_name = 'ET_Proxy'
            if index_name == 'Chlorophyll' and source == 'Landsat': index_band_name = 'Chlorophyll_Proxy'

            stat = img_with_index.select(index_band_name).reduceRegion(
                reducer=ee.Reducer.mean(),
                geometry=farm_geometry,
                scale=30, # Adjust scale based on source and desired precision
                maxPixels=1e9
            )
            # Return feature with null geometry, index value, and date
            return ee.Feature(None, {
                'date': image.date().format(DATE_FORMAT),
                index_band_name: stat.get(index_band_name)
            })

        # Filter out images where the calculation might fail (e.g., no valid pixels)
        def map_func(img):
            indexed_img = index_func(img, source)
            index_band_name = index_name
            if index_name == 'ET' and source == 'Sentinel-2': index_band_name = 'ET_Proxy'
            if index_name == 'Chlorophyll' and source == 'Landsat': index_band_name = 'Chlorophyll_Proxy'
            # Check if the band exists before calculating stats
            return indexed_img.set('system:time_start', img.get('system:time_start')) # Keep timestamp

        valid_collection = collection.map(map_func)

        # Calculate stats only if the collection is not empty
        if valid_collection.size().getInfo() == 0:
            # st.warning(f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            print(f"Warning: No valid images found for time series {index_name} between {start_date} and {end_date}")
            return pd.DataFrame(columns=['date', index_name]) # Return empty dataframe


        stats = valid_collection.map(calculate_index_stat).filter(ee.Filter.notNull([index_name if not (index_name == 'ET' and source == 'Sentinel-2') and not (index_name == 'Chlorophyll' and source == 'Landsat') else ('ET_Proxy' if index_name == 'ET' else 'Chlorophyll_Proxy')]))

        # Convert to Pandas DataFrame
        data = stats.getInfo()['features']
        dates = [item['properties']['date'] for item in data]
        # Handle potential proxy names when extracting values
        index_band_name_prop = index_name
        if index_name == 'ET' and source == 'Sentinel-2': index_band_name_prop = 'ET_Proxy'
        if index_name == 'Chlorophyll' and source == 'Landsat': index_band_name_prop = 'Chlorophyll_Proxy'

        values = [item['properties'][index_band_name_prop] for item in data]

        df = pd.DataFrame({'date': pd.to_datetime(dates), index_name: values})
        df = df.sort_values(by='date').reset_index(drop=True)
        return df

    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ {index_name}: {e}")
        return None
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}")
        return None

# --- Get Map Image ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ù†Ù‚Ø´Ù‡...", ttl=3600)
def get_map_image(_farm_name, farm_geometry, index_name, date, source):
    """Generates a GEE Image for the selected index and date."""
    try:
        # Get collection for a small window around the date to increase chances of getting an image
        start_date = (date - datetime.timedelta(days=3)).strftime(DATE_FORMAT)
        end_date = (date + datetime.timedelta(days=1)).strftime(DATE_FORMAT) # Include the selected date
        collection = get_image_collection(farm_geometry.buffer(500), start_date, end_date, source) # Wider buffer for context

        if collection.size().getInfo() == 0:
            # st.warning(f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø­Ø¯ÙˆØ¯ ØªØ§Ø±ÛŒØ® {date.strftime(DATE_FORMAT)} Ø¨Ø±Ø§ÛŒ {index_name} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            print(f"Warning: No image found near {date.strftime(DATE_FORMAT)} for {index_name}")
            return None, None # Return None for image and actual date

        # Use the image closest to the target date
        image = ee.Image(collection.sort('system:time_start', False).first()) # Get latest first within window
        actual_date = ee.Date(image.get('system:time_start')).format(DATE_FORMAT).getInfo()

        if index_name not in INDEX_FUNCTIONS:
            st.error(f"ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{index_name}' ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            return None, None

        index_func = INDEX_FUNCTIONS[index_name]
        map_image = index_func(image, source)

        # Select the correct band name (handle proxies)
        index_band_name = index_name
        if index_name == 'ET' and source == 'Sentinel-2': index_band_name = 'ET_Proxy'
        if index_name == 'Chlorophyll' and source == 'Landsat': index_band_name = 'Chlorophyll_Proxy'

        return map_image.select(index_band_name), actual_date

    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù†Ù‚Ø´Ù‡ Ø¨Ø±Ø§ÛŒ {index_name}: {e}")
        return None, None
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù†Ù‚Ø´Ù‡: {e}")
        return None, None

# --- Calculate Weekly Average ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÚ¯ÛŒ...", ttl=3600)
def calculate_weekly_average(_farm_name_list, farm_geometries_dict, index_name, end_date_dt, source):
    """Calculates the average index value over the last week for multiple farms."""
    start_date_dt = end_date_dt - datetime.timedelta(days=7)
    start_date = start_date_dt.strftime(DATE_FORMAT)
    end_date = end_date_dt.strftime(DATE_FORMAT)

    farm_results = {}

    # Combine geometries for potentially faster initial filtering (optional)
    # combined_aoi = ee.Geometry.MultiPoint([geom.centroid(maxError=1) for geom in farm_geometries_dict.values()]).bounds()
    # Use a large bounding box instead if MultiPoint is too complex
    all_lons = [geom.centroid(maxError=1).coordinates().get(0).getInfo() for geom in farm_geometries_dict.values()]
    all_lats = [geom.centroid(maxError=1).coordinates().get(1).getInfo() for geom in farm_geometries_dict.values()]
    combined_aoi = ee.Geometry.Rectangle([min(all_lons), min(all_lats), max(all_lons), max(all_lats)])


    try:
        collection = get_image_collection(combined_aoi, start_date, end_date, source)

        if index_name not in INDEX_FUNCTIONS:
            st.error(f"ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{index_name}' ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            return {}

        index_func = INDEX_FUNCTIONS[index_name]

        # Calculate the index for the entire collection
        def add_index(image):
            return index_func(image, source)
        indexed_collection = collection.map(add_index)

        # Select the correct band name
        index_band_name = index_name
        if index_name == 'ET' and source == 'Sentinel-2': index_band_name = 'ET_Proxy'
        if index_name == 'Chlorophyll' and source == 'Landsat': index_band_name = 'Chlorophyll_Proxy'

        # Calculate the mean over the time period
        mean_image = indexed_collection.select(index_band_name).mean()

        # Calculate mean value for each farm geometry
        for farm_name, geom in farm_geometries_dict.items():
            try:
                stat = mean_image.reduceRegion(
                    reducer=ee.Reducer.mean(),
                    geometry=geom,
                    scale=30,
                    maxPixels=1e9
                )
                # Use .get() with a default value (e.g., None)
                mean_value = stat.get(index_band_name).getInfo()
                farm_results[farm_name] = mean_value if mean_value is not None else float('nan') # Handle null results
            except ee.EEException as e:
                # Log error for specific farm but continue
                print(f"Error calculating weekly average for {farm_name}: {e}")
                farm_results[farm_name] = float('nan') # Assign NaN on error
            except Exception as e:
                 print(f"Unexpected error calculating weekly average for {farm_name}: {e}")
                 farm_results[farm_name] = float('nan') # Assign NaN on error


        return farm_results

    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ {index_name}: {e}")
        return {name: float('nan') for name in _farm_name_list} # Return NaN for all on major error
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÚ¯ÛŒ: {e}")
        return {name: float('nan') for name in _farm_name_list} # Return NaN for all on major error


# ==============================================================================
# Streamlit UI Layout
# ==============================================================================

st.title("ğŸŒ¾ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§")
st.markdown("Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù‡ÙØªÚ¯ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ùˆ Google Earth Engine")

# --- Sidebar ---
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

# Data Source Selection
data_source = st.sidebar.radio("Ù…Ù†Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ:", ('Sentinel-2', 'Landsat'), index=0, horizontal=True)

# Farm Selection
available_farms = sorted(farm_data_valid['Ù…Ø²Ø±Ø¹Ù‡'].unique())
selected_farm_name = st.sidebar.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡:", available_farms)

# Filter farms based on selected farm name
selected_farm_data = farm_data_valid[farm_data_valid['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
selected_farm_geometry = selected_farm_data['geometry']
selected_farm_coords = (selected_farm_data['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], selected_farm_data['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])

# Day of the Week Filter (Filters the *list* of farms for comparison/ranking)
available_days = sorted(farm_data_full['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique())
selected_day = st.sidebar.selectbox("ÙÛŒÙ„ØªØ± Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ² Ù‡ÙØªÙ‡ (Ø¨Ø±Ø§ÛŒ Ø¬Ø¯Ø§ÙˆÙ„):", ["Ù‡Ù…Ù‡"] + available_days)

# Filter farm_data_valid based on the selected day for ranking/comparison
if selected_day == "Ù‡Ù…Ù‡":
    filtered_farm_data = farm_data_valid.copy()
else:
    filtered_farm_data = farm_data_valid[farm_data_valid['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()

filtered_farm_names = filtered_farm_data['Ù…Ø²Ø±Ø¹Ù‡'].tolist()
filtered_farm_geometries = {row['Ù…Ø²Ø±Ø¹Ù‡']: row['geometry'] for index, row in filtered_farm_data.iterrows()}


# Index Selection
available_indices = list(INDEX_FUNCTIONS.keys())
selected_index = st.sidebar.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø§Ø®Øµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ:", available_indices)

# Date Selection (for map display) - Default to today
today = datetime.date.today()
selected_date = st.sidebar.date_input("Ø§Ù†ØªØ®Ø§Ø¨ ØªØ§Ø±ÛŒØ® Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡:", today)

# Time Series Date Range
st.sidebar.markdown("---")
st.sidebar.markdown("**Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ:**")
col1_ts, col2_ts = st.sidebar.columns(2)
default_start_ts = today - relativedelta(years=1) # Default to one year back
ts_start_date = col1_ts.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹:", default_start_ts)
ts_end_date = col2_ts.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†:", today) # Default to today

# Validate date range
if ts_start_date > ts_end_date:
    st.sidebar.error("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø¹Ø¯ Ø§Ø² ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø´Ø¯.")
    st.stop()


# --- Main Panel ---
col1_map, col2_info = st.columns([3, 1]) # Map takes more space

with col1_map:
    st.subheader(f"Ù†Ù‚Ø´Ù‡ Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}")
    st.markdown(f"ØªØ§Ø±ÛŒØ® ØªÙ‚Ø±ÛŒØ¨ÛŒ ØªØµÙˆÛŒØ±: {selected_date.strftime(DATE_FORMAT)}")

    # Initialize map centered on the selected farm or default coordinates
    map_center = selected_farm_coords if selected_farm_name else (DEFAULT_LATITUDE, DEFAULT_LONGITUDE)
    m = geemap.Map(center=map_center, zoom=INITIAL_ZOOM + 2, add_google_map=False) # Start zoomed closer
    m.add_basemap("HYBRID") # Use Google Satellite Hybrid

    # Add Farm Boundary Layer
    try:
        # Create a buffer around the point geometry to represent the farm area visually
        # Adjust buffer size as needed (e.g., 500 meters)
        farm_boundary_viz = selected_farm_geometry.buffer(500) # 500m buffer
        m.add_ee_layer(farm_boundary_viz, {'color': 'FFFF00', 'fillColor': 'FFFF0050'}, f'Ù…Ø±Ø² Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}')
    except Exception as e:
        st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ù…Ø±Ø² Ù…Ø²Ø±Ø¹Ù‡: {e}")


    # Get and Add Index Layer
    map_image, actual_image_date = get_map_image(selected_farm_name, selected_farm_geometry, selected_index, selected_date, data_source)

    if map_image:
        index_vis_params = INDEX_RANGES.get(selected_index, {'min': 0, 'max': 1})
        index_palette = INDEX_PALETTES.get(selected_index, '00FF00') # Default to green if not found
        index_vis_params['palette'] = index_palette.split(', ') # Split palette string into list

        # Determine the correct band name for visualization
        index_band_name_viz = selected_index
        if selected_index == 'ET' and data_source == 'Sentinel-2': index_band_name_viz = 'ET_Proxy'
        if selected_index == 'Chlorophyll' and data_source == 'Landsat': index_band_name_viz = 'Chlorophyll_Proxy'

        try:
            m.add_ee_layer(map_image, index_vis_params, f"{selected_index} ({actual_image_date})")
            m.add_colorbar(index_vis_params, label=selected_index, layer_name=f"{selected_index} ({actual_image_date})")
            st.info(f"Ù†Ù‚Ø´Ù‡ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† ØªØµÙˆÛŒØ± Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± ØªØ§Ø±ÛŒØ® {actual_image_date} Ø§Ø³Øª.")
        except ee.EEException as e:
             st.error(f"Ø®Ø·Ø§ÛŒ GEE Ù‡Ù†Ú¯Ø§Ù… Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ Ù†Ù‚Ø´Ù‡ {selected_index}: {e}")
        except Exception as e:
             st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ Ù‡Ù†Ú¯Ø§Ù… Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ Ù†Ù‚Ø´Ù‡ ÛŒØ§ Ú©Ø§Ù„Ø±Ø¨Ø§Ø±: {e}")

    else:
        st.warning(f"ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø´Ø§Ø®Øµ {selected_index} Ø¯Ø± ØªØ§Ø±ÛŒØ® {selected_date.strftime(DATE_FORMAT)} ÛŒØ§ÙØª Ù†Ø´Ø¯.")

    # Add Layer Control
    m.add_layer_control()

    # Display Map
    m.to_streamlit(height=500)

    # Map Download Button (Placeholder - geemap download needs refinement for server-side)
    # st.download_button(
    #     label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ù‚Ø´Ù‡ (PNG)",
    #     data=m.to_png() if map_image else "", # Needs geemap's download functionality properly implemented
    #     file_name=f"map_{selected_farm_name}_{selected_index}_{selected_date.strftime('%Y%m%d')}.png",
    #     mime="image/png",
    #     disabled=not map_image
    # )
    st.caption("Ù‚Ø§Ø¨Ù„ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ù‚Ø´Ù‡ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª.")


with col2_info:
    st.subheader(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")
    farm_info = farm_data_full[farm_data_full['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
    # Display farm details - handle potential missing data gracefully
    st.markdown(f"""
    - **Ú©Ø§Ù†Ø§Ù„:** {farm_info.get('Ú©Ø§Ù†Ø§Ù„', 'N/A')}
    - **Ø§Ø¯Ø§Ø±Ù‡:** {farm_info.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')}
    - **Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª:** {farm_info.get('Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª', 'N/A')} Ù‡Ú©ØªØ§Ø±
    - **ÙˆØ§Ø±ÛŒØªÙ‡:** {farm_info.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}
    - **Ø³Ù†:** {farm_info.get('Ø³Ù†', 'N/A')}
    - **Ù…Ø®ØªØµØ§Øª:** ({farm_info.get('Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'N/A'):.5f}, {farm_info.get('Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'N/A'):.5f})
    - **ÙˆØ¶Ø¹ÛŒØª Ø¯Ø§Ø¯Ù‡ Ù…Ø®ØªØµØ§Øª:** {'Ù…ÙˆØ¬ÙˆØ¯' if not farm_info.get('coordinates_missing', True) else 'Ú¯Ù…Ø´Ø¯Ù‡'}
    - **Ø±ÙˆØ² Ù‡ÙØªÙ‡ (ÙÛŒÙ„ØªØ±):** {farm_info.get('Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'N/A')}
    """)
    st.markdown("---")
    st.subheader("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø±Ù†Ú¯ Ù†Ù‚Ø´Ù‡")
    palette_name = INDEX_PALETTES.get(selected_index, '')
    if palette_name:
        colors = palette_name.split(', ')
        if len(colors) == 3: # Assuming Green/Yellow/Red or similar 3-color scheme
             st.markdown(f"""
             - <span style='color:#{colors[2]};'>â– </span> : ÙˆØ¶Ø¹ÛŒØª Ù†Ø§Ù…Ø·Ù„ÙˆØ¨ / Ø§Ø³ØªØ±Ø³ / Ù…Ù‚Ø¯Ø§Ø± Ù¾Ø§ÛŒÛŒÙ†
             - <span style='color:#{colors[1]};'>â– </span> : ÙˆØ¶Ø¹ÛŒØª Ù…ØªÙˆØ³Ø·
             - <span style='color:#{colors[0]};'>â– </span> : ÙˆØ¶Ø¹ÛŒØª Ø®ÙˆØ¨ / Ø³Ø§Ù„Ù… / Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø§Ù„Ø§
             """, unsafe_allow_html=True)
        else: # Generic legend for other palettes
            st.markdown(f"Ù¾Ø§Ù„Øª Ø±Ù†Ú¯: {palette_name}")
            st.markdown("Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø¨Ù‡ Ø³Ù…Øª Ø±Ù†Ú¯ Ø§ÙˆÙ„ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ù‡ Ø³Ù…Øª Ø±Ù†Ú¯ Ø¢Ø®Ø± Ú¯Ø±Ø§ÛŒØ´ Ø¯Ø§Ø±Ù†Ø¯.")
    else:
        st.markdown("Ù¾Ø§Ù„Øª Ø±Ù†Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø´Ø§Ø®Øµ ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")


st.markdown("---")

# --- Time Series Chart ---
st.subheader(f"Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}")
st.markdown(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {ts_start_date.strftime(DATE_FORMAT)} ØªØ§ {ts_end_date.strftime(DATE_FORMAT)}")

# Add a placeholder while data is loading
ts_chart_placeholder = st.empty()
ts_chart_placeholder.info("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ...")

ts_df = get_time_series_for_farm(
    selected_farm_name,
    selected_farm_geometry,
    selected_index,
    ts_start_date.strftime(DATE_FORMAT),
    ts_end_date.strftime(DATE_FORMAT),
    data_source
)

if ts_df is not None and not ts_df.empty:
    # Determine the correct column name (handle proxies)
    index_col_name_ts = selected_index
    if selected_index == 'ET' and data_source == 'Sentinel-2': index_col_name_ts = 'ET_Proxy'
    if selected_index == 'Chlorophyll' and data_source == 'Landsat': index_col_name_ts = 'Chlorophyll_Proxy'

    if index_col_name_ts in ts_df.columns:
        fig = px.line(ts_df, x='date', y=index_col_name_ts, title=f'Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index}', markers=True)
        fig.update_layout(xaxis_title='ØªØ§Ø±ÛŒØ®', yaxis_title=selected_index)
        ts_chart_placeholder.plotly_chart(fig, use_container_width=True)
    else:
         ts_chart_placeholder.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ† '{index_col_name_ts}' Ø¯Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

elif ts_df is not None and ts_df.empty:
    ts_chart_placeholder.warning(f"Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
else:
    ts_chart_placeholder.error("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ.")


st.markdown("---")

# --- Farm Ranking and Comparison ---
st.subheader(f"ØªØ­Ù„ÛŒÙ„ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ {selected_index}")
st.markdown(f"ØªØ§Ø±ÛŒØ® Ù…Ø±Ø¬Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ: {today.strftime(DATE_FORMAT)}")
if selected_day != "Ù‡Ù…Ù‡":
    st.markdown(f"ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø±ÙˆØ² Ù‡ÙØªÙ‡: **{selected_day}**")


# --- Weekly Ranking Table ---
ranking_col, comparison_col = st.columns(2)

with ranking_col:
    st.markdown(f"**Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Û· Ø±ÙˆØ² Ø§Ø®ÛŒØ±)**")
    ranking_placeholder = st.empty()
    ranking_placeholder.info(f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÚ¯ÛŒ {selected_index}...")

    # Calculate average for the last 7 days ending today
    weekly_avg_today = calculate_weekly_average(
        filtered_farm_names,
        filtered_farm_geometries,
        selected_index,
        today,
        data_source
    )

    if weekly_avg_today:
        ranking_df = pd.DataFrame(list(weekly_avg_today.items()), columns=['Ù…Ø²Ø±Ø¹Ù‡', f'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† {selected_index}'])
        ranking_df = ranking_df.dropna() # Remove farms where calculation failed
        # Sort descending for beneficial indices (NDVI, EVI, LAI, Biomass, Chlorophyll, ET_Proxy)
        # Sort ascending for stress indices (MSI)
        ascending_sort = selected_index in ['MSI']
        ranking_df = ranking_df.sort_values(by=f'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† {selected_index}', ascending=ascending_sort).reset_index(drop=True)
        ranking_df.index += 1 # Start ranking from 1
        ranking_placeholder.dataframe(ranking_df.style.format({f'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† {selected_index}': "{:.3f}"}), use_container_width=True)
    else:
        ranking_placeholder.warning("Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÚ¯ÛŒ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


# --- Weekly Comparison ---
with comparison_col:
    st.markdown(f"**Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ (Û· Ø±ÙˆØ² Ø§Ø®ÛŒØ± Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Û· Ø±ÙˆØ² Ù‚Ø¨Ù„)**")
    comparison_placeholder = st.empty()
    comparison_placeholder.info(f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ {selected_index}...")

    # Calculate average for the 7 days before the last 7 days
    previous_week_end_date = today - datetime.timedelta(days=7)
    weekly_avg_previous = calculate_weekly_average(
        filtered_farm_names,
        filtered_farm_geometries,
        selected_index,
        previous_week_end_date,
        data_source
    )

    if weekly_avg_today and weekly_avg_previous:
        compare_data = []
        report_lines = [f"**Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ {selected_index}:**",
                        f"(Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† {today - datetime.timedelta(days=6)} ØªØ§ {today} Ø¨Ø§ {previous_week_end_date - datetime.timedelta(days=6)} ØªØ§ {previous_week_end_date})",
                        ""] # Add empty line

        increased_farms = []
        decreased_farms = []
        no_change_farms = []

        for farm_name in filtered_farm_names:
            current_avg = weekly_avg_today.get(farm_name)
            previous_avg = weekly_avg_previous.get(farm_name)

            if current_avg is not None and previous_avg is not None and not pd.isna(current_avg) and not pd.isna(previous_avg):
                change = current_avg - previous_avg
                change_pct = (change / previous_avg) * 100 if previous_avg != 0 else 0
                compare_data.append({
                    'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
                    'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ±': current_avg,
                    'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„': previous_avg,
                    'ØªØºÛŒÛŒØ±': change,
                    'Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±': change_pct
                })
                # Add to report lists
                if abs(change_pct) < 1: # Threshold for significant change (e.g., 1%)
                     no_change_farms.append(farm_name)
                elif change > 0:
                    increased_farms.append(f"{farm_name} ({change_pct:+.1f}%)")
                else:
                    decreased_farms.append(f"{farm_name} ({change_pct:+.1f}%)")

            else:
                 # Add row with N/A if data is missing for comparison
                 compare_data.append({
                    'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
                    'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ±': current_avg if current_avg is not None else 'N/A',
                    'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„': previous_avg if previous_avg is not None else 'N/A',
                    'ØªØºÛŒÛŒØ±': 'N/A',
                    'Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±': 'N/A'
                })


        compare_df = pd.DataFrame(compare_data)
        comparison_placeholder.dataframe(compare_df.style.format({
            'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ±': "{:.3f}",
            'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„': "{:.3f}",
            'ØªØºÛŒÛŒØ±': "{:+.3f}",
            'Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±': "{:+.1f}%"
        }), use_container_width=True)

        # --- Generate Text Report ---
        st.markdown("---")
        st.subheader("Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ Ù‡ÙØªÚ¯ÛŒ")
        report_placeholder = st.empty()
        report_placeholder.info("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´...")

        # Interpretation based on index type
        positive_change_is_good = selected_index not in ['MSI'] # Higher MSI is generally worse (more stress)

        if positive_change_is_good:
            if increased_farms:
                report_lines.append(f"ğŸ“ˆ **Ø¨Ù‡Ø¨ÙˆØ¯ ÙˆØ¶Ø¹ÛŒØª ({selected_index}):** Ù…Ø²Ø§Ø±Ø¹ {', '.join(increased_farms)} Ø¯Ø± Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ± Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯.")
            if decreased_farms:
                report_lines.append(f"ğŸ“‰ **Ú©Ø§Ù‡Ø´ ÙˆØ¶Ø¹ÛŒØª ({selected_index}):** Ù…Ø²Ø§Ø±Ø¹ {', '.join(decreased_farms)} Ø¯Ø± Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ± Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ú©Ø§Ù‡Ø´ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¨ÛŒØ´ØªØ± Ø¯Ø§Ø±Ù†Ø¯.")
        else: # For stress indices like MSI
             if increased_farms: # Increase in MSI is bad
                report_lines.append(f"ğŸ“ˆ **Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø³ØªØ±Ø³ ({selected_index}):** Ù…Ø²Ø§Ø±Ø¹ {', '.join(increased_farms)} Ø¯Ø± Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ± Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø³ØªØ±Ø³ (ÛŒØ§ Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª Ø¨Ø±Ø§ÛŒ NDMI) Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ÙÙˆØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯.")
             if decreased_farms: # Decrease in MSI is good
                report_lines.append(f"ğŸ“‰ **Ú©Ø§Ù‡Ø´ Ø§Ø³ØªØ±Ø³ ({selected_index}):** Ù…Ø²Ø§Ø±Ø¹ {', '.join(decreased_farms)} Ø¯Ø± Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ± Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ú©Ø§Ù‡Ø´ Ø§Ø³ØªØ±Ø³ (ÛŒØ§ Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª Ø¨Ø±Ø§ÛŒ NDMI) Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯.")

        if no_change_farms:
             report_lines.append(f"ğŸ“Š **ÙˆØ¶Ø¹ÛŒØª Ù¾Ø§ÛŒØ¯Ø§Ø± ({selected_index}):** Ù…Ø²Ø§Ø±Ø¹ {', '.join(no_change_farms)} ØªØºÛŒÛŒØ± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ù†Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯.")

        if not increased_farms and not decreased_farms and not no_change_farms:
             report_lines.append("Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

        report_placeholder.markdown("\n".join(report_lines))


    else:
        comparison_placeholder.warning("Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ùˆ Ø¯ÙˆØ±Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.markdown("---")
        st.subheader("Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ Ù‡ÙØªÚ¯ÛŒ")
        st.warning("Ø§Ù…Ú©Ø§Ù† ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")


# --- Footer ---
st.markdown("---")
st.caption("Ø·Ø±Ø§Ø­ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ | Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ: Sentinel-2 (ESA), Landsat 8/9 (NASA/USGS) | Ù¾Ø±Ø¯Ø§Ø²Ø´: Google Earth Engine")

