# --- START OF FILE app (67).py ---

import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
import plotly.express as px
import os
from io import BytesIO
import requests # Needed for getThumbUrl download
import traceback
from streamlit_folium import st_folium
import base64
import time # For potential delays if needed

# --- Gemini API Integration ---
import google.generativeai as genai

# WARNING: Storing API keys directly in code is insecure!
# Use environment variables or st.secrets in production.
# Replace "YOUR_GEMINI_API_KEY" with your actual key for this specific implementation.
GEMINI_API_KEY = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ" # <-- PASTE YOUR KEY HERE

# --- Configure Gemini ---
try:
    if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY":
        st.error("âŒ Ú©Ù„ÛŒØ¯ API Gemini ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯ Ù…Ø¹ØªØ¨Ø± Ø±Ø§ Ø¯Ø± Ú©Ø¯ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        st.stop() # Stop if key is missing
    genai.configure(api_key=GEMINI_API_KEY)
    gemini_model = genai.GenerativeModel('gemini-1.5-flash') # Or another suitable model
    print("Gemini API Configured Successfully.")
    gemini_available = True
except Exception as e:
    st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Gemini API: {e}")
    st.warning("âš ï¸ ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")
    gemini_available = False
    gemini_model = None # Ensure model is None if configuration fails

# --- Custom CSS ---
st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±",
    page_icon="ğŸŒ¾",
    layout="wide"
)

# Custom CSS for Persian text alignment and professional styling (remains the same)
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');
        body { direction: rtl; text-align: right; font-family: 'Vazirmatn', sans-serif !important; }
        .main { font-family: 'Vazirmatn', sans-serif; }
        h1, h2, h3 { font-family: 'Vazirmatn', sans-serif; color: #2c3e50; text-align: right; }
        .css-1xarl3l { font-family: 'Vazirmatn', sans-serif; background-color: #f8f9fa; border-radius: 10px; padding: 1rem; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .stTabs [data-baseweb="tab-list"] { gap: 2px; direction: rtl; }
        .stTabs [data-baseweb="tab"] { height: 50px; padding: 10px 20px; background-color: #f8f9fa; border-radius: 5px 5px 0 0; font-family: 'Vazirmatn', sans-serif; font-weight: 600; }
        .dataframe { font-family: 'Vazirmatn', sans-serif; text-align: right; }
        .css-1d391kg { font-family: 'Vazirmatn', sans-serif; direction: rtl; }
        .stSelectbox label, .stDateInput label, .stTextInput label, .stTextArea label { text-align: right !important; width: 100%; }
        .stExpander > div > div > p { text-align: right; } /* Align text inside expander */
    </style>
""", unsafe_allow_html=True)


# --- Configuration ---
APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±"
APP_SUBTITLE = "Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

# --- File Paths (Relative to the script location in Hugging Face) ---
CSV_FILE_PATH = 'cleaned_output.csv'
# IMPORTANT: Ensure this JSON file exists in your Hugging Face Space repository
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'

# --- GEE Authentication ---
@st.cache_resource # Cache the GEE initialization
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully using Service Account.")
        return True
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª ÙØ§ÛŒÙ„ Service Account Ùˆ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø¢Ù† Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ GEE Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.stop()


# --- Load Farm Data ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...")
def load_farm_data(csv_path=CSV_FILE_PATH):
    """Loads farm data from the specified CSV file."""
    try:
        df = pd.read_csv(csv_path)
        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'coordinates_missing']
        if not all(col in df.columns for col in required_cols):
            st.error(f"âŒ ÙØ§ÛŒÙ„ CSV Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø§Ø´Ø¯: {', '.join(required_cols)}")
            return None
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['coordinates_missing'] = df['coordinates_missing'].fillna(False).astype(bool)
        df = df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
        df = df[~df['coordinates_missing']]
        if df.empty:
            st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø®ØªØµØ§Øª).")
            return None
        df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] = df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].astype(str).str.strip()
        st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {len(df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return df
    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ CSV Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        return None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        st.error(traceback.format_exc())
        return None

# Initialize GEE and Load Data
if initialize_gee():
    farm_data_df = load_farm_data()
else:
    st.error("âŒ Ø§Ù…Ú©Ø§Ù† Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø¨Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    st.stop()

if farm_data_df is None:
    st.error("âŒ Ø§Ù…Ú©Ø§Ù† Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    st.stop()


# ==============================================================================
# Sidebar Filters
# ==============================================================================
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

# --- Day of the Week Selection ---
available_days = sorted(farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique())
selected_day = st.sidebar.selectbox(
    "ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
    options=available_days,
    index=0,
    help="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø±ÙˆØ² ÙÛŒÙ„ØªØ± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯."
)

# --- Filter Data Based on Selected Day ---
filtered_farms_df = farm_data_df[farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()

if filtered_farms_df.empty:
    st.warning(f"âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    st.stop()

# --- Farm Selection ---
available_farms = sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique())
farm_options = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + available_farms
selected_farm_name = st.sidebar.selectbox(
    "ğŸŒ¾ Ù…Ø²Ø±Ø¹Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
    options=farm_options,
    index=0,
    help="Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¢Ù† Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯ ÛŒØ§ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ."
)

# --- Index Selection (Updated) ---
index_options = {
    "NDVI": "Ø´Ø§Ø®Øµ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ",
    "NDWI": "Ø´Ø§Ø®Øµ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ú¯ÛŒØ§Ù‡Ø§Ù†",
    "NDRE": "Ø´Ø§Ø®Øµ Ù…ÛŒØ²Ø§Ù† Ø§Ø²Øª Ú¯ÛŒØ§Ù‡ (Ù„Ø¨Ù‡ Ù‚Ø±Ù…Ø²)",
    "LAI": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
    "CHL": "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
}
selected_index = st.sidebar.selectbox(
    "ğŸ“ˆ Ø´Ø§Ø®Øµ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´:",
    options=list(index_options.keys()),
    format_func=lambda x: f"{x} ({index_options[x]})",
    index=0 # Default to NDVI
)

# --- Date Range Calculation ---
today = datetime.date.today()
persian_to_weekday = {
    "Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1,
    "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4,
}
try:
    target_weekday = persian_to_weekday[selected_day]
    days_ago = (today.weekday() - target_weekday + 7) % 7
    end_date_current = today - datetime.timedelta(days=days_ago) if days_ago != 0 else today
    start_date_current = end_date_current - datetime.timedelta(days=6)
    end_date_previous = start_date_current - datetime.timedelta(days=1)
    start_date_previous = end_date_previous - datetime.timedelta(days=6)

    start_date_current_str = start_date_current.strftime('%Y-%m-%d')
    end_date_current_str = end_date_current.strftime('%Y-%m-%d')
    start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
    end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')

    st.sidebar.info(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÙØ¹Ù„ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
    st.sidebar.info(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")

except KeyError:
    st.sidebar.error(f"Ù†Ø§Ù… Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ù‚Ø§Ø¨Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ³Øª.")
    st.stop()
except Exception as e:
    st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}")
    st.stop()


# ==============================================================================
# Google Earth Engine Functions (Updated)
# ==============================================================================

# --- Cloud Masking Function for Sentinel-2 ---
def maskS2clouds(image):
    """Masks clouds in a Sentinel-2 SR image using the QA band and SCL."""
    qa = image.select('QA60')
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(
             qa.bitwiseAnd(cirrusBitMask).eq(0))

    scl = image.select('SCL')
    # Valid classes: 4 (Veg), 5 (Bare Soil), 6 (Water), 7 (Unclassified), 11 (Snow/Ice) - Keep 7? Maybe not.
    # Let's keep Veg, Bare Soil, Water: 4, 5, 6
    good_quality = scl.remap([4, 5, 6], [1, 1, 1], 0) # Map good classes to 1, others to 0

    # Scale optical bands (Needed for index calculations)
    opticalBands = image.select('B.*').multiply(0.0001)

    return image.addBands(opticalBands, None, True)\
                .updateMask(mask).updateMask(good_quality) # Apply both masks


# --- Index Calculation Functions (Updated) ---
def add_indices(image):
    """Calculates and adds NDVI, NDWI, NDRE, LAI, CHL bands."""
    # Ensure required bands exist and handle potential missing bands gracefully
    required_bands = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11']
    # Check if all required bands are present
    # Note: GEE lazy evaluation means we can't easily check bands *before* calculation
    # We rely on GEE errors if a band is missing or operations fail.

    try:
        # NDVI: (NIR - Red) / (NIR + Red) | S2: (B8 - B4) / (B8 + B4)
        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')

        # NDWI (Gao version uses NIR & SWIR): (NIR - SWIR1) / (NIR + SWIR1) | S2: (B8 - B11) / (B8 + B11)
        # Often used for vegetation water content. McFeeters version (Green-NIR) is for surface water.
        ndwi = image.normalizedDifference(['B8', 'B11']).rename('NDWI')

        # NDRE: (NIR - RedEdge1) / (NIR + RedEdge1) | S2: (B8 - B5) / (B8 + B5)
        ndre = image.normalizedDifference(['B8', 'B5']).rename('NDRE')

        # LAI (Leaf Area Index) - Simple estimation using NDVI (Needs calibration)
        # Placeholder: LAI proportional to NDVI. Adjust multiplier based on research/calibration.
        lai = ndvi.multiply(3.5).rename('LAI') # Simple empirical estimation

        # CHL (Chlorophyll Index) - Using Red Edge (e.g., CI_RedEdge = NIR/RE1 - 1) | S2: B8/B5 - 1
        # Ensure RedEdge band (B5) is not zero to avoid division errors
        re1_safe = image.select('B5').max(ee.Image(0.0001)) # Add small epsilon
        chl = image.expression('(NIR / RE1) - 1', {
            'NIR': image.select('B8'),
            'RE1': re1_safe
        }).rename('CHL')

        return image.addBands([ndvi, ndwi, ndre, lai, chl])
    except Exception as e:
        # If an error occurs (e.g., missing band), return the image without added indices
        # Or handle more gracefully if possible, but GEE makes this tricky pre-computation
        print(f"Warning: Could not calculate indices for image {image.id().getInfo()}: {e}")
        return image # Return original image if calculation fails


# --- Function to get processed image for a date range and geometry ---
# @st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ...", persist=True) # Re-enable caching if performance allows
def get_processed_image(_geometry, start_date, end_date, index_name):
    """
    Gets cloud-masked, index-calculated Sentinel-2 median composite.
    """
    try:
        # Increased timeout might be needed for complex calcs or large areas
        # ee.data.setDeadline(60000) # Example: 60 seconds timeout (optional)

        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_geometry)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds))

        count = s2_sr_col.size().getInfo()
        if count == 0:
            return None, f"No cloud-free Sentinel-2 images found for {start_date} to {end_date}."

        # Calculate indices *after* filtering. Handle potential errors inside add_indices.
        indexed_col = s2_sr_col.map(add_indices)

        # Select only images that likely have the calculated index band
        # This is a bit indirect; assumes if NDVI exists, others likely do too if bands were present.
        # A more robust way might involve checking band names after map, but that's complex in GEE.
        # indexed_col = indexed_col.filter(ee.Filter.listContains('system:band_names', index_name))

        # Create a median composite image
        median_image = indexed_col.median() # Use median

        # Select the specific index band *after* compositing
        # Check if the band exists in the final composite
        band_names = median_image.bandNames().getInfo()
        if index_name not in band_names:
             return None, f"Ø´Ø§Ø®Øµ '{index_name}' Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± ØªØµÙˆÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù†Ø¨ÙˆØ¯ Ø¨Ø§Ù†Ø¯ ÙˆØ±ÙˆØ¯ÛŒ ÛŒØ§ Ø®Ø·Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡)."

        output_image = median_image.select(index_name)

        return output_image, None
    except ee.EEException as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Google Earth Engine: {e}"
        try:
            error_details = e.args[0] if e.args else str(e)
            if isinstance(error_details, str):
                if 'required band' in error_details.lower() or 'not found' in error_details.lower():
                     error_message += f"\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ø§Ù†Ø¯ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ {index_name} Ø¯Ø± ØªØµØ§ÙˆÛŒØ± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª)"
                elif 'computation timed out' in error_details.lower():
                     error_message += "\n(Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø²)"
                elif 'user memory limit exceeded' in error_details.lower():
                     error_message += "\n(Ø­Ø§ÙØ¸Ù‡ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø²)"
        except Exception: pass
        # st.error(error_message) # Don't show error here, return it
        return None, error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ GEE: {e}\n{traceback.format_exc()}"
        # st.error(error_message) # Don't show error here, return it
        return None, error_message


# --- Function to get time series data for a point ---
# @st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ...", persist=True) # Re-enable caching if needed
def get_index_time_series(_point_geom, index_name, start_date='2023-01-01', end_date=today.strftime('%Y-%m-%d')):
    """Gets a time series of a specified index for a point geometry."""
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_point_geom)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds)
                     .map(add_indices)) # Add all indices

        def extract_value(image):
            # Ensure the index band exists before trying to reduce
            if index_name in image.bandNames().getInfo():
                value = image.select(index_name).reduceRegion(
                    reducer=ee.Reducer.first(), # Use 'first' or 'mean'
                    geometry=_point_geom,
                    scale=10 # S2 scale
                ).get(index_name)
                return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd'), index_name: value})
            else:
                # Return null feature if the band doesn't exist in this specific image
                return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd'), index_name: None})


        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.notNull([index_name]))

        ts_info = ts_features.getInfo()['features']

        if not ts_info:
            return pd.DataFrame(columns=['date', index_name]), "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."

        ts_data = [{'date': f['properties']['date'], index_name: f['properties'][index_name]} for f in ts_info]
        ts_df = pd.DataFrame(ts_data)
        ts_df['date'] = pd.to_datetime(ts_df['date'])
        ts_df = ts_df.sort_values('date').set_index('date')

        return ts_df, None
    except ee.EEException as e:
        error_message = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ({index_name}): {e}"
        return pd.DataFrame(columns=['date', index_name]), error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ({index_name}): {e}\n{traceback.format_exc()}"
        return pd.DataFrame(columns=['date', index_name]), error_message


# ==============================================================================
# Gemini AI Analysis Function
# ==============================================================================

# @st.cache_data(show_spinner="ğŸ§  Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...", persist=True) # Cache AI response for same inputs
def get_gemini_analysis(_index_name, _farm_name, _current_val, _previous_val, _change_val):
    """Generates analysis and recommendations using Gemini API."""
    if not gemini_available or gemini_model is None:
        return "ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ API Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.", None

    if pd.isna(_current_val) or pd.isna(_previous_val) or pd.isna(_change_val):
         return "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ (Ù…Ù‚Ø§Ø¯ÛŒØ± ÙØ¹Ù„ÛŒØŒ Ù‚Ø¨Ù„ÛŒ Ùˆ ØªØºÛŒÛŒØ±) ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.", None

    # Format values for the prompt
    current_str = f"{_current_val:.3f}"
    previous_str = f"{_previous_val:.3f}"
    change_str = f"{_change_val:.3f}"
    
    # Define index interpretations for the prompt
    index_interpretations = {
        "NDVI": "Ø´Ø§Ø®Øµ ØªØ±Ø§Ú©Ù… Ùˆ Ø³Ù„Ø§Ù…Øª Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø§Ø³Øª. Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± (Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Û±) Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ùˆ Ø³Ø§Ù„Ù…â€ŒØªØ± Ø§Ø³Øª.",
        "NDWI": "Ø´Ø§Ø®Øµ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ Ø¯Ø± Ø¨Ø±Ú¯ Ú¯ÛŒØ§Ù‡Ø§Ù† Ø§Ø³Øª. Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø±Ø·ÙˆØ¨Øª Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª.",
        "NDRE": "Ø´Ø§Ø®Øµ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ùˆ Ù†ÛŒØªØ±ÙˆÚ˜Ù† Ø¯Ø± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª (Ø­Ø³Ø§Ø³ Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± Ù…Ø±Ø§Ø­Ù„ Ù…ÛŒØ§Ù†ÛŒ Ùˆ Ù¾Ø§ÛŒØ§Ù†ÛŒ Ø±Ø´Ø¯). Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ø¹Ù…ÙˆÙ…Ø§Ù‹ Ø¨Ù‡ØªØ± Ø§Ø³Øª.",
        "LAI": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (Ù†Ø³Ø¨Øª Ø³Ø·Ø­ Ú©Ù„ Ø¨Ø±Ú¯ Ø¨Ù‡ Ø³Ø·Ø­ Ø²Ù…ÛŒÙ†) Ø§Ø³Øª. Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ ÙØªÙˆØ³Ù†ØªØ² Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø³Øª.",
        "CHL": "Ø´Ø§Ø®Øµ ØªØ®Ù…ÛŒÙ†ÛŒ Ù…ÛŒØ²Ø§Ù† Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¯Ø± Ø¨Ø±Ú¯ Ø§Ø³Øª. Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ùˆ Ø³Ù„Ø§Ù…Øª Ø¨Ù‡ØªØ± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª."
    }
    
    interpretation = index_interpretations.get(_index_name, f"Ø´Ø§Ø®Øµ {_index_name}")

    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ù‡Ø³ØªÛŒØ¯.
    Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ù†Ø§Ù… "{_farm_name}"ØŒ Ø´Ø§Ø®Øµ "{_index_name}" ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³Øª.
    {interpretation}

    Ù…Ù‚Ø¯Ø§Ø± Ø§ÛŒÙ† Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ: {current_str}
    Ù…Ù‚Ø¯Ø§Ø± Ø§ÛŒÙ† Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„: {previous_str}
    Ù…ÛŒØ²Ø§Ù† ØªØºÛŒÛŒØ± Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„: {change_str}

    ÙˆØ¸Ø§ÛŒÙ Ø´Ù…Ø§:
    1.  **ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª:** Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ø¯Ø± Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ {_index_name} Ú†Ù‡ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…Øª Ùˆ Ø±Ø´Ø¯ Ù†ÛŒØ´Ú©Ø± Ø¯Ø± Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø§Ø±Ø¯. (Ù…Ø«Ù„Ø§Ù‹ Ø¢ÛŒØ§ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ØŸ Ø¢ÛŒØ§ Ø¯Ú†Ø§Ø± ØªÙ†Ø´ Ø´Ø¯Ù‡ØŸ ÙˆØ¶Ø¹ÛŒØª Ù¾Ø§ÛŒØ¯Ø§Ø± Ø§Ø³ØªØŸ)
    2.  **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ùˆ Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®ØµØŒ ÛŒÚ© Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„ÛŒ Ùˆ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ø¯Ø± Ù‡ÙØªÙ‡ Ù¾ÛŒØ´ Ø±Ùˆ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯. (Ù…Ø«Ù„Ø§Ù‹ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§ÙØ²Ø§ÛŒØ´/Ú©Ø§Ù‡Ø´/Ø­ÙØ¸ Ø±ÙˆÙ†Ø¯ ÙØ¹Ù„ÛŒ Ø¢Ø¨ÛŒØ§Ø±ÛŒ)
    3.  **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ùˆ Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®Øµ (Ø¨Ù‡â€ŒØ®ØµÙˆØµ Ø§Ú¯Ø± NDRE ÛŒØ§ CHL Ø¨Ø§Ø´Ø¯)ØŒ ÛŒÚ© Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„ÛŒ Ùˆ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©ÙˆØ¯Ø¯Ù‡ÛŒ (Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ Ù†ÛŒØªØ±ÙˆÚ˜Ù†) Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ØŒ Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø³Øª.

    Ù†Ú©Ø§Øª Ù…Ù‡Ù…:
    -   ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø§ÛŒØ¯ **ÙÙ‚Ø·** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ (ØªØºÛŒÛŒØ± ÛŒÚ© Ø´Ø§Ø®Øµ) Ø¨Ø§Ø´Ø¯.
    -   Ø²Ø¨Ø§Ù† Ù†ÙˆØ´ØªØ§Ø± Ø¨Ø§ÛŒØ¯ Ø±Ø³Ù…ÛŒ Ùˆ Ø¹Ù„Ù…ÛŒ Ø§Ù…Ø§ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§Ø´Ø¯.
    -   Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ØªÙ…Ø±Ú©Ø² Ø¨Ø± ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø§Ø´Ø¯.
    -   Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ø¯.

    ÙØ±Ù…Øª Ù¾Ø§Ø³Ø®:
    **ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª:** [ØªÙˆØ¶ÛŒØ­ Ø´Ù…Ø§]
    **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** [Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ù…Ø§]
    **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ:** [Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ù…Ø§]
    """

    try:
        response = gemini_model.generate_content(prompt)
        # Add basic safety check if needed (though newer models handle this better)
        # if not response.candidates or not response.candidates[0].content.parts:
        #     return "Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾Ø§Ø³Ø®ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ú©Ø±Ø¯. (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø­ØªÙˆØ§ Ù†Ø§Ø§Ù…Ù† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)", None
        
        analysis_text = response.text
        return analysis_text, None # Return analysis and no error
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API: {e}"
        st.error(error_message) # Show error in the UI as well
        return "Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ.", error_message


# ==============================================================================
# Main Panel Display
# ==============================================================================

# --- Get Selected Farm Geometry and Details ---
selected_farm_details = None
selected_farm_geom = None
map_center_lat = INITIAL_LAT
map_center_lon = INITIAL_LON
map_zoom = INITIAL_ZOOM

if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
    min_lon, min_lat = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
    max_lon, max_lat = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(), filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
    selected_farm_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])
    map_center_lat = filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean()
    map_center_lon = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean()
    map_zoom = INITIAL_ZOOM # Keep initial zoom for overview
    st.subheader(f"Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ²: {selected_day}")
    st.info(f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ²: {len(filtered_farms_df)}")
else:
    selected_farm_details = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
    lat = selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    lon = selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    selected_farm_geom = ee.Geometry.Point([lon, lat])
    map_center_lat = lat
    map_center_lon = lon
    map_zoom = 14 # Zoom closer for single farm
    st.subheader(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name} (Ø±ÙˆØ²: {selected_day})")
    details_cols = st.columns(3)
    with details_cols[0]:
        st.metric("Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª (Ù‡Ú©ØªØ§Ø±)", f"{selected_farm_details.get('Ù…Ø³Ø§Ø­Øª', 'N/A'):,.2f}" if pd.notna(selected_farm_details.get('Ù…Ø³Ø§Ø­Øª')) else "N/A")
        st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", f"{selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}")
    with details_cols[1]:
        st.metric("Ú©Ø§Ù†Ø§Ù„", f"{selected_farm_details.get('Ú©Ø§Ù†Ø§Ù„', 'N/A')}")
        st.metric("Ø³Ù†", f"{selected_farm_details.get('Ø³Ù†', 'N/A')}")
    with details_cols[2]:
        st.metric("Ø§Ø¯Ø§Ø±Ù‡", f"{selected_farm_details.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')}")
        st.metric("Ù…Ø®ØªØµØ§Øª", f"{lat:.5f}, {lon:.5f}")


# --- Map Display ---
st.markdown("---")
st.subheader(" Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")

# Define visualization parameters based on the selected index (Updated)
vis_params = {
    'NDVI': {'min': 0.0, 'max': 0.9, 'palette': 'RdYlGn'}, # Standard NDVI range and palette
    'NDWI': {'min': -0.2, 'max': 0.6, 'palette': ['#d7191c', '#fdae61', '#ffffbf', '#abd9e9', '#2c7bb6']}, # Diverging for moisture: Red(dry)->Yellow->Blue(wet)
    'NDRE': {'min': 0.0, 'max': 0.6, 'palette': 'Purples'}, # Often lower range than NDVI, Purples palette
    'LAI': {'min': 0, 'max': 7, 'palette': 'YlGn'}, # 0 to ~7 is common for crops, YlGn palette
    'CHL': {'min': 0, 'max': 10, 'palette': 'YlOrBr'}, # CIrededge range, YlOrBr palette (Yellow->Brown = low->high stress/less Chl?) Let's reverse it: BrOrangeYl
    'CHL': {'min': 0, 'max': 10, 'palette': ['#b35806','#f1a340','#fee0b6','#d8daeb','#998ec3','#542788']}, # Better: Brown(low Chl/stress) -> Purple(high Chl)
}

# Create a geemap Map instance
m = geemap.Map(
    location=[map_center_lat, map_center_lon],
    zoom=map_zoom,
    add_google_map=False # Start clean
)
m.add_basemap("HYBRID") # Add Google Satellite Hybrid basemap

# Get the processed image for the current week
if selected_farm_geom:
    gee_image_current, error_msg_current = get_processed_image(
        selected_farm_geom, start_date_current_str, end_date_current_str, selected_index
    )

    if gee_image_current:
        try:
            current_vis_param = vis_params.get(selected_index, {'min': 0, 'max': 1, 'palette': 'gray'}) # Default gray if not found
            m.addLayer(
                gee_image_current,
                current_vis_param,
                f"{selected_index} ({start_date_current_str} to {end_date_current_str})"
            )

            # --- Add Custom Legend ---
            # Use user-provided descriptions
            legend_dict = {
                'NDVI': ("NDVI (Ø´Ø§Ø®Øµ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ)", "Ø±Ù†Ú¯ Ø³Ø¨Ø² Ø¨ÛŒØ§Ù†Ú¯Ø± Ù…Ø­ØµÙˆÙ„ Ù…ØªØ±Ø§Ú©Ù… Ùˆ Ø³Ø§Ù„Ù… Ùˆ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡â€ŒÛŒ Ù…Ø­ØµÙˆÙ„ Ú©Ù…â€ŒÙ¾Ø´Øª Ùˆ Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡ Ø§Ø³Øª."),
                'NDWI': ("NDWI (Ø´Ø§Ø®Øµ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ú¯ÛŒØ§Ù‡Ø§Ù†)", "Ø±Ù†Ú¯ Ø¢Ø¨ÛŒ Ø¨ÛŒØ´ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù…â€ŒØ¢Ø¨ÛŒ Ø§Ø³Øª."),
                'NDRE': ("NDRE (Ø´Ø§Ø®Øµ Ù…ÛŒØ²Ø§Ù† Ø§Ø²Øª Ú¯ÛŒØ§Ù‡)", "Ø±Ù†Ú¯ Ø¨Ù†ÙØ´ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…ÛŒØ²Ø§Ù† Ø²ÛŒØ§Ø¯ Ø§Ø²Øª/Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ùˆ Ø±Ù†Ú¯ Ø±ÙˆØ´Ù†â€ŒØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ø§Ù‡Ø´ Ø¢Ù† Ø¯Ø± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª."),
                'LAI': ("LAI (Ø´Ø§Ø®Øµ Ú¯ÛŒØ§Ù‡ÛŒ Ø³Ø·Ø­ Ø¨Ø±Ú¯)", "Ø±Ù†Ú¯ Ø³Ø¨Ø² Ù¾Ø±Ø±Ù†Ú¯â€ŒØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø³Øª."),
                'CHL': ("CHL (Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„)", "Ø±Ù†Ú¯ Ø¨Ù†ÙØ´/ØªÛŒØ±Ù‡ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª Ùˆ Ø±Ù†Ú¯ Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ/Ø±ÙˆØ´Ù† Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ø§Ù‡Ø´ Ú©Ù„Ø±ÙˆÙÛŒÙ„ ÛŒØ§ ØªÙ†Ø´ Ø§Ø³Øª.")
            }

            legend_title, legend_desc = legend_dict.get(selected_index, (selected_index, "Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ† Ø¨Ù‡ Ø¨Ø§Ù„Ø§"))
            palette = current_vis_param.get('palette', [])
            min_val = current_vis_param.get('min', 0)
            max_val = current_vis_param.get('max', 1)

            # Create a simple gradient or categorical legend based on palette
            legend_html = f'''
            <div style="position: fixed; bottom: 50px; right: 10px; z-index: 1000; background-color: rgba(255, 255, 255, 0.8); padding: 10px; border: 1px solid grey; border-radius: 5px; font-family: 'Vazirmatn', sans-serif; font-size: 12px; text-align: right;">
                <p style="margin: 0 0 5px 0; font-weight: bold;">{legend_title}</p>
                <p style="margin: 0 0 10px 0; font-size: 11px;">{legend_desc}</p>
            '''
            # Add color scale bar (simple version)
            if isinstance(palette, list) and len(palette) > 1:
                gradient = f"linear-gradient(to top, {', '.join(palette)})"
                legend_html += f'<div style="height: 100px; width: 20px; background: {gradient}; border: 1px solid #ccc; display: inline-block; margin-left: 5px;"></div>'
                legend_html += f'<div style="display: inline-block; vertical-align: top; height: 100px; position: relative;">'
                legend_html += f'<span style="position: absolute; top: 0;">{max_val:.1f} (Ø¨Ø§Ù„Ø§)</span>'
                legend_html += f'<span style="position: absolute; bottom: 0;">{min_val:.1f} (Ù¾Ø§ÛŒÛŒÙ†)</span>'
                legend_html += f'</div>'
            elif isinstance(palette, str): # If palette name is given (like RdYlGn)
                 legend_html += f'<div style="text-align: center;">(Ù…Ù‚ÛŒØ§Ø³ Ø±Ù†Ú¯ÛŒ: {palette})<br>Ú©Ù… â† Ø²ÛŒØ§Ø¯</div>' # Placeholder if gradient is hard

            legend_html += '</div>'
            m.get_root().html.add_child(folium.Element(legend_html))

            # Add markers
            if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                 for idx, farm in filtered_farms_df.iterrows():
                     folium.Marker(
                         location=[farm['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']],
                         popup=f"Ù…Ø²Ø±Ø¹Ù‡: {farm['Ù…Ø²Ø±Ø¹Ù‡']}\nÚ©Ø§Ù†Ø§Ù„: {farm['Ú©Ø§Ù†Ø§Ù„']}\nØ§Ø¯Ø§Ø±Ù‡: {farm['Ø§Ø¯Ø§Ø±Ù‡']}",
                         tooltip=farm['Ù…Ø²Ø±Ø¹Ù‡'],
                         icon=folium.Icon(color='blue', icon='info-sign')
                     ).add_to(m)
            else:
                 folium.Marker(
                     location=[lat, lon],
                     popup=f"Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}\n{selected_index} (Ø¬Ø§Ø±ÛŒ): Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡...",
                     tooltip=selected_farm_name,
                     icon=folium.Icon(color='red', icon='star')
                 ).add_to(m)

            m.add_layer_control()

        except Exception as map_err:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ Ø¨Ù‡ Ù†Ù‚Ø´Ù‡: {map_err}")
            st.error(traceback.format_exc())
    else:
        st.warning(f"ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯. {error_msg_current}")

# Display the map
st_folium(m, width=None, height=500, use_container_width=True)
st.caption("Ø±Ø§Ù‡Ù†Ù…Ø§: Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ø±ÙˆÛŒ Ù…Ø§Ø±Ú©Ø±Ù‡Ø§ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯. Ø§Ø² Ú©Ù†ØªØ±Ù„ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ (Ø¨Ø§Ù„Ø§ Ø³Ù…Øª Ø±Ø§Ø³Øª Ù†Ù‚Ø´Ù‡) Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ù†Ù‚Ø´Ù‡ Ù¾Ø§ÛŒÙ‡ ÛŒØ§ Ø®Ø§Ù…ÙˆØ´/Ø±ÙˆØ´Ù† Ú©Ø±Ø¯Ù† Ù„Ø§ÛŒÙ‡ Ø´Ø§Ø®Øµ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
st.info("ğŸ’¡ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‚Ø´Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§Ø¨Ø²Ø§Ø± Ø¹Ú©Ø³ Ú¯Ø±ÙØªÙ† Ø§Ø² ØµÙØ­Ù‡ (Screenshot) Ù…Ø±ÙˆØ±Ú¯Ø± ÛŒØ§ Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„ Ø®ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")


# --- Time Series Chart ---
st.markdown("---")
st.subheader(f"ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index}")

if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
    st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
elif selected_farm_geom and isinstance(selected_farm_geom, ee.Geometry.Point):
    timeseries_end_date = today.strftime('%Y-%m-%d')
    timeseries_start_date = (today - datetime.timedelta(days=180)).strftime('%Y-%m-%d') # Last 6 months

    ts_df, ts_error = get_index_time_series(
        selected_farm_geom,
        selected_index,
        start_date=timeseries_start_date,
        end_date=timeseries_end_date
    )

    if ts_error:
        st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}")
    elif not ts_df.empty:
        # Ensure index column is numeric for plotting
        ts_df[selected_index] = pd.to_numeric(ts_df[selected_index], errors='coerce')
        ts_df.dropna(subset=[selected_index], inplace=True)
        if not ts_df.empty:
            st.line_chart(ts_df[selected_index])
            st.caption(f"Ù†Ù…ÙˆØ¯Ø§Ø± ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name} Ø¯Ø± 6 Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡ (Ù†Ù‚Ø§Ø· Ø¯Ø§Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª).")
        else:
             st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    else:
        st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
elif not isinstance(selected_farm_geom, ee.Geometry.Point):
     st.warning("Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù…Ù†ÙØ±Ø¯ (Ù†Ù‚Ø·Ù‡) Ù‚Ø§Ø¨Ù„ Ù†Ù…Ø§ÛŒØ´ Ø§Ø³Øª.")


# --- Ranking Table and AI Analysis ---
st.markdown("---")
st.subheader(f"ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} (Ø±ÙˆØ²: {selected_day})")
st.markdown("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„.")

# Use a session state variable to store ranking results to avoid recalculating on every interaction
if 'ranking_data' not in st.session_state:
    st.session_state.ranking_data = {'df': pd.DataFrame(), 'errors': [], 'params': None}

# Function to calculate rankings (modified to reduce direct GEE calls if possible)
# @st.cache_data(show_spinner=f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...", persist=True) # Cache might be tricky with GEE objects/errors
def calculate_farm_indices(farms_df, index_name, start_curr, end_curr, start_prev, end_prev):
    """Calculates the average index value for the current and previous week for a list of farms."""
    results = []
    errors = []
    total_farms = len(farms_df)
    # progress_bar = st.progress(0) # Progress bar can be slow with many small GEE calls

    # Pre-fetch images if possible (might time out for large areas/long ranges)
    # This is complex to manage correctly with point-based reduction.
    # Sticking to per-farm calculation for now.

    status_placeholder = st.empty() # Placeholder for status updates

    for i, (idx, farm) in enumerate(farms_df.iterrows()):
        status_placeholder.info(f"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø²Ø±Ø¹Ù‡ {i+1}/{total_farms}: {farm['Ù…Ø²Ø±Ø¹Ù‡']}...")
        farm_name = farm['Ù…Ø²Ø±Ø¹Ù‡']
        lat = farm['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
        lon = farm['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
        point_geom = ee.Geometry.Point([lon, lat])

        def get_mean_value(start, end):
            try:
                # Use the function that returns image and error msg
                image, error_img = get_processed_image(point_geom, start, end, index_name)
                if image:
                    mean_dict = image.reduceRegion(
                        reducer=ee.Reducer.mean(),
                        geometry=point_geom,
                        scale=10
                    ).getInfo()
                    # Check if index_name is actually in the result
                    if mean_dict and index_name in mean_dict:
                         return mean_dict.get(index_name), None
                    elif mean_dict is None:
                         return None, "ReduceRegion returned None."
                    else:
                         return None, f"Ø´Ø§Ø®Øµ '{index_name}' Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ ReduceRegion ÛŒØ§ÙØª Ù†Ø´Ø¯."
                else:
                    # If image is None, return None value and the error from get_processed_image
                    return None, error_img or "ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯."
            except ee.EEException as e:
                 # Catch GEE specific errors during reduceRegion/getInfo
                 err_detail = f"EE Error: {e}"
                 try: # Try to get more specific GEE error details
                      err_detail = e.args[0] if e.args else str(e)
                 except: pass
                 return None, f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø±: {err_detail}"
            except Exception as e:
                 # Catch other errors
                 return None, f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø±: {e}"

        # Calculate for current week
        current_val, err_curr = get_mean_value(start_curr, end_curr)
        if err_curr: errors.append(f"{farm_name} (Ø¬Ø§Ø±ÛŒ: {start_curr} ØªØ§ {end_curr}): {err_curr}")

        # Calculate for previous week
        previous_val, err_prev = get_mean_value(start_prev, end_prev)
        if err_prev: errors.append(f"{farm_name} (Ù‚Ø¨Ù„: {start_prev} ØªØ§ {end_prev}): {err_prev}")

        # Calculate change
        change = None
        if current_val is not None and previous_val is not None:
            try:
                 # Ensure they are floats before subtracting
                 change = float(current_val) - float(previous_val)
            except (TypeError, ValueError):
                 change = None # Handle if values are not numeric

        results.append({
            'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
            'Ú©Ø§Ù†Ø§Ù„': farm.get('Ú©Ø§Ù†Ø§Ù„', 'N/A'),
            'Ø§Ø¯Ø§Ø±Ù‡': farm.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A'),
            f'{index_name}_curr': current_val, # Store raw values
            f'{index_name}_prev': previous_val,
            f'{index_name}_change': change
        })
        # Update progress bar (removed for potential performance gain)
        # progress_bar.progress((i + 1) / total_farms)
        time.sleep(0.05) # Small delay to prevent hitting GEE limits too hard?

    # progress_bar.empty()
    status_placeholder.success(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ {index_name} Ø¨Ø±Ø§ÛŒ {total_farms} Ù…Ø²Ø±Ø¹Ù‡ Ú©Ø§Ù…Ù„ Ø´Ø¯.")
    time.sleep(2)
    status_placeholder.empty() # Clear status message

    return pd.DataFrame(results), errors

# Define parameters for caching check
current_params = (selected_index, start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str, selected_day)

# Check if calculation is needed
if st.session_state.ranking_data['params'] != current_params:
    print(f"Recalculating ranking for: {current_params}") # Debug print
    ranking_df_raw, calculation_errors = calculate_farm_indices(
        filtered_farms_df,
        selected_index,
        start_date_current_str,
        end_date_current_str,
        start_date_previous_str,
        end_date_previous_str
    )
    st.session_state.ranking_data['df'] = ranking_df_raw
    st.session_state.ranking_data['errors'] = calculation_errors
    st.session_state.ranking_data['params'] = current_params # Store current parameters
else:
    print("Using cached ranking data.") # Debug print
    ranking_df_raw = st.session_state.ranking_data['df']
    calculation_errors = st.session_state.ranking_data['errors']


# Display errors if any
if calculation_errors:
    with st.expander("âš ï¸ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§", expanded=False):
        st.warning(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø®Ø·Ø§Ù‡Ø§: {len(calculation_errors)}")
        # Show unique errors to avoid repetition
        unique_errors = sorted(list(set(calculation_errors)))
        for i, error in enumerate(unique_errors):
            st.error(f"- {error}")
            if i > 20: # Limit displayed unique errors
                 st.warning(f"... Ùˆ {len(unique_errors) - i} Ø®Ø·Ø§ÛŒ Ù…Ù†Ø­ØµØ±Ø¨ÙØ±Ø¯ Ø¯ÛŒÚ¯Ø±.")
                 break

if not ranking_df_raw.empty:
    # Create display copy
    ranking_df_display = ranking_df_raw.copy()
    
    # Rename columns for display
    ranking_df_display = ranking_df_display.rename(columns={
        f'{selected_index}_curr': f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)',
        f'{selected_index}_prev': f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)',
        f'{selected_index}_change': 'ØªØºÛŒÛŒØ±'
    })

    # Define status based on change (Most indices: higher is better)
    def determine_status(change_val, index_name):
        # All requested indices (NDVI, NDWI, NDRE, LAI, CHL) generally mean 'better' when higher
        if pd.isna(change_val):
            return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" # Status: No data / Cannot compare

        threshold = 0.03 # Define a threshold for significant change (adjust as needed)

        if change_val > threshold:
            return "Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯" # Status: Positive change
        elif change_val < -threshold:
            return "Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´" # Status: Negative change
        else:
            return "Ø«Ø§Ø¨Øª / Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±" # Status: Neutral / Stable

    ranking_df_display['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_display['ØªØºÛŒÛŒØ±'].apply(lambda x: determine_status(x, selected_index))

    # Sort table
    # Generally sort descending for these indices (higher = better rank)
    ranking_df_sorted = ranking_df_display.sort_values(
        by=f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)',
        ascending=False,
        na_position='last'
    ).reset_index(drop=True)

    # Add Rank
    ranking_df_sorted.index = ranking_df_sorted.index + 1
    ranking_df_sorted.index.name = 'Ø±ØªØ¨Ù‡'

    # Format numbers for display
    cols_to_format = [f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±']
    for col in cols_to_format:
        if col in ranking_df_sorted.columns:
             ranking_df_sorted[col] = ranking_df_sorted[col].apply(lambda x: f"{float(x):.3f}" if pd.notna(x) and isinstance(x, (int, float)) else ("N/A" if pd.isna(x) else x))


    # Display the table
    st.dataframe(ranking_df_sorted[[
        'Ù…Ø²Ø±Ø¹Ù‡', 'Ú©Ø§Ù†Ø§Ù„', 'Ø§Ø¯Ø§Ø±Ù‡',
        f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±', 'ÙˆØ¶Ø¹ÛŒØª'
        ]], use_container_width=True)

    # --- Display Gemini AI Analysis for Selected Farm ---
    if selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" and gemini_available:
        st.markdown("---")
        st.subheader(f"ğŸ§  ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")

        # Find the data for the selected farm in the raw results
        farm_analysis_data = ranking_df_raw[ranking_df_raw['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name]

        if not farm_analysis_data.empty:
            farm_row = farm_analysis_data.iloc[0]
            current_val = farm_row.get(f'{selected_index}_curr')
            previous_val = farm_row.get(f'{selected_index}_prev')
            change_val = farm_row.get(f'{selected_index}_change')

            # Call Gemini function (use caching maybe)
            analysis_text, analysis_error = get_gemini_analysis(
                selected_index,
                selected_farm_name,
                current_val,
                previous_val,
                change_val
            )

            if analysis_error:
                 st.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„: {analysis_error}")
            elif analysis_text:
                 st.markdown(analysis_text) # Display the formatted text from Gemini
                 st.caption("ØªÙˆØ¬Ù‡: Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ ØµØ±ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ù…ÛŒØ¯Ø§Ù†ÛŒ Ùˆ Ø¯Ø§Ù†Ø´ Ú©Ø§Ø±Ø´Ù†Ø§Ø³ÛŒ ØªÙ„ÙÛŒÙ‚ Ú©Ù†ÛŒØ¯.")
            else:
                 st.info("ØªØ­Ù„ÛŒÙ„ÛŒ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯.")
        else:
             st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¬Ù‡Øª ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    elif selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" and not gemini_available:
         st.warning("âš ï¸ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ØµØ­ÛŒØ­ API Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

    # --- Summary Stats ---
    st.markdown("---")
    st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
    status_counts = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].value_counts()
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        count_pos = status_counts.get("Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯", 0)
        st.metric("ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯", count_pos)
    with col2:
        count_neu = status_counts.get("Ø«Ø§Ø¨Øª / Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±", 0)
        st.metric("âšª Ø«Ø§Ø¨Øª / Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±", count_neu)
    with col3:
        count_neg = status_counts.get("Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´", 0)
        st.metric("ğŸ”´ Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´", count_neg)
    with col4:
        count_nan = status_counts.get("Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", 0)
        st.metric("âš«ï¸ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", count_nan)

    st.info(f"""
    **Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª:**
    - **ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø´Ø§Ø®Øµ {selected_index} Ø¢Ù†Ù‡Ø§ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.
    - **âšª Ø«Ø§Ø¨Øª / Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ ØªØºÛŒÛŒØ± Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ø¯Ø± Ø´Ø§Ø®Øµ {selected_index} Ù†Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯.
    - **ğŸ”´ Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø´Ø§Ø®Øµ {selected_index} Ø¢Ù†Ù‡Ø§ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ú©Ø§Ù‡Ø´ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.
    - **âš«ï¸ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø§Ù…Ú©Ø§Ù† Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¯Ø± Ø¯Ùˆ Ù‡ÙØªÙ‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.
    """)

    # --- Download Button ---
    try:
        csv_data = ranking_df_sorted.to_csv(index=True, encoding='utf-8-sig') # Use utf-8-sig for Excel compatibility
        st.download_button(
            label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (CSV)",
            data=csv_data,
            file_name=f'ranking_{selected_index}_{selected_day}_{end_date_current_str}.csv',
            mime='text/csv',
        )
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {e}")

else:
    st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø±ÙˆØ² ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯.")


st.markdown("---")
st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ ğŸ’» ØªÙˆØ³Ø· Ø§Ø³Ù…Ø§Ø¹ÛŒÙ„ Ú©ÛŒØ§Ù†ÛŒ")
st.sidebar.markdown("Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Streamlit, Google Earth Engine, geemap Ùˆ Google Gemini")
st.sidebar.warning("ğŸš¨ Ù‡Ø´Ø¯Ø§Ø±: Ú©Ù„ÛŒØ¯ API Gemini Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¯Ø± Ú©Ø¯ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª Ú©Ù‡ Ù†Ø§Ø§Ù…Ù† Ø§Ø³Øª. Ø¯Ø± Ù…Ø­ÛŒØ· Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†â€ŒØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")

# --- END OF FILE ---