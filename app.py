import streamlit as st
import ee
import geemap.foliumap as geemap # Using foliumap backend for Streamlit compatibility
import pandas as pd
import plotly.express as px
import os
import json # To potentially read the service account file format

# --- Configuration ---
st.set_page_config(layout="wide", page_title="Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§", page_icon="ğŸŒ±")

# Define paths for input files
GEE_KEY_FILENAME = "ee-esmaeilkiani13877-cfdea6eaf411 (4).json" # Ensure this is the correct filename
CSV_FILENAME = "farm_data.csv" # Ensure this is the correct filename

# Service Account Email (from the JSON file or provided)
SERVICE_ACCOUNT_EMAIL = "dehkhodamap-e9f0da4ce9f6514021@ee-esmaeilkiani13877.iam.gserviceaccount.com"

# Initial map center and zoom (Dehkhoda area)
INITIAL_CENTER = [31.534442, 48.724416] # [Lat, Lon]
INITIAL_ZOOM = 12

# --- GEE Authentication ---
@st.cache_resource
def authenticate_gee(key_filename, email):
    """Authenticates GEE using a service account key file."""
    key_path = os.path.join(".", key_filename) # Look for the key file in the current directory

    if not os.path.exists(key_path):
        st.error(f"ÙØ§ÛŒÙ„ Ú©Ù„ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ GEE ÛŒØ§ÙØª Ù†Ø´Ø¯: {os.path.abspath(key_path)}")
        st.info("Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ÙØ§ÛŒÙ„ Ú©Ù„ÛŒØ¯ GEE Ø¨Ø§ Ù†Ø§Ù… ØµØ­ÛŒØ­ Ø¯Ø± Ú©Ù†Ø§Ø± ÙØ§ÛŒÙ„ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯.")
        return False

    try:
        # The service account JSON file itself contains the required information
        # We just need its path. The ee.ServiceAccountCredentials will read it.
        credentials = ee.ServiceAccountCredentials(email, key_path)
        ee.Initialize(credentials)
        st.success("Google Earth Engine Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ø´Ø¯.")
        return True
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Google Earth Engine: {e}")
        st.warning("Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ Ø§Ú©Ø§Ù†Øª Ø´Ù…Ø§ ÙØ¹Ø§Ù„ Ø§Ø³Øª Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø±Ø§ Ø¯Ø§Ø±Ø¯.")
        return False

# --- Data Loading ---
@st.cache_data
def load_farm_data(csv_filename):
    """Loads farm data from the CSV file."""
    csv_path = os.path.join(".", csv_filename) # Look for the CSV file in the current directory

    if not os.path.exists(csv_path):
        st.error(f"ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯: {os.path.abspath(csv_path)}")
        st.info("Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ÙØ§ÛŒÙ„ CSV Ø¨Ø§ Ù†Ø§Ù… ØµØ­ÛŒØ­ Ø¯Ø± Ú©Ù†Ø§Ø± ÙØ§ÛŒÙ„ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯.")
        return pd.DataFrame()

    try:
        # Assuming UTF-8 encoding, adjust if necessary
        df = pd.read_csv(csv_path, encoding='utf-8')

        # Check for essential columns using their Persian names
        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡']
        for col in required_cols:
            if col not in df.columns:
                st.error(f"Ø³ØªÙˆÙ† Ø¶Ø±ÙˆØ±ÛŒ '{col}' Ø¯Ø± ÙØ§ÛŒÙ„ CSV ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                return pd.DataFrame()

        # Clean data: remove rows with missing coordinates
        original_rows = len(df)
        df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], inplace=True)
        if len(df) < original_rows:
            st.warning(f"Ø­Ø°Ù {original_rows - len(df)} Ø±Ø¯ÛŒÙ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù†Ø¯Ø§Ø´ØªÙ† Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø±.")

        return df
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        return pd.DataFrame()

# --- GEE Processing Functions ---

def add_s2_indices(image):
    """Adds common agricultural index bands to a Sentinel-2 image."""
    # Sentinel-2 bands (approximate wavelengths in nm):
    # B1: Coastal aerosol (443)
    # B2: Blue (490)
    # B3: Green (560)
    # B4: Red (665)
    # B5: Red Edge 1 (705)
    # B6: Red Edge 2 (740)
    # B7: Red Edge 3 (783)
    # B8: NIR (842)
    # B8A: Narrow NIR (865)
    # B9: Water vapor (940)
    # B10: SWIR 1 (1375) - Used for cloud screening
    # B11: SWIR 1 (1610) - Used for moisture/agriculture
    # B12: SWIR 2 (2190) - Used for moisture/geology

    # Check if necessary bands exist
    band_names = image.bandNames()
    needed_bands = ['B2', 'B3', 'B4', 'B5', 'B7', 'B8', 'B11'] # Required for most indices below
    if not all(b in band_names.getInfo() for b in needed_bands):
         st.warning("ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ ÙØ§Ù‚Ø¯ Ø¨Ø±Ø®ÛŒ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø§Ø³Øª.")
         # Return image with only the bands that are present, subsequent selections will handle missing ones.


    # NDVI = (NIR - Red) / (NIR + Red) -> (B8 - B4) / (B8 + B4)
    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')

    # EVI = 2.5 * (NIR - Red) / (NIR + 6 * Red - 7.5 * Blue + 1) -> 2.5 * (B8 - B4) / (B8 + 6*B4 - 7.5*B2 + 1)
    # Coefficients C1=6, C2=7.5, L=1 (adjustment factor for canopy background signal)
    evi = image.expression(
        '2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1.0)', {
            'NIR': image.select('B8'),
            'RED': image.select('B4'),
            'BLUE': image.select('B2')
        }).rename('EVI')

    # NDMI = (NIR - SWIR1) / (NIR + SWIR1) -> (B8 - B11) / (B8 + B11)
    ndmi = image.normalizedDifference(['B8', 'B11']).rename('NDMI')

    # MSI = SWIR1 / NIR -> B11 / B8 (Higher MSI = more water stress)
    # Handle potential division by zero (e.g., water bodies where NIR is 0)
    msi = image.select('B11').divide(image.select('B8')).rename('MSI').clamp(0, 100) # Clamp to prevent extreme values


    # LAI (Leaf Area Index) - Placeholder, needs calibration. Simple linear model example based on NDVI: LAI = p * NDVI + q
    # A more common approach relates LAI non-linearly to NDVI/EVI or uses look-up tables.
    # Here, using a simple linear proxy.
    LAI_p = 6.0 # Hypothetical coefficient, NEEDS CALIBRATION
    LAI_q = 0.0 # Hypothetical coefficient, NEEDS CALIBRATION
    # Ensure NDVI is used after it's calculated in this function
    lai = ndvi.multiply(LAI_p).add(LAI_q).rename('LAI')
    # Clamp LAI to a reasonable range (e.g., 0 to 7 for most crops)
    lai = lai.max(0).min(7)


    # Biomass - Placeholder, needs calibration. Using the requested formula: Biomass = a * LAI + b
    # Here, using the LAI calculated above.
    Biomass_a = 12.0 # Hypothetical coefficient (e.g., tonnes/ha per LAI unit), NEEDS CALIBRATION
    Biomass_b = 0.0 # Hypothetical intercept, NEEDS CALIBRATION
    biomass = lai.multiply(Biomass_a).add(Biomass_b).rename('Biomass')
    # Ensure Biomass is not negative
    biomass = biomass.max(0)

    # Chlorophyll Indices - Several exist. Common ones use Red Edge bands (B5, B6, B7).
    # Example 1: Chlorophyll Index Red Edge (CIRE) = (NIR / RedEdge1) - 1 -> (B8 / B5) - 1
    if 'B5' in band_names.getInfo() and 'B8' in band_names.getInfo():
        cire = image.expression('(NIR / RE1) - 1', {
             'NIR': image.select('B8'),
             'RE1': image.select('B5')
        }).rename('CIRE')
    else:
        cire = ee.Image(-9999).rename('CIRE') # Placeholder if bands are missing

    # Example 2: Green Chlorophyll Index (CIG) = (NIR / Green) - 1 -> (B8 / B3) - 1
    if 'B3' in band_names.getInfo() and 'B8' in band_names.getInfo():
        cig = image.expression('(NIR / GREEN) - 1', {
             'NIR': image.select('B8'),
             'GREEN': image.select('B3')
        }).rename('CIG')
    else:
        cig = ee.Image(-9999).rename('CIG') # Placeholder if bands are missing


    # ET (Evapotranspiration) is not a simple band math index. It requires complex models
    # or specific GEE datasets (like MODIS ET or EEFLUX).
    # Adding a placeholder band for ET is not meaningful without a calculation method.
    # We will skip ET calculation via simple band math.

    # Combine all calculated indices into a single image
    # Filter out placeholder bands if underlying bands were missing
    indices = [ndvi, evi, ndmi, msi, lai, biomass, cire, cig]
    valid_indices = [idx for idx in indices if idx.getInfo()['bands'][0]['id'] != -9999]

    return image.addBands(valid_indices)

def get_index_time_series(image_collection, geometry, index_name, scale=10):
    """Extracts time series for a given index over a geometry (e.g., a farm point buffer)."""
    def reduce_region_on_image(image):
        # Select the desired index band
        # Ensure the band exists in the image (added by add_s2_indices)
        if index_name not in image.bandNames().getInfo():
             # print(f"Warning: Index band '{index_name}' not found in image {image.id().getInfo()}")
             return None # Skip images where the index wasn't calculated successfully

        index_band = image.select(index_name)

        # Reduce the region. Use 'mean' reducer over the specified geometry.
        try:
            mean_value = index_band.reduceRegion(
                reducer=ee.Reducer.mean(),
                geometry=geometry,
                scale=scale, # Use appropriate scale, 10m for Sentinel-2 optical
                maxPixels=1e9 # Increase maxPixels for potentially larger reduction areas
            ).get(index_name) # Get the value for the specific band name

            # Check if the result is null (e.g., geometry outside image bounds, or all pixels masked)
            if mean_value.getInfo() is None:
                return None

            # Get the image date
            date = image.date().format('YYYY-MM-dd')

            # Return as a Feature for easy conversion to a list later
            return ee.Feature(None, {
                'date': date,
                'value': mean_value
            })
        except Exception as e:
            # Catch potential GEE errors during reduction for a specific image
            print(f"Error reducing region for image {image.id().getInfo()}: {e}")
            return None

    # Map the reduction function over the image collection
    # Use .flatten() to get rid of potential None results from the map function before getInfo
    time_series_fc = image_collection.map(reduce_region_on_image).flatten()

    # Get info from GEE - this is a blocking call
    time_series_list = time_series_fc.getInfo()

    # Process the list of results into a Pandas DataFrame
    data = []
    for item in time_series_list:
        if item and item.get('properties'): # Check if item is valid and has properties
            props = item['properties']
            # Ensure 'date' and 'value' keys exist and value is not None
            if 'date' in props and 'value' in props and props['value'] is not None:
                data.append({'date': props['date'], 'value': props['value']})

    df = pd.DataFrame(data)

    # Convert 'date' column to datetime objects and sort
    if not df.empty:
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)

    return df

# --- Visualization Palettes ---
# Define color palettes for different indices. Palettes go from min to max value.
# Use geemap.get_palette or define custom ones.
# We assume Bad -> Good or Dry -> Wet mapping
palettes = {
    'NDVI': ['red', 'orange', 'yellow', 'green', 'darkgreen'],      # Low Veg Health -> High Veg Health
    'EVI': ['red', 'orange', 'yellow', 'green', 'darkgreen'],       # Low Veg Health -> High Veg Health
    'NDMI': ['brown', 'yellow', 'lightblue', 'blue', 'darkblue'],   # Dry -> Wet
    'MSI': ['darkblue', 'blue', 'lightblue', 'yellow', 'brown'],    # Wet -> Dry (Higher MSI is drier)
    'LAI': ['red', 'orange', 'yellow', 'green', 'darkgreen'],       # Low LAI -> High LAI
    'Biomass': ['red', 'orange', 'yellow', 'green', 'darkgreen'],   # Low Biomass -> High Biomass
    'CIRE': ['red', 'orange', 'yellow', 'lightgreen', 'green'],     # Low Chlorophyll -> High Chlorophyll
    'CIG': ['red', 'orange', 'yellow', 'lightgreen', 'green'],      # Low Chlorophyll -> High Chlorophyll
}

# Define visualization parameters (min, max, palette) for display
vis_params = {
    'NDVI': {'min': 0.0, 'max': 0.9, 'palette': palettes['NDVI']},
    'EVI': {'min': 0.0, 'max': 0.9, 'palette': palettes['EVI']},
    'NDMI': {'min': -1.0, 'max': 1.0, 'palette': palettes['NDMI']}, # NDMI ranges from -1 to 1
    'MSI': {'min': 0.5, 'max': 3.0, 'palette': palettes['MSI']},   # Typical range for vegetation
    'LAI': {'min': 0.0, 'max': 6.0, 'palette': palettes['LAI']},   # Typical LAI for dense crops
    'Biomass': {'min': 0.0, 'max': 50.0, 'palette': palettes['Biomass']}, # Example biomass range (tonnes/ha)
    'CIRE': {'min': -0.5, 'max': 4.0, 'palette': palettes['CIRE']}, # Example range
    'CIG': {'min': -0.5, 'max': 4.0, 'palette': palettes['CIG']}, # Example range
}

# --- Streamlit App Layout ---

st.title("ğŸŒ± Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§")
st.write("Ø§ÛŒÙ† Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Sentinel-2 Ùˆ Google Earth Engine Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.")

# --- GEE Authentication Check ---
gee_authenticated = authenticate_gee(GEE_KEY_FILENAME, SERVICE_ACCOUNT_EMAIL)

if not gee_authenticated:
    st.stop() # Stop the app execution if GEE authentication fails

# --- Load Data ---
df_farms = load_farm_data(CSV_FILENAME)

if df_farms.empty:
    st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ CSV Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    st.stop() # Stop if no farm data is loaded

# --- Sidebar for Filtering ---
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯")

# Day of Week Filter (assuming 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' contains comma-separated days or a single day)
# We'll get unique entries and let the user select one. A more advanced filter
# would check if the entry *contains* the selected day.
# For simplicity here, we'll filter rows where 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' *exactly matches* or *contains* the selected day string.
# Let's use str.contains for better flexibility.
all_days_in_csv = sorted(df_farms['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique().tolist())
# Create a list of unique individual days mentioned in the CSV
individual_days = set()
for entry in all_days_in_csv:
    if isinstance(entry, str):
        # Split by common separators like ',', '/', or spaces if needed
        days = [d.strip() for d in entry.replace('/', ',').split(',')]
        individual_days.update(days)

day_options = ['Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§'] + sorted(list(individual_days))

selected_day = st.sidebar.selectbox(
    "Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ² Ù‡ÙØªÙ‡:",
    day_options
)

# Filter farms based on selected day using string contains
if selected_day != 'Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§':
    # Use a boolean mask where 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' column contains the selected_day string
    filtered_farms_df = df_farms[
        df_farms['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].astype(str).str.contains(selected_day, na=False)
    ].copy() # Use .copy() to avoid SettingWithCopyWarning
else:
    filtered_farms_df = df_farms.copy()


# Farm Name Filter
farm_names = filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique().tolist()
if not farm_names:
     st.sidebar.warning("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
     selected_farm_name = None
else:
    # Add a default "Select a Farm" option
    farm_names = ["--- Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡ ---"] + farm_names
    selected_farm_name = st.sidebar.selectbox(
        "Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡:",
        farm_names
    )

selected_farm_data = None
farm_point_geometry = None

# Find the data row and create GEE geometry if a farm is selected (and not the placeholder)
if selected_farm_name and selected_farm_name != "--- Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡ ---":
    selected_farm_data = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name]

    if not selected_farm_data.empty:
        selected_farm_data = selected_farm_data.iloc[0]
        lat = selected_farm_data['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
        lon = selected_farm_data['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
        # Create GEE point geometry for the selected farm
        try:
            # GEE expects [lon, lat] for Points
            farm_point_geometry = ee.Geometry.Point(lon, lat)
        except Exception as e:
            st.error(f"Ù…Ø®ØªØµØ§Øª Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª: Ø·ÙˆÙ„={lon}, Ø¹Ø±Ø¶={lat}. Ø®Ø·Ø§: {e}")
            farm_point_geometry = None
            selected_farm_data = None # Invalidate farm data if geometry fails
    else:
         # This case should theoretically not happen if selected_farm_name is in farm_names,
         # but added for robustness.
         st.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
         selected_farm_name = None # Reset selection
         selected_farm_data = None
         farm_point_geometry = None


# Display message or map if no farm is selected or data is invalid
if selected_farm_name is None or selected_farm_name == "--- Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡ ---" or selected_farm_data is None or farm_point_geometry is None:
    st.info("Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ù¾Ù†Ù„ Ø³Ù…Øª Ú†Ù¾ (Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ) ÛŒÚ© Ø±ÙˆØ² Ùˆ Ø³Ù¾Ø³ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
    # Display a general map centered on the initial location
    m = geemap.Map(center=INITIAL_CENTER, zoom=INITIAL_ZOOM)
    m.add_basemap('HYBRID')
    m.add_colorbar(palettes['NDVI'], 0, 1, caption='NDVI Placeholder Legend', layer_name='NDVI Placeholder')
    st.write("Ù†Ù‚Ø´Ù‡ Ú©Ù„ÛŒ Ù…Ù†Ø·Ù‚Ù‡ Ø¯Ù‡Ø®Ø¯Ø§.")
    m.to_streamlit(height=500) # Set a default height for the map
    st.stop() # Stop execution until a valid farm is selected


# --- Display Selected Farm Info ---
st.header(f"ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")
st.write(f"**Ù…Ø®ØªØµØ§Øª:** Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ: {selected_farm_data['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']}, Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ: {selected_farm_data['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']}")
# Use .get() with a default value in case columns are missing in some CSV rows
st.write(f"**Ø§Ø·Ù„Ø§Ø¹Ø§Øª:** Ú©Ø§Ù†Ø§Ù„: {selected_farm_data.get('Ú©Ø§Ù†Ø§Ù„', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')}, Ø§Ø¯Ø§Ø±Ù‡: {selected_farm_data.get('Ø§Ø¯Ø§Ø±Ù‡', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')}, Ù…Ø³Ø§Ø­Øª: {selected_farm_data.get('Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')} Ù‡Ú©ØªØ§Ø±, ÙˆØ§Ø±ÛŒØªÙ‡: {selected_farm_data.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')}, Ø³Ù†: {selected_farm_data.get('Ø³Ù†', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')}")


# --- GEE Processing for Map and Current Status ---

st.subheader("Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ")
st.info("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§... Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ù†Ø¯ Ù„Ø­Ø¸Ù‡ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯.")

# Define date range for current status map (e.g., look back 45 days to find a recent cloud-free image)
now = ee.Date(ee.Algorithms.TemporalComposite.NOW)
start_date_map = now.advance(-45, 'day') # Look back 45 days
end_date_map = now

# Load Sentinel-2 collection for the map area
# Filter bounds by a slightly larger area around the farm point for context
map_area = farm_point_geometry.buffer(2000) # Buffer by 2000 meters

s2_collection_map = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
                      .filterDate(start_date_map, end_date_map) \
                      .filterBounds(map_area)

# Simple cloud filter using QA60 band (bits 10 and 11 are clouds)
def mask_s2_clouds(image):
    qa = image.select('QA60')
    # Both flags should be zero, indicating clear conditions.
    cloud_bit_mask = 1 << 10
    cirrus_bit_mask = 1 << 11
    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))
    # Return the masked image and add the original bands
    # Also scale bands 2-12 by 0.0001 (Surface Reflectance)
    return image.updateMask(mask).divide(10000).copyProperties(image, ["system:time_start"]) # Scale SR bands


s2_collection_map_masked = s2_collection_map.map(mask_s2_clouds) \
                                            .select(['B2', 'B3', 'B4', 'B5', 'B7', 'B8', 'B11']) # Select relevant bands before adding indices

# Select the latest image from the filtered, masked collection
# Sort by time_start descending and take the first one
latest_image = s2_collection_map_masked.sort('system:time_start', False).first()


# --- Display Map ---
m = geemap.Map(center=[lat, lon], zoom=15) # Center map on the selected farm
m.add_basemap('HYBRID') # Add a base map

if latest_image is None:
    st.warning("ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø§Ø®ÛŒØ± Ùˆ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ù…Ù…Ú©Ù† Ù†ÛŒØ³Øª.")
    st.info("Ù†Ù‚Ø´Ù‡ Ø±ÙˆÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    m.add_marker([lat, lon], tooltip=selected_farm_name) # Add a marker for the farm
else:
    st.info(f"Ù†Ù‚Ø´Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø§Ø² ØªØ§Ø±ÛŒØ®: {ee.Date(latest_image.get('system:time_start')).format('YYYY-MM-dd').getInfo()} Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    # Add index bands to the latest image
    image_with_indices = add_s2_indices(latest_image)

    # Get list of actual bands (indices) present in the image after adding them
    available_indices = image_with_indices.bandNames().getInfo()

    # Add the calculated index layers to the map
    for index_name, viz in vis_params.items():
        # Only try to add the layer if the index band is actually present in the image
        if index_name in available_indices:
            try:
                m.addLayer(image_with_indices.select(index_name), viz, index_name)
                # Add legend for this layer
                # Adjust legend caption based on whether palette is low->high or high->low
                legend_caption = f'{index_name} (Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ† \u2192 Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§)' # Default: Low -> High
                if index_name == 'MSI':
                     legend_caption = f'{index_name} (ØªÙ†Ø´ Ø¢Ø¨ÛŒ Ú©Ù… \u2192 ØªÙ†Ø´ Ø¢Ø¨ÛŒ Ø²ÛŒØ§Ø¯)' # MSI is High -> Low Water
                elif index_name in ['NDMI']:
                    legend_caption = f'{index_name} (Ø®Ø´Ú© \u2192 Ù…Ø±Ø·ÙˆØ¨)' # NDMI is Low -> High Water

                m.add_colorbar(viz['palette'], viz['min'], viz['max'], caption=legend_caption, layer_name=index_name)

            except Exception as e:
                 st.error(f"Error adding layer {index_name} to map: {e}")
        else:
            # This warning is already shown inside add_s2_indices, but useful here too
            # st.warning(f"Ø¨Ø§Ù†Ø¯ '{index_name}' Ø¯Ø± ØªØµÙˆÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯ Ùˆ Ù„Ø§ÛŒÙ‡ Ø¢Ù† Ø§Ø¶Ø§ÙÙ‡ Ù†Ø´Ø¯.")
            pass # Ignore if the band wasn't successfully created


    # Add the farm point to the map
    m.addLayer(farm_point_geometry, {'color': 'red'}, selected_farm_name)

# Display the map using geemap's Streamlit component
m.to_streamlit(height=600) # Set map height


st.write("""
**Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ùˆ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ:**
-   **NDVI (Ø´Ø§Ø®Øµ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ):** Ø³Ù„Ø§Ù…Øª Ùˆ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ (Ù‚Ø±Ù…Ø²: Ú©Ù… \u2192 Ø³Ø¨Ø² ØªÛŒØ±Ù‡: Ø²ÛŒØ§Ø¯)
-   **EVI (Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªÙ‚ÙˆÛŒØªâ€ŒØ´Ø¯Ù‡):** Ù…Ø´Ø§Ø¨Ù‡ NDVIØŒ Ø§Ù…Ø§ Ø¯Ø± Ù…Ù†Ø§Ø·Ù‚ Ù¾Ø± Ù¾ÙˆØ´Ø´ ÛŒØ§ Ø¨Ø§ ØªØ¯Ø§Ø®Ù„ Ø®Ø§Ú© Ø¨Ù‡ØªØ± Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. (Ù‚Ø±Ù…Ø²: Ú©Ù… \u2192 Ø³Ø¨Ø² ØªÛŒØ±Ù‡: Ø²ÛŒØ§Ø¯)
-   **NDMI (Ø´Ø§Ø®Øµ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ Ø±Ø·ÙˆØ¨Øª ØªÙØ§Ø¶Ù„ÛŒ):** Ù…ÛŒØ²Ø§Ù† Ø±Ø·ÙˆØ¨Øª Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ (Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ: Ø®Ø´Ú© \u2192 Ø¢Ø¨ÛŒ ØªÛŒØ±Ù‡: Ù…Ø±Ø·ÙˆØ¨)
-   **MSI (Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ):** Ù…ÛŒØ²Ø§Ù† ØªÙ†Ø´ Ø¢Ø¨ÛŒ Ø¯Ø± Ú¯ÛŒØ§Ù‡ (Ø¢Ø¨ÛŒ ØªÛŒØ±Ù‡: Ø±Ø·ÙˆØ¨Øª Ø²ÛŒØ§Ø¯ \u2192 Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ: ØªÙ†Ø´ Ø²ÛŒØ§Ø¯)
-   **LAI (Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯):** Ù…Ø¬Ù…ÙˆØ¹ Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¯Ø± ÙˆØ§Ø­Ø¯ Ø³Ø·Ø­ Ø²Ù…ÛŒÙ† (Ù‚Ø±Ù…Ø²: Ú©Ù… \u2192 Ø³Ø¨Ø² ØªÛŒØ±Ù‡: Ø²ÛŒØ§Ø¯) *(Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ†)*
-   **Biomass (Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡):** Ù…Ù‚Ø¯Ø§Ø± Ù…Ø§Ø¯Ù‡ Ø®Ø´Ú© Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¯Ø± ÙˆØ§Ø­Ø¯ Ø³Ø·Ø­ (Ù‚Ø±Ù…Ø²: Ú©Ù… \u2192 Ø³Ø¨Ø² ØªÛŒØ±Ù‡: Ø²ÛŒØ§Ø¯) *(Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ†)*
-   **CIRE & CIG (Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø±ÙˆÙÛŒÙ„):** Ù…ÛŒØ²Ø§Ù† Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¯Ø± Ø¨Ø±Ú¯â€ŒÙ‡Ø§ØŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø³Ù„Ø§Ù…Øª Ùˆ Ù†ÛŒØªØ±ÙˆÚ˜Ù† Ú¯ÛŒØ§Ù‡ (Ù‚Ø±Ù…Ø²: Ú©Ù… \u2192 Ø³Ø¨Ø²: Ø²ÛŒØ§Ø¯)
""")

st.warning("""
**ØªÙˆØ¬Ù‡ Ù…Ù‡Ù… Ø¯Ø± Ù…ÙˆØ±Ø¯ LAI Ùˆ Biomass:**
Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ LAI Ùˆ Biomass Ø¯Ø± Ø§ÛŒÙ† Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡â€ŒÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø² NDVI/LAI Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ (Biomass = a * LAI + b Ùˆ LAI = p * NDVI + q). **Ø¶Ø±Ø§ÛŒØ¨ Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ (a, b, p, q) Ú©Ø§Ù„ÛŒØ¨Ø±Ù‡ *Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯* Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¢Ù†â€ŒÙ‡Ø§ ØµØ±ÙØ§Ù‹ Ø¬Ù‡Øª Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÙ†Ø¯ ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù† Ù…ÛŒâ€ŒØ¨Ø§Ø´Ù†Ø¯.** Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒØ§Ø¨ÛŒ Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§ØªÚ©Ø§ Ø¨Ø±Ø§ÛŒ LAI Ùˆ BiomassØŒ Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…ÛŒÙ†ÛŒ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§ Ú©Ø§Ù„ÛŒØ¨Ø±Ù‡ Ø´ÙˆÙ†Ø¯ ÛŒØ§ Ø§Ø² Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ GEE Ú©Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú¯Ø±Ø¯Ø¯. Ø´Ø§Ø®Øµ ET Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.
""")

# --- Time Series Analysis ---
st.subheader("ØªØ­Ù„ÛŒÙ„ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§")

# Define date range for time series (e.g., last 1-2 years)
ts_years_lookback = st.slider("Ø¨Ø§Ø²Ù‡â€ŒÛŒ Ø²Ù…Ø§Ù†ÛŒ (Ø³Ø§Ù„) Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§:", 1, 5, 1)
ts_start_date = now.advance(-ts_years_lookback, 'year')
ts_end_date = now # Up to today

st.write(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø² {ts_start_date.format('YYYY-MM-dd').getInfo()} ØªØ§ {ts_end_date.format('YYYY-MM-dd').getInfo()}")
st.info("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø§Ø² Google Earth Engine. Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ø¨Ø§Ø²Ù‡â€ŒÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ Ùˆ Ø­Ø¬Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ú©Ù…ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ø± Ø¨Ø§Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ØµØ¨ÙˆØ± Ø¨Ø§Ø´ÛŒØ¯.")

# Define the buffer size for time series extraction around the point (in meters)
# Using a small buffer is often a compromise between point accuracy and avoiding single-pixel noise/errors
ts_buffer_size = 30 # meters - Adjust as needed (e.g., 10m is Sentinel pixel size, 30m-50m covers a small area)
ts_geometry = farm_point_geometry.buffer(ts_buffer_size)


# Load Sentinel-2 collection for time series (wider date range, focus on farm area)
ts_collection_raw = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
                      .filterDate(ts_start_date, ts_end_date) \
                      .filterBounds(ts_geometry.buffer(100)) # Filter slightly beyond the reduction area


# Apply cloud masking and scale before adding indices
ts_collection_masked = ts_collection_raw.map(mask_s2_clouds) \
                                        .select(['B2', 'B3', 'B4', 'B5', 'B7', 'B8', 'B11']) # Select relevant bands


# Map the function to add indices over the *entire* collection
# This adds index bands to every image in the collection
ts_collection_with_indices = ts_collection_masked.map(add_s2_indices)


# Select indices to plot time series for
indices_to_plot = ['NDVI', 'EVI', 'NDMI', 'MSI', 'LAI', 'Biomass', 'CIRE', 'CIG']
# Filter to only include indices that were potentially added by add_s2_indices (based on bands existing)
# A simpler way here is to just try to extract for all and handle empty results.

# Use a list to store dataframes for each index's time series
all_time_series_dfs = []

# Get time series for each index
progress_bar = st.progress(0)
status_text = st.empty()
total_indices = len(indices_to_plot)

for i, index_name in enumerate(indices_to_plot):
    status_text.text(f"Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ: {index_name} ({i+1}/{total_indices})")
    progress_bar.progress((i + 1) / total_indices)

    try:
        # Get the time series for the current index
        # Note: get_index_time_series handles filtering images that have the specific band
        index_ts_df = get_index_time_series(ts_collection_with_indices.select(index_name), # Select only the band needed to speed up reduction
                                            ts_geometry,
                                            index_name)

        if not index_ts_df.empty:
            index_ts_df['Ø´Ø§Ø®Øµ'] = index_name # Add a column to identify the index
            all_time_series_dfs.append(index_ts_df)
            # st.write(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ {index_name} Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø¨ÙˆØ¯. ØªØ¹Ø¯Ø§Ø¯ Ù†Ù‚Ø§Ø·: {len(index_ts_df)}")
        # else:
            # st.info(f"Ù‡ÛŒÚ† Ù†Ù‚Ø·Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ {index_name} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

    except Exception as e:
         st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ {index_name}: {e}")
         # Continue to the next index

progress_bar.empty()
status_text.empty()


# Combine all time series dataframes
if all_time_series_dfs:
    combined_ts_df = pd.concat(all_time_series_dfs, ignore_index=True)

    # Create Plotly time series chart
    fig = px.line(combined_ts_df, x='date', y='value', color='Ø´Ø§Ø®Øµ',
                  title=f'Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}',
                  labels={'date': 'ØªØ§Ø±ÛŒØ®', 'value': 'Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ', 'Ø´Ø§Ø®Øµ': 'Ø´Ø§Ø®Øµ'},
                  template='plotly_white') # Use a clean template

    fig.update_layout(
        hovermode='x unified', # Improves hover experience
        xaxis_title="ØªØ§Ø±ÛŒØ®",
        yaxis_title="Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ",
        legend_title="Ø´Ø§Ø®Øµ"
    )

    st.plotly_chart(fig, use_container_width=True)

    # Optional: Show raw time series data
    if st.checkbox("Ù†Ù…Ø§ÛŒØ´ Ø¬Ø¯ÙˆÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡"):
         st.dataframe(combined_ts_df)

    # Optional: Download time series data
    # Pivot the data for easier download if preferred, or keep combined
    # combined_ts_pivot = combined_ts_df.pivot(index='date', columns='Ø´Ø§Ø®Øµ', values='value')
    csv_data = combined_ts_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ (CSV)",
        data=csv_data,
        file_name=f'{selected_farm_name}_time_series.csv',
        mime='text/csv',
    )

else:
    st.warning("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ ÙÛŒÙ„ØªØ± Ø§Ø¨Ø±Ù‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")


# --- Farm Ranking (Simplified) ---
# Implementing a full ranking table for ALL farms dynamically would require processing
# the latest image/data for ALL farms whenever the app runs, which can be slow and
# hit GEE limits for many farms.
# A simplified approach is to show the values for the *selected* farm from the latest image.
st.subheader("Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ (Ø¢Ø®Ø±ÛŒÙ† ØªØµÙˆÛŒØ±)")

if latest_image is not None and farm_point_geometry is not None:
    st.info("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ...")
    try:
        # Reduce region for the selected point on the latest image with calculated indices
        # Use the same buffer size as time series or smaller/larger based on desired area
        reduction_geometry = farm_point_geometry.buffer(ts_buffer_size) # Use same buffer as TS
        reduction_scale = 10 # Sentinel-2 resolution

        # Ensure we only try to reduce bands that were actually added
        available_indices_in_latest = [idx for idx in vis_params.keys() if idx in image_with_indices.bandNames().getInfo()]

        if available_indices_in_latest:
             latest_values = image_with_indices.select(available_indices_in_latest).reduceRegion(
                reducer=ee.Reducer.mean(),
                geometry=reduction_geometry,
                scale=reduction_scale,
                maxPixels=1e9
             ).getInfo()

             if latest_values:
                 # Display values in a nice format
                 st.write("Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¯Ø± Ø§Ø·Ø±Ø§Ù Ù†Ù‚Ø·Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ:")
                 values_df = pd.DataFrame([latest_values]).T.reset_index()
                 values_df.columns = ['Ø´Ø§Ø®Øµ', 'Ù…Ù‚Ø¯Ø§Ø±']
                 # Add basic interpretation based on typical ranges and good/bad
                 values_df['ØªÙØ³ÛŒØ± (ØªÙ‚Ø±ÛŒØ¨ÛŒ)'] = values_df.apply(lambda row:
                     f"({vis_params.get(row['Ø´Ø§Ø®Øµ'], {}).get('min', '-')} ØªØ§ {vis_params.get(row['Ø´Ø§Ø®Øµ'], {}).get('max', '-')})"
                     + (f" | Ø±Ù†Ú¯ Ø¯Ø± Ù†Ù‚Ø´Ù‡: {'Ø³Ø¨Ø²/Ø¢Ø¨ÛŒ ØªÛŒØ±Ù‡ (Ø®ÙˆØ¨/Ù…Ø±Ø·ÙˆØ¨)' if row['Ù…Ù‚Ø¯Ø§Ø±'] > vis_params.get(row['Ø´Ø§Ø®Øµ'], {}).get('max', 1)/2 else 'Ù‚Ø±Ù…Ø²/Ù‚Ù‡ÙˆÙ‡ Ø§ÛŒ (Ø¨Ø¯/Ø®Ø´Ú©)'}" if row['Ø´Ø§Ø®Øµ'] in ['NDVI', 'EVI', 'LAI', 'Biomass', 'NDMI', 'CIG', 'CIRE'] else f" | Ø±Ù†Ú¯ Ø¯Ø± Ù†Ù‚Ø´Ù‡: {'Ù‚Ù‡ÙˆÙ‡ Ø§ÛŒ (ØªÙ†Ø´ Ø²ÛŒØ§Ø¯)' if row['Ù…Ù‚Ø´Ø§Ø®Øµ'] > vis_params.get(row['Ø´Ø§Ø®Øµ'], {}).get('max', 3)/2 else 'Ø¢Ø¨ÛŒ ØªÛŒØ±Ù‡ (ØªÙ†Ø´ Ú©Ù…)'}" if row['Ø´Ø§Ø®Øµ'] == 'MSI' else ""),
                     axis=1
                 )

                 st.dataframe(values_df)

             else:
                 st.warning("Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯ (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ù†Ø·Ù‚Ù‡ Ù¾ÙˆØ´Ø´ Ø§Ø¨Ø± Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯).")
        else:
             st.warning("Ù‡ÛŒÚ† Ø¨Ø§Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ØªØµÙˆÛŒØ± Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")

    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ØªØµÙˆÛŒØ±: {e}")
else:
    st.info("Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ØŒ ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø§Ø®ÛŒØ± Ø¨Ø§ÛŒØ¯ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯.")

st.markdown("---")

st.markdown("""
### Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡
1.  Ø§Ø² Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ Ø³Ù…Øª Ø±Ø§Ø³ØªØŒ "Ø±ÙˆØ² Ù‡ÙØªÙ‡" Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯. Ù„ÛŒØ³Øª Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ² ÙÛŒÙ„ØªØ± Ù…ÛŒâ€ŒØ´ÙˆØ¯.
2.  Ø§Ø² Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒØŒ "Ù…Ø²Ø±Ø¹Ù‡" Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.
3.  Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ØŒ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ØŒ Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
4.  Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ø±Ø® Ù…Ø§ÙˆØ³ ÛŒØ§ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ØŒ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ Ø²ÙˆÙ… Ùˆ Ù¾ÙÙ† Ú©Ù†ÛŒØ¯. Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø´Ø§Ø®Øµ Ø±Ø§ Ø±ÙˆØ´Ù†/Ø®Ø§Ù…ÙˆØ´ Ú©Ù†ÛŒØ¯.
5.  Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯.
6.  Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ù‡ ÙØ±Ù…Øª CSV Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.
""")

# --- Footer ---
st.sidebar.markdown("---")
st.sidebar.write("Ø·Ø±Ø§Ø­ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§")
st.sidebar.write("ØªÙˆØ³Ø· Ø§Ø³Ù…Ø§Ø¹ÛŒÙ„ Ú©ÛŒØ§Ù†ÛŒ")

st.sidebar.markdown("---")
st.sidebar.subheader("Ù†Ø­ÙˆÙ‡ Ø§Ø¬Ø±Ø§:")
st.sidebar.write(f"Û±. ÙØ§ÛŒÙ„ `{GEE_KEY_FILENAME}` Ùˆ `{CSV_FILENAME}` Ø±Ø§ Ø¯Ø± Ú©Ù†Ø§Ø± ÙØ§ÛŒÙ„ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾Ø§ÛŒØªÙˆÙ† Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
st.sidebar.write("Û². Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ù†ØµØ¨ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯: `streamlit geemap earthengine-api pandas plotly`")
st.sidebar.write("Û³. Ø¯Ø± ØªØ±Ù…ÛŒÙ†Ø§Ù„ØŒ Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø±ÙØªÙ‡ Ùˆ Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:")
st.sidebar.code("streamlit run dehkhoda_dashboard.py") # Replace dehkhoda_dashboard.py with your script name
st.sidebar.write("Û´. Ø³Ø±ÙˆÛŒØ³ Ø§Ú©Ø§Ù†Øª GEE Ø¨Ø§ÛŒØ¯ Ø¯Ø³ØªØ±Ø³ÛŒ Ú©Ø§ÙÛŒ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Sentinel-2 Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.")