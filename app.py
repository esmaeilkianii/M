import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
from datetime import timedelta # Import timedelta
import plotly.express as px
import plotly.graph_objects as go # For grouped bar chart
import os
from io import BytesIO
import requests # Needed for getThumbUrl download
import numpy as np # For calculations and handling potential NaNs

# --- Configuration ---
APP_TITLE = "Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

# --- File Paths (Relative to the script location in Hugging Face) ---
# Ensure these files are in the same directory as your app.py or provide correct path
CSV_FILE_PATH = 'output (1).csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json' # Your service account file

# --- GEE Authentication ---
@st.cache_resource # Cache the GEE initialization for efficiency
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø±Ø§ Ú©Ù†Ø§Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
            st.stop()
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        # Use high-volume endpoint for potentially better performance
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully using Service Account.")
        return True # Indicate success
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª ÙØ§ÛŒÙ„ Service AccountØŒ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø¢Ù† Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ GEE Ùˆ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        st.stop() # Stop execution if GEE fails
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.stop()

# --- Data Loading ---
@st.cache_data # Cache the loaded data
def load_data(csv_path):
    """Loads and preprocesses farm data from the CSV file."""
    try:
        df = pd.read_csv(csv_path)
        # **Critical Step**: Clean column names FIRST
        df.columns = df.columns.str.strip() # Remove leading/trailing whitespace from headers
        print(f"Original columns: {df.columns.tolist()}") # Debug: See original columns

        # Rename columns for easier access if needed (optional)
        # df = df.rename(columns={'Ø³Ù† ': 'Ø³Ù†'}) # Example if you prefer no space

        # Convert coordinates to numeric, coercing errors to NaN
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')

        # Convert area to numeric
        df['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª'] = pd.to_numeric(df['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª'], errors='coerce')

        # Standardize farm IDs
        df['Ù…Ø²Ø±Ø¹Ù‡'] = df['Ù…Ø²Ø±Ø¹Ù‡'].str.strip()

        # Fill potential NaN in categorical columns with a placeholder AFTER converting to string
        for col in ['Ú©Ø§Ù†Ø§Ù„', 'Ø§Ø¯Ø§Ø±Ù‡', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡']: # Use cleaned name 'Ø³Ù†'
             if col in df.columns:
                # Convert to string first to handle mixed types (like numbers in 'Ú©Ø§Ù†Ø§Ù„')
                df[col] = df[col].astype(str).fillna('Ù†Ø§Ù…Ø´Ø®Øµ')
             else:
                 print(f"Warning: Column '{col}' not found during data loading.")


        # Ensure coordinates_missing is integer, handle potential NaN after coercion
        if 'coordinates_missing' in df.columns:
             df['coordinates_missing'] = pd.to_numeric(df['coordinates_missing'], errors='coerce').fillna(1).astype(int)
        else:
             print("Warning: Column 'coordinates_missing' not found. Assuming missing (1).")
             df['coordinates_missing'] = 1 # Add column if missing, assuming coordinates are missing


        print(f"Data loaded successfully. Shape: {df.shape}")
        print(f"Cleaned columns: {df.columns.tolist()}") # Debug: See cleaned columns
        return df
    except FileNotFoundError:
        st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ CSV Ø¯Ø± Ù…Ø³ÛŒØ± '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        st.exception(e) # Print full traceback for debugging
        st.stop()

# --- GEE Image Processing Functions ---

# Define common band names (used AFTER processing)
COMMON_BAND_NAMES = ['Blue', 'Green', 'Red', 'RedEdge1', 'NIR', 'SWIR1', 'SWIR2']

# --- Masking Functions (Optimized) ---
def mask_s2_clouds(image):
    img_ee = ee.Image(image)
    qa = img_ee.select('QA60')
    cloud_mask = 1 << 10
    cirrus_mask = 1 << 11
    mask = qa.bitwiseAnd(cloud_mask).eq(0).And(qa.bitwiseAnd(cirrus_mask).eq(0))
    # Select necessary data bands, scale, and apply mask
    data_bands = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12']
    # Scale factor for Sentinel-2 SR is 10000
    return img_ee.select(data_bands).updateMask(mask).divide(10000.0)\
        .copyProperties(img_ee, ["system:time_start"])

def mask_landsat_clouds(image):
    img_ee = ee.Image(image)
    qa = img_ee.select('QA_PIXEL')
    # Check Collection 2 specification for cloud, shadow, snow bits
    cloud_shadow_mask = 1 << 3
    snow_mask = 1 << 4
    cloud_mask = 1 << 5
    mask = qa.bitwiseAnd(cloud_shadow_mask).eq(0)\
             .And(qa.bitwiseAnd(snow_mask).eq(0))\
             .And(qa.bitwiseAnd(cloud_mask).eq(0))
    # Apply scaling factors for Collection 2 Level 2 SR bands
    sr_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']
    scale = 0.0000275; offset = -0.2
    scaled_bands = img_ee.select(sr_bands).multiply(scale).add(offset)
    return scaled_bands.updateMask(mask)\
        .copyProperties(img_ee, ["system:time_start"])


# --- Index Calculation Functions ---
# Ensure they return the calculated index band correctly named.
def calculate_ndvi(image):
    img_ee = ee.Image(image)
    return img_ee.normalizedDifference(['NIR', 'Red']).rename('NDVI')

def calculate_evi(image):
    img_ee = ee.Image(image)
    # Ensure necessary bands exist before expression
    try:
        img_ee.select(['NIR', 'Red', 'Blue']) # Check existence
        evi = img_ee.expression(
            '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {
                'NIR': img_ee.select('NIR'), 'RED': img_ee.select('Red'), 'BLUE': img_ee.select('Blue')
            })
        return evi.rename('EVI')
    except ee.EEException as e:
        # Return a dummy band or handle error if bands are missing
        print(f"Could not calculate EVI, possibly missing bands: {e}")
        return ee.Image().rename('EVI') # Return empty image named EVI

def calculate_ndmi(image):
    img_ee = ee.Image(image)
    return img_ee.normalizedDifference(['NIR', 'SWIR1']).rename('NDMI')

def calculate_msi(image):
    img_ee = ee.Image(image)
    return img_ee.expression('SWIR1 / NIR', { 'SWIR1': img_ee.select('SWIR1'), 'NIR': img_ee.select('NIR') }).rename('MSI')

def calculate_lai_simple(image):
    img_ee = ee.Image(image)
    try:
        # Prefer EVI if available
        evi_img = calculate_evi(img_ee) # Calculate EVI (handles band check internally)
        # Check if EVI calculation was successful (returned a band)
        if 'EVI' in evi_img.bandNames().getInfo():
            lai = evi_img.select('EVI').multiply(3.5).add(0.1) # Placeholder EVI-based LAI
        else:
             raise ee.EEException("EVI calculation failed, using NDVI for LAI.") # Force fallback
    except Exception: # Catch potential EVI failure
        # Fallback to NDVI
        ndvi = img_ee.normalizedDifference(['NIR', 'Red'])
        lai = ndvi.multiply(5.0).add(0.1) # Placeholder NDVI-based LAI
    # Rename the final LAI calculation and clamp
    return lai.clamp(0, 8).rename('LAI')

def calculate_biomass_simple(image):
    img_ee = ee.Image(image)
    lai_image = calculate_lai_simple(img_ee) # This calculates and returns an image named 'LAI'
    # Check if LAI calculation was successful
    if 'LAI' in lai_image.bandNames().getInfo():
        lai = lai_image.select('LAI')
        a = 1.5; b = 0.2 # Placeholder coefficients - NEEDS CALIBRATION
        biomass = lai.multiply(a).add(b)
        return biomass.clamp(0, 50).rename('Biomass') # Placeholder clamp
    else:
        print("LAI calculation failed, cannot calculate Biomass.")
        return ee.Image().rename('Biomass') # Return empty Biomass image

def calculate_chlorophyll_mcari(image):
    img_ee = ee.Image(image)
    try:
        # Check for RedEdge1 band explicitly
        img_ee.select('RedEdge1')
        mcari = img_ee.expression('((RE1 - RED) - 0.2 * (RE1 - GREEN)) * (RE1 / RED)',
                                  {'RE1': img_ee.select('RedEdge1'), 'RED': img_ee.select('Red'), 'GREEN': img_ee.select('Green')})
        return mcari.rename('Chlorophyll')
    except ee.EEException:
         # Fallback to NDVI if RedEdge1 is missing (e.g., Landsat)
         ndvi = img_ee.normalizedDifference(['NIR', 'Red'])
         return ndvi.rename('Chlorophyll')

def calculate_et_placeholder(image):
    img_ee = ee.Image(image)
    # Using NDMI as a proxy for water content, related to ET potential
    ndmi = img_ee.normalizedDifference(['NIR', 'SWIR1'])
    return ndmi.rename('ET_proxy')

# --- Index Definitions Dictionary (with descriptions) ---
INDEX_DEFINITIONS = {
    'NDVI': {
        'func': calculate_ndvi, 'vis': {'min': 0, 'max': 1, 'palette': ['#d73027', '#fee08b', '#1a9850']}, # Red-Yellow-Green
        'name_fa': "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ (NDVI)",
        'desc_fa': """**NDVI (Ø´Ø§Ø®Øµ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ ØªÙØ§ÙˆØª Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ):** Ø±Ø§ÛŒØ¬â€ŒØªØ±ÛŒÙ† Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ Ø³Ù†Ø¬Ø´ Ø³Ù„Ø§Ù…Øª Ùˆ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø³Ø¨Ø². Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø³Ø§Ù„Ù…â€ŒØªØ± Ùˆ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ø§Ø³Øª.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û± (Ø¨Ø±Ø§ÛŒ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û°.Û± ØªØ§ Û°.Û¹)
                    - **ØªÙØ³ÛŒØ±:** < Û°.Û² (Ø®Ø§Ú©ØŒ Ø¢Ø¨)ØŒ Û°.Û²-Û°.Ûµ (Ú¯ÛŒØ§Ù‡ Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡/ØªÙ†Ø´)ØŒ > Û°.Ûµ (Ú¯ÛŒØ§Ù‡ Ø³Ø§Ù„Ù… Ùˆ Ù…ØªØ±Ø§Ú©Ù…)""",
        'sort_ascending': False # Higher is better
    },
    'EVI': {
        'func': calculate_evi, 'vis': {'min': 0, 'max': 1, 'palette': ['#d73027', '#fee08b', '#1a9850']},
        'name_fa': "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ (EVI)",
        'desc_fa': """**EVI (Ø´Ø§Ø®Øµ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ):** Ù…Ø´Ø§Ø¨Ù‡ NDVI Ø§Ù…Ø§ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø§Ø«Ø±Ø§Øª Ø¬ÙˆÛŒ Ùˆ Ø®Ø§Ú© Ø²Ù…ÛŒÙ†Ù‡ØŒ Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ Ø¯Ø± Ù…Ù†Ø§Ø·Ù‚ Ø¨Ø§ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù…ØªØ±Ø§Ú©Ù….
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û° ØªØ§ Û±
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø³Ø§Ù„Ù…â€ŒØªØ± Ùˆ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'NDMI': {
        'func': calculate_ndmi, 'vis': {'min': -0.5, 'max': 0.8, 'palette': ['#a50026', '#ffffbf', '#313695']}, # Brown-Yellow-Blue
        'name_fa': "Ø´Ø§Ø®Øµ Ø±Ø·ÙˆØ¨Øª (NDMI)",
        'desc_fa': """**NDMI (Ø´Ø§Ø®Øµ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ ØªÙØ§ÙˆØª Ø±Ø·ÙˆØ¨Øª):** Ù…ÛŒØ²Ø§Ù† Ø¢Ø¨ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¨Ø±Ú¯â€ŒÙ‡Ø§ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** -Û± ØªØ§ +Û±
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± (Ø¢Ø¨ÛŒ) Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø±Ø·ÙˆØ¨Øª Ø¨ÛŒØ´ØªØ±ØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ) Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø®Ø´Ú©ÛŒ ÛŒØ§ ØªÙ†Ø´ Ø¢Ø¨ÛŒ Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'MSI': {
        'func': calculate_msi, 'vis': {'min': 0.4, 'max': 2.5, 'palette': ['#1a9641', '#ffffbf', '#d7191c']}, # Green-Yellow-Red
        'name_fa': "Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ (MSI)",
        'desc_fa': """**MSI (Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ):** Ù†ÛŒØ² Ø¨Ù‡ Ø±Ø·ÙˆØ¨Øª Ú¯ÛŒØ§Ù‡ Ø­Ø³Ø§Ø³ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± **Ø¨Ø§Ù„Ø§ØªØ±** Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ **Ø¨ÛŒØ´ØªØ±** Ø§Ø³Øª (Ø¨Ø±Ø¹Ú©Ø³ NDMI).
                    - **Ù…Ø­Ø§Ø³Ø¨Ù‡:** SWIR1 / NIR
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ > Û°.Û´
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± (Ø³Ø¨Ø²) Ø¨Ù‡ØªØ± Ø§Ø³ØªØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± (Ù‚Ø±Ù…Ø²) Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ØªÙ†Ø´ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.""",
        'sort_ascending': True # Higher is worse (more stress)
    },
    'LAI': {
        'func': calculate_lai_simple, 'vis': {'min': 0, 'max': 8, 'palette': ['#fff5f0', '#fdcdb9', '#e34a33']}, # Light Orange to Red
        'name_fa': "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (LAI - ØªØ®Ù…ÛŒÙ†ÛŒ)",
        'desc_fa': """**LAI (Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯):** Ù†Ø³Ø¨Øª Ú©Ù„ Ù…Ø³Ø§Ø­Øª ÛŒÚ© Ø·Ø±ÙÙ‡ Ø¨Ø±Ú¯ Ø¨Ù‡ ÙˆØ§Ø­Ø¯ Ø³Ø·Ø­ Ø²Ù…ÛŒÙ† (mÂ²/mÂ²). Ø§ÛŒÙ† ÛŒÚ© **ØªØ®Ù…ÛŒÙ†** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¯Ø§Ø±Ø¯.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Û° ØªØ§ Û¸+
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù…ØªØ±Ø§Ú©Ù…â€ŒØªØ± Ø¨Ø§ Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'Biomass': {
        'func': calculate_biomass_simple, 'vis': {'min': 0, 'max': 30, 'palette': ['#f7fcb9', '#addd8e', '#31a354']}, # Yellow-LightGreen-DarkGreen
        'name_fa': "Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ (Biomass - ØªØ®Ù…ÛŒÙ†ÛŒ)",
        'desc_fa': """**Biomass:** ÙˆØ²Ù† Ù…Ø§Ø¯Ù‡ Ø®Ø´Ú© Ú¯ÛŒØ§Ù‡ÛŒ Ø¯Ø± ÙˆØ§Ø­Ø¯ Ø³Ø·Ø­ (Ù…Ø«Ù„Ø§Ù‹ ØªÙ† Ø¨Ø± Ù‡Ú©ØªØ§Ø±). Ø§ÛŒÙ† Ù†ÛŒØ² ÛŒÚ© **ØªØ®Ù…ÛŒÙ†** Ø¨Ø± Ø§Ø³Ø§Ø³ LAI ÛŒØ§ Ø³Ø§ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¯Ù‚ÛŒÙ‚ Ø¯Ø§Ø±Ø¯.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** ÙˆØ§Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ù†ÙˆØ¹ Ú¯ÛŒØ§Ù‡ Ùˆ Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ†.
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø²ÛŒØ³Øªâ€ŒØªÙˆØ¯Ù‡ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'Chlorophyll': {
        'func': calculate_chlorophyll_mcari, 'vis': {'min': 0, 'max': 1, 'palette': ['#ffffcc', '#a1dab4', '#253494']}, # Yellow-Green-Blue
        'name_fa': "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (MCARI/NDVI)",
        'desc_fa': """**Chlorophyll Index:** Ø¨Ù‡ ØºÙ„Ø¸Øª Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¯Ø± Ø¨Ø±Ú¯â€ŒÙ‡Ø§ Ø­Ø³Ø§Ø³ Ø§Ø³Øª (Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ÙØªÙˆØ³Ù†ØªØ² Ùˆ Ø³Ù„Ø§Ù…Øª). Ø§Ø² Ø´Ø§Ø®Øµ MCARI (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ù†Ø¯ RedEdge Ø¯Ø± Sentinel-2) ÛŒØ§ NDVI (Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªÙ‚Ø±ÛŒØ¨ÛŒ) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
                    - **Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Ù…ØªØºÛŒØ±.
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ùˆ Ø³Ù„Ø§Ù…Øª Ø¨Ù‡ØªØ± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª.""",
        'sort_ascending': False
    },
    'ET_proxy': {
        'func': calculate_et_placeholder, 'vis': {'min': -0.5, 'max': 0.8, 'palette': ['#a50026', '#ffffbf', '#313695']}, # Same as NDMI
        'name_fa': "Ù¾Ø±Ø§Ú©Ø³ÛŒ ØªØ¨Ø®ÛŒØ±-ØªØ¹Ø±Ù‚ (ET - Ø¨Ø± Ø§Ø³Ø§Ø³ NDMI)",
        'desc_fa': """**ET Proxy:** ÛŒÚ© Ø´Ø§Ø®Øµ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª Ø±Ø·ÙˆØ¨ØªÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ØªØ¨Ø®ÛŒØ± Ùˆ ØªØ¹Ø±Ù‚ (ET). Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø² NDMI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚ ET Ø¨Ø³ÛŒØ§Ø± Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø§Ø³Øª.
                    - **ØªÙØ³ÛŒØ±:** Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ø§Ù„Ø§ØªØ± NDMI (Ø±Ø·ÙˆØ¨Øª Ø¨ÛŒØ´ØªØ±) Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ ET Ø¨Ø§Ù„Ø§ØªØ±ÛŒ Ø±Ø§ Ù†Ø´Ø§Ù† Ø¯Ù‡Ø¯.""",
        'sort_ascending': False
    }
}


# --- GEE Data Retrieval ---
def get_image_collection(start_date, end_date, geometry=None, sensor='Sentinel-2'):
    """Gets, filters, masks, scales, and renames Sentinel-2 or Landsat images."""
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')

    collection_id = None
    bands_to_select_orig = []
    bands_to_rename_to = []
    mask_func = None

    if sensor == 'Sentinel-2':
        collection_id = 'COPERNICUS/S2_SR_HARMONIZED'
        mask_func = mask_s2_clouds
        bands_to_select_orig = ['B2', 'B3', 'B4', 'B5', 'B8', 'B11', 'B12', 'QA60']
        bands_to_rename_to = COMMON_BAND_NAMES # Uses the global list
    elif sensor == 'Landsat':
        # Combine L8 and L9 SR collections
        l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')
        l8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')
        collection_id = l9.merge(l8) # Use merged collection
        mask_func = mask_landsat_clouds
        bands_to_select_orig = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'QA_PIXEL']
        # Landsat doesn't have RedEdge1 equivalent easily available for all indices
        bands_to_rename_to = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2']
    else:
        st.error(f"Ø³Ù†Ø³ÙˆØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {sensor}")
        return None

    # Basic Date Range Check
    if start_date > end_date:
         st.error("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø¹Ø¯ Ø§Ø² ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù† Ø¨Ø§Ø´Ø¯.")
         return None

    # Create base collection object
    collection = ee.ImageCollection(collection_id) if isinstance(collection_id, str) else collection_id

    # Apply filters
    collection = collection.filterDate(start_date_str, end_date_str)
    if geometry:
        try:
            # Simple check if geometry seems valid before filtering
            if geometry.type().getInfo():
                 collection = collection.filterBounds(geometry)
        except Exception as e:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù…Ø±Ø²Ù‡Ø§ÛŒ Ù‡Ù†Ø¯Ø³ÛŒ: {e}")
            return None

    # Check size before processing (can be slow)
    try:
        initial_count = collection.size().getInfo()
        if initial_count == 0:
            # Don't show warning if the date range itself is empty
            if (end_date - start_date).days >= 0:
                 st.warning(f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù…Ù†Ø·Ù‚Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ({sensor}) Ù‚Ø¨Ù„ Ø§Ø² Ù…Ø§Ø³Ú© Ø§Ø¨Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="â³")
            return None
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ Ø§ÙˆÙ„ÛŒÙ‡ ØªØµØ§ÙˆÛŒØ±: {e}")
        return None


    # --- Processing Function (Mapped) ---
    def process_image(image_element):
        image = ee.Image(image_element)
        # Select necessary bands FIRST
        img_selected_orig = image.select(bands_to_select_orig)
        # Apply masking and scaling
        img_processed = mask_func(img_selected_orig)
        # Ensure it's an image before renaming
        img_processed_safe = ee.Image(img_processed)
        # Rename to common names
        # Rename might fail if mask_func returned fewer bands than expected
        try:
            # Check band count compatibility if needed
            # actual_bands = img_processed_safe.bandNames().length()
            # expected_bands = ee.Number(len(bands_to_rename_to))
            # ... conditional logic ...
            img_renamed = img_processed_safe.rename(bands_to_rename_to)
        except ee.EEException as rename_e:
            # Handle rename error, maybe return the image without renaming or log warning
            print(f"Warning: Could not rename bands for an image. Error: {rename_e}")
            # Decide how to proceed: return unprocessed, processed without rename, or skip?
            # Returning processed but not renamed might break downstream index calcs
            return None # Skip image if renaming fails
        # Copy essential properties
        return img_renamed.copyProperties(image, ["system:time_start"])

    # Map the processing function, removing nulls (images that failed processing)
    processed_collection = collection.map(process_image).filter(ee.Filter.neq('item', None))


    # Check size AFTER processing
    try:
        count = processed_collection.size().getInfo()
        if count == 0:
            st.warning(f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù…Ù†Ø·Ù‚Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ({sensor}) ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="â˜ï¸")
            return None
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {e}")
        return None


    # Final check on first image bands (optional)
    try:
        first_image = processed_collection.first()
        if first_image:
            final_bands = ee.Image(first_image).bandNames().getInfo()
            print(f"Bands in first processed image: {final_bands}")
        else:
            # This case should be caught by the size check above, but for safety:
             st.warning("Ú©Ø§Ù„Ú©Ø´Ù† Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø®Ø§Ù„ÛŒ Ø´Ø¯.", icon="âš ï¸")
             return None

    except ee.EEException as e:
        # Non-critical error, proceed but log it
        print(f"Warning: Could not verify bands in first processed image: {e}")

    return processed_collection

# --- Function to calculate a single index for a collection ---
def calculate_single_index(collection, index_name):
    """Calculates a single specified index for the collection."""
    if collection is None: return None
    index_detail = INDEX_DEFINITIONS.get(index_name)
    if not index_detail:
        st.error(f"ØªØ¹Ø±ÛŒÙ Ø´Ø§Ø®Øµ '{index_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return None

    index_func = index_detail['func']
    try:
        # Map the function - it should return an image containing the calculated index band
        indexed_collection = collection.map(index_func)

        # Check if the index band was actually created in the first image
        first_img = indexed_collection.first()
        if first_img and index_name in ee.Image(first_img).bandNames().getInfo():
             # Return the collection containing images with (at least) the calculated index band
             # Select only the index band for consistency downstream?
             return indexed_collection.select(index_name)
        else:
             # Log which bands ARE available if the index is missing
             available_bands = ee.Image(first_img).bandNames().getInfo() if first_img else "None"
             st.warning(f"Ø¨Ø§Ù†Ø¯ Ø´Ø§Ø®Øµ '{index_name}' Ù¾Ø³ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯. Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {available_bands}", icon="âš ï¸")
             return None # Indicate failure
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{index_name}': {e}")
        # Attempt to provide more context
        try:
            first_input_img = collection.first()
            if first_input_img:
                st.info(f"Bands input to failed index calculation: {ee.Image(first_input_img).bandNames().getInfo()}")
        except: pass # Ignore errors during error reporting
        return None
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ± GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{index_name}': {e}")
        st.exception(e) # Show full traceback
        return None


# --- get_timeseries_for_farm ---
@st.cache_data(ttl=1800) # Cache for 30 minutes
def get_timeseries_for_farm(_farm_geom_geojson, start_date, end_date, index_name, sensor):
    """Retrieves and calculates the time series for a specific index and farm geometry."""
    try:
        farm_geom = ee.Geometry(json.loads(_farm_geom_geojson))
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø±Ø¹Ù‡: {e}")
        return pd.DataFrame(columns=['Date', index_name])

    # Get the base masked, renamed collection
    base_collection = get_image_collection(start_date, end_date, farm_geom, sensor)
    if base_collection is None: return pd.DataFrame(columns=['Date', index_name])

    # Calculate the specific index
    indexed_collection = calculate_single_index(base_collection, index_name)
    if indexed_collection is None: return pd.DataFrame(columns=['Date', index_name])

    # Define the extraction function
    def extract_value(image):
        img_ee = ee.Image(image) # Ensure image type
        # Use mean reducer over the buffered farm point geometry
        stats = img_ee.reduceRegion(
            reducer=ee.Reducer.mean(), geometry=farm_geom, scale=30, maxPixels=1e9, tileScale=4
        )
        val = stats.get(index_name) # Get the calculated value
        time_ms = img_ee.get('system:time_start') # Get time from the image object
        # Return feature with time and value (or placeholder if null)
        return ee.Feature(None, {'time': time_ms, index_name: ee.Algorithms.If(val, val, -9999)})

    # Execute the extraction
    try:
        # Increase timeout? Not directly possible here. Use tileScale.
        ts_info = indexed_collection.map(extract_value).getInfo()
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ (reduceRegion): {e}")
        st.info("Ø§ÛŒÙ† Ø®Ø·Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø­Ø§ÙØ¸Ù‡ ÛŒØ§ Ø²Ù…Ø§Ù† GEE Ø¨Ø§Ø´Ø¯. Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± ÛŒØ§ Ù…Ù†Ø·Ù‚Ù‡ Ú©ÙˆÚ†Ú©â€ŒØªØ±ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
        return pd.DataFrame(columns=['Date', index_name])
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}")
        return pd.DataFrame(columns=['Date', index_name])


    # Process results into DataFrame
    data = []
    if 'features' in ts_info:
        for feature in ts_info['features']:
            props = feature.get('properties', {})
            value = props.get(index_name)
            time_ms = props.get('time')
            # Validate data before appending
            if value not in [None, -9999] and time_ms is not None:
                try:
                    # Convert milliseconds timestamp to datetime
                    dt = datetime.datetime.fromtimestamp(time_ms / 1000.0)
                    data.append([dt, value])
                except (TypeError, ValueError) as time_e:
                     st.warning(f"Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ† Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ø²Ù…Ø§Ù† Ù†Ø§Ù…Ø¹ØªØ¨Ø± ({time_ms}): {time_e}", icon="âš ï¸")
    else:
        st.warning("Ø³Ø§Ø®ØªØ§Ø± 'features' Ø¯Ø± Ù†ØªØ§ÛŒØ¬ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

    if not data: return pd.DataFrame(columns=['Date', index_name]) # Return empty if no valid data
    ts_df = pd.DataFrame(data, columns=['Date', index_name]).sort_values(by='Date').reset_index(drop=True)
    return ts_df

# --- Function for getting median index over a period for multiple farms ---
@st.cache_data(ttl=1800) # Cache for 30 minutes
def get_median_index_for_period(_farms_df_json, start_date, end_date, index_name, sensor):
    """Gets the median index value over a period for multiple farms."""
    farms_df = pd.read_json(_farms_df_json)
    farms_df_valid_coords = farms_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']).copy()

    if farms_df_valid_coords.empty:
         # Don't show warning here, let calling function handle empty result
         # st.warning("No farms with valid coordinates for period calculation.", icon="ğŸ“")
         return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    features = []
    for idx, row in farms_df_valid_coords.iterrows():
        try:
             geom = ee.Geometry.Point([row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']])
             buffered_geom = geom.buffer(50) # Buffer for reduction robustness
             # Ensure farm_id is included in properties
             feature = ee.Feature(buffered_geom, {'farm_id': row['Ù…Ø²Ø±Ø¹Ù‡']})
             features.append(feature)
        except Exception as e:
             print(f"Warning: Skipping farm {row.get('Ù…Ø²Ø±Ø¹Ù‡', 'Unknown')} due to geometry error: {e}")

    if not features:
         # st.warning("No valid farm geometries created.", icon="âš ï¸")
         return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    farm_fc = ee.FeatureCollection(features)

    # Get base collection for the period
    base_collection = get_image_collection(start_date, end_date, farm_fc.geometry(), sensor)
    if base_collection is None: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    # Calculate the specified index
    indexed_collection = calculate_single_index(base_collection, index_name)
    if indexed_collection is None: return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    # Create a median composite image for robustness against outliers
    median_image = indexed_collection.median() # Contains only the index band

    # Reduce the composite image over all farm geometries
    try:
        farm_values = median_image.reduceRegions(
            collection=farm_fc, reducer=ee.Reducer.mean(), scale=30, tileScale=8 # Increased tileScale
        ).getInfo()
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø²Ø§Ø±Ø¹ (reduceRegions): {e}")
        return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])
    except Exception as e:
         st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø²Ø§Ø±Ø¹: {e}")
         return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    # Extract results into a DataFrame
    results_data = []
    if 'features' in farm_values:
        for feature in farm_values['features']:
            props = feature.get('properties', {})
            farm_id = props.get('farm_id') # Get farm_id from properties
            value = props.get('mean') # Default output name for mean reducer
            if farm_id is not None and value is not None:
                results_data.append({'Ù…Ø²Ø±Ø¹Ù‡': farm_id, index_name: value})
            else:
                # Log if reduction failed for a specific farm
                print(f"Warning: Could not get value for farm_id: {farm_id}, Props: {props}")
    else:
        st.warning("Ø³Ø§Ø®ØªØ§Ø± 'features' Ø¯Ø± Ù†ØªØ§ÛŒØ¬ reduceRegions ÛŒØ§ÙØª Ù†Ø´Ø¯.")

    if not results_data:
         # st.warning("No data extracted after GEE processing for farms.", icon="ğŸ“Š")
         return pd.DataFrame(columns=['Ù…Ø²Ø±Ø¹Ù‡', index_name])

    results_df = pd.DataFrame(results_data)
    return results_df

# --- Function for Weekly Comparison ---
@st.cache_data(ttl=1800) # Cache for 30 minutes
def get_weekly_comparison(_filtered_df_json, start_date, end_date, index_name, sensor):
    """Compares the index values from the current week to the previous week."""
    if not isinstance(start_date, datetime.date) or not isinstance(end_date, datetime.date):
        st.error("ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ùˆ Ù¾Ø§ÛŒØ§Ù† Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ.")
        return pd.DataFrame()

    # Define current and previous week date ranges
    current_start = start_date
    current_end = end_date
    # Ensure previous week doesn't overlap
    prev_end = current_start - timedelta(days=1)
    prev_start = prev_end - timedelta(days=(end_date-start_date).days) # Match duration

    st.write(f"Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ: {current_start.strftime('%Y-%m-%d')} ØªØ§ {current_end.strftime('%Y-%m-%d')}")
    st.write(f"Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„ÛŒ: {prev_start.strftime('%Y-%m-%d')} ØªØ§ {prev_end.strftime('%Y-%m-%d')}")

    # Get data for the current period
    with st.spinner(f"Ø¯Ø±Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ '{index_name}' Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ..."):
        df_current = get_median_index_for_period(_filtered_df_json, current_start, current_end, index_name, sensor)
    if df_current.empty:
        st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ ({current_start} ØªØ§ {current_end}) Ø¬Ù‡Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
        return pd.DataFrame()

    # Get data for the previous period
    with st.spinner(f"Ø¯Ø±Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ '{index_name}' Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„ÛŒ..."):
        df_previous = get_median_index_for_period(_filtered_df_json, prev_start, prev_end, index_name, sensor)
    if df_previous.empty:
        st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ù‚Ø¨Ù„ÛŒ ({prev_start} ØªØ§ {prev_end}) Ø¬Ù‡Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
        return pd.DataFrame() # Cannot compare without previous week's data

    # Merge the dataframes on 'Ù…Ø²Ø±Ø¹Ù‡'
    df_comparison = pd.merge(
        df_previous.rename(columns={index_name: f'{index_name}_prev'}),
        df_current.rename(columns={index_name: f'{index_name}_curr'}),
        on='Ù…Ø²Ø±Ø¹Ù‡',
        how='inner' # Only compare farms present in BOTH periods
    )

    if df_comparison.empty:
        st.info("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø´ØªØ±Ú©ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ Ø¯ÙˆØ±Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return pd.DataFrame()

    # Calculate difference and percentage change robustly
    df_comparison['ØªØºÛŒÛŒØ±'] = df_comparison[f'{index_name}_curr'] - df_comparison[f'{index_name}_prev']
    # Use numpy for safe division and handling potential NaNs
    df_comparison['Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±'] = np.where(
        np.abs(df_comparison[f'{index_name}_prev']) > 1e-9, # Avoid division by very small numbers
       ((df_comparison['ØªØºÛŒÛŒØ±'] / df_comparison[f'{index_name}_prev']) * 100.0),
        np.nan # Assign NaN if previous value is too small or zero
    )

    # Filter for farms with decrease (change < 0)
    # Consider a small threshold? e.g., df_comparison['ØªØºÛŒÛŒØ±'] < -0.01
    df_decreased = df_comparison[df_comparison['ØªØºÛŒÛŒØ±'] < 0].copy()

    # Sort by percentage change (most negative first)
    df_decreased = df_decreased.sort_values(by='Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±', ascending=True, na_position='last')

    return df_decreased


# --- Streamlit App Layout ---
st.set_page_config(page_title=APP_TITLE, layout="wide", initial_sidebar_state="expanded")
st.title(f"ğŸŒ¾ {APP_TITLE}")
st.markdown("Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ùˆ Google Earth Engine")
st.divider()

# Initialize GEE (shows error if fails)
if initialize_gee():
    # Load data (shows error if fails)
    farm_data_df = load_data(CSV_FILE_PATH)

    # --- Sidebar Controls ---
    with st.sidebar:
        st.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ ÙÛŒÙ„ØªØ±Ù‡Ø§")
        st.divider()

        # --- Date Range Selection ---
        st.subheader("ğŸ—“ï¸ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ")
        today = datetime.date.today()
        # Default to last 7 days ending today
        default_start = today - timedelta(days=6)
        start_date = st.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", value=default_start, max_value=today, help="ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ø¯ÙˆØ±Ù‡ ØªØ­Ù„ÛŒÙ„ Ø§ØµÙ„ÛŒ")
        end_date = st.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", value=today, min_value=start_date, max_value=today, help="ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù† Ø¯ÙˆØ±Ù‡ ØªØ­Ù„ÛŒÙ„ Ø§ØµÙ„ÛŒ")
        st.info(f"Ù…Ø¯Øª Ø¯ÙˆØ±Ù‡: {(end_date - start_date).days + 1} Ø±ÙˆØ²", icon="â³")
        st.divider()

        # --- Data Filters ---
        st.subheader("ğŸ” ÙÛŒÙ„ØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
        # Day of Week Filter
        days_list = ["Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§"] + sorted(farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique().tolist())
        selected_day = st.selectbox("Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ", options=days_list, help="ÙÛŒÙ„ØªØ± Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø«Ø¨Øª Ø´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ CSV")

        # Filter DataFrame based on selected day *before* subsequent controls
        if selected_day == "Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§":
            filtered_df = farm_data_df.copy()
        else:
            filtered_df = farm_data_df[farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()
        st.caption(f"{len(filtered_df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø§Ø³Øª.")

        # Index Selection for Analysis
        available_indices = list(INDEX_DEFINITIONS.keys())
        selected_index = st.selectbox(
            "Ø´Ø§Ø®Øµ Ù…ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„",
            options=available_indices,
            format_func=lambda x: INDEX_DEFINITIONS[x]['name_fa'], # Show Persian name
            help="Ø´Ø§Ø®ØµÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡ØŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯"
            )

        # Sensor Selection
        selected_sensor = st.radio(
            "Ø³Ù†Ø³ÙˆØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡",
            ('Sentinel-2', 'Landsat'), index=0, horizontal=True,
            help="Sentinel-2 ØªÙÚ©ÛŒÚ© Ù…Ú©Ø§Ù†ÛŒ Ø¨Ù‡ØªØ± (10m) Ùˆ Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ RedEdge Ø¯Ø§Ø±Ø¯. Landsat ØªÙˆØ§Ù„ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ± Ø¯Ø§Ø±Ø¯."
            )
        st.divider()

        # --- Farm Selection ---
        st.subheader("ğŸšœ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡")
        # Populate farm list based on the *day-filtered* data
        farm_list = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + sorted(filtered_df['Ù…Ø²Ø±Ø¹Ù‡'].unique().tolist())
        selected_farm = st.selectbox(
            "Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ (ÛŒØ§ Ù‡Ù…Ù‡)", options=farm_list,
             help="ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ØŒ ÛŒØ§ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯ Ú©Ù„ÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯."
             )
        st.divider()


        # --- Display Index Information ---
        st.header("â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§")
        index_options = list(INDEX_DEFINITIONS.keys())
        index_to_explain = st.selectbox(
            "Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø´Ø§Ø®Øµ:",
            options=index_options,
            index=index_options.index(selected_index), # Default to selected index for analysis
            format_func=lambda x: INDEX_DEFINITIONS[x]['name_fa']
        )
        if index_to_explain:
            with st.expander(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ø´Ø§Ø®Øµ {INDEX_DEFINITIONS[index_to_explain]['name_fa']}", expanded=False):
                st.markdown(INDEX_DEFINITIONS[index_to_explain]['desc_fa'], unsafe_allow_html=True)
        st.divider()
        st.caption("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ Streamlit Ùˆ Google Earth Engine")


    # --- Main Panel with Tabs ---
    tab1, tab2, tab3 = st.tabs([
        "ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ Ùˆ Ø¬Ø²Ø¦ÛŒØ§Øª",
        "ğŸ“Š Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹",
        "ğŸ“‰ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ"
        ])

    # --- Tab 1: Map and Farm Details ---
    with tab1:
        col_map, col_detail = st.columns([2, 1]) # Adjust column ratio

        with col_map:
            st.subheader(f"Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
            st.caption(f"Ø¯ÙˆØ±Ù‡: {start_date.strftime('%Y-%m-%d')} ØªØ§ {end_date.strftime('%Y-%m-%d')} | Ø³Ù†Ø³ÙˆØ±: {selected_sensor}")
            map_placeholder = st.empty() # Placeholder for the map
            m = geemap.Map(center=[INITIAL_LAT, INITIAL_LON], zoom=INITIAL_ZOOM, add_google_map=False)
            m.add_basemap('HYBRID') # Use satellite view

            vis_params = INDEX_DEFINITIONS.get(selected_index, {}).get('vis')
            if not vis_params: vis_params = {'min': 0, 'max': 1, 'palette': ['white', 'gray']} # Fallback vis

            # Determine display geometry and target farm info
            display_geom = None
            target_object_for_map = None
            farm_info_for_display = None # Store info of the selected farm for details pane

            # Use the day-filtered data for display logic
            display_df = filtered_df.copy()

            if selected_farm == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                # Use only farms with valid coordinates for bounds calculation
                display_df_valid = display_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
                if not display_df_valid.empty:
                    try:
                        min_lon, min_lat = display_df_valid['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), display_df_valid['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
                        max_lon, max_lat = display_df_valid['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(), display_df_valid['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
                        display_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])
                        target_object_for_map = display_geom
                    except Exception as bounds_e:
                        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø±Ø²Ù‡Ø§: {bounds_e}")
                else:
                    st.info("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ² Ù‡ÙØªÙ‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="ğŸ“")
            else: # Single farm selected
                farm_info_rows = display_df[display_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm]
                if not farm_info_rows.empty:
                    farm_info_for_display = farm_info_rows.iloc[0] # Save for details pane
                    farm_lat = farm_info_for_display['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
                    farm_lon = farm_info_for_display['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
                    if pd.notna(farm_lat) and pd.notna(farm_lon):
                        try:
                            farm_geom = ee.Geometry.Point([farm_lon, farm_lat])
                            display_geom = farm_geom.buffer(150) # Area around point for vis
                            target_object_for_map = farm_geom # Center on the actual point
                        except Exception as point_e:
                             st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ù‚Ø·Ù‡: {point_e}")
                             farm_info_for_display = None # Invalidate if geom fails
                    else:
                        st.warning(f"Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm}.", icon="ğŸ“")
                        farm_info_for_display = None
                else:
                    st.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ {selected_farm} Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")

            # --- Fetch data and display layer on map ---
            if display_geom:
                with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø´Ù‡ '{selected_index}'... Ù„Ø·ÙØ§Ù‹ Ú©Ù…ÛŒ ØµØ¨Ø± Ú©Ù†ÛŒØ¯."):
                    base_collection = get_image_collection(start_date, end_date, display_geom, selected_sensor)
                    layer_added = False # Flag to check if layer was added
                    if base_collection:
                        indexed_collection = calculate_single_index(base_collection, selected_index)
                        if indexed_collection:
                            try:
                                median_image = indexed_collection.median()
                                # Clip layer visually if single farm selected
                                layer_image = median_image.clip(display_geom) if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else median_image
                                # Add layer to map
                                m.addLayer(layer_image, vis_params, f'{selected_index} (Median)')
                                layer_added = True # Mark as added
                                # Add legend
                                try:
                                    m.add_legend(title=f'{selected_index}', builtin_legend=None, palette=vis_params['palette'], min=vis_params['min'], max=vis_params['max'])
                                except Exception as legend_e:
                                     print(f"Warning: Could not add legend: {legend_e}") # Log warning

                                # Add download button for map layer
                                try:
                                    thumb_url = median_image.getThumbURL({
                                        'region': display_geom.toGeoJson(), 'bands': selected_index,
                                        'palette': vis_params['palette'], 'min': vis_params['min'], 'max': vis_params['max'],
                                        'dimensions': 512 })
                                    response = requests.get(thumb_url)
                                    if response.status_code == 200:
                                        st.sidebar.download_button(
                                            label=f"ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ù‚Ø´Ù‡ ({selected_index})", data=BytesIO(response.content),
                                            file_name=f"map_{selected_farm if selected_farm != 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' else 'all'}_{selected_index}.png",
                                            mime="image/png", key=f"dl_map_{selected_index}_{selected_farm}" )
                                except Exception as thumb_e:
                                     print(f"Warning: Could not generate map thumbnail: {thumb_e}") # Log warning

                            except ee.EEException as ee_err:
                                st.error(f"Ø®Ø·Ø§ÛŒ GEE Ù‡Ù†Ú¯Ø§Ù… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§ÛŒÙ‡ Ù†Ù‚Ø´Ù‡: {ee_err}")
                            except Exception as err:
                                st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ù‡Ù†Ú¯Ø§Ù… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§ÛŒÙ‡ Ù†Ù‚Ø´Ù‡: {err}")
                        else:
                             st.warning(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{selected_index}' Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø´Ù‡ Ù…Ù…Ú©Ù† Ù†Ø¨ÙˆØ¯.", icon="âš ï¸")
                    else:
                         # Warnings are shown inside get_image_collection if no images found
                         pass # st.info("ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‚Ø´Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

                # --- Add markers ---
                if layer_added: # Only add markers if the layer was processed
                    if selected_farm == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                        # Mark all farms from the day-filtered list with valid coords
                        df_to_mark = display_df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
                        for idx, row in df_to_mark.iterrows():
                            # Use cleaned column name 'Ø³Ù†'
                            popup_html = f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {row['Ù…Ø²Ø±Ø¹Ù‡']}<br><b>Ú©Ø§Ù†Ø§Ù„:</b> {row['Ú©Ø§Ù†Ø§Ù„']} | <b>Ø§Ø¯Ø§Ø±Ù‡:</b> {row['Ø§Ø¯Ø§Ø±Ù‡']}<br><b>Ù…Ø³Ø§Ø­Øª:</b> {row['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}<br><b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {row['ÙˆØ§Ø±ÛŒØªÙ‡']} | <b>Ø³Ù†:</b> {row['Ø³Ù†']}"
                            folium.Marker(location=[row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']],
                                          popup=folium.Popup(popup_html, max_width=250),
                                          tooltip=f"{row['Ù…Ø²Ø±Ø¹Ù‡']}",
                                          icon=folium.Icon(color='blue', icon='info-sign', prefix='fa') # Use FontAwesome icons
                                          ).add_to(m)
                    elif farm_info_for_display is not None: # Single farm selected and info is valid
                        farm_info = farm_info_for_display
                        # Use cleaned column name 'Ø³Ù†'
                        popup_html = f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {farm_info['Ù…Ø²Ø±Ø¹Ù‡']}<br><b>Ú©Ø§Ù†Ø§Ù„:</b> {farm_info['Ú©Ø§Ù†Ø§Ù„']} | <b>Ø§Ø¯Ø§Ø±Ù‡:</b> {farm_info['Ø§Ø¯Ø§Ø±Ù‡']}<br><b>Ù…Ø³Ø§Ø­Øª:</b> {farm_info['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}<br><b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {farm_info['ÙˆØ§Ø±ÛŒØªÙ‡']} | <b>Ø³Ù†:</b> {farm_info['Ø³Ù†']}"
                        folium.Marker(location=[farm_info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm_info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']],
                                      popup=folium.Popup(popup_html, max_width=250),
                                      tooltip=f"{farm_info['Ù…Ø²Ø±Ø¹Ù‡']} (Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡)",
                                      icon=folium.Icon(color='red', icon='star', prefix='fa') # Red star for selected
                                      ).add_to(m)

                # Center the map view
                if target_object_for_map:
                    zoom_level = INITIAL_ZOOM + 2 if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else INITIAL_ZOOM
                    try: m.center_object(target_object_for_map, zoom=zoom_level)
                    except Exception as center_e:
                         print(f"Warning: Could not center map object: {center_e}")
                         m.set_center(INITIAL_LON, INITIAL_LAT, INITIAL_ZOOM) # Fallback center

            else:
                # No valid geometry determined earlier
                st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø¹ØªØ¨Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ù…Ø®ØªØµØ§Øª ØµØ­ÛŒØ­ Ø¯Ø± ÙØ§ÛŒÙ„ CSV Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")


            # Render the map in the placeholder
            with map_placeholder:
                m.to_streamlit(height=550) # Slightly taller map


        # --- Column 2: Farm Details and Timeseries ---
        with col_detail:
            if selected_farm != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                st.subheader(f" Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm}")
                st.divider()
                if farm_info_for_display is not None:
                    farm_info = farm_info_for_display # Use the data fetched for map display
                    # Display metrics using cleaned column name 'Ø³Ù†'
                    st.metric("Ú©Ø§Ù†Ø§Ù„", str(farm_info.get('Ú©Ø§Ù†Ø§Ù„', 'N/A')), help="Ø´Ù…Ø§Ø±Ù‡ Ú©Ø§Ù†Ø§Ù„ Ø¢Ø¨ÛŒØ§Ø±ÛŒ")
                    st.metric("Ø§Ø¯Ø§Ø±Ù‡", str(farm_info.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')), help="Ø´Ù…Ø§Ø±Ù‡ Ø§Ø¯Ø§Ø±Ù‡ Ù…Ø±Ø¨ÙˆØ·Ù‡")
                    st.metric("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", f"{farm_info['Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª']:.2f}" if pd.notna(farm_info.get('Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª')) else "N/A", help="Ù…Ø³Ø§Ø­Øª Ø«Ø¨Øª Ø´Ø¯Ù‡ Ù…Ø²Ø±Ø¹Ù‡")
                    st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", str(farm_info.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')), help="Ù†ÙˆØ¹ ÙˆØ§Ø±ÛŒØªÙ‡ Ú©Ø´Øª Ø´Ø¯Ù‡")
                    st.metric("Ø³Ù†", str(farm_info.get('Ø³Ù†', 'N/A')), help="Ø³Ù† Ú©Ø´Øª (P: Ù¾Ù„Ø§Ù†ØªØŒ R: Ø±Ø§ØªÙˆÙ†)") # Access cleaned name
                    st.metric("Ø±ÙˆØ² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", str(farm_info.get('Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'N/A')), help="Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ø·Ø¨Ù‚ Ø¨Ø±Ù†Ø§Ù…Ù‡")
                    st.divider()

                    # --- Timeseries Chart ---
                    st.subheader(f"ğŸ“ˆ Ø±ÙˆÙ†Ø¯ Ø´Ø§Ø®Øµ: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
                    # Check coordinates again before potentially expensive GEE call
                    if pd.notna(farm_info.get('Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ')) and pd.notna(farm_info.get('Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ')):
                        with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ '{selected_index}'..."):
                            # Create geometry again safely
                            try:
                                farm_geom_ts = ee.Geometry.Point([farm_info['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm_info['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']])
                                # Pass geom as GeoJSON string for caching
                                ts_df = get_timeseries_for_farm(farm_geom_ts.toGeoJsonString(), start_date, end_date, selected_index, selected_sensor)
                            except Exception as ts_geom_e:
                                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù‡Ù†Ø¯Ø³Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_geom_e}")
                                ts_df = pd.DataFrame() # Ensure empty df

                        if not ts_df.empty:
                            fig_ts = px.line(ts_df, x='Date', y=selected_index,
                                            title=f"Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm}",
                                            markers=True, labels={'Date': 'ØªØ§Ø±ÛŒØ®', selected_index: f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                            fig_ts.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}", title_x=0.5)
                            fig_ts.update_traces(line=dict(color='royalblue', width=2), marker=dict(color='salmon', size=6))
                            st.plotly_chart(fig_ts, use_container_width=True)
                        else:
                            st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ '{selected_index}' Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="ğŸ“‰")
                    else:
                        st.warning("Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ.", icon="ğŸ“")
                else:
                    st.info("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ ÛŒØ§ Ø§Ù†ØªØ®Ø§Ø¨ ÙØ¹Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª ÛŒØ§ Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
            else: # "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" selected
                 st.subheader("Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ø±ÙˆÙ†Ø¯")
                 st.info("""
                 Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„ Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ:
                 1.  Ø§Ø² Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒØŒ ÙÛŒÙ„ØªØ± **Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ** Ø±Ø§ (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²) ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.
                 2.  Ø§Ø² Ù…Ù†ÙˆÛŒ **Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ (ÛŒØ§ Ù‡Ù…Ù‡)**ØŒ Ù†Ø§Ù… Ù…Ø²Ø±Ø¹Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ù…Ø§ÛŒÛŒØ¯.
                 3.  Ø¬Ø²Ø¦ÛŒØ§Øª Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.
                 """, icon="ğŸ‘ˆ")


    # --- Tab 2: Ranking ---
    with tab2:
        st.subheader(f"ğŸ“Š Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ: {INDEX_DEFINITIONS[selected_index]['name_fa']}")
        st.caption(f"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ '{selected_index}' Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ {start_date.strftime('%Y-%m-%d')} ØªØ§ {end_date.strftime('%Y-%m-%d')} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}'.")
        st.divider()

        # Use the filtered_df which respects the day filter
        if filtered_df.empty:
             st.warning(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ø¬Ù‡Øª Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
        else:
            with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ '{selected_index}'..."):
                # Pass the day-filtered DataFrame JSON for ranking
                ranking_df = get_median_index_for_period(filtered_df.to_json(), start_date, end_date, selected_index, sensor=selected_sensor)

            if not ranking_df.empty:
                # Determine sort order based on index definition
                ascending_sort = INDEX_DEFINITIONS[selected_index].get('sort_ascending', False)
                ranking_df_sorted = ranking_df.sort_values(by=selected_index, ascending=ascending_sort, na_position='last').reset_index(drop=True)

                st.dataframe(
                    ranking_df_sorted.style.format({selected_index: "{:.3f}"}) # Format the index value
                                          .bar(subset=[selected_index], color='lightcoral' if ascending_sort else 'lightgreen', align='mid'), # Add data bars
                    use_container_width=True
                    )

                # Download Button for Ranking
                csv_rank = ranking_df_sorted.to_csv(index=False).encode('utf-8')
                st.download_button(
                   label=f"ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ({selected_index})", data=csv_rank,
                   file_name=f'ranking_{selected_index}_{selected_day}.csv', mime='text/csv', key='dl_rank'
                 )
            else:
                st.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ ÙÛŒÙ„ØªØ± '{selected_day}' Ùˆ Ø´Ø§Ø®Øµ '{selected_index}' ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="ğŸ“Š")
        st.divider()


    # --- Tab 3: Weekly Comparison ---
    with tab3:
        st.subheader(f"ğŸ“‰ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ: Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ ({INDEX_DEFINITIONS[selected_index]['name_fa']})")
        st.caption(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø´Ø§Ø®Øµ Ø¨ÛŒÙ† Ø¯ÙˆØ±Ù‡ Ø¬Ø§Ø±ÛŒ Ùˆ Ø¯ÙˆØ±Ù‡ Ù…Ø´Ø§Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}'.")
        st.markdown("ÙÙ‚Ø· Ù…Ø²Ø§Ø±Ø¹ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ Ú©Ù‡ Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ **Ú©Ø§Ù‡Ø´** Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.")
        st.divider()

        # Use the filtered_df which respects the day filter
        if filtered_df.empty:
             st.warning(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ø¬Ù‡Øª Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
        else:
            with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ '{selected_index}'..."):
                # Pass the day-filtered json for comparison relevant to the selected day
                comparison_df_decreased = get_weekly_comparison(filtered_df.to_json(), start_date, end_date, selected_index, selected_sensor)

            if not comparison_df_decreased.empty:
                st.markdown("##### Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ:")
                # Display table with relevant columns, formatted nicely
                display_cols = ['Ù…Ø²Ø±Ø¹Ù‡', f'{index_name}_prev', f'{index_name}_curr', 'ØªØºÛŒÛŒØ±', 'Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±']
                st.dataframe(
                    comparison_df_decreased[display_cols].style.format({
                        f'{index_name}_prev': "{:.3f}", f'{index_name}_curr': "{:.3f}",
                        'ØªØºÛŒÛŒØ±': "{:+.3f}", 'Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±': "{:+.1f}%" # Add sign to change
                    }).applymap(lambda x: 'color: red' if x < 0 else ('color: black' if x==0 else 'color: green'), subset=['ØªØºÛŒÛŒØ±','Ø¯Ø±ØµØ¯_ØªØºÛŒÛŒØ±']), # Color changes
                    use_container_width=True
                )
                st.divider()

                st.markdown("##### Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ:")
                # Create grouped bar chart for visual comparison
                fig_comp = go.Figure()
                fig_comp.add_trace(go.Bar(
                    x=comparison_df_decreased['Ù…Ø²Ø±Ø¹Ù‡'], y=comparison_df_decreased[f'{index_name}_prev'],
                    name='Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„', marker_color='dodgerblue', text=comparison_df_decreased[f'{index_name}_prev'].round(3), textposition='auto'
                ))
                fig_comp.add_trace(go.Bar(
                    x=comparison_df_decreased['Ù…Ø²Ø±Ø¹Ù‡'], y=comparison_df_decreased[f'{index_name}_curr'],
                    name='Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ', marker_color='lightcoral', text=comparison_df_decreased[f'{index_name}_curr'].round(3), textposition='auto'
                ))

                fig_comp.update_layout(
                    barmode='group', title=f'Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø§Ø®Øµ {selected_index} (Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ú©Ø§Ù‡Ø´)',
                    xaxis_title='Ù…Ø²Ø±Ø¹Ù‡', yaxis_title=f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}', legend_title='Ø¯ÙˆØ±Ù‡ Ø²Ù…Ø§Ù†ÛŒ',
                    xaxis={'categoryorder':'total descending'}, # Order bars if needed
                    hovermode="x unified", title_x=0.5
                )
                st.plotly_chart(fig_comp, use_container_width=True)
                st.divider()

                # Download Button for Comparison Data
                csv_comp = comparison_df_decreased.to_csv(index=False).encode('utf-8')
                st.download_button(
                   label=f"ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ ({selected_index})", data=csv_comp,
                   file_name=f'comparison_decrease_{selected_index}_{selected_day}.csv', mime='text/csv', key='dl_comp'
                 )

            else:
                st.success(f"âœ… Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ø§Ù‡Ø´ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¯Ø± Ø´Ø§Ø®Øµ '{selected_index}' Ø¨ÛŒÙ† Ø¯Ùˆ Ù‡ÙØªÙ‡ Ø§Ø®ÛŒØ± Ù†Ø´Ø§Ù† Ù†Ø¯Ø§Ø¯.")

else:
    st.error("Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§ Ùˆ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.", icon="ğŸš¨")