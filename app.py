# -*- coding: utf-8 -*-
# --- START OF FILE app.py ---

import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
import plotly.express as px
import plotly.graph_objects as go
import os
from io import BytesIO
import requests
import traceback
from streamlit_folium import st_folium
# import base64 # No longer explicitly needed
import google.generativeai as genai
from shapely.geometry import Polygon
import pyproj
import numpy as np # Import numpy for np.nan

# Define the source CRS (likely UTM Zone 39N for Khuzestan)
SOURCE_CRS = "EPSG:32639"
TARGET_CRS = "EPSG:4326" # WGS 84 geographic 2D

transformer = None
try:
    transformer = pyproj.Transformer.from_crs(SOURCE_CRS, TARGET_CRS, always_xy=True)
    print(f"Coordinate transformer created: {SOURCE_CRS} to {TARGET_CRS}")
except pyproj.exceptions.CRSError as e:
    st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª: {e}. Ù„Ø·ÙØ§Ù‹ Ú©Ø¯Ù‡Ø§ÛŒ EPSG {SOURCE_CRS} Ùˆ {TARGET_CRS} Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
except Exception as e:
     st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ù†Ø¯Ù‡ Ù…Ø®ØªØµØ§Øª: {e}")


# --- HARDCODED GEMINI API KEY (SECURITY RISK - NOT RECOMMENDED) ---
GEMINI_API_KEY_HARDCODED = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ" # --- YOUR HARDCODED KEY ---
# --- END OF HARDCODED API KEY ---


# --- Custom CSS ---
st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±",
    page_icon="ğŸŒ¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700;900&display=swap');
        @import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css');

        html, body, .main, .stApp {
            font-family: 'Vazirmatn', sans-serif !important;
            background: linear-gradient(180deg, #e0f7fa 0%, #f8fafc 100%);
            color: #333;
        }

        @media (prefers-color-scheme: dark) {
            html, body, .main, .stApp {
                background: linear-gradient(180deg, #2b2b2b 0%, #3f3f3f 100%);
                color: #f8f8f8;
            }
            .stTabs [data-baseweb="tab-list"] button [data-baseweb="tab"] { color: #bbb !important; }
             .stTabs [data-baseweb="tab-list"] button:hover { color: #f8f8f8 !important; }
            .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] { color: #43cea2 !important; border-bottom-color: #43cea2 !important; }
             .modern-card { background: linear-gradient(135deg, #1a435a 0%, #2a2a2a 100%); color: #f8f8f8; box-shadow: 0 4px 16px rgba(0,0,0,0.3); }
             .status-positive { background-color: #218838; }
             .status-negative { background-color: #c82333; }
             .status-neutral { background-color: #5a6268; color: #fff; }
             .status-nodata { background-color: #d39e00; color: #f8f8f8; }
             table { box-shadow: 0 4px 12px rgba(0,0,0,0.3); }
              th { background-color: #0e3a5d; color: #f8f8f8; }
             tr:nth-child(even) { background-color: #3a3a3a; }
             tr:nth-child(odd) { background-color: #2b2b2b; }
             td { border-bottom-color: #555; }
             .stAlert a { color: #43cea2; }
             .js-plotly-plot { box-shadow: 0 4px 12px rgba(0,0,0,0.3); }
             .stSidebar { background: linear-gradient(180deg, #1a435a 0%, #2b2b2b 100%); color: #f8f8f8; }
              .stSidebar label { color: #f8f8f8; }
              .stSidebar .stTextInput > div > div > input,
              .stSidebar .stSelectbox > div > div > div > input[type="text"],
              .stSidebar .stNumberInput > div > div > input { background-color: #3a3a3a; color: #f8f8f8; border-color: #555; }
              .stSidebar .stTextInput > div > div > input:focus,
              .stSidebar .stSelectbox > div > div > div > input[type="text"]:focus,
              .stSidebar .stNumberInput > div > div > input:focus { border-color: #43cea2; box-shadow: 0 0 5px rgba(67, 206, 162, 0.5); }
              .stSidebar .stRadio > label > div:first-child { color: #f8f8f8; }
              .stExpander { border-color: #555; box-shadow: 0 2px 8px rgba(0,0,0,0.2); }
               .stExpander div[data-baseweb="accordion-header"] { background-color: #3a3a3a; border-bottom-color: #555; color: #f8f8f8; }
               hr { border-top: 2px dashed #555; }
        }

        h1, h2, h3, h4, h5, h6 { color: #185a9d; font-weight: 700; }
         .stMarkdown h1 { color: #185a9d !important; }

        .modern-card { background: linear-gradient(135deg, #43cea2 0%, #185a9d 100%); color: white; border-radius: 18px; padding: 20px; margin: 15px 0; box-shadow: 0 6px 20px rgba(30,60,114,0.1); text-align: center; transition: transform 0.3s ease-in-out, box-shadow 0.3s ease-in-out; overflow: hidden; }
        .modern-card:hover { transform: translateY(-5px) scale(1.02); box-shadow: 0 10px 30px rgba(30,60,114,0.15); }
        .modern-card div:first-child { font-size: 1em; opacity: 0.9; margin-bottom: 8px; }
         .modern-card div:last-child { font-size: 2em; font-weight: 900; }

        .sidebar-logo { display: flex; align-items: center; justify-content: center; margin-bottom: 2rem; padding-top: 1rem; }
        .sidebar-logo img { width: 100px; height: 100px; border-radius: 20px; box-shadow: 0 4px 12px rgba(30,60,114,0.15); }

        .main-logo { width: 55px; height: 55px; border-radius: 15px; margin-left: 15px; vertical-align: middle; box-shadow: 0 2px 8px rgba(30,60,114,0.1); }

        .stTabs [data-baseweb="tab-list"] { gap: 20px; }
        .stTabs [data-baseweb="tab-list"] button { background-color: #f0f2f6; padding: 10px 15px; border-radius: 8px 8px 0 0; border-bottom: 2px solid transparent; transition: all 0.3s ease; font-weight: 700; color: #555; }
         .stTabs [data-baseweb="tab-list"] button:hover { background-color: #e2e6eb; color: #185a9d; border-bottom-color: #185a9d; }
        .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] { background-color: #ffffff; border-bottom-color: #43cea2; color: #185a9d; box-shadow: 0 -2px 8px rgba(30,60,114,0.05); }
         .stTabs [data-baseweb="tab-panel"] { padding: 20px 5px; }

        .status-badge { display: inline-block; padding: 0.3em 0.6em; font-size: 0.8em; font-weight: bold; line-height: 1.2; text-align: center; white-space: nowrap; vertical-align: middle; border-radius: 0.35rem; color: #fff; margin: 2px; }
        .status-positive { background-color: #28a745; }
        .status-negative { background-color: #dc3545; }
        .status-neutral { background-color: #6c757d; color: #fff; }
        .status-nodata { background-color: #ffc107; color: #212529; }

        table { border-collapse: collapse; width: 100%; margin: 20px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.05); border-radius: 8px; overflow: hidden; }
        th, td { text-align: center; padding: 10px; border-bottom: 1px solid #ddd; vertical-align: middle !important; }
        th { background-color: #185a9d; color: white; font-weight: 700; }
        tr:nth-child(even) { background-color: #f2f2f2; }

        .stAlert { border-radius: 8px; margin: 15px 0; padding: 15px; display: flex; align-items: flex-start; }
        .stAlert > div:first-child { font-size: 1.5em; margin-right: 15px; flex-shrink: 0; }
         .stAlert > div:last-child { font-size: 1em; line-height: 1.5; flex-grow: 1; }
          .stAlert a { color: #185a9d; }

         .js-plotly-plot { border-radius: 8px; overflow: hidden; margin: 20px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.05); }

         .stSidebar { background: linear-gradient(180deg, #cce7ff 0%, #e0f7fa 100%); color: #333; padding: 20px; }

          .stSidebar h2 { color: #185a9d; }
          .stSidebar .stRadio > label > div:first-child { padding-right: 10px; }
           .stSidebar .stSelectbox > label { font-weight: 700; }
           .stSidebar .stSlider > label { font-weight: 700; }

         .stTextInput > div > div > input,
         .stSelectbox > div > div > div > input[type="text"],
         .stNumberInput > div > div > input { border-radius: 8px; border: 1px solid #ccc; padding: 8px 12px; transition: border-color 0.3s; }
          .stTextInput > div > div > input:focus,
          .stSelectbox > div > div > div > input[type="text"]:focus,
          .stNumberInput > div > div > input:focus { border-color: #43cea2; outline: none; box-shadow: 0 0 5px rgba(67, 206, 162, 0.5); }

         .stButton > button { background-color: #185a9d; color: white; border-radius: 8px; padding: 10px 20px; font-size: 1em; transition: background-color 0.3s, transform 0.1s; border: none; cursor: pointer; }
          .stButton > button:hover { background-color: #0f3c66; transform: translateY(-1px); }
           .stButton > button:active { transform: translateY(0); background-color: #0a2840; }

          .stDownloadButton > button { background-color: #43cea2; }
           .stDownloadButton > button:hover { background-color: #31a380; }
            .stDownloadButton > button:active { background-color: #247a60; }

         .stExpander { border-radius: 8px; border: 1px solid #ddd; box-shadow: 0 2px 8px rgba(0,0,0,0.03); margin: 15px 0; }
           .stExpander div[data-baseweb="accordion-header"] { background-color: #f8f8f8; border-bottom: 1px solid #ddd; border-top-left-radius: 8px; border-top-right-radius: 8px; padding: 10px 15px; font-weight: 700; color: #333; }
            .stExpander div[data-baseweb="accordion-panel"] { padding: 15px; }

           hr { border-top: 2px dashed #ccc; margin: 30px 0; }

            [data-testid="stMetricValue"] { text-align: center; width: 100%; display: block; }
             [data-testid="stMetricLabel"] { text-align: center; width: 100%; display: block; }
    </style>
""", unsafe_allow_html=True)


def status_badge(status: str) -> str:
    """Returns HTML for a status badge with color."""
    if status is None or pd.isna(status):
        return f'<span class="status-badge status-nodata">N/A</span>'

    status_lower = str(status).lower()
    if "Ø¨Ù‡Ø¨ÙˆØ¯" in status_lower or "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª" in status_lower or "Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª" in status_lower:
        badge_class = "status-positive"
    elif any(term in status_lower for term in ["ØªÙ†Ø´", "Ú©Ø§Ù‡Ø´", "Ø¨Ø¯ØªØ±", "Ù†ÛŒØ§Ø²"]):
        badge_class = "status-negative"
    elif any(term in status_lower for term in ["Ø«Ø§Ø¨Øª", "Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª", "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ†", "Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡", "Ù†Ø§Ù…Ø´Ø®Øµ"]):
        badge_class = "status-neutral"
    elif "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" in status_lower:
        badge_class = "status-nodata"
    else:
        badge_class = "status-neutral"

    return f'<span class="status-badge {badge_class}">{status}</span>'

def modern_metric_card(title: str, value: str, icon: str, color: str) -> str:
    """Returns a modern styled HTML card for displaying a metric."""
    return f'''
    <div class="modern-card" style="background: linear-gradient(135deg, {color} 0%, #185a9d 100%);">
        <div>{title} <i class="fa {icon}"></i></div>
        <div>{value}</div>
    </div>
    '''

# Sidebar Logo
st.sidebar.markdown(
    """
    <div class='sidebar-logo'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' alt='Ù„ÙˆÚ¯Ùˆ Ø³Ø§Ù…Ø§Ù†Ù‡' />
    </div>
    """,
    unsafe_allow_html=True
)

# Main Header with Logo
st.markdown(
    """
    <div style='display: flex; align-items: center; gap: 16px; margin-bottom: 0.5rem;'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' class='main-logo' alt='Ù„ÙˆÚ¯Ùˆ' />
        <h1 style='font-family: Vazirmatn, sans-serif; color: #185a9d; margin: 0;'>Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±</h1>
    </div>
    <h4 style='color: #43cea2; margin-top: 0;'>Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§</h4>
    """,
    unsafe_allow_html=True
)

APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±"
APP_SUBTITLE = "Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

FARM_DATA_CSV_PATH = 'merged_farm_data_renamed (1).csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'
ANALYSIS_CSV_PATH = 'Ù…Ø­Ø§Ø³Ø¨Ø§Øª 2.csv'


@st.cache_resource(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine...")
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        credentials = None
        auth_info = None
        if "gee_auth_json" in st.secrets:
             try:
                auth_info = json.loads(st.secrets["gee_auth_json"])
                credentials = ee.ServiceAccountCredentials(auth_info['client_email'], None, private_key_id=auth_info['private_key_id'], private_key=auth_info['private_key'], token_uri=auth_info['token_uri'])
                print("GEE Initialized Successfully using Streamlit Secrets JSON.")
             except Exception as e:
                 st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Secrets Ø¨Ø±Ø§ÛŒ GEE: {e}. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ø­Ù„ÛŒ...")
                 credentials = None

        if credentials is None and os.path.exists(SERVICE_ACCOUNT_FILE):
             try:
                credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
                print("GEE Initialized Successfully using Service Account File.")
             except Exception as e:
                 st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ Service Account Ù…Ø­Ù„ÛŒ '{SERVICE_ACCOUNT_FILE}': {e}")
                 return None
        elif credentials is None:
             st.error("âŒ Ù‡ÛŒÚ† Ø§Ø¹ØªØ¨Ø§Ø±Ù†Ø§Ù…Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Google Earth Engine ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù†Ù‡ Ø¯Ø± Secrets Ùˆ Ù†Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª ÙØ§ÛŒÙ„ Ù…Ø­Ù„ÛŒ).")
             st.info("Ù„Ø·ÙØ§Ù‹ Streamlit Secret 'gee_auth_json' ÛŒØ§ ÙØ§ÛŒÙ„ Service Account Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.")
             return None

        project_id = None
        if hasattr(credentials, 'project_id'):
            project_id = credentials.project_id
        elif isinstance(auth_info, dict) and 'project_id' in auth_info:
             project_id = auth_info['project_id']

        ee.Initialize(credentials=credentials, project=project_id, opt_url='https://earthengine-highvolume.googleapis.com')
        print(f"GEE Initialized Successfully. Project: {project_id or 'Default'}")
        return True

    except ee.EEException as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.error(traceback.format_exc())
        return None


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...", persist="disk")
def load_farm_data_from_csv(_transformer, csv_path=FARM_DATA_CSV_PATH):
    """Loads farm data from the specified CSV file and processes coordinates."""
    if _transformer is None:
         st.error("âŒ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ù†Ø¯Ù‡ Ù…Ø®ØªØµØ§Øª Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
         return pd.DataFrame()

    try:
        df = None
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path, encoding='utf-8')
            print(f"Loaded Farm data from local CSV: {csv_path}")
        else:
            github_raw_url = f'https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/{os.path.basename(csv_path)}'
            try:
                response = requests.get(github_raw_url)
                response.raise_for_status()
                df = pd.read_csv(BytesIO(response.content), encoding='utf-8')
                print(f"Loaded Farm data from URL: {github_raw_url}")
            except requests.exceptions.RequestException as e:
                 st.error(f"âŒ ÙØ§ÛŒÙ„ '{os.path.basename(csv_path)}' Ø¯Ø± Ù…Ø³ÛŒØ± Ù…Ø­Ù„ÛŒ ÛŒØ§ Ø§Ø² URL Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ '{github_raw_url}' ÛŒØ§ÙØª Ù†Ø´Ø¯: {e}")
                 return pd.DataFrame()
            except Exception as e:
                 st.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ CSV Ù…Ø²Ø§Ø±Ø¹ Ø§Ø² URL: {e}")
                 return pd.DataFrame()

        if df is None or df.empty:
             st.error("âŒ ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª ÛŒØ§ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù†Ø´Ø¯.")
             return pd.DataFrame()

        df.columns = df.columns.str.strip().str.replace('\ufeff', '')

        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø±ÙˆØ²', 'lat1', 'lon1', 'lat2', 'lon2', 'lat3', 'lon3', 'lat4', 'lon4']
        if not all(col in df.columns for col in required_cols):
            missing_cols = [col for col in required_cols if col not in df.columns]
            st.error(f"âŒ ÙØ§ÛŒÙ„ CSV Ù…Ø²Ø§Ø±Ø¹ ÙØ§Ù‚Ø¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª: {', '.join(missing_cols)}")
            return pd.DataFrame()

        df['wgs84_centroid_lon'] = np.nan
        df['wgs84_centroid_lat'] = np.nan
        df['ee_geometry'] = None
        df['wgs84_polygon_coords'] = None

        processed_records = []
        skipped_farms = []

        for index, row in df.iterrows():
            farm_name = row.get('Ù…Ø²Ø±Ø¹Ù‡', f'Ù…Ø²Ø±Ø¹Ù‡ Ù†Ø§Ø´Ù†Ø§Ø³ {index+1}')
            try:
                points_utm = []
                valid_points = True
                for i in range(1, 5):
                    lat_col, lon_col = f'lat{i}', f'lon{i}'
                    if pd.notna(row.get(lat_col)) and pd.notna(row.get(lon_col)):
                        try:
                            points_utm.append((float(row[lon_col]), float(row[lat_col])))
                        except (ValueError, TypeError): valid_points = False; break
                    else: valid_points = False; break

                if not valid_points or len(points_utm) < 4:
                    skipped_farms.append(f"'{farm_name}': Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±/Ù†Ø§Ù‚Øµ.")
                    continue

                points_wgs84 = []
                try:
                    for easting, northing in points_utm:
                         points_wgs84.append(_transformer.transform(easting, northing))
                except pyproj.exceptions.ProjError as te:
                     skipped_farms.append(f"'{farm_name}': Ø®Ø·Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…Ø®ØªØµØ§Øª {te}")
                     continue
                except Exception as e:
                     skipped_farms.append(f"'{farm_name}': Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ ØªØ¨Ø¯ÛŒÙ„ Ù…Ø®ØªØµØ§Øª: {e}")
                     continue

                if not points_wgs84: continue

                polygon_coords_wgs84 = points_wgs84 + [points_wgs84[0]] if points_wgs84[-1] != points_wgs84[0] else points_wgs84
                if len(polygon_coords_wgs84) < 4:
                    skipped_farms.append(f"'{farm_name}': Ù†Ù‚Ø§Ø· WGS84 Ù†Ø§Ú©Ø§ÙÛŒ.")
                    continue

                try:
                    shapely_polygon = Polygon(polygon_coords_wgs84)
                    if not shapely_polygon.is_valid:
                        fixed_polygon = shapely_polygon.buffer(0)
                        if not fixed_polygon.is_valid or fixed_polygon.is_empty or not isinstance(fixed_polygon, Polygon):
                             skipped_farms.append(f"'{farm_name}': Ù¾Ù„ÛŒâ€ŒÚ¯ÙˆÙ† WGS84 Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ùˆ ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ø§ØµÙ„Ø§Ø­.")
                             continue
                        shapely_polygon = fixed_polygon

                    gee_coords_list = [list(coord) for coord in shapely_polygon.exterior.coords]
                    if not gee_coords_list: continue

                    ee_polygon = ee.Geometry.Polygon(gee_coords_list, proj=TARGET_CRS, evenOdd=False)
                    centroid_ee = ee_polygon.centroid(maxError=1)
                    centroid_coords_wgs84 = centroid_ee.getInfo()['coordinates']

                    processed_row = row.to_dict()
                    processed_row['wgs84_centroid_lon'] = centroid_coords_wgs84[0]
                    processed_row['wgs84_centroid_lat'] = centroid_coords_wgs84[1]
                    processed_row['ee_geometry'] = ee_polygon
                    processed_row['wgs84_polygon_coords'] = gee_coords_list
                    processed_records.append(processed_row)

                except ee.EEException as ee_geom_e: skipped_farms.append(f"'{farm_name}': Ø®Ø·Ø§ÛŒ Ù‡Ù†Ø¯Ø³Ù‡ GEE: {ee_geom_e}")
                except Exception as e: skipped_farms.append(f"'{farm_name}': Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù†Ø¯Ø³Ù‡: {e}")

            except Exception as e: skipped_farms.append(f"'{farm_name}': Ø®Ø·Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø±Ø¯ÛŒÙ: {e}")

        processed_df = pd.DataFrame(processed_records)

        if skipped_farms:
            st.warning("âš ï¸ Ø¨Ø±Ø®ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù†Ø¯ (ØªØ§ Û±Û° Ø®Ø·Ø§):")
            unique_skipped = list(set(skipped_farms))
            for msg in unique_skipped[:10]: st.warning(f"- {msg}")
            if len(unique_skipped) > 10: st.warning(f"... Ùˆ {len(unique_skipped) - 10} Ù…ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ø±.")

        if processed_df.empty:
            st.error("âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ CSV Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return pd.DataFrame()

        for col in ['Ø±ÙˆØ²', 'Ú¯Ø±ÙˆÙ‡', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†']:
            if col in processed_df.columns:
                processed_df[col] = processed_df[col].fillna('Ù†Ø§Ù…Ø´Ø®Øµ').astype(str).str.replace(r'\s+', ' ', regex=True).str.strip()
                processed_df[col] = processed_df[col].replace(['nan', '', 'NaN'], 'Ù†Ø§Ù…Ø´Ø®Øµ')
            else: processed_df[col] = 'Ù†Ø§Ù…Ø´Ø®Øµ'

        if 'Ù…Ø³Ø§Ø­Øª' in processed_df.columns:
             processed_df['Ù…Ø³Ø§Ø­Øª'] = pd.to_numeric(processed_df['Ù…Ø³Ø§Ø­Øª'], errors='coerce').fillna(0.0)
        else: processed_df['Ù…Ø³Ø§Ø­Øª'] = 0.0

        return processed_df
    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{os.path.basename(csv_path)}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ/Ù¾Ø±Ø¯Ø§Ø²Ø´ CSV Ù…Ø²Ø§Ø±Ø¹: {e}")
        st.error(traceback.format_exc())
        return pd.DataFrame()


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª...", persist="disk")
def load_analysis_data(csv_path=ANALYSIS_CSV_PATH):
    """Loads and preprocesses data from the analysis CSV file."""
    try:
        lines = None
        if os.path.exists(csv_path):
            with open(csv_path, 'r', encoding='utf-8') as f: lines = f.readlines()
            print(f"Loaded Analysis CSV from: {csv_path}")
        else:
             github_raw_url = f'https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/{os.path.basename(csv_path)}'
             try:
                 response = requests.get(github_raw_url); response.raise_for_status()
                 lines = response.text.splitlines()
                 print(f"Loaded Analysis CSV from URL: {github_raw_url}")
             except Exception as e:
                 st.error(f"âŒ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª '{os.path.basename(csv_path)}' ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯: {e}")
                 return None, None

        if lines is None: return None, None

        header_patterns = ['Ø§Ø¯Ø§Ø±Ù‡,Ø³Ù†,', 'ØªÙˆÙ„ÛŒØ¯,Ø³Ù†,']
        headers_indices = [i for i, line in enumerate(lines)
                           if any(pat in line.strip().lstrip('\ufeff').replace(" ","") for pat in header_patterns)]

        if not headers_indices:
            st.error(f"âŒ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ø± '{os.path.basename(csv_path)}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return None, None

        s1_start, s1_end = headers_indices[0], len(lines)
        s2_start, s2_end = -1, len(lines)
        if len(headers_indices) > 1: s1_end, s2_start = headers_indices[1], headers_indices[1]
        for i in range(s1_start + 1, s1_end):
            if "Grand Total" in lines[i] or len(lines[i].strip()) < 5: s1_end = i; break
        if s2_start != -1:
            for i in range(s2_start + 1, s2_end):
                 if "Grand Total" in lines[i] or len(lines[i].strip()) < 5: s2_end = i; break

        df_area, df_prod = pd.DataFrame(), pd.DataFrame()
        try:
            if lines[s1_start:s1_end]: df_area = pd.read_csv(BytesIO("\n".join(lines[s1_start:s1_end]).encode('utf-8')))
        except Exception as e: st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ø®Ø´ Ù…Ø³Ø§Ø­Øª: {e}")
        if s2_start != -1:
             try:
                  if lines[s2_start:s2_end]: df_prod = pd.read_csv(BytesIO("\n".join(lines[s2_start:s2_end]).encode('utf-8')))
             except Exception as e: st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ø®Ø´ ØªÙˆÙ„ÛŒØ¯: {e}")

        def preprocess_df(df, section_name):
            if df is None or df.empty: return None
            df.columns = df.columns.str.strip().str.replace('\ufeff', '')
            if df.columns.tolist() and df.columns[0] not in ['Ø§Ø¯Ø§Ø±Ù‡', 'ØªÙˆÙ„ÛŒØ¯'] and 'Ø§Ø¯Ø§Ø±Ù‡' not in df.columns:
                 df.rename(columns={df.columns[0]: 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)
            if not all(col in df.columns for col in ['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†']):
                 st.warning(f"âš ï¸ Ø³ØªÙˆÙ† Ø¶Ø±ÙˆØ±ÛŒ 'Ø§Ø¯Ø§Ø±Ù‡' ÛŒØ§ 'Ø³Ù†' Ø¯Ø± Ø¨Ø®Ø´ '{section_name}' Ù†ÛŒØ³Øª."); return None
            df['Ø§Ø¯Ø§Ø±Ù‡'] = df['Ø§Ø¯Ø§Ø±Ù‡'].ffill()
            df = df[~df['Ø³Ù†'].astype(str).str.contains('total', case=False, na=False)].copy()
            df['Ø§Ø¯Ø§Ø±Ù‡_num'] = pd.to_numeric(df['Ø§Ø¯Ø§Ø±Ù‡'], errors='coerce')
            df = df.dropna(subset=['Ø§Ø¯Ø§Ø±Ù‡_num']).copy()
            df['Ø§Ø¯Ø§Ø±Ù‡'] = df['Ø§Ø¯Ø§Ø±Ù‡_num'].astype('Int64')
            df = df.drop(columns=['Ø§Ø¯Ø§Ø±Ù‡_num'])
            df = df[~df['Ø§Ø¯Ø§Ø±Ù‡'].isin([99, 999, 0])] # Filter totals
            if df.empty: return None
            value_cols = [col for col in df.columns if col not in ['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†', 'Ø¯Ø±ØµØ¯', 'Grand Total']]
            for col in value_cols: df[col] = pd.to_numeric(df[col], errors='coerce')
            df = df.dropna(axis=1, how='all').drop(columns=['Grand Total', 'Ø¯Ø±ØµØ¯'], errors='ignore')
            if 'Ø§Ø¯Ø§Ø±Ù‡' in df.columns and 'Ø³Ù†' in df.columns:
                try:
                    df['Ø³Ù†'] = df['Ø³Ù†'].astype(str).str.strip()
                    df = df.set_index(['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†']).copy()
                except ValueError as e: st.warning(f"âš ï¸ Ø®Ø·Ø§ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¯Ø± '{section_name}': {e}")
            return df

        df_area_processed = preprocess_df(df_area, "Ù…Ø³Ø§Ø­Øª")
        df_prod_processed = preprocess_df(df_prod, "ØªÙˆÙ„ÛŒØ¯")
        if df_area_processed is None and df_prod_processed is None:
             st.warning("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯.")
        return df_area_processed, df_prod_processed

    except FileNotFoundError: st.error(f"âŒ ÙØ§ÛŒÙ„ '{os.path.basename(csv_path)}' ÛŒØ§ÙØª Ù†Ø´Ø¯."); return None, None
    except Exception as e: st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ/Ù¾Ø±Ø¯Ø§Ø²Ø´ CSV Ù…Ø­Ø§Ø³Ø¨Ø§Øª: {e}"); st.error(traceback.format_exc()); return None, None


# --- Initialization ---
gee_initialized = initialize_gee()
farm_data_df = pd.DataFrame()
if transformer is not None and gee_initialized:
    farm_data_df = load_farm_data_from_csv(transformer, FARM_DATA_CSV_PATH)
elif transformer is None:
     st.error("âŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ù…Ù…Ú©Ù† Ù†ÛŒØ³Øª (Ø®Ø·Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ù†Ø¯Ù‡ Ù…Ø®ØªØµØ§Øª).")
analysis_area_df, analysis_prod_df = load_analysis_data(ANALYSIS_CSV_PATH)


@st.cache_resource(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
def configure_gemini(api_key):
    """Configures the Gemini API client."""
    if not api_key: st.error("âŒ Ú©Ù„ÛŒØ¯ API Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."); return None
    try:
        genai.configure(api_key=api_key)
        safety_settings = [{"category": c, "threshold": "BLOCK_NONE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        model = genai.GenerativeModel('gemini-1.5-flash-latest', safety_settings=safety_settings)
        print("Using Gemini Model: gemini-1.5-flash-latest")
        return model
    except Exception as e1:
        print(f"Failed loading latest flash model: {e1}. Falling back.")
        try:
            model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings)
            print("Using Gemini Model: gemini-1.5-flash")
            return model
        except Exception as e2:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… Ù…Ø¯Ù„ Gemini: {e2}")
            return None

gemini_model = None
if gee_initialized:
    gemini_model = configure_gemini(GEMINI_API_KEY_HARDCODED)
    if gemini_model is None: st.warning("âš ï¸ Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

# ==============================================================================
# Sidebar Filters
# ==============================================================================
st.sidebar.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

selected_day = None
if farm_data_df is not None and not farm_data_df.empty and 'Ø±ÙˆØ²' in farm_data_df.columns:
    valid_days = sorted([d for d in farm_data_df['Ø±ÙˆØ²'].dropna().unique() if d != 'Ù†Ø§Ù…Ø´Ø®Øµ'])
    if valid_days:
        selected_day = st.sidebar.selectbox("ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡:", options=valid_days, index=0)
    else: st.sidebar.warning("âš ï¸ 'Ø±ÙˆØ² Ù‡ÙØªÙ‡' Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
elif farm_data_df is None or farm_data_df.empty: st.sidebar.info("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡.")
else: st.sidebar.warning("âš ï¸ Ø³ØªÙˆÙ† 'Ø±ÙˆØ²' Ø¯Ø± Ø¯Ø§Ø¯Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ³Øª.")

filtered_farms_df = pd.DataFrame()
if selected_day and farm_data_df is not None and not farm_data_df.empty:
    filtered_farms_df = farm_data_df[farm_data_df['Ø±ÙˆØ²'] == selected_day].reset_index(drop=True)

selected_farm_name = "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"
if not filtered_farms_df.empty:
    if 'Ù…Ø²Ø±Ø¹Ù‡' in filtered_farms_df.columns:
        available_farms = sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].dropna().unique())
        farm_options = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + available_farms
        selected_farm_name = st.sidebar.selectbox("ğŸŒ¾ Ù…Ø²Ø±Ø¹Ù‡:", options=farm_options, index=0)
    else: st.sidebar.warning("âš ï¸ Ø³ØªÙˆÙ† 'Ù…Ø²Ø±Ø¹Ù‡' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
elif selected_day: st.sidebar.info(f"â„¹ï¸ Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' Ù†ÛŒØ³Øª.")

index_options = {
    "NDVI": "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ", "EVI": "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡", "NDMI": "Ø±Ø·ÙˆØ¨Øª",
    "LAI": "Ø³Ø·Ø­ Ø¨Ø±Ú¯", "MSI": "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ", "CVI": "Ú©Ù„Ø±ÙˆÙÛŒÙ„", "SAVI": "Ù¾ÙˆØ´Ø´ (Ø®Ø§Ú©)"}
selected_index = st.sidebar.selectbox(
    "ğŸ“ˆ Ø´Ø§Ø®Øµ:", options=list(index_options.keys()),
    format_func=lambda x: f"{x} ({index_options[x]})", index=0)

today = datetime.date.today()
start_date_current_str, end_date_current_str = None, None
start_date_previous_str, end_date_previous_str = None, None
if selected_day:
    try:
        persian_to_weekday = {"Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1, "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4}
        target_weekday = persian_to_weekday[selected_day.strip()]
        days_ago = (today.weekday() - target_weekday + 7) % 7
        end_date_current = today - datetime.timedelta(days=days_ago)
        start_date_current = end_date_current - datetime.timedelta(days=6)
        end_date_previous = start_date_current - datetime.timedelta(days=1)
        start_date_previous = end_date_previous - datetime.timedelta(days=6)
        start_date_current_str = start_date_current.strftime('%Y-%m-%d')
        end_date_current_str = end_date_current.strftime('%Y-%m-%d')
        start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
        end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')
        st.sidebar.caption(f"Ø¬Ø§Ø±ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
        st.sidebar.caption(f"Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")
    except Exception as e: st.sidebar.error(f"Ø®Ø·Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡: {e}")

st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ â¤ï¸")

# ==============================================================================
# GEE Processing Functions
# ==============================================================================

def maskS2clouds(image):
    """Masks clouds and shadows in Sentinel-2 SR images."""
    qa = image.select('QA60'); cloudBitMask = 1 << 10; cirrusBitMask = 1 << 11
    mask_qa = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))
    scl = image.select('SCL'); masked_classes_scl = [1, 3, 8, 9, 10, 11]
    mask_scl = scl.remap(masked_classes_scl, [0]*len(masked_classes_scl), 1).eq(1)
    final_mask = mask_qa.And(mask_scl)
    return image.addBands(image.select('B.*').multiply(0.0001), None, True).updateMask(final_mask)

def add_indices(image):
    """Calculates various vegetation indices using ee.Image.expression."""
    epsilon = 1e-9
    common_params = {
        'NIR': image.select('B8'), 'RED': image.select('B4'), 'BLUE': image.select('B2'),
        'GREEN': image.select('B3'), 'SWIR1': image.select('B11'), 'epsilon': epsilon}
    ndvi = image.expression('(NIR - RED) / (NIR + RED + epsilon)', common_params).rename('NDVI')
    evi = image.expression('2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1 + epsilon)', common_params).rename('EVI')
    ndmi = image.expression('(NIR - SWIR1) / (NIR + SWIR1 + epsilon)', common_params).rename('NDMI')
    savi = image.expression('((NIR - RED) / (NIR + RED + 0.5 + epsilon)) * (1.5)', common_params).rename('SAVI')
    msi = image.expression('SWIR1 / (NIR + epsilon)', common_params).rename('MSI')
    lai = evi.multiply(3.618).subtract(0.118).rename('LAI'); lai = lai.updateMask(lai.gte(0))
    cvi = image.expression('(NIR / (GREEN + epsilon)) * (RED / (GREEN + epsilon))', common_params).rename('CVI')
    return image.addBands([ndvi, evi, ndmi, msi, lai, cvi, savi])


@st.cache_data(show_spinner=False, persist="disk")#, ttl=3600)
def get_processed_image(_geometry, start_date, end_date, index_name):
    """Gets cloud-masked, index-calculated Sentinel-2 median composite."""
    if not gee_initialized: return None, "GEE Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø´Ø¯Ù‡."
    if _geometry is None: return None, "Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±."

    fallback_days, error_msg, image = 15, None, None # Shortened fallback

    def filter_and_process(s_date, e_date):
        try:
            s2_sr_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
                .filterBounds(_geometry).filterDate(s_date, e_date).map(maskS2clouds)
            count = s2_sr_col.size().getInfo()
            if count == 0: return None, f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± S2 Ø¯Ø± {s_date}-{e_date} ÛŒØ§ÙØª Ù†Ø´Ø¯."

            median_image = s2_sr_col.map(add_indices).median()
            if index_name not in median_image.bandNames().getInfo():
                return None, f"Ø´Ø§Ø®Øµ '{index_name}' Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯ (Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {', '.join(median_image.bandNames().getInfo())})."

            output_image = median_image.select(index_name)
            data_check = output_image.reduceRegion(ee.Reducer.count(), _geometry, 30, bestEffort=True).get(index_name).getInfo()
            if data_check is None or data_check == 0:
                return None, f"ØªØµÙˆÛŒØ± '{index_name}' Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø±ÙˆÛŒ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ø¯Ø§Ø±Ø¯."
            return output_image, None
        except ee.EEException as e: return None, f"Ø®Ø·Ø§ÛŒ GEE ({s_date}-{e_date}): {e}"
        except Exception as e: return None, f"Ø®Ø·Ø§ÛŒ Python ({s_date}-{e_date}): {e}"

    image, error_msg = filter_and_process(start_date, end_date)
    if image is None and ("Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±" in error_msg or "not found" in error_msg.lower()):
        try:
            fb_end = (datetime.datetime.strptime(end_date, '%Y-%m-%d') + datetime.timedelta(days=fallback_days)).strftime('%Y-%m-%d')
            fb_start = start_date
            st.info(f"â³ ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ ØªÙ„Ø§Ø´ Ø¨Ø§ Ø¨Ø§Ø²Ù‡ Ú¯Ø³ØªØ±Ø¯Ù‡â€ŒØªØ± ØªØ§ {fb_end}...")
            image, fb_error_msg = filter_and_process(fb_start, fb_end)
            if image: error_msg = None; st.info(f"â„¹ï¸ Ø§Ø² Ø¯Ø§Ø¯Ù‡ ØªØ§ {fb_end} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯.")
            else: error_msg = f"Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø§Ù…ÙˆÙÙ‚ ({error_msg}). Ø¨Ø§Ø²Ù‡ Ú¯Ø³ØªØ±Ø¯Ù‡ Ù†ÛŒØ² Ù†Ø§Ù…ÙˆÙÙ‚: {fb_error_msg}"
        except Exception as fb_e: error_msg = f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†: {fb_e}. Ø®Ø·Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡: {error_msg}"

    if image is None and not error_msg: error_msg = f"Ù¾Ø±Ø¯Ø§Ø²Ø´ {start_date}-{end_date} Ù†Ø§Ù…ÙˆÙÙ‚ (Ù†Ø§Ù…Ø´Ø®Øµ)."
    return image, error_msg


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ...", persist="disk", ttl=7200)
def get_index_time_series(_point_geom, index_name, start_date, end_date):
    """Gets time series data for a point geometry."""
    if not gee_initialized: return pd.DataFrame(), "GEE Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø´Ø¯Ù‡."
    if _point_geom is None: return pd.DataFrame(), "Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ù‚Ø·Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±."

    try:
        s2_sr_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
            .filterBounds(_point_geom).filterDate(start_date, end_date) \
            .map(maskS2clouds).map(add_indices).select(index_name)

        def extract_value(image):
            value = image.reduceRegion(ee.Reducer.first(), _point_geom, 10).get(index_name)
            return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd'), index_name: value}) \
                   .set('system:time_start', image.get('system:time_start'))

        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.notNull([index_name]))
        dates_list = ts_features.aggregate_array('date').getInfo()

        if not dates_list:
            orig_count = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(_point_geom).filterDate(start_date, end_date).size().getInfo()
            msg = f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± S2 ÛŒØ§ÙØª Ù†Ø´Ø¯." if orig_count == 0 else f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ '{index_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§ Ø§Ø¨Ø±ÛŒ)."
            return pd.DataFrame(), msg

        values_list = ts_features.aggregate_array(index_name).getInfo()
        ts_df = pd.DataFrame({'date': pd.to_datetime(dates_list), index_name: pd.to_numeric(values_list, errors='coerce')})
        return ts_df.sort_values('date').set_index('date').dropna(subset=[index_name]), None

    except ee.EEException as e: return pd.DataFrame(), f"Ø®Ø·Ø§ÛŒ GEE Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ '{index_name}': {e}"
    except Exception as e: return pd.DataFrame(), f"Ø®Ø·Ø§ÛŒ Python Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ '{index_name}': {e}"


@st.cache_data(show_spinner=False, persist="disk", ttl=7200)
def get_farm_needs_data(_farm_geometry, start_curr, end_curr, start_prev, end_prev):
    """Gets mean NDVI, NDMI, EVI, SAVI for current and previous periods."""
    if not gee_initialized: return {'error': "GEE Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø´Ø¯Ù‡."}
    if _farm_geometry is None: return {'error': "Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±."}

    results = {f'{idx}_{p}': np.nan for idx in ['NDVI', 'NDMI', 'EVI', 'SAVI'] for p in ['curr', 'prev']}
    results['error'] = None
    indices_to_get = ['NDVI', 'NDMI', 'EVI', 'SAVI']

    def get_means(start, end):
        period_vals, err_msg = {idx: np.nan for idx in indices_to_get}, None
        img_found = False
        try:
            s2_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
                .filterBounds(_farm_geometry).filterDate(start, end).map(maskS2clouds)
            count = s2_col.size().getInfo()
            if count == 0: # Try fallback
                fb_days = 20; fb_end = (datetime.datetime.strptime(end,'%Y-%m-%d') + datetime.timedelta(days=fb_days)).strftime('%Y-%m-%d')
                s2_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(_farm_geometry).filterDate(start, fb_end).map(maskS2clouds)
                count = s2_col.size().getInfo()
                if count == 0: return period_vals, f"ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± {start}-{end} (ÛŒØ§ Ø¨Ø§Ø²Ù‡ Ú¯Ø³ØªØ±Ø¯Ù‡) ÛŒØ§ÙØª Ù†Ø´Ø¯", False

            img_found = True
            median_image = s2_col.map(add_indices).median().select(indices_to_get)
            mean_stats = median_image.reduceRegion(ee.Reducer.mean(), _farm_geometry, 10, bestEffort=True, maxPixels=1e8).getInfo()
            for index in indices_to_get:
                val = mean_stats.get(index)
                if val is not None: period_vals[index] = float(val)
            return period_vals, None, img_found
        except ee.EEException as e: err_msg = f"Ø®Ø·Ø§ÛŒ GEE ({start}-{end}): {e}"; return period_vals, err_msg, img_found
        except Exception as e: err_msg = f"Ø®Ø·Ø§ÛŒ Python ({start}-{end}): {e}"; return period_vals, err_msg, img_found

    curr_values, err_curr, img_curr = get_means(start_curr, end_curr)
    results.update({f'{idx}_curr': curr_values.get(idx, np.nan) for idx in indices_to_get})
    if err_curr: results['error'] = f"Ø¬Ø§Ø±ÛŒ: {err_curr}"

    prev_values, err_prev, img_prev = get_means(start_prev, end_prev)
    results.update({f'{idx}_prev': prev_values.get(idx, np.nan) for idx in indices_to_get})
    if err_prev: results['error'] = (results['error'] + f"\nÙ‚Ø¨Ù„ÛŒ: {err_prev}") if results['error'] else f"Ù‚Ø¨Ù„ÛŒ: {err_prev}"

    if not img_curr and not img_prev and not results['error']: results['error'] = "ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ù‡ÛŒÚ† Ø¨Ø§Ø²Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
    elif pd.isna(results['NDVI_curr']) and pd.isna(results['NDMI_curr']) and pd.isna(results['NDVI_prev']) and pd.isna(results['NDMI_prev']) and not results['error']:
          results['error'] = " Ù…Ù‚Ø§Ø¯ÛŒØ± NDVI/NDMI Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ùˆ Ø¨Ø§Ø²Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯."

    return results


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ AI...", persist="disk", ttl=3600)
def get_ai_needs_analysis(_model, farm_name, index_data, recommendations):
    """Generates AI analysis for the farm's condition related to needs."""
    if _model is None: return "Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    data_str_parts = []
    for idx in ['NDVI', 'NDMI', 'EVI', 'SAVI']:
         curr_val, prev_val = index_data.get(f'{idx}_curr'), index_data.get(f'{idx}_prev')
         curr_s, prev_s = f"{curr_val:.3f}" if pd.notna(curr_val) else "N/A", f"{prev_val:.3f}" if pd.notna(prev_val) else "N/A"
         line = f"- {idx}: "
         if curr_s != "N/A":
             line += f"Ø¬Ø§Ø±ÛŒ: {curr_s}"
             if prev_s != "N/A":
                 line += f" (Ù‚Ø¨Ù„ÛŒ: {prev_s}"
                 if pd.notna(curr_val) and pd.notna(prev_val):
                     change, pct_change = curr_val - prev_val, np.nan
                     if prev_val != 0: pct_change = (change / abs(prev_val)) * 100
                     line += f", ØªØºÛŒÛŒØ±: {change:.3f}" + (f" [{pct_change:+.1f}%])" if pd.notna(pct_change) else ")")
                     status = determine_status({f'{idx} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': curr_val, f'{idx} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': prev_val}, idx)
                     line += f" - ÙˆØ¶Ø¹ÛŒØª: {status}"
                 else: line += ")"
             else: line += " (Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ Ù†ÛŒØ³Øª)"
             data_str_parts.append(line)
         elif prev_s != "N/A": data_str_parts.append(f"- {idx}: Ù‚Ø¨Ù„ÛŒ: {prev_s} (Ø¯Ø§Ø¯Ù‡ Ø¬Ø§Ø±ÛŒ Ù†ÛŒØ³Øª)")

    data_str = "\n".join(data_str_parts) if data_str_parts else "Ø¯Ø§Ø¯Ù‡ Ø´Ø§Ø®Øµ Ø¹Ø¯Ø¯ÛŒ Ù†ÛŒØ³Øª."
    recommendations_str = "\n".join([f"- {rec}" for rec in recommendations]) if recommendations else 'ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ Ù†ÛŒØ³Øª.'

    prompt = f"""
    Ø´Ù…Ø§ Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}' Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.
    Ø´Ø§Ù…Ù„: 1. ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ (Ø³Ù„Ø§Ù…Øª/Ø±Ø·ÙˆØ¨Øª). 2. Ø±ÙˆÙ†Ø¯ (Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù‚Ø¨Ù„). 3. Ù†ÛŒØ§Ø²Ù‡Ø§ (Ø¢Ø¨ÛŒØ§Ø±ÛŒ/Ú©ÙˆØ¯/Ø¢ÙØ§ØªØŸ) Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡. 4. ØªÙˆØµÛŒÙ‡ Ú©Ù„ÛŒ (Ø¨Ø§Ø²Ø¯ÛŒØ¯/Ø¨Ø±Ù†Ø§Ù…Ù‡). 5. Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø§Ø¯Ù‡ (Ø§Ú¯Ø± Ù‡Ø³Øª).
    Ø²Ø¨Ø§Ù†: ÙØ§Ø±Ø³ÛŒØŒ ØªØ®ØµØµÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù….

    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ:
{data_str}

    ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡:
{recommendations_str}

    ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø´Ù…Ø§:
    """
    try:
        response = _model.generate_content(prompt)
        if response and response.parts: return "".join([part.text for part in response.parts if hasattr(part, 'text')])
        elif response.prompt_feedback and response.prompt_feedback.block_reason: return f"Ù¾Ø§Ø³Ø® AI Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯ ({response.prompt_feedback.block_reason.name})."
        else: print("AI Needs Resp:", response); return "Ù¾Ø§Ø³Ø® AI Ù†Ø§Ù…Ø¹ØªØ¨Ø±."
    except Exception as e: st.warning(f"âš ï¸ Ø®Ø·Ø§ÛŒ AI Ù†ÛŒØ§Ø²Ù‡Ø§: {e}"); return "Ø®Ø·Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ AI."


@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø®Ù„Ø§ØµÙ‡ AI Ù†Ù‚Ø´Ù‡...", persist="disk", ttl=3600)
def get_ai_map_summary(_model, ranking_df_sorted, selected_index, selected_day):
    """Generates AI summary for the overall map/ranking status."""
    if _model is None: return "Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
    if ranking_df_sorted is None or ranking_df_sorted.empty: return "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù†ÛŒØ³Øª."
    if 'ÙˆØ¶Ø¹ÛŒØª' not in ranking_df_sorted.columns: return "Ø³ØªÙˆÙ† 'ÙˆØ¶Ø¹ÛŒØª' Ù†ÛŒØ³Øª."

    ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].fillna("Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡")
    status_counts = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].value_counts()
    neg = sum(c for s, c in status_counts.items() if any(t in str(s).lower() for t in ["ØªÙ†Ø´", "Ú©Ø§Ù‡Ø´","Ù†ÛŒØ§Ø²"]))
    pos = sum(c for s, c in status_counts.items() if any(t in str(s).lower() for t in ["Ø¨Ù‡Ø¨ÙˆØ¯", "Ø±Ø´Ø¯","Ø§ÙØ²Ø§ÛŒØ´"]))
    nod = sum(c for s, c in status_counts.items() if "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" in str(s).lower() or "n/a" in str(s).lower())
    neu = len(ranking_df_sorted) - neg - pos - nod

    summary = f"Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª {len(ranking_df_sorted)} Ù…Ø²Ø±Ø¹Ù‡ ({selected_day}, Ø´Ø§Ø®Øµ: {selected_index}):\n"
    summary += f"- Ø¨Ù‡Ø¨ÙˆØ¯/Ø±Ø´Ø¯: {pos}\n- Ø«Ø§Ø¨Øª/Ø®Ù†Ø«ÛŒ: {neu}\n- ØªÙ†Ø´/Ú©Ø§Ù‡Ø´: {neg}\n- Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡: {nod}\n\n"

    sort_prob = selected_index != 'MSI'
    prob_farms = ranking_df_sorted.sort_index(ascending=sort_prob)[ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].astype(str).str.contains("ØªÙ†Ø´|Ú©Ø§Ù‡Ø´|Ù†ÛŒØ§Ø²", case=False, na=False)].head(5)
    if not prob_farms.empty:
        summary += "Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙˆØ¬Ù‡:\n"
        curr_col, chg_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', 'ØªØºÛŒÛŒØ±'
        for idx, row in prob_farms.iterrows():
            curr, chg = pd.to_numeric(row.get(curr_col), errors='coerce'), pd.to_numeric(row.get(chg_col), errors='coerce')
            summary += f"- Ø±ØªØ¨Ù‡ {idx}: {row.get('Ù…Ø²Ø±Ø¹Ù‡', '?')}, ÙˆØ¶Ø¹ÛŒØª: {row.get('ÙˆØ¶Ø¹ÛŒØª', '?')}, Ø´Ø§Ø®Øµ: {curr:.3f" if pd.notna(curr) else "N/A"}, ØªØºÛŒÛŒØ±: {chg:.3f" if pd.notna(chg) else "N/A"}\n"

    sort_good = selected_index == 'MSI'
    good_farms = ranking_df_sorted.sort_index(ascending=sort_good)[ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].astype(str).str.contains("Ø¨Ù‡Ø¨ÙˆØ¯|Ø±Ø´Ø¯", case=False, na=False)].head(5)
    if not good_farms.empty:
         summary += "\nÙ…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† ÙˆØ¶Ø¹ÛŒØª/Ø¨Ù‡Ø¨ÙˆØ¯:\n"
         curr_col, chg_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', 'ØªØºÛŒÛŒØ±'
         for idx, row in good_farms.iterrows():
            curr, chg = pd.to_numeric(row.get(curr_col), errors='coerce'), pd.to_numeric(row.get(chg_col), errors='coerce')
            summary += f"- Ø±ØªØ¨Ù‡ {idx}: {row.get('Ù…Ø²Ø±Ø¹Ù‡', '?')}, ÙˆØ¶Ø¹ÛŒØª: {row.get('ÙˆØ¶Ø¹ÛŒØª', '?')}, Ø´Ø§Ø®Øµ: {curr:.3f" if pd.notna(curr) else "N/A"}, ØªØºÛŒÛŒØ±: {chg:.3f" if pd.notna(chg) else "N/A"}\n"

    prompt = f"""
    Ø´Ù…Ø§ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø²ÛŒØ± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
    Ø´Ø§Ù…Ù„: 1. ØªØµÙˆÛŒØ± Ú©Ù„ÛŒ (ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØª). 2. Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø­Ø±Ø§Ù†ÛŒ (Ø·Ø¨Ù‚ Ù„ÛŒØ³Øª) Ùˆ Ø§Ù‚Ø¯Ø§Ù… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµ {selected_index}. 3. Ù…Ø²Ø§Ø±Ø¹ Ø®ÙˆØ¨ (Ø·Ø¨Ù‚ Ù„ÛŒØ³Øª) Ùˆ Ø§Ù…Ú©Ø§Ù† Ø§Ù„Ú¯ÙˆØ¨Ø±Ø¯Ø§Ø±ÛŒ. 4. Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯. 5. Ø§Ù‡Ù…ÛŒØª Ø´Ø§Ø®Øµ {selected_index}.
    Ø²Ø¨Ø§Ù†: ÙØ§Ø±Ø³ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ.

    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:
{summary}

    Ø®Ù„Ø§ØµÙ‡ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø´Ù…Ø§:
    """
    try:
        response = _model.generate_content(prompt)
        if response and response.parts: return "".join([part.text for part in response.parts if hasattr(part, 'text')])
        elif response.prompt_feedback: return f"Ø®Ù„Ø§ØµÙ‡ AI Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯ ({response.prompt_feedback.block_reason.name})."
        else: print("AI Map Resp:", response); return "Ù¾Ø§Ø³Ø® AI Ù†Ø§Ù…Ø¹ØªØ¨Ø±."
    except Exception as e: st.warning(f"âš ï¸ Ø®Ø·Ø§ÛŒ AI Ø®Ù„Ø§ØµÙ‡ Ù†Ù‚Ø´Ù‡: {e}"); return "Ø®Ø·Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø®Ù„Ø§ØµÙ‡ AI."


def determine_status(row_data, index_name):
    """Determines status based on index change. Expects dict/Series."""
    NDMI_IRR_TH, NDVI_LOW_TH = 0.25, 0.3
    ABS_CHG_TH, PCT_POS_TH, PCT_NEG_TH = 0.02, 3.0, -5.0

    curr_val = pd.to_numeric(row_data.get(f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)'), errors='coerce')
    prev_val = pd.to_numeric(row_data.get(f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)'), errors='coerce')
    change = curr_val - prev_val if pd.notna(curr_val) and pd.notna(prev_val) else np.nan
    pct_change = (change / abs(prev_val)) * 100 if pd.notna(change) and pd.notna(prev_val) and prev_val != 0 else np.nan

    status = "Ù†Ø§Ù…Ø´Ø®Øµ"
    if pd.notna(curr_val) and pd.notna(prev_val):
        is_pos = (pd.notna(change) and change > ABS_CHG_TH) or (pd.notna(pct_change) and pct_change > PCT_POS_TH)
        is_neg = (pd.notna(change) and change < -ABS_CHG_TH) or (pd.notna(pct_change) and pct_change < PCT_NEG_TH)
        if index_name in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI']: status = "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯" if is_pos else ("ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´" if is_neg else "Ø«Ø§Ø¨Øª")
        elif index_name == 'MSI': status = "Ø¨Ù‡Ø¨ÙˆØ¯ (Ú©Ø§Ù‡Ø´ ØªÙ†Ø´)" if is_neg else ("ØªÙ†Ø´ (Ø§ÙØ²Ø§ÛŒØ´ MSI)" if is_pos else "Ø«Ø§Ø¨Øª") # Inverted logic
        elif index_name == 'NDMI':
            low = pd.notna(curr_val) and curr_val <= NDMI_IRR_TH
            if is_neg: status = "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø´Ø¯ÛŒØ¯ / Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ" if low else "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡"
            elif is_pos: status = "Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯"
            else: status = "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ / Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ" if low else "Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª"
    elif pd.notna(curr_val):
        status = "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„"
        if index_name == 'NDMI' and curr_val <= NDMI_IRR_TH: status += " (ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ)"
        elif index_name == 'NDVI' and curr_val <= NDVI_LOW_TH: status += " (Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ†)"
    elif pd.notna(prev_val): status = "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ"
    else: status = "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
    return status


@st.cache_data(show_spinner=False, persist="disk", ttl=3600)
def calculate_weekly_indices_for_table(_farms_df_filtered, index_name, start_curr, end_curr, start_prev, end_prev):
    """ Calculates mean index values using GEE reduceRegions. Returns DataFrame and errors."""
    errors = []
    if not gee_initialized: return pd.DataFrame(), ["GEE Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù†Ø´Ø¯Ù‡."]
    if _farms_df_filtered is None or _farms_df_filtered.empty: return pd.DataFrame(), ["DataFrame ÙˆØ±ÙˆØ¯ÛŒ Ø®Ø§Ù„ÛŒ."]
    if not all([start_curr, end_curr, start_prev, end_prev]): return pd.DataFrame(), ["ØªØ§Ø±ÛŒØ® Ù†Ø§Ù…Ø¹ØªØ¨Ø±."]
    print(f"Calculating {index_name} for {len(_farms_df_filtered)} farms...")

    required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'ee_geometry', 'Ú¯Ø±ÙˆÙ‡', 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡']
    if not all(c in _farms_df_filtered.columns for c in required_cols if c != 'ee_geometry'): # Check essentials
        missing = [c for c in required_cols if c not in _farms_df_filtered.columns and c != 'ee_geometry']
        return pd.DataFrame(), [f"Ø³ØªÙˆÙ† Ø¶Ø±ÙˆØ±ÛŒ Ù†ÛŒØ³Øª: {', '.join(missing)}"]

    features, farm_props_dict, geoms = [], {}, []
    for idx, farm in _farms_df_filtered.iterrows():
        name, geom = farm.get('Ù…Ø²Ø±Ø¹Ù‡'), farm.get('ee_geometry')
        props = {'Ù…Ø²Ø±Ø¹Ù‡': name, 'Ú¯Ø±ÙˆÙ‡': farm.get('Ú¯Ø±ÙˆÙ‡','?'), 'Ø³Ù†': farm.get('Ø³Ù†','?'), 'ÙˆØ§Ø±ÛŒØªÙ‡': farm.get('ÙˆØ§Ø±ÛŒØªÙ‡','?')}
        farm_props_dict[name] = props # Store props regardless of geometry
        if name and geom and isinstance(geom, ee.Geometry):
            try: features.append(ee.Feature(geom, props).set('farm_id', name)); geoms.append(geom)
            except Exception as e: errors.append(f"Ø®Ø·Ø§ÛŒ Feature '{name}': {e}")
        else: errors.append(f"Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±/Ù†Ø¨ÙˆØ¯ Ø¨Ø±Ø§ÛŒ '{name}'.") # Will add back with NaN later

    if not features:
        errors.append("Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ GEE Ù†ÛŒØ³Øª.")
        return pd.DataFrame(list(farm_props_dict.values())), errors # Return original props

    farm_fc = ee.FeatureCollection(features)
    bounds = ee.Geometry.MultiPolygon(geoms).bounds(maxError=1)

    @st.cache_data(show_spinner=False)
    def get_images(bounds_info, s_c, e_c, s_p, e_p, idx_n):
        img_err = []
        img_c, err_c = get_processed_image(bounds, s_c, e_c, idx_n); img_err.append(f"Ø¬Ø§Ø±ÛŒ: {err_c}" if err_c else "")
        img_p, err_p = get_processed_image(bounds, s_p, e_p, idx_n); img_err.append(f"Ù‚Ø¨Ù„ÛŒ: {err_p}" if err_p else "")
        return img_c, img_p, [e for e in img_err if e]

    image_curr, image_prev, img_errors = get_images(bounds.getInfo(), start_curr, end_curr, start_prev, end_prev, index_name)
    errors.extend(img_errors)

    image_to_reduce, reducers, band_map = None, [], {}
    if image_curr:
        band_c = f"{index_name}_curr"; image_curr = image_curr.select(index_name).rename(band_c)
        reducers.append(ee.Reducer.mean().setOutputs([f'{band_c}_mean'])); band_map[f'{band_c}_mean'] = band_c
        image_to_reduce = image_curr
    if image_prev:
        band_p = f"{index_name}_prev"; image_prev = image_prev.select(index_name).rename(band_p)
        reducers.append(ee.Reducer.mean().setOutputs([f'{band_p}_mean'])); band_map[f'{band_p}_mean'] = band_p
        image_to_reduce = image_to_reduce.addBands(image_prev) if image_to_reduce else image_prev

    gee_results = {}
    if image_to_reduce and reducers:
        try:
            print(f"Running reduceRegions for {index_name}...")
            reduced_fc = image_to_reduce.reduceRegions(farm_fc, ee.Reducer.combine(reducers, True), 10, tileScale=4)
            results_dict_agg = reduced_fc.aggregate_dictionary('farm_id').getInfo()
            print(f"Fetched GEE results for {len(results_dict_agg)} farms.")
            for farm_id, props in results_dict_agg.items():
                res = {b_map: float(props[g_b]) if g_b in props and props[g_b] is not None else np.nan
                       for g_b, b_map in band_map.items()}
                gee_results[farm_id] = res # farm_id is farm_name
        except ee.EEException as e: errors.append(f"Ø®Ø·Ø§ÛŒ GEE reduceRegions: {e}")
        except Exception as e: errors.append(f"Ø®Ø·Ø§ÛŒ Python reduceRegions: {e}")

    final_list = []
    processed_names = set(gee_results.keys())
    for name, props in farm_props_dict.items():
        combined = props.copy()
        if name in gee_results: combined.update(gee_results[name])
        else: combined.update({f'{index_name}_curr': np.nan, f'{index_name}_prev': np.nan}) # Ensure keys exist if GEE failed
        final_list.append(combined)

    if not final_list: errors.append("Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø§Ù…ÙˆÙÙ‚ØŒ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ù†ÛŒØ³Øª."); return pd.DataFrame(), errors

    final_df = pd.DataFrame(final_list)
    curr_c, prev_c = f'{index_name}_curr', f'{index_name}_prev'
    if curr_c in final_df.columns and prev_c in final_df.columns:
        final_df[curr_c] = pd.to_numeric(final_df[curr_c], errors='coerce')
        final_df[prev_c] = pd.to_numeric(final_df[prev_c], errors='coerce')
        final_df['ØªØºÛŒÛŒØ±'] = final_df[curr_c] - final_df[prev_c]
    else: final_df['ØªØºÛŒÛŒØ±'] = np.nan

    final_df = final_df.rename(columns={curr_c: f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', prev_c: f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)'})
    cols_order = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ú¯Ø±ÙˆÙ‡', 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡', f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±']
    final_df = final_df[[c for c in cols_order if c in final_df.columns]]

    print(f"Finished calculating weekly indices. Output shape: {final_df.shape}")
    return final_df, list(set(errors))


# ==============================================================================
# Main Application Layout (Tabs)
# ==============================================================================

tab1, tab2, tab3 = st.tabs(["ğŸ“Š Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹", "ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª", "ğŸ’§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§"])

with tab1:
    st.header("ğŸ“Š Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹ (Ù†Ù‚Ø´Ù‡ Ùˆ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ)")
    st.markdown("ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…Øª Ùˆ Ø±Ø·ÙˆØ¨Øª Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ. Ù†Ù‚Ø´Ù‡: ØªÙˆØ²ÛŒØ¹ Ø´Ø§Ø®Øµ Ø¬Ø§Ø±ÛŒ. Ø¬Ø¯ÙˆÙ„: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù‚Ø¨Ù„.")

    # --- Workflow Check ---
    if farm_data_df is None or farm_data_df.empty: st.error("âŒ Ø¯Ø§Ø¯Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡/Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
    elif filtered_farms_df.empty: st.warning(f"âš ï¸ Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    elif not gee_initialized: st.warning("âš ï¸ Ø§ØªØµØ§Ù„ GEE Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª.")
    elif not all([start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str]):
         st.warning("âš ï¸ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± (Ù„Ø·ÙØ§Ù‹ 'Ø±ÙˆØ² Ù‡ÙØªÙ‡' Ù…Ø¹ØªØ¨Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯).")
    else:
        # --- Calculate Ranking Data ONCE ---
        ranking_data, calculation_errors = None, []
        with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ '{selected_index}' Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ '{selected_day}'..."):
            try:
                 ranking_data, calculation_errors = calculate_weekly_indices_for_table(
                     filtered_farms_df, selected_index, start_date_current_str,
                     end_date_current_str, start_date_previous_str, end_date_previous_str)
            except Exception as e:
                 st.error(f"âŒ Ø®Ø·Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§: {e}"); st.error(traceback.format_exc())
                 ranking_data = pd.DataFrame() # Ensure empty DF on error

        if calculation_errors:
            st.warning("âš ï¸ Ø®Ø·Ø§ Ø­ÛŒÙ† Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (ØªØ§ Ûµ Ù…ÙˆØ±Ø¯):")
            unique_errors = list(set(calculation_errors))
            for err in unique_errors[:5]: st.warning(f"- {err}")
            if len(unique_errors) > 5: st.warning(f"... Ùˆ {len(unique_errors) - 5} Ø®Ø·Ø§ÛŒ Ø¯ÛŒÚ¯Ø±.")

        if ranking_data is None: st.error("âŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ù†Ø§Ù…ÙˆÙÙ‚.")
        else:
             # --- Map Display Logic ---
            selected_farm_details, map_bounds_geom = None, None
            center_lat, center_lon, zoom_level = INITIAL_LAT, INITIAL_LON, INITIAL_ZOOM
            is_single_farm = (selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹")

            if is_single_farm:
                details_list = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name]
                if not details_list.empty:
                    selected_farm_details = details_list.iloc[0]
                    lat, lon = selected_farm_details.get('wgs84_centroid_lat'), selected_farm_details.get('wgs84_centroid_lon')
                    geom = selected_farm_details.get('ee_geometry')
                    if pd.notna(lat) and pd.notna(lon) and geom:
                        center_lat, center_lon, zoom_level = lat, lon, 14
                        map_bounds_geom = geom
                    else: st.warning(f"Ù…Ø®ØªØµØ§Øª/Ù‡Ù†Ø¯Ø³Ù‡ '{selected_farm_name}' Ù†Ø§Ù…Ø¹ØªØ¨Ø±.")
                else: st.error(f"Ø¬Ø²Ø¦ÛŒØ§Øª '{selected_farm_name}' Ù†ÛŒØ³Øª."); is_single_farm = False

            if not is_single_farm or map_bounds_geom is None:
                 all_geoms = [g for g in filtered_farms_df['ee_geometry'] if g]
                 if all_geoms:
                     try:
                         map_bounds_geom = ee.Geometry.MultiPolygon(all_geoms).bounds(maxError=1)
                         center = map_bounds_geom.centroid(maxError=1).getInfo()['coordinates']
                         center_lon, center_lat = center[0], center[1]
                         coords = map_bounds_geom.getInfo()['coordinates'][0]
                         lons, lats = [c[0] for c in coords], [c[1] for c in coords]
                         lon_diff, lat_diff = max(lons)-min(lons), max(lats)-min(lats)
                         if max(lon_diff, lat_diff)>0.5: zoom_level=10
                         elif max(lon_diff, lat_diff)>0.1: zoom_level=11
                         else: zoom_level = 12
                     except Exception as e: st.warning(f"Ø®Ø·Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø±Ø² Ú©Ù„ÛŒ: {e}")
                 else: st.warning("Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ Ù†ÛŒØ³Øª.")

            if is_single_farm and selected_farm_details is not None:
                 st.subheader(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name} ({selected_day})")
                 # Display metric cards... (omitted for brevity)
            elif not is_single_farm:
                 st.subheader(f"Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ ({selected_day})")
                 st.markdown(modern_metric_card("ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹", f"{len(filtered_farms_df):,}", "fa-leaf", "#185a9d"), unsafe_allow_html=True)
                 # Optional Pie chart... (omitted)

            st.markdown("---")
            st.subheader("ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
            st.markdown(f"Ø´Ø§Ø®Øµ: '{selected_index}', Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")

            vis_params = { # Define palettes etc.
                'NDVI': {'min': 0.1, 'max': 0.9, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
                 'EVI': {'min': 0.1, 'max': 0.8, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
                'NDMI': {'min': -0.5, 'max': 0.6, 'palette': ['#b2182b', '#ef8a62', '#fddbc7', '#f7f7f7', '#d1e5f0', '#67a9cf', '#2166ac']},
                 'LAI': {'min': 0, 'max': 6, 'palette': ['#f7f7f7', '#dcdcdc', '#babcba', '#8aae8b', '#5a9c5a', '#2a8a2a', '#006400']},
                 'MSI': {'min': 0.6, 'max': 2.5, 'palette': ['#2166ac', '#67a9cf', '#d1e5f0', '#f7f7f7', '#fddbc7', '#ef8a62', '#b2182b']},
                 'CVI': {'min': 0, 'max': 20, 'palette': ['#ffffb2', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
                 'SAVI': {'min': 0.1, 'max': 0.8, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
            }
            index_vis_params = vis_params.get(selected_index, {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']})

            m = geemap.Map(location=[center_lat, center_lon], zoom=zoom_level, add_google_map=False)
            m.add_basemap("HYBRID")

            gee_image_current, error_msg_current = None, None
            if map_bounds_geom:
                 with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ..."):
                     gee_image_current, error_msg_current = get_processed_image(map_bounds_geom, start_date_current_str, end_date_current_str, selected_index)
            else: error_msg_current = "Ù…Ø±Ø² Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªØµÙˆÛŒØ± Ù†ÛŒØ³Øª."

            if gee_image_current:
                try:
                    m.addLayer(gee_image_current.clip(map_bounds_geom), index_vis_params, f"{selected_index} (Ø¬Ø§Ø±ÛŒ)")
                    # Add Legend... (omitted)
                    # Add Boundaries... (optional, potentially slow)
                    bound_style = {'color': 'yellow', 'fillColor': '00000000', 'width': 1}
                    if is_single_farm and selected_farm_details and selected_farm_details.get('ee_geometry'):
                         m.addLayer(selected_farm_details['ee_geometry'], bound_style, f'Ù…Ø±Ø² {selected_farm_name}')
                    # elif not is_single_farm and map_bounds_geom: # Show all bounds?
                    #      all_feat = [ee.Feature(g) for g in filtered_farms_df['ee_geometry'] if g]
                    #      if all_feat: m.addLayer(ee.FeatureCollection(all_feat), bound_style, 'Ù…Ø±Ø²Ù‡Ø§')
                except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ GEE: {e}")
            else: st.warning(f"ØªØµÙˆÛŒØ± Ù†Ù‚Ø´Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯. {error_msg_current or ''}")

            # Add Markers using PRE-CALCULATED data
            if ranking_data is not None and not ranking_data.empty:
                 popup_dict = ranking_data.set_index('Ù…Ø²Ø±Ø¹Ù‡').to_dict('index')
                 for idx, farm_row in filtered_farms_df.iterrows():
                      lat, lon, name = farm_row.get('wgs84_centroid_lat'), farm_row.get('wgs84_centroid_lon'), farm_row.get('Ù…Ø²Ø±Ø¹Ù‡')
                      if pd.notna(lat) and pd.notna(lon) and name:
                           info = popup_dict.get(name)
                           curr, prev, chg, status = ("N/A",)*3 + ["Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯"]
                           if info:
                               curr_r = info.get(f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)')
                               prev_r = info.get(f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)')
                               chg_r = info.get('ØªØºÛŒÛŒØ±')
                               curr = f"{curr_r:.3f}" if pd.notna(curr_r) else "N/A"
                               prev = f"{prev_r:.3f}" if pd.notna(prev_r) else "N/A"
                               chg = f"{chg_r:.3f}" if pd.notna(chg_r) else "N/A"
                               status = determine_status(info, selected_index)

                           html = f"<strong>{name}</strong><br>Ú¯Ø±ÙˆÙ‡: {farm_row.get('Ú¯Ø±ÙˆÙ‡','?')}<br>Ø³Ù†: {farm_row.get('Ø³Ù†','?')}<br>ÙˆØ§Ø±ÛŒØªÙ‡: {farm_row.get('ÙˆØ§Ø±ÛŒØªÙ‡','?')}<hr style='margin:2px 0;'>{selected_index}: {curr} (Ù‚Ø¨Ù„: {prev})<br>ØªØºÛŒÛŒØ±: {chg}<br>ÙˆØ¶Ø¹ÛŒØª: {status}"
                           color = 'cadetblue'
                           if any(t in status.lower() for t in ["ØªÙ†Ø´", "Ú©Ø§Ù‡Ø´", "Ù†ÛŒØ§Ø²"]): color='red'
                           elif any(t in status.lower() for t in ["Ø¨Ù‡Ø¨ÙˆØ¯", "Ø±Ø´Ø¯", "Ø§ÙØ²Ø§ÛŒØ´"]): color='green'
                           elif "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" in status.lower(): color='orange'
                           icon = 'star' if is_single_farm and name == selected_farm_name else 'info-circle'
                           if is_single_farm and name == selected_farm_name: color = 'purple'

                           folium.Marker([lat, lon], popup=folium.Popup(html, max_width=300), tooltip=f"{name} ({status})", icon=folium.Icon(color=color, icon=icon, prefix='fa')).add_to(m)
            else: st.info("Ø¯Ø§Ø¯Ù‡ Ù¾Ø§Ù¾â€ŒØ¢Ù¾ Ù†ÛŒØ³Øª.")

            m.add_layer_control()
            with st.container(): # Use container to manage layout
                st_folium(m, width=None, height=500, use_container_width=True, returned_objects=[])
            st.caption("Ø¨Ø±Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø±ÙˆÛŒ Ù…Ø§Ø±Ú©Ø± Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯.")

            # Time Series Plot
            st.markdown("---")
            st.subheader(f"ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index}")
            if not is_single_farm: st.info("ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
            elif not gee_initialized: st.warning("Ø§ØªØµØ§Ù„ GEE Ù†ÛŒØ³Øª.")
            elif selected_farm_details is None or pd.isna(selected_farm_details.get('wgs84_centroid_lon')): st.warning("Ù…Ø®ØªØµØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±.")
            else:
                 point = ee.Geometry.Point([selected_farm_details['wgs84_centroid_lon'], selected_farm_details['wgs84_centroid_lat']])
                 ts_df, ts_err = get_index_time_series(point, selected_index, (today-datetime.timedelta(days=365)).strftime('%Y-%m-%d'), today.strftime('%Y-%m-%d'))
                 if ts_err: st.warning(f"Ø®Ø·Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_err}")
                 elif not ts_df.empty and selected_index in ts_df.columns and not ts_df[selected_index].isna().all():
                      fig_ts = px.line(ts_df.dropna(subset=[selected_index]), y=selected_index, title=f'Ø±ÙˆÙ†Ø¯ {selected_index} - {selected_farm_name}', markers=True)
                      fig_ts.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title=selected_index, hovermode="x unified", margin=dict(l=20,r=20,t=40,b=20),paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
                      st.plotly_chart(fig_ts, use_container_width=True)
                 else: st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ '{selected_index}' Ù†ÛŒØ³Øª.")

            # Ranking Table
            st.markdown("---")
            st.subheader(f"ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ({selected_index}, {selected_day})")
            st.markdown("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ Ø´Ø§Ø®Øµ.")

            if ranking_data is not None and not ranking_data.empty:
                sort_asc = (selected_index == 'MSI')
                sort_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)'
                if sort_col in ranking_data.columns:
                    ranked_df_s = ranking_data.sort_values(by=sort_col, ascending=sort_asc, na_position='last').reset_index(drop=True)
                else: ranked_df_s = ranking_data.copy(); st.warning(f"Ø³ØªÙˆÙ† Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ '{sort_col}' Ù†ÛŒØ³Øª.")

                if not ranked_df_s.empty:
                    ranked_df_s.index = ranked_df_s.index + 1; ranked_df_s.index.name = 'Ø±ØªØ¨Ù‡'
                    ranked_df_s['ÙˆØ¶Ø¹ÛŒØª'] = ranked_df_s.apply(lambda r: determine_status(r.to_dict(), selected_index), axis=1)
                    ranked_df_s['ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´'] = ranked_df_s['ÙˆØ¶Ø¹ÛŒØª'].apply(status_badge)

                    display_df = ranked_df_s.copy()
                    cols_fmt = [f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±']
                    for col in cols_fmt:
                        if col in display_df.columns: display_df[col] = display_df[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")

                    disp_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ú¯Ø±ÙˆÙ‡', 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡'] + cols_fmt + ['ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´']
                    final_cols = [c for c in disp_cols if c in display_df.columns]
                    display_df = display_df[final_cols].rename(columns={'ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´': 'ÙˆØ¶Ø¹ÛŒØª'})

                    st.write("<style>td, th {text-align: center !important; vertical-align: middle !important;}</style>", unsafe_allow_html=True)
                    st.write(display_df.to_html(escape=False, index=True, classes=['data-table'], justify='center'), unsafe_allow_html=True)

                    # Summary Stats
                    st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª")
                    if 'ÙˆØ¶Ø¹ÛŒØª' in ranked_df_s.columns:
                         counts = ranked_df_s['ÙˆØ¶Ø¹ÛŒØª'].value_counts()
                         neg = sum(c for s, c in counts.items() if any(t in str(s).lower() for t in ["ØªÙ†Ø´","Ú©Ø§Ù‡Ø´","Ù†ÛŒØ§Ø²"]))
                         pos = sum(c for s, c in counts.items() if any(t in str(s).lower() for t in ["Ø¨Ù‡Ø¨ÙˆØ¯","Ø±Ø´Ø¯","Ø§ÙØ²Ø§ÛŒØ´"]))
                         nod = sum(c for s, c in counts.items() if "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" in str(s).lower() or "n/a" in str(s).lower())
                         neu = len(ranked_df_s) - neg - pos - nod
                         c1,c2,c3,c4 = st.columns(4)
                         with c1: st.metric("ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯/Ø±Ø´Ø¯", pos)
                         with c2: st.metric("âšª Ø«Ø§Ø¨Øª/Ø®Ù†Ø«ÛŒ", neu)
                         with c3: st.metric("ğŸ”´ ØªÙ†Ø´/Ú©Ø§Ù‡Ø´", neg)
                         with c4: st.metric("ğŸŸ¡ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", nod)
                         with st.expander("ØªÙˆØ¶ÛŒØ­Ø§Øª ÙˆØ¶Ø¹ÛŒØª"): st.markdown("- **ğŸŸ¢**: Ø¨Ù‡Ø¨ÙˆØ¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡\n- **âšª**: ØªØºÛŒÛŒØ± Ù†Ø§Ù…Ø­Ø³ÙˆØ³\n- **ğŸ”´**: ÙˆØ¶Ø¹ÛŒØª Ù†Ø§Ù…Ø·Ù„ÙˆØ¨â€ŒØªØ± ÛŒØ§ Ù†ÛŒØ§Ø²\n- **ğŸŸ¡**: Ø¹Ø¯Ù… Ø§Ù…Ú©Ø§Ù† Ù…Ø­Ø§Ø³Ø¨Ù‡")
                    else: st.warning("Ø³ØªÙˆÙ† 'ÙˆØ¶Ø¹ÛŒØª' Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ù†ÛŒØ³Øª.")

                    # AI Summary
                    st.markdown("---")
                    st.subheader("ğŸ¤– Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
                    if gemini_model:
                       with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ AI Ù†Ù‚Ø´Ù‡..."):
                           ai_summary = get_ai_map_summary(gemini_model, ranked_df_s, selected_index, selected_day)
                           st.markdown(ai_summary)
                    else: st.info("âš ï¸ Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

                    # Download
                    try:
                        dl_df = ranked_df_s.drop(columns=['ÙˆØ¶Ø¹ÛŒØª_Ù†Ù…Ø§ÛŒØ´'], errors='ignore')
                        csv = dl_df.to_csv(index=True, encoding='utf-8-sig')
                        st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (CSV)", csv, f'ranking_{selected_index}_{selected_day}.csv', 'text/csv')
                    except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯: {e}")

                else: st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†ÛŒØ³Øª.")
            elif calculation_errors: st.error("Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
            else: st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ '{selected_index}' Ù†ÛŒØ³Øª.")
# --- End of Tab 1 ---


# ==============================================================================
# Tab 2: Analysis Data
# ==============================================================================
with tab2:
    st.header("ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª")
    st.markdown("Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ù…Ø³Ø§Ø­Øª Ùˆ ØªÙˆÙ„ÛŒØ¯ Ø¨Ù‡ ØµÙˆØ±Øª Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ.")

    if analysis_area_df is None and analysis_prod_df is None: st.error("âŒ Ø¯Ø§Ø¯Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡.")
    else:
        available_edareh = []
        for df in [analysis_area_df, analysis_prod_df]:
            if df is not None:
                 if isinstance(df.index, pd.MultiIndex) and 'Ø§Ø¯Ø§Ø±Ù‡' in df.index.names: available_edareh.extend(df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique().tolist())
                 elif 'Ø§Ø¯Ø§Ø±Ù‡' in df.columns: available_edareh.extend(df['Ø§Ø¯Ø§Ø±Ù‡'].unique().tolist())
        available_edareh = sorted(list(set(e for e in available_edareh if pd.notna(e))))

        if not available_edareh: st.warning("âš ï¸ 'Ø§Ø¯Ø§Ø±Ù‡' Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        else:
            selected_edareh = st.selectbox("Ø§Ø¯Ø§Ø±Ù‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:", options=available_edareh, key='analysis_edareh')
            st.subheader(f"ğŸ“Š Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡: {selected_edareh}")
            c1, c2 = st.columns(2)

            with c1: # Area Plots
                st.markdown("#### Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)")
                df_sel = None
                if analysis_area_df is not None:
                     try: # Select data for the Edareh
                         if isinstance(analysis_area_df.index, pd.MultiIndex): df_sel = analysis_area_df.loc[selected_edareh].copy() if selected_edareh in analysis_area_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡') else None
                         elif 'Ø§Ø¯Ø§Ø±Ù‡' in analysis_area_df.columns: df_sel = analysis_area_df[analysis_area_df['Ø§Ø¯Ø§Ø±Ù‡'] == selected_edareh].copy(); df_sel = df_sel.set_index('Ø³Ù†', drop=False) if 'Ø³Ù†' in df_sel.columns else df_sel # Adjust index if needed
                     except Exception as e: st.warning(f"Ø®Ø·Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª: {e}")

                     if df_sel is not None and not df_sel.empty:
                         if 'Ø§Ø¯Ø§Ø±Ù‡' in df_sel.columns: df_sel = df_sel.drop(columns=['Ø§Ø¯Ø§Ø±Ù‡'], errors='ignore') # Drop edareh col if present
                         df_sel=df_sel.fillna(0) # fill na for plotting
                         ages, varieties, z = df_sel.index.astype(str).tolist(), df_sel.columns.tolist(), df_sel.values
                         # Surface Plot
                         if len(ages)>1 and len(varieties)>1:
                             try:
                                 fig3d = go.Figure(data=[go.Surface(z=z,x=ages,y=varieties,colorscale='Viridis')])
                                 fig3d.update_layout(title=f'Ø³Ø·Ø­ Ù…Ø³Ø§Ø­Øª - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}', scene=dict(xaxis_title='Ø³Ù†',yaxis_title='ÙˆØ§Ø±ÛŒØªÙ‡',zaxis_title='Ù…Ø³Ø§Ø­Øª'),height=450,margin=dict(l=0,r=0,t=40,b=0), paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
                                 st.plotly_chart(fig3d, use_container_width=True)
                             except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø·Ø­ Ù…Ø³Ø§Ø­Øª: {e}"); st.dataframe(df_sel)
                         else: st.info("Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø·Ø­."); st.dataframe(df_sel)
                         # Histogram
                         try:
                             df_melt = df_sel.reset_index().melt(id_vars=df_sel.index.name or 'Ø³Ù†', var_name='ÙˆØ§Ø±ÛŒØªÙ‡', value_name='Ù…Ø³Ø§Ø­Øª')
                             df_melt = df_melt[df_melt['Ù…Ø³Ø§Ø­Øª'] > 0]
                             if not df_melt.empty:
                                 fighist = px.histogram(df_melt, x='ÙˆØ§Ø±ÛŒØªÙ‡', y='Ù…Ø³Ø§Ø­Øª', color=df_sel.index.name or 'Ø³Ù†', title=f'Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù…Ø³Ø§Ø­Øª - {selected_edareh}', barmode='group', text_auto='.2s')
                                 fighist.update_layout(height=400, margin=dict(l=0,r=0,t=40,b=0), paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
                                 st.plotly_chart(fighist, use_container_width=True)
                             else: st.info("Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù…Ø³Ø§Ø­Øª Ù†ÛŒØ³Øª.")
                         except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù…Ø³Ø§Ø­Øª: {e}")
                     else: st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} Ù†ÛŒØ³Øª.")
                else: st.info("Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡.")

            with c2: # Production Plots
                st.markdown("#### ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)")
                df_sel = None
                if analysis_prod_df is not None: # Similar logic as area
                    try:
                        if isinstance(analysis_prod_df.index, pd.MultiIndex): df_sel = analysis_prod_df.loc[selected_edareh].copy() if selected_edareh in analysis_prod_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡') else None
                        elif 'Ø§Ø¯Ø§Ø±Ù‡' in analysis_prod_df.columns: df_sel = analysis_prod_df[analysis_prod_df['Ø§Ø¯Ø§Ø±Ù‡'] == selected_edareh].copy(); df_sel = df_sel.set_index('Ø³Ù†', drop=False) if 'Ø³Ù†' in df_sel.columns else df_sel
                    except Exception as e: st.warning(f"Ø®Ø·Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯: {e}")

                    if df_sel is not None and not df_sel.empty:
                        if 'Ø§Ø¯Ø§Ø±Ù‡' in df_sel.columns: df_sel = df_sel.drop(columns=['Ø§Ø¯Ø§Ø±Ù‡'], errors='ignore')
                        df_sel=df_sel.fillna(0)
                        ages, varieties, z = df_sel.index.astype(str).tolist(), df_sel.columns.tolist(), df_sel.values
                        # Surface plot
                        if len(ages)>1 and len(varieties)>1:
                            try:
                                fig3d=go.Figure(data=[go.Surface(z=z,x=ages,y=varieties,colorscale='Plasma')])
                                fig3d.update_layout(title=f'Ø³Ø·Ø­ ØªÙˆÙ„ÛŒØ¯ - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}', scene=dict(xaxis_title='Ø³Ù†',yaxis_title='ÙˆØ§Ø±ÛŒØªÙ‡',zaxis_title='ØªÙˆÙ„ÛŒØ¯'),height=450,margin=dict(l=0,r=0,t=40,b=0), paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
                                st.plotly_chart(fig3d, use_container_width=True)
                            except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø·Ø­ ØªÙˆÙ„ÛŒØ¯: {e}"); st.dataframe(df_sel)
                        else: st.info("Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø·Ø­."); st.dataframe(df_sel)
                        # Histogram
                        try:
                             df_melt = df_sel.reset_index().melt(id_vars=df_sel.index.name or 'Ø³Ù†', var_name='ÙˆØ§Ø±ÛŒØªÙ‡', value_name='ØªÙˆÙ„ÛŒØ¯')
                             df_melt = df_melt[df_melt['ØªÙˆÙ„ÛŒØ¯'] > 0]
                             if not df_melt.empty:
                                 fighist = px.histogram(df_melt, x='ÙˆØ§Ø±ÛŒØªÙ‡', y='ØªÙˆÙ„ÛŒØ¯', color=df_sel.index.name or 'Ø³Ù†', title=f'Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆÙ„ÛŒØ¯ - {selected_edareh}', barmode='group', text_auto='.3s')
                                 fighist.update_layout(height=400, margin=dict(l=0,r=0,t=40,b=0), paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
                                 st.plotly_chart(fighist, use_container_width=True)
                             else: st.info("Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆÙ„ÛŒØ¯ Ù†ÛŒØ³Øª.")
                        except Exception as e: st.error(f"Ø®Ø·Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆÙ„ÛŒØ¯: {e}")
                    else: st.info(f"Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} Ù†ÛŒØ³Øª.")
                else: st.info("Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡.")
    st.markdown("---")

# ==============================================================================
# Tab 3: Needs Analysis
# ==============================================================================
with tab3:
    st.header("ğŸ’§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ")
    st.markdown("Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ø¨Ø§ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ.")

    is_single_farm = (selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹")

    if not is_single_farm: st.info("ğŸ‘ˆ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
    elif filtered_farms_df.empty: st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡/Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ù†ÛŒØ³Øª.")
    elif not gee_initialized: st.warning("âš ï¸ Ø§ØªØµØ§Ù„ GEE Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª.")
    elif not all([start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str]):
         st.warning("âš ï¸ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±.")
    else:
        details_tab3 = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
        geom_tab3 = details_tab3.get('ee_geometry')

        if geom_tab3 is None: st.error(f"âŒ Ù‡Ù†Ø¯Ø³Ù‡ GEE '{selected_farm_name}' Ù†ÛŒØ³Øª.")
        else:
            st.subheader(f"ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø² - Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")
            needs_data = None
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø´Ø§Ø®Øµ Ù†ÛŒØ§Ø²Ù‡Ø§..."):
                 needs_data = get_farm_needs_data(
                     geom_tab3, start_date_current_str, end_date_current_str,
                     start_date_previous_str, end_date_previous_str)

            if needs_data.get('error'): st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡: {needs_data['error']}")
            elif all(pd.isna(needs_data.get(k)) for k in ['NDMI_curr','NDVI_curr','NDMI_prev','NDVI_prev']):
                st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ø´Ø§Ø®Øµ Ù„Ø§Ø²Ù… (NDMI/NDVI) Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ùˆ Ø¯ÙˆØ±Ù‡ Ù†ÛŒØ³Øª.")
            else:
                 st.markdown("---")
                 st.markdown("#### Ù†ØªØ§ÛŒØ¬ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§")
                 def display_metric(lbl, val): st.metric(lbl, f"{val:.3f}" if pd.notna(val) else "N/A")
                 st.markdown("**Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ:**")
                 c1,c2,c3,c4 = st.columns(4)
                 with c1: display_metric("NDVI", needs_data.get('NDVI_curr'))
                 with c2: display_metric("NDMI", needs_data.get('NDMI_curr'))
                 with c3: display_metric("EVI", needs_data.get('EVI_curr'))
                 with c4: display_metric("SAVI", needs_data.get('SAVI_curr'))
                 st.markdown("**Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„:**")
                 c1p, c2p, c3p, c4p = st.columns(4)
                 with c1p: display_metric("NDVI", needs_data.get('NDVI_prev'))
                 with c2p: display_metric("NDMI", needs_data.get('NDMI_prev'))
                 with c3p: display_metric("EVI", needs_data.get('EVI_prev'))
                 with c4p: display_metric("SAVI", needs_data.get('SAVI_prev'))

                 st.markdown("---")
                 st.markdown("#### ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡")
                 recs = []
                 status_inp = {f'{i}_{p}': needs_data.get(f'{i}_{p}') for i in ['NDVI','NDMI','EVI','SAVI'] for p in ['curr','prev']}
                 status_inp_fmt = { # Format for "determine_status" which expects specific keys
                     f'{idx} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': status_inp.get(f'{idx}_curr') for idx in ['NDVI','NDMI','EVI','SAVI']
                 }
                 status_inp_fmt.update({
                     f'{idx} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': status_inp.get(f'{idx}_prev') for idx in ['NDVI','NDMI','EVI','SAVI']
                 })

                 ndmi_stat = determine_status(status_inp_fmt, 'NDMI')
                 ndvi_stat = determine_status(status_inp_fmt, 'NDVI')
                 evi_stat = determine_status(status_inp_fmt, 'EVI')

                 if any(t in ndmi_stat for t in ["Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ"]): recs.append(f"ğŸ’§ **Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** {ndmi_stat}")
                 elif "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª" in ndmi_stat: recs.append(f"âš ï¸ **Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª:** Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø¨ÛŒØ§Ø±ÛŒ ({ndmi_stat})")
                 elif "Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø·ÙˆØ¨Øª" in ndmi_stat: recs.append(f"âœ… **Ø±Ø·ÙˆØ¨Øª:** Ø¨Ù‡Ø¨ÙˆØ¯/Ø§ÙØ²Ø§ÛŒØ´ ({ndmi_stat})")
                 elif "Ø±Ø·ÙˆØ¨Øª Ø«Ø§Ø¨Øª" in ndmi_stat: recs.append(f"â„¹ï¸ **Ø±Ø·ÙˆØ¨Øª:** Ø«Ø§Ø¨Øª ({ndmi_stat})")
                 elif "(ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ)" in ndmi_stat: recs.append(f"âš ï¸ **ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:** (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡ Ø¬Ø§Ø±ÛŒ).")

                 veg_concern = False
                 if "ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´" in ndvi_stat: recs.append(f"ğŸ“‰ **Ú©Ø§Ù‡Ø´ Ù¾ÙˆØ´Ø´ (NDVI):** {ndvi_stat}. Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆØ¯/Ø¹ÙˆØ§Ù…Ù„ Ø¯ÛŒÚ¯Ø±."); veg_concern=True
                 if "ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´" in evi_stat and not veg_concern: recs.append(f"ğŸ“‰ **Ú©Ø§Ù‡Ø´ Ù¾ÙˆØ´Ø´ (EVI):** {evi_stat}. Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆØ¯/Ø¹ÙˆØ§Ù…Ù„ Ø¯ÛŒÚ¯Ø±."); veg_concern=True
                 if "(Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ†)" in ndvi_stat: recs.append(f"âš ï¸ **Ù¾ÙˆØ´Ø´ Ù¾Ø§ÛŒÛŒÙ† (NDVI):** (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡ Ø¬Ø§Ø±ÛŒ)."); veg_concern = True
                 elif "(Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ù¾Ø§ÛŒÛŒÙ†)" in evi_stat and not veg_concern: recs.append(f"âš ï¸ **Ù¾ÙˆØ´Ø´ Ù¾Ø§ÛŒÛŒÙ† (EVI):** (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡ Ø¬Ø§Ø±ÛŒ).")


                 if not recs: recs.append("âœ… ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù†Ø±Ù…Ø§Ù„ ÛŒØ§ ØªØºÛŒÛŒØ±Ø§Øª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ù†ÛŒØ³Øª.")

                 for r in recs:
                    rl = r.lower()
                    if any(t in rl for t in ["Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ", "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª"]): st.error(r)
                    elif any(t in rl for t in ["Ú©Ø§Ù‡Ø´ Ù¾ÙˆØ´Ø´", "Ù¾ÙˆØ´Ø´ Ù¾Ø§ÛŒÛŒÙ†"]): st.warning(r)
                    elif any(t in rl for t in ["Ø¨Ù‡Ø¨ÙˆØ¯", "Ø§ÙØ²Ø§ÛŒØ´"]): st.success(r)
                    else: st.info(r)

                 # AI Analysis
                 st.markdown("---")
                 st.markdown("#### ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ")
                 if gemini_model:
                     with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ AI Ù†ÛŒØ§Ø²Ù‡Ø§..."):
                         ai_expl = get_ai_needs_analysis(gemini_model, selected_farm_name, needs_data, recs)
                         st.markdown(ai_expl)
                 else: st.info("âš ï¸ Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
    st.markdown("---")
# --- End of Tab 3 ---

# --- End of File app.py ---