import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap # Using foliumap backend for Streamlit compatibility
import folium
import os
import json
from datetime import datetime, timedelta

# ==============================================================================
# Configuration and Initialization
# ==============================================================================

# --- Page Configuration ---
st.set_page_config(
    page_title="Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¯Ù‡Ø®Ø¯Ø§",
    page_icon="ğŸŒ¾",
    layout="wide", # Use wide layout for better map display
    initial_sidebar_state="expanded" # Keep sidebar open initially
)

# --- Constants ---
CSV_FILE_PATH = 'output (1).csv'
SERVICE_ACCOUNT_KEY_PATH = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'
SERVICE_ACCOUNT_EMAIL = 'dehkhodamap-e9f0da4ce9f6514021@ee-esmaeilkiani13877.iam.gserviceaccount.com'
DEFAULT_LATITUDE = 31.534442
DEFAULT_LONGITUDE = 48.724416
DEFAULT_ZOOM = 13
AOI_BUFFER_METERS = 500 # Buffer radius around the farm point for analysis
DATE_RANGE_MONTHS = 3 # Analyze data for the last 3 months

# --- GEE Authentication ---
@st.cache_resource(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine...")
def authenticate_gee(service_account_key_path, service_account_email):
    """Authenticates Google Earth Engine using a Service Account."""
    try:
        # Check if the key file exists
        if not os.path.exists(service_account_key_path):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Ú©Ù„ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ù…Ø³ÛŒØ± '{service_account_key_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()

        # Load credentials from the file
        with open(service_account_key_path) as f:
            credentials_dict = json.load(f)

        credentials = ee.ServiceAccountCredentials(service_account_email, service_account_key_path)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Authenticated Successfully using Service Account.")
        return True # Indicate successful authentication
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ÙØ§ÛŒÙ„ Ú©Ù„ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø±Ø§ Ø¯Ø§Ø±Ø¯.")
        st.stop() # Stop execution if authentication fails
    except FileNotFoundError:
        st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Ú©Ù„ÛŒØ¯ Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ù…Ø³ÛŒØ± '{service_account_key_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    except Exception as e:
        st.error(f"ÛŒÚ© Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ø±Ø® Ø¯Ø§Ø¯: {e}")
        st.stop()

# --- Data Loading ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...")
def load_farm_data(csv_path):
    """Loads farm data from the CSV file."""
    try:
        df = pd.read_csv(csv_path, encoding='utf-8') # Specify UTF-8 encoding for Persian characters
        # Basic data cleaning/validation
        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡']
        if not all(col in df.columns for col in required_cols):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ CSV Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ {required_cols} Ø¨Ø§Ø´Ø¯.")
            st.stop()
        # Convert coordinate columns to numeric, coercing errors
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        # Handle potential missing coordinates indicated by the flag or NaN values
        df['coordinates_missing'] = df['coordinates_missing'].fillna(False).astype(bool) | df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].isna() | df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].isna()
        # Fill NaN in 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' with a placeholder if necessary, or handle appropriately
        df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] = df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].fillna('Ù†Ø§Ù…Ø´Ø®Øµ') # Or drop rows: df.dropna(subset=['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'])
        return df
    except FileNotFoundError:
        st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ CSV Ø¯Ø± Ù…Ø³ÛŒØ± '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        st.stop()

# --- GEE Image Processing Functions ---

def mask_s2_clouds(image):
    """Masks clouds in Sentinel-2 SR images using the SCL band."""
    scl = image.select('SCL')
    # Select clear (4), vegetation (5), and non-vegetated (6) pixels. Also include water (7).
    # Avoid cloud shadows (3), clouds medium probability (8), clouds high probability (9), cirrus (10).
    mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(7))
    # Also mask based on QA60 band if needed (though SCL is generally better for SR)
    # qa = image.select('QA60')
    # cloud_bit_mask = 1 << 10
    # cirrus_bit_mask = 1 << 11
    # mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))
    return image.updateMask(mask).divide(10000).copyProperties(image, ["system:time_start"]) # Scale factor for SR

def calculate_ndvi(image):
    """Calculates NDVI."""
    # NDVI = (NIR - Red) / (NIR + Red)
    # Sentinel-2 Bands: NIR=B8, Red=B4
    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')
    return image.addBands(ndvi)

def calculate_evi(image):
    """Calculates EVI."""
    # EVI = 2.5 * (NIR - Red) / (NIR + 6 * Red - 7.5 * Blue + 1)
    # Sentinel-2 Bands: NIR=B8, Red=B4, Blue=B2
    evi = image.expression(
        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {
            'NIR': image.select('B8'),
            'RED': image.select('B4'),
            'BLUE': image.select('B2')
        }).rename('EVI')
    return image.addBands(evi)

def calculate_ndmi(image):
    """Calculates NDMI (Normalized Difference Moisture Index)."""
    # NDMI = (NIR - SWIR1) / (NIR + SWIR1)
    # Sentinel-2 Bands: NIR=B8, SWIR1=B11
    ndmi = image.normalizedDifference(['B8', 'B11']).rename('NDMI')
    return image.addBands(ndmi)

def estimate_lai(image):
    """Estimates LAI using a simple NDVI-based formula (requires calibration)."""
    # Example formula: LAI = sqrt(NDVI * (1 + NDVI)) - This is highly empirical!
    # A more common simple approach might be linear or exponential based on NDVI
    # LAI = a * NDVI + b OR LAI = exp(c * NDVI + d)
    # Using a simple placeholder: LAI directly proportional to NDVI (for demonstration)
    # For a slightly more standard empirical approach (e.g., based on SNAP toolbox relations):
    # lai = image.expression('3.618 * EVI - 0.118', {'EVI': image.select('EVI')}).rename('LAI_EVI') # If EVI is calculated
    # Or based on NDVI:
    lai_ndvi = image.expression('sqrt(NDVI * (1 + NDVI))', {'NDVI': image.select('NDVI')}).rename('LAI') # Placeholder
    # Ensure LAI is not negative
    lai_ndvi = lai_ndvi.where(lai_ndvi.gt(0), 0)
    return image.addBands(lai_ndvi)

def estimate_biomass(image):
    """Estimates Biomass using NDVI as a proxy (requires calibration)."""
    # Biomass is often correlated with NDVI or LAI.
    # Using NDVI directly as a proxy indicator.
    biomass_proxy = image.select('NDVI').rename('Biomass_Proxy')
    return image.addBands(biomass_proxy)

def get_image_collection(aoi, start_date, end_date):
    """Gets, filters, masks, and processes Sentinel-2 image collection."""
    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') # Use Harmonized SR
               .filterBounds(aoi)
               .filterDate(start_date, end_date)
               .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) # Pre-filter by metadata
               .map(mask_s2_clouds) # Apply cloud masking
               .map(calculate_ndvi)
               .map(calculate_evi)
               .map(calculate_ndmi)
               .map(estimate_lai) # Add estimated LAI
               .map(estimate_biomass) # Add Biomass proxy
               )
    return s2_sr_col

# --- Visualization Parameters ---
ndvi_vis = {
    'min': 0.0, 'max': 1.0,
    'palette': ['#FF0000', '#FFA500', '#FFFF00', '#ADFF2F', '#008000'] # Red -> Orange -> Yellow -> GreenYellow -> Green
}
evi_vis = {
    'min': 0.0, 'max': 1.0,
    'palette': ['#FF0000', '#FFA500', '#FFFF00', '#ADFF2F', '#008000'] # Similar palette for EVI
}
ndmi_vis = {
    'min': -0.5, 'max': 0.8, # Typical range for NDMI
    'palette': ['#FF0000', '#FFA500', '#FFFF00', '#ADD8E6', '#0000FF'] # Red -> Orange -> Yellow -> LightBlue -> Blue
}
lai_vis = {
    'min': 0.0, 'max': 6.0, # Typical LAI range
    'palette': ['#FFFFFF', '#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901', '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01', '#012E01', '#011D01', '#011301'] # Common LAI palette
}
biomass_proxy_vis = {
    'min': 0.0, 'max': 1.0, # Same range as NDVI proxy
    'palette': ['#FDE725', '#7AD151', '#22A884', '#2A788E', '#414487', '#440154'] # Viridis palette often used for biomass/productivity
}
rgb_vis = {
    'min': 0.0, 'max': 0.3, # Max value for SR reflectance (adjust as needed)
    'bands': ['B4', 'B3', 'B2'] # Red, Green, Blue
}

# --- Main Application Logic ---
def main():
    """Main function to run the Streamlit application."""

    # --- Authentication ---
    if 'gee_authenticated' not in st.session_state:
        st.session_state.gee_authenticated = authenticate_gee(SERVICE_ACCOUNT_KEY_PATH, SERVICE_ACCOUNT_EMAIL)

    if not st.session_state.gee_authenticated:
        st.warning("Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ØµÙØ­Ù‡ Ø±Ø§ Ø±ÙØ±Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù…Ø§ÛŒÛŒØ¯.")
        st.stop()

    # --- Load Data ---
    df_farms = load_farm_data(CSV_FILE_PATH)

    # --- Sidebar ---
    st.sidebar.title("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")
    st.sidebar.header("ÙÛŒÙ„ØªØ± Ù…Ø²Ø§Ø±Ø¹")

    # -- Day of the Week Filter --
    available_days = sorted(df_farms['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique())
    selected_day = st.sidebar.selectbox(
        "Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ² Ù‡ÙØªÙ‡:",
        options=available_days,
        index=0 # Default to the first day
    )

    # Filter farms based on selected day
    df_filtered_by_day = df_farms[df_farms['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()

    # Check if any farms are available for the selected day
    if df_filtered_by_day.empty:
        st.sidebar.warning(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.warning(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' Ø¯Ø± ÙØ§ÛŒÙ„ CSV ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø±ÙˆØ² Ø¯ÛŒÚ¯Ø±ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ÛŒØ§ ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù…Ø§ÛŒÛŒØ¯.")
        st.stop() # Stop if no farms match the day

    # Remove farms with missing coordinates from selection
    df_valid_farms = df_filtered_by_day[~df_filtered_by_day['coordinates_missing']].copy()
    if df_valid_farms.empty:
         st.sidebar.warning(f"ØªÙ…Ø§Ù… Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÙØ§Ù‚Ø¯ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± Ù‡Ø³ØªÙ†Ø¯.")
         st.warning(f"ØªÙ…Ø§Ù… Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÙØ§Ù‚Ø¯ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± Ø¯Ø± ÙØ§ÛŒÙ„ CSV Ù‡Ø³ØªÙ†Ø¯.")
         st.stop()

    # -- Farm Selection Dropdown --
    available_farms = sorted(df_valid_farms['Ù…Ø²Ø±Ø¹Ù‡'].unique())
    selected_farm_name = st.sidebar.selectbox(
        "Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡:",
        options=available_farms,
        index=0 # Default to the first farm in the filtered list
    )

    # Get selected farm details
    selected_farm_data = df_valid_farms[df_valid_farms['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
    farm_lat = selected_farm_data['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    farm_lon = selected_farm_data['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']

    # --- Display Selected Farm Info ---
    st.sidebar.header("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡")
    st.sidebar.markdown(f"**Ù†Ø§Ù… Ù…Ø²Ø±Ø¹Ù‡:** {selected_farm_data['Ù…Ø²Ø±Ø¹Ù‡']}")
    st.sidebar.markdown(f"**Ú©Ø§Ù†Ø§Ù„:** {selected_farm_data.get('Ú©Ø§Ù†Ø§Ù„', 'N/A')}") # Use .get for optional columns
    st.sidebar.markdown(f"**Ø§Ø¯Ø§Ø±Ù‡:** {selected_farm_data.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')}")
    st.sidebar.markdown(f"**Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª:** {selected_farm_data.get('Ù…Ø³Ø§Ø­Øª Ø¯Ø§Ø´Øª', 'N/A')}")
    st.sidebar.markdown(f"**ÙˆØ§Ø±ÛŒØªÙ‡:** {selected_farm_data.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}")
    st.sidebar.markdown(f"**Ø³Ù†:** {selected_farm_data.get('Ø³Ù†', 'N/A')}")
    st.sidebar.markdown(f"**Ø±ÙˆØ² Ù‡ÙØªÙ‡:** {selected_farm_data['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡']}")
    st.sidebar.markdown(f"**Ù…Ø®ØªØµØ§Øª:** ({farm_lat:.6f}, {farm_lon:.6f})")

    # --- Map Section ---
    st.header(f"Ù†Ù‚Ø´Ù‡ Ùˆ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")

    # Create AOI (Area of Interest) point and buffer
    farm_point = ee.Geometry.Point([farm_lon, farm_lat])
    aoi = farm_point.buffer(AOI_BUFFER_METERS)

    # Define date range for analysis
    end_date = datetime.now()
    start_date = end_date - timedelta(days=DATE_RANGE_MONTHS * 30) # Approximate months
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')

    st.info(f"Ø¯ÙˆØ±Ù‡ Ø²Ù…Ø§Ù†ÛŒ ØªØ­Ù„ÛŒÙ„: {start_date_str} ØªØ§ {end_date_str}")

    # Get processed image collection
    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ... Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯."):
        image_collection = get_image_collection(aoi, start_date_str, end_date_str)

        # Check if the collection is empty
        collection_size = image_collection.size().getInfo()
        if collection_size == 0:
            st.warning("Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù…Ù†Ø§Ø³Ø¨ÛŒ (Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø±) Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ùˆ Ù…Ú©Ø§Ù†ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.warning("Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ±Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯ ÛŒØ§ Ù…Ù†ØªØ¸Ø± ØªØµØ§ÙˆÛŒØ± Ø¬Ø¯ÛŒØ¯ Ø¨Ù…Ø§Ù†ÛŒØ¯.")
            # Display a basic map without GEE layers if no images found
            Map = geemap.Map(location=[farm_lat, farm_lon], zoom=DEFAULT_ZOOM, add_google_map=False)
            Map.add_basemap("HYBRID")
            # Add marker for the farm
            folium.Marker(
                location=[farm_lat, farm_lon],
                popup=f"Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}\nLat: {farm_lat:.4f}, Lon: {farm_lon:.4f}",
                tooltip=selected_farm_name,
                icon=folium.Icon(color='green')
            ).add_to(Map)
            Map.add_layer_control()
            Map.to_streamlit(height=600)
            st.stop() # Stop further processing if no images

        # Create a median composite image for visualization
        median_image = image_collection.median().clip(aoi) # Clip to AOI for cleaner display

    # --- Initialize Map ---
    Map = geemap.Map(location=[farm_lat, farm_lon], zoom=DEFAULT_ZOOM, add_google_map=False)
    Map.add_basemap("HYBRID") # Use Satellite Hybrid basemap

    # --- Add Layers to Map ---
    try:
        # Add RGB Layer
        Map.addLayer(median_image, rgb_vis, 'ØªØµÙˆÛŒØ± ÙˆØ§Ù‚Ø¹ÛŒ (RGB)')

        # Add Index Layers
        Map.addLayer(median_image.select('NDVI'), ndvi_vis, 'Ø´Ø§Ø®Øµ NDVI', True) # Show NDVI by default
        Map.addLayer(median_image.select('EVI'), evi_vis, 'Ø´Ø§Ø®Øµ EVI', False)
        Map.addLayer(median_image.select('NDMI'), ndmi_vis, 'Ø´Ø§Ø®Øµ Ø±Ø·ÙˆØ¨Øª NDMI', False)
        Map.addLayer(median_image.select('LAI'), lai_vis, 'Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (LAI ØªØ®Ù…ÛŒÙ†ÛŒ)', False)
        Map.addLayer(median_image.select('Biomass_Proxy'), biomass_proxy_vis, 'Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¨ÛŒÙˆÙ…Ø§Ø³ (Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± NDVI)', False)

        # Add marker for the selected farm
        folium.Marker(
            location=[farm_lat, farm_lon],
            popup=f"Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}\nLat: {farm_lat:.4f}, Lon: {farm_lon:.4f}",
            tooltip=selected_farm_name,
            icon=folium.Icon(color='red', icon='info-sign')
        ).add_to(Map)

        # Add AOI boundary (optional)
        Map.add_geojson(aoi.getInfo(), layer_name="Ù…Ø­Ø¯ÙˆØ¯Ù‡ ØªØ­Ù„ÛŒÙ„ (AOI)", style={'color': 'yellow', 'fillOpacity': 0.0})

        # Add Layer Control
        Map.add_layer_control()

        # Add Legends
        Map.add_legend(title="NDVI", builtin_legend='NDVI', palette=ndvi_vis['palette'])
        # Add other legends if needed, position them carefully
        # Map.add_legend(title="EVI", palette=evi_vis['palette'], min=evi_vis['min'], max=evi_vis['max'], position='bottomright')
        # Map.add_legend(title="NDMI", palette=ndmi_vis['palette'], min=ndmi_vis['min'], max=ndmi_vis['max'], position='bottomright')

        # --- Display Map ---
        Map.to_streamlit(height=600) # Adjust height as needed

    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ Ù†Ù…Ø§ÛŒØ´ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù†Ù‚Ø´Ù‡: {e}")
        st.error("Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ GEE ÛŒØ§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.")
    except Exception as e:
         st.error(f"ÛŒÚ© Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ø±Ø® Ø¯Ø§Ø¯: {e}")


    # --- Time Series Charts Section ---
    st.header("Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§")
    st.markdown(f"Ø±ÙˆÙ†Ø¯ ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ **{selected_farm_name}** Ø¯Ø± {DATE_RANGE_MONTHS} Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡")

    # Select indices for charting
    indices_to_chart = ['NDVI', 'EVI', 'NDMI', 'LAI', 'Biomass_Proxy']
    selected_indices = st.multiselect(
        "Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ù†Ù…ÙˆØ¯Ø§Ø±:",
        options=indices_to_chart,
        default=['NDVI', 'EVI'] # Default selections
    )

    if selected_indices:
        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ..."):
            try:
                # Use geemap's built-in charting capabilities if possible, or extract data
                # geemap's chart functions might require different setup for streamlit
                # Alternative: Extract data and plot with Streamlit/Altair/Plotly

                # Extract time series data
                ts_data = image_collection.select(selected_indices).map(lambda image: image.reduceRegion(
                    reducer=ee.Reducer.mean(),
                    geometry=aoi,
                    scale=30 # Adjust scale based on data resolution (10m for Sentinel-2 relevant bands)
                ).set('system:time_start', image.get('system:time_start')))

                # Filter out null results
                ts_data_filtered = ts_data.filter(ee.Filter.notNull(ts_data.first().keys()))

                # Get data to client-side (can be slow for long series/many indices)
                ts_list = ts_data_filtered.getInfo()['features']

                if not ts_list:
                    st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø± Ø§ÛŒÙ† Ø¯ÙˆØ±Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                else:
                    # Convert to Pandas DataFrame for easier plotting
                    data_for_df = []
                    for feature in ts_list:
                        props = feature['properties']
                        row = {'date': datetime.fromtimestamp(props['system:time_start'] / 1000.0)}
                        for index_name in selected_indices:
                            # Check if index exists in properties (might be null if calculation failed for that image)
                            row[index_name] = props.get(index_name)
                        data_for_df.append(row)

                    df_chart = pd.DataFrame(data_for_df)
                    df_chart = df_chart.set_index('date')
                    df_chart = df_chart.dropna(axis=1, how='all') # Drop columns if all values are NaN
                    df_chart = df_chart.dropna(axis=0, how='any') # Drop rows with any NaN for cleaner plot

                    if not df_chart.empty and not df_chart.columns.intersection(selected_indices).empty:
                         # Melt DataFrame for Altair/Streamlit native charts
                        df_melt = df_chart.reset_index().melt('date', var_name='Ø´Ø§Ø®Øµ', value_name='Ù…Ù‚Ø¯Ø§Ø±')

                        # Display line chart using Streamlit's native charting
                        st.line_chart(df_chart[selected_indices])

                        # Or use Altair for more customization (optional)
                        # import altair as alt
                        # chart = alt.Chart(df_melt).mark_line(point=True).encode(
                        #     x='date:T',
                        #     y='Ù…Ù‚Ø¯Ø§Ø±:Q',
                        #     color='Ø´Ø§Ø®Øµ:N',
                        #     tooltip=['date:T', 'Ø´Ø§Ø®Øµ:N', 'Ù…Ù‚Ø¯Ø§Ø±:Q']
                        # ).interactive()
                        # st.altair_chart(chart, use_container_width=True)

                        # Display data table
                        st.subheader("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±")
                        st.dataframe(df_chart.style.format("{:.3f}"))
                    else:
                         st.warning("Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


            except ee.EEException as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø² GEE: {e}")
            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø±: {e}")
    else:
        st.info("Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ø´Ø§Ø®Øµ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")

    # --- Farm Ranking Table (Placeholder/Simplified) ---
    # Note: Calculating indices for ALL farms dynamically can be very slow.
    # This section shows data for the SELECTED farm as an example.
    # A full ranking would require pre-calculation or a different architecture.
    st.header("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡)")
    try:
        # Calculate average values for the selected farm over the period
        mean_values = median_image.reduceRegion(
            reducer=ee.Reducer.mean(),
            geometry=aoi,
            scale=30 # Match chart scale
        ).getInfo() # GetInfo fetches the result

        if mean_values:
            # Prepare data for table display
            farm_summary_data = {
                "Ø´Ø§Ø®Øµ": list(mean_values.keys()),
                "Ù…Ù‚Ø¯Ø§Ø± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† (Ø¯Ø± Ø¯ÙˆØ±Ù‡)": [f"{v:.3f}" if isinstance(v, (int, float)) else v for v in mean_values.values()]
            }
            df_summary = pd.DataFrame(farm_summary_data)
            st.dataframe(df_summary)
        else:
            st.warning("Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ù‚Ø§Ø¨Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø¨ÙˆØ¯.")

    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„: {e}")
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø¨Ø®Ø´ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡: {e}")

    # --- Download Map (Placeholder) ---
    # Note: Downloading the current map view from geemap/folium within Streamlit
    # can be complex. Offering download of the composite image might be more feasible.
    # st.header("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ù‚Ø´Ù‡")
    # st.info("Ù‚Ø§Ø¨Ù„ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø³ØªÙ‚ÛŒÙ… Ù†Ù‚Ø´Ù‡ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª.")
    # Add a button to download the mean values data as CSV
    try:
        if 'df_summary' in locals() and not df_summary.empty:
             csv_summary = df_summary.to_csv(index=False).encode('utf-8')
             st.download_button(
                 label="Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø®Ù„Ø§ØµÙ‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (CSV)",
                 data=csv_summary,
                 file_name=f'summary_{selected_farm_name}_{selected_day}.csv',
                 mime='text/csv',
             )
    except NameError: # df_summary might not exist if calculation failed
         pass
    except Exception as e:
         st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ú©Ù…Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV: {e}")


# ==============================================================================
# Run the App
# ==============================================================================
if __name__ == "__main__":
    main()
