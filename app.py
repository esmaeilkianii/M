# --- START OF FILE app_chatbot_v2.py ---

import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
import plotly.express as px
import plotly.graph_objects as go
import os
from io import BytesIO
import requests
import traceback
from streamlit_folium import st_folium
import base64
import time
import math
import re # For simple text processing in chatbot

# --- Gemini API Integration ---
import google.generativeai as genai

# WARNING: Storing API keys directly in code is insecure!
GEMINI_API_KEY = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ" # <-- PASTE YOUR KEY HERE

# --- Constants ---
APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø± (Ù†Ø³Ø®Ù‡ Ú†Øªâ€ŒØ¨Ø§Øª Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡)"
CSV_FILE_PATH = 'cleaned_output.csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json' #<-- YOUR SERVICE ACCOUNT FILE
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12
INDEX_INFO = {
    "NDVI": {"name": "Ø´Ø§Ø®Øµ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ", "palette": 'RdYlGn', "min": 0.0, "max": 0.9, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø³Ø¨Ø² Ø¨ÛŒØ§Ù†Ú¯Ø± Ù…Ø­ØµÙˆÙ„ Ù…ØªØ±Ø§Ú©Ù… Ùˆ Ø³Ø§Ù„Ù… Ùˆ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡â€ŒÛŒ Ù…Ø­ØµÙˆÙ„ Ú©Ù…â€ŒÙ¾Ø´Øª Ùˆ Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡ Ø§Ø³Øª."},
    "NDWI": {"name": "Ø´Ø§Ø®Øµ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ú¯ÛŒØ§Ù‡Ø§Ù†", "palette": ['#d7191c', '#fdae61', '#ffffbf', '#abd9e9', '#2c7bb6'], "min": -0.2, "max": 0.6, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¢Ø¨ÛŒ Ø¨ÛŒØ´ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù…â€ŒØ¢Ø¨ÛŒ Ø§Ø³Øª."},
    "NDRE": {"name": "Ø´Ø§Ø®Øµ Ù…ÛŒØ²Ø§Ù† Ø§Ø²Øª Ú¯ÛŒØ§Ù‡ (Ù„Ø¨Ù‡ Ù‚Ø±Ù…Ø²)", "palette": 'Purples', "min": 0.0, "max": 0.6, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¨Ù†ÙØ´ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…ÛŒØ²Ø§Ù† Ø²ÛŒØ§Ø¯ Ø§Ø²Øª/Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ùˆ Ø±Ù†Ú¯ Ø±ÙˆØ´Ù†â€ŒØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ø§Ù‡Ø´ Ø¢Ù† Ø¯Ø± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª."},
    "LAI": {"name": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)", "palette": 'YlGn', "min": 0, "max": 7, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø³Ø¨Ø² Ù¾Ø±Ø±Ù†Ú¯â€ŒØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø³Øª."},
    "CHL": {"name": "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (ØªØ®Ù…ÛŒÙ†ÛŒ)", "palette": ['#b35806','#f1a340','#fee0b6','#d8daeb','#998ec3','#542788'], "min": 0, "max": 10, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¨Ù†ÙØ´/ØªÛŒØ±Ù‡ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª Ùˆ Ø±Ù†Ú¯ Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ/Ø±ÙˆØ´Ù† Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ø§Ù‡Ø´ Ú©Ù„Ø±ÙˆÙÛŒÙ„ ÛŒØ§ ØªÙ†Ø´ Ø§Ø³Øª."}
}
CHANGE_THRESHOLD = 0.03

# --- Page Config and CSS (unchanged) ---
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸŒ¾", layout="wide")
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');
        body, .main, button, input, textarea, select, .stTextInput, .stSelectbox, .stDateInput, .stButton>button, .stTabs [data-baseweb="tab"], .stMetric, .stDataFrame, .stPlotlyChart, .stChatMessage {
            font-family: 'Vazirmatn', sans-serif !important; direction: rtl;
        }
        .stBlock, .stHorizontalBlock { direction: rtl; }
        h1, h2, h3, h4, h5, h6 { text-align: right; color: #2c3e50; }
        .plotly .gtitle { text-align: right !important; }
        .stSelectbox > label, .stDateInput > label, .stTextInput > label, .stTextArea > label {
             text-align: right !important; width: 100%; display: block;
         }
        .dataframe { text-align: right; }
        .stTabs [data-baseweb="tab-list"] { gap: 5px; }
        .stTabs [data-baseweb="tab"] { height: 50px; padding: 10px 20px; background-color: #f0f2f6; border-radius: 8px 8px 0 0; font-weight: 600; }
        .stTabs [aria-selected="true"] { background-color: #e6f2ff; }
        .stMetric { background-color: #f8f9fa; border-radius: 10px; padding: 1rem; box-shadow: 0 2px 4px rgba(0,0,0,0.05); text-align: center;}
        .stMetric > label { font-weight: bold; color: #495057; }
        .stMetric > div { font-size: 1.5em; color: #007bff; }
        .css-1d391kg { direction: rtl; }
        .css-1d391kg .stSelectbox > label { text-align: right !important; }
        .stChatMessage[data-testid="chatAvatarIcon-user"] + div { order: 1; }
        .stChatMessage[data-testid="chatAvatarIcon-assistant"] + div { order: -1; }
        .stChatMessage div[data-testid="stChatMessageContent"] p { text-align: right; }
    </style>
""", unsafe_allow_html=True)

# --- Initialize Session State (unchanged) ---
if 'gee_initialized' not in st.session_state: st.session_state.gee_initialized = False
if 'farm_data' not in st.session_state: st.session_state.farm_data = None
if 'ranking_data' not in st.session_state: st.session_state.ranking_data = {'df': pd.DataFrame(), 'errors': [], 'params': None}
if 'gemini_analysis' not in st.session_state: st.session_state.gemini_analysis = {'text': None, 'error': None, 'params': None}
if 'gemini_available' not in st.session_state: st.session_state.gemini_available = False
if 'gemini_model' not in st.session_state: st.session_state.gemini_model = None
if "messages" not in st.session_state: st.session_state.messages = []

# --- GEE and Gemini Initialization (unchanged) ---
@st.cache_resource
def initialize_gee():
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE): st.error(f"'{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯."); return False
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized."); return True
    except Exception as e: st.error(f"GEE Init Error: {e}"); return False

@st.cache_resource
def configure_gemini():
    try:
        if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY": print("Gemini Key missing."); return None, False
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        print("Gemini Configured."); return model, True
    except Exception as e: print(f"Gemini Config Error: {e}"); st.warning(f"Gemini API Error: {e}"); return None, False

if not st.session_state.gee_initialized:
    st.session_state.gee_initialized = initialize_gee()
    if not st.session_state.gee_initialized: st.stop()

if st.session_state.gemini_model is None:
     st.session_state.gemini_model, st.session_state.gemini_available = configure_gemini()

# --- Load Farm Data (unchanged) ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...")
def load_farm_data(csv_path=CSV_FILE_PATH):
    try:
        df = pd.read_csv(csv_path)
        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'coordinates_missing']
        if not all(col in df.columns for col in required_cols): st.error(f"CSV ÙØ§Ù‚Ø¯ Ø³ØªÙˆÙ†: {required_cols}"); return None
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['coordinates_missing'] = df['coordinates_missing'].fillna(False).astype(bool)
        df = df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
        df = df[~df['coordinates_missing']]
        if df.empty: st.warning("Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ³Øª."); return None
        df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] = df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].astype(str).str.strip()
        df['farm_id'] = df['Ù…Ø²Ø±Ø¹Ù‡'] + '_' + df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].astype(str) + '_' + df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].astype(str)
        print(f"Farm data loaded: {len(df)} farms."); return df
    except FileNotFoundError: st.error(f"'{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯."); return None
    except Exception as e: st.error(f"CSV Load Error: {e}"); st.error(traceback.format_exc()); return None

if st.session_state.farm_data is None: st.session_state.farm_data = load_farm_data()
if st.session_state.farm_data is None: st.stop()

# ========================= Sidebar Inputs (unchanged) =========================
st.sidebar.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")
available_days = sorted(st.session_state.farm_data['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique())
selected_day = st.sidebar.selectbox("ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡:", options=available_days, index=available_days.index("Ø´Ù†Ø¨Ù‡") if "Ø´Ù†Ø¨Ù‡" in available_days else 0, key='sd_key')
filtered_farms_df = st.session_state.farm_data[st.session_state.farm_data['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()
if filtered_farms_df.empty: st.warning(f"Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ '{selected_day}' Ù†ÛŒØ³Øª."); st.stop()
available_farm_names_today = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique())
selected_farm_name = st.sidebar.selectbox("ğŸŒ¾ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡:", options=available_farm_names_today, index=0, key='sf_key')
selected_index = st.sidebar.selectbox("ğŸ“ˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø§Ø®Øµ:", options=list(INDEX_INFO.keys()), format_func=lambda x: f"{x} ({INDEX_INFO[x]['name']})", index=0, key='si_key')
index_props = INDEX_INFO[selected_index]
vis_params = {'min': index_props['min'], 'max': index_props['max'], 'palette': index_props['palette']}
today_date = datetime.date.today() # Renamed to avoid conflict
persian_to_weekday = {"Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1, "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4}
try:
    target_weekday = persian_to_weekday[selected_day]
    days_ago = (today_date.weekday() - target_weekday + 7) % 7
    end_date_current = today_date - datetime.timedelta(days=days_ago) if days_ago != 0 else today_date
    start_date_current = end_date_current - datetime.timedelta(days=6)
    end_date_previous = start_date_current - datetime.timedelta(days=1)
    start_date_previous = end_date_previous - datetime.timedelta(days=6)
    start_date_current_str = start_date_current.strftime('%Y-%m-%d')
    end_date_current_str = end_date_current.strftime('%Y-%m-%d')
    start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
    end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')
    st.sidebar.info(f"ğŸ—“ï¸ Ø¨Ø§Ø²Ù‡ ÙØ¹Ù„ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
    st.sidebar.info(f"ğŸ—“ï¸ Ø¨Ø§Ø²Ù‡ Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")
except KeyError: st.sidebar.error(f"Ø±ÙˆØ² '{selected_day}' Ù†Ø§Ù…Ø¹ØªØ¨Ø±."); st.stop()
except Exception as e: st.sidebar.error(f"Ø®Ø·Ø§ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}"); st.stop()

# ========================= GEE Functions (REVISED) =========================
# These functions now operate on and return ee.Image objects directly for server-side chaining.
# Caching is still applied to the logic of these functions.
@st.cache_data(persist="disk") # Cache the function logic
def maskS2clouds_ee(image: ee.Image) -> ee.Image:
    """Masks clouds in a Sentinel-2 SR image using the QA band and SCL. Operates on ee.Image."""
    qa = image.select('QA60')
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))
    scl = image.select('SCL')
    good_quality = scl.remap([4, 5, 6], [1, 1, 1], 0) # Keep Veg, Bare Soil, Water
    # Scale optical bands (Needed for index calculations)
    opticalBands = image.select('B.*').multiply(0.0001)
    return image.addBands(opticalBands, None, True).updateMask(mask).updateMask(good_quality)

@st.cache_data(persist="disk") # Cache the function logic
def add_indices_ee(image: ee.Image) -> ee.Image:
    """Calculates and adds NDVI, NDWI, NDRE, LAI, CHL bands. Operates on ee.Image."""
    try:
        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')
        ndwi = image.normalizedDifference(['B8', 'B11']).rename('NDWI')
        ndre = image.normalizedDifference(['B8', 'B5']).rename('NDRE')
        lai = ndvi.multiply(3.5).rename('LAI') # Simple empirical estimation
        re1_safe = image.select('B5').max(ee.Image(0.0001)) # Add small epsilon
        chl = image.expression('(NIR / RE1) - 1', {'NIR': image.select('B8'), 'RE1': re1_safe}).rename('CHL')
        return image.addBands([ndvi, ndwi, ndre, lai, chl])
    except Exception as e:
        # If an error occurs (e.g., missing band), return the image without added indices
        # This error should ideally be caught by GEE during computation.
        print(f"Warning: Could not calculate indices for an image: {e}")
        return image # Return original image if calculation fails

# This function fetches and processes the image collection, then serializes the final image.
@st.cache_data(ttl=3600, show_spinner=False, persist="disk")
def get_processed_image_serialized(_geometry_json, start_date, end_date, index_name):
    """
    Gets cloud-masked, index-calculated Sentinel-2 median composite.
    Input geometry as JSON, returns final Image serialized or error string.
    """
    _geometry = ee.Geometry(json.loads(_geometry_json))
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_geometry)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds_ee) # Apply cloud masking (server-side)
                     .map(add_indices_ee))  # Calculate indices (server-side)

        # Check if any images are available after filtering and processing
        count = s2_sr_col.size().getInfo() # getInfo() here to check count
        if count == 0:
            return None, f"No valid Sentinel-2 images found after processing for {start_date} to {end_date}."

        # Create a median composite image
        # Select all known indices before median to ensure availability if one is chosen later
        median_image = s2_sr_col.select(list(INDEX_INFO.keys())).median()

        # Final check if the specific index exists after median
        # This requires getInfo(), defer if possible or make it optional for performance
        # For now, we assume if processing was fine, index should be there.
        # band_names = median_image.bandNames().getInfo()
        # if index_name not in band_names:
        #      return None, f"Index '{index_name}' not present in final median. Available: {band_names}"

        output_image = median_image.select(index_name)

        # Serialize the GEE Image object for caching
        return output_image.serialize(), None

    except ee.EEException as e:
        error_message = f"GEE Error in get_processed_image: {e}"
        return None, error_message
    except Exception as e:
        error_message = f"Unknown Error in get_processed_image: {e}\n{traceback.format_exc()}"
        return None, error_message

# --- Function to get thumbnail URL (unchanged, uses serialized image) ---
@st.cache_data(ttl=3600, show_spinner="Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú©...")
def get_thumbnail_url(_image_serialized, _geometry_json, _vis_params):
    if not _image_serialized: return None, "No image data for thumbnail."
    try:
        image = ee.Image.deserialize(_image_serialized) # Deserialize here
        geometry = ee.Geometry(json.loads(_geometry_json))
        thumb_url = image.getThumbURL({'region': geometry.buffer(500).bounds(), 'dimensions': 256, 'params': _vis_params, 'format': 'png'})
        return thumb_url, None
    except Exception as e: return None, f"Thumbnail Error: {e}"

# --- Function to get time series (REVISED) ---
@st.cache_data(ttl=3600, show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ...")
def get_index_time_series_data(_point_geom_json, index_name, start_date, end_date):
    _point_geom = ee.Geometry(json.loads(_point_geom_json))
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_point_geom)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds_ee) # Server-side
                     .map(add_indices_ee))  # Server-side

        # Filter for images that actually have the index band after processing
        # This requires checking band names, which ideally happens on server if possible
        # For simplicity, we'll assume add_indices_ee handles this or rely on reduceRegion failure
        # A more robust filter: .filter(ee.Filter.listContains('system:band_names', index_name))

        def extract_value(image: ee.Image):
            # Ensure the image has the band before reducing (robustness)
            # This check is client-side after a map, so might be slow or better done differently
            # value = ee.Algorithms.If(image.bandNames().contains(index_name),
            #                         image.select(index_name).reduceRegion(reducer=ee.Reducer.first(), geometry=_point_geom, scale=10).get(index_name),
            #                         None) # Or some other placeholder
            value = image.select(index_name).reduceRegion(reducer=ee.Reducer.first(), geometry=_point_geom, scale=10).get(index_name)
            img_date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')
            return ee.Feature(None, {'date': img_date, index_name: value})

        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.notNull([index_name]))
        ts_info = ts_features.getInfo()['features'] # getInfo() to bring data to client

        if not ts_info: return None, f"No valid time series data points found for {index_name}."
        ts_data = [{'date': f['properties']['date'], index_name: f['properties'][index_name]} for f in ts_info]
        ts_df = pd.DataFrame(ts_data)
        ts_df['date'] = pd.to_datetime(ts_df['date'])
        ts_df = ts_df.sort_values('date').set_index('date')
        ts_df[index_name] = pd.to_numeric(ts_df[index_name], errors='coerce')
        ts_df.dropna(subset=[index_name], inplace=True)
        if ts_df.empty: return None, f"No valid numeric time series data for {index_name}."
        return ts_df.to_json(orient='split', date_format='iso'), None
    except ee.EEException as e: return None, f"GEE Time Series Error ({index_name}): {e}"
    except Exception as e: return None, f"Unknown Time Series Error ({index_name}): {e}"

# --- Function to calculate indices for ranking table (REVISED) ---
def calculate_all_farm_indices(farms_df, index_name, start_curr, end_curr, start_prev, end_prev):
    results = []
    errors = []
    total_farms = len(farms_df)
    with st.expander(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ {index_name} Ø¨Ø±Ø§ÛŒ {total_farms} Ù…Ø²Ø±Ø¹Ù‡...", expanded=True):
        progress_bar = st.progress(0)
        status_text = st.empty()
        for i, (idx, farm) in enumerate(farms_df.iterrows()):
            farm_name = farm['Ù…Ø²Ø±Ø¹Ù‡']
            lat = farm['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
            lon = farm['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
            point_geom = ee.Geometry.Point([lon, lat])
            point_geom_json = json.dumps(point_geom.getInfo()) # Serialize for cached function
            status_text.text(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø²Ø±Ø¹Ù‡ {i+1}/{total_farms}: {farm_name}")

            def get_mean_value_from_serialized(geom_json, start, end, idx_name):
                image_serialized, error_img = get_processed_image_serialized(geom_json, start, end, idx_name) # Use revised function
                if image_serialized:
                    try:
                        image = ee.Image.deserialize(image_serialized) # Deserialize GEE object
                        mean_dict = image.reduceRegion(
                            reducer=ee.Reducer.mean(),
                            geometry=ee.Geometry(json.loads(geom_json)), # Recreate geometry for reduceRegion
                            scale=10
                        ).getInfo() # Get the result
                        val = mean_dict.get(idx_name) if mean_dict else None
                        if val is None and mean_dict is not None: return None, f"'{idx_name}' not in reduceRegion."
                        elif val is None: return None, "ReduceRegion no result."
                        return val, None
                    except ee.EEException as e_reduce: return None, f"GEE Error in reduceRegion: {e_reduce}"
                    except Exception as e_other: return None, f"Unknown Error in reduceRegion: {e_other}"
                else: return None, error_img or "Image not found for processing."

            current_val, err_curr = get_mean_value_from_serialized(point_geom_json, start_curr, end_curr, index_name)
            if err_curr: errors.append(f"{farm_name} (Current): {err_curr}")
            previous_val, err_prev = get_mean_value_from_serialized(point_geom_json, start_prev, end_prev, index_name)
            if err_prev: errors.append(f"{farm_name} (Previous): {err_prev}")
            change = None
            if current_val is not None and previous_val is not None:
                try: change = float(current_val) - float(previous_val)
                except (TypeError, ValueError): change = None
            results.append({'farm_id': farm['farm_id'], 'Ù…Ø²Ø±Ø¹Ù‡': farm_name, 'Ú©Ø§Ù†Ø§Ù„': farm.get('Ú©Ø§Ù†Ø§Ù„', 'N/A'), 'Ø§Ø¯Ø§Ø±Ù‡': farm.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A'),
                           'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ': lon, 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ': lat, f'{index_name}_curr': current_val, f'{index_name}_prev': previous_val, f'{index_name}_change': change})
            progress_bar.progress((i + 1) / total_farms)
        status_text.text(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù…Ù„ Ø´Ø¯.")
        time.sleep(1)
    return pd.DataFrame(results), errors

# --- Gemini AI Analysis Function (unchanged) ---
@st.cache_data(show_spinner="ğŸ§  Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
def get_gemini_analysis(_index_name, _farm_name, _current_val, _previous_val, _change_val):
    if not st.session_state.gemini_available or st.session_state.gemini_model is None: return "AI API Error.", None
    try:
        if pd.isna(_current_val) or pd.isna(_previous_val) or pd.isna(_change_val) or \
           math.isnan(float(_current_val)) or math.isnan(float(_previous_val)) or math.isnan(float(_change_val)):
            return "Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„.", None
    except (TypeError, ValueError): return "Ø¯Ø§Ø¯Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±.", None
    current_str = f"{float(_current_val):.3f}"
    previous_str = f"{float(_previous_val):.3f}"
    change_str = f"{float(_change_val):.3f}"
    index_details = INDEX_INFO.get(_index_name, {"name": _index_name, "desc": ""})
    interpretation = f"Ø´Ø§Ø®Øµ {_index_name} ({index_details['name']}) {index_details['desc']}"
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ù‡Ø³ØªÛŒØ¯.
    Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ù†Ø§Ù… "{_farm_name}"ØŒ Ø´Ø§Ø®Øµ "{_index_name}" ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³Øª. {interpretation}
    Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ: {current_str}. Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„: {previous_str}. Ù…ÛŒØ²Ø§Ù† ØªØºÛŒÛŒØ±: {change_str}.

    ÙˆØ¸Ø§ÛŒÙ:
    1.  **ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª:** Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯Ù‚ÛŒÙ‚ ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ø¯Ø± Ø´Ø§Ø®Øµ {_index_name} Ú†Ù‡ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…ØªØŒ Ø±Ø´Ø¯ØŒ ÛŒØ§ ØªÙ†Ø´ (Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ø´Ø§Ø®Øµ) Ù†ÛŒØ´Ú©Ø± Ø¯Ø§Ø±Ø¯.
    2.  **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ùˆ Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®ØµØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
    3.  **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ùˆ Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®ØµØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©ÙˆØ¯Ø¯Ù‡ÛŒ (Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ Ù†ÛŒØªØ±ÙˆÚ˜Ù†) Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.

    Ù†Ú©Ø§Øª: ØªØ­Ù„ÛŒÙ„ ÙÙ‚Ø· Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯. Ø²Ø¨Ø§Ù† Ø±Ø³Ù…ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù…. Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ØªÙ…Ø±Ú©Ø². Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ.

    ÙØ±Ù…Øª Ù¾Ø§Ø³Ø®:
    **ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª:** [ØªÙˆØ¶ÛŒØ­ Ø´Ù…Ø§]
    **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** [Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ù…Ø§]
    **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ:** [Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ù…Ø§]
    """
    try:
        response = st.session_state.gemini_model.generate_content(prompt)
        analysis_text = response.text
        if not analysis_text or len(analysis_text) < 50: return "AI Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ø¯Ø§Ø¯.", None
        return analysis_text, None
    except Exception as e: return None, f"Gemini API Error: {e}"

# --- Chatbot Helper Function (unchanged) ---
def extract_farm_name(text, available_farms_list):
    farms_to_check = [f for f in available_farms_list if f != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"]
    for farm_name in farms_to_check:
        if farm_name in text: return farm_name
    return None

# ========================= Main Panel Layout (Map Tab REVISED for deserialization) =========================
st.title(APP_TITLE)
st.markdown(f"**Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§** | ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´: {datetime.date.today().strftime('%Y-%m-%d')}")
st.markdown("---")

selected_farm_details = None
selected_farm_geom = None
selected_farm_geom_json = None
if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
    st.info(f"Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {len(filtered_farms_df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø± Ø±ÙˆØ² **{selected_day}**.")
    try:
        min_lon, min_lat = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
        max_lon, max_lat = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(), filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
        selected_farm_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])
        selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo())
    except Exception: # Fallback
        center_lat = filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean(); center_lon = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean()
        selected_farm_geom = ee.Geometry.Point([center_lon, center_lat]); selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo())
else:
    selected_farm_details = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
    lat = selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']; lon = selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    selected_farm_geom = ee.Geometry.Point([lon, lat]); selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo())
    st.subheader(f"ğŸ“ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")
    cols = st.columns([1, 1, 1, 2])
    with cols[0]: st.metric("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", f"{selected_farm_details.get('Ù…Ø³Ø§Ø­Øª', '-'):,.2f}" if pd.notna(selected_farm_details.get('Ù…Ø³Ø§Ø­Øª')) else "-"); st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", f"{selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', '-')}")
    with cols[1]: st.metric("Ú©Ø§Ù†Ø§Ù„", f"{selected_farm_details.get('Ú©Ø§Ù†Ø§Ù„', '-')}"); st.metric("Ø³Ù†", f"{selected_farm_details.get('Ø³Ù†', '-')}")
    with cols[2]: st.metric("Ø§Ø¯Ø§Ø±Ù‡", f"{selected_farm_details.get('Ø§Ø¯Ø§Ø±Ù‡', '-')}"); st.metric("Ø±ÙˆØ² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", f"{selected_farm_details.get('Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', '-')}")
    with cols[3]:
        st.markdown("**ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú© (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ):**")
        if selected_farm_geom_json: # Ensure geometry is available
            thumb_image_serial, err_img = get_processed_image_serialized(selected_farm_geom_json, start_date_current_str, end_date_current_str, selected_index)
            if thumb_image_serial:
                thumb_url, err_thumb = get_thumbnail_url(thumb_image_serial, selected_farm_geom_json, vis_params)
                if thumb_url: st.image(thumb_url, caption=f"{selected_index}", width=200)
                elif err_thumb: st.warning(f"Ø®Ø·Ø§ Thumbnail: {err_thumb}")
            elif err_img: st.warning(f"Ø®Ø·Ø§ ØªØµÙˆÛŒØ±: {err_img}")
        else: st.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¨Ø±Ø§ÛŒ ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú© Ù†ÛŒØ³Øª.")


tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡", "ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ", "ğŸ“ˆ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ", " dashboards Ø®Ù„Ø§ØµÙ‡", "ğŸ’¬ Ú†Øªâ€ŒØ¨Ø§Øª"])

with tab1:
    st.subheader(f"Ù†Ù‚Ø´Ù‡ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ - Ø´Ø§Ø®Øµ: {selected_index}")
    m = geemap.Map(location=[INITIAL_LAT, INITIAL_LON], zoom=INITIAL_ZOOM, add_google_map=False)
    m.add_basemap("HYBRID")
    map_data_placeholder = st.empty()
    if selected_farm_geom_json:
        map_data_placeholder.info("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„Ø§ÛŒÙ‡ Ø´Ø§Ø®Øµ...")
        # Use the REVISED function that returns serialized image
        gee_image_serialized, error_msg_current = get_processed_image_serialized(
            selected_farm_geom_json, start_date_current_str, end_date_current_str, selected_index
        )
        if gee_image_serialized:
            try:
                gee_image_current = ee.Image.deserialize(gee_image_serialized) # Deserialize for map
                m.addLayer(gee_image_current, vis_params, f"{selected_index} ({start_date_current_str} to {end_date_current_str})")
                legend_title = f"{selected_index} ({index_props['name']})"
                m.add_legend(legend_title=legend_title, palette=index_props['palette'], min=index_props['min'], max=index_props['max']) # Geemap legend
                if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                    points = filtered_farms_df[['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ù…Ø²Ø±Ø¹Ù‡']].to_dict('records')
                    features = [{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [p['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], p['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']]}, 'properties': {'name': p['Ù…Ø²Ø±Ø¹Ù‡']}} for p in points]
                    farm_geojson = {'type': 'FeatureCollection', 'features': features}
                    m.add_geojson(farm_geojson, layer_name="Ù…Ø²Ø§Ø±Ø¹", info_mode='on_hover', style={'color': 'blue', 'fillColor': 'blue', 'opacity': 0.7, 'weight': 1, 'radius': 3})
                    if isinstance(selected_farm_geom, ee.geometry.Geometry): m.center_object(selected_farm_geom, zoom=INITIAL_ZOOM)
                else:
                    folium.Marker(location=[selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=f"<b>{selected_farm_name}</b>", tooltip=selected_farm_name, icon=folium.Icon(color='red', icon='star')).add_to(m)
                    if isinstance(selected_farm_geom, ee.geometry.Geometry): m.center_object(selected_farm_geom, zoom=15)
                m.add_layer_control()
                map_data_placeholder.empty()
                st_folium(m, width=None, height=600, use_container_width=True, key="map_tab_main")
            except Exception as map_err: map_data_placeholder.error(f"Ø®Ø·Ø§ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡: {map_err}\n{traceback.format_exc()}")
        else: map_data_placeholder.warning(f"ØªØµÙˆÛŒØ± Ù†Ù‚Ø´Ù‡ Ù†ÛŒØ³Øª. {error_msg_current}")
    else: map_data_placeholder.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ù†Ù‚Ø´Ù‡ Ù†ÛŒØ³Øª.")

# --- Ranking Table Tab (Tab 2 - Logic largely unchanged, relies on calculate_all_farm_indices) ---
with tab2:
    st.subheader(f"Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} ({selected_day})")
    st.markdown("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„.")
    ranking_params = (selected_index, start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str, selected_day)
    if st.session_state.ranking_data['params'] != ranking_params or st.session_state.ranking_data['df'].empty:
        print(f"Recalculating ranking table for: {ranking_params}")
        st.session_state.ranking_data = {'df': pd.DataFrame(), 'errors': [], 'params': None}
        with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹... Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯."):
            ranking_df_raw, calculation_errors = calculate_all_farm_indices(
                filtered_farms_df, selected_index, start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str)
        st.session_state.ranking_data['df'] = ranking_df_raw
        st.session_state.ranking_data['errors'] = calculation_errors
        st.session_state.ranking_data['params'] = ranking_params
        st.session_state.gemini_analysis = {'text': None, 'error': None, 'params': None}
        st.rerun() # Rerun to ensure new data is used by other tabs
    else:
        print("Using cached ranking data from session state.")
        ranking_df_raw = st.session_state.ranking_data['df']
        calculation_errors = st.session_state.ranking_data['errors']

    if not ranking_df_raw.empty:
        ranking_df_display = ranking_df_raw.copy()
        curr_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)'
        prev_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)'
        change_col = 'ØªØºÛŒÛŒØ±'
        ranking_df_display = ranking_df_display.rename(columns={f'{selected_index}_curr': curr_col, f'{selected_index}_prev': prev_col, f'{selected_index}_change': change_col})
        higher_is_better = index_props['higher_is_better']
        def determine_status_tab2(change_val): # Renamed to avoid conflict
            try:
                if pd.isna(change_val) or math.isnan(float(change_val)): return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
                change_val = float(change_val)
                if higher_is_better:
                    if change_val > CHANGE_THRESHOLD: return "ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯"
                    elif change_val < -CHANGE_THRESHOLD: return "ğŸ”´ Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´"
                    else: return "âšª Ø«Ø§Ø¨Øª"
                else:
                    if change_val < -CHANGE_THRESHOLD: return "ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯"
                    elif change_val > CHANGE_THRESHOLD: return "ğŸ”´ Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´"
                    else: return "âšª Ø«Ø§Ø¨Øª"
            except (TypeError, ValueError): return "Ø®Ø·Ø§ Ø¯Ø± Ù…Ù‚Ø¯Ø§Ø±"
        ranking_df_display['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_display[change_col].apply(determine_status_tab2)
        ranking_df_sorted = ranking_df_display.sort_values(by=curr_col, ascending=not higher_is_better, na_position='last').reset_index(drop=True)
        ranking_df_sorted.index = ranking_df_sorted.index + 1; ranking_df_sorted.index.name = 'Ø±ØªØ¨Ù‡'
        cols_to_format = [curr_col, prev_col, change_col]
        for col_name in cols_to_format: # Renamed loop variable
            if col_name in ranking_df_sorted.columns:
                ranking_df_sorted[col_name] = ranking_df_sorted[col_name].apply(lambda x: f"{float(x):.3f}" if pd.notna(x) and isinstance(x, (int, float)) else ("-" if pd.isna(x) else x))
        st.dataframe(ranking_df_sorted[['Ù…Ø²Ø±Ø¹Ù‡', 'Ú©Ø§Ù†Ø§Ù„', 'Ø§Ø¯Ø§Ø±Ù‡', curr_col, prev_col, change_col, 'ÙˆØ¶Ø¹ÛŒØª']], use_container_width=True, height=400)
        try:
            csv_data = ranking_df_sorted.to_csv(index=True, encoding='utf-8-sig')
            st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ (CSV)", data=csv_data, file_name=f'ranking_{selected_index}_{selected_day}.csv', mime='text/csv')
        except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯: {e}")
        if calculation_errors:
            with st.expander("âš ï¸ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡", expanded=False):
                unique_errors = sorted(list(set(calculation_errors)))
                st.warning(f"Ú©Ù„ Ø®Ø·Ø§Ù‡Ø§: {len(calculation_errors)}")
                for i, error in enumerate(unique_errors): st.error(f"- {error}");
                if i > 15: st.warning("..."); break
    else:
        st.info(f"Ø¯Ø§Ø¯Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ {selected_index} Ù†ÛŒØ³Øª.")
        if calculation_errors: st.error("Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ (Ø¨Ø§Ù„Ø§).")

# --- Time Series Tab (Tab 3 - Logic largely unchanged) ---
with tab3:
    st.subheader(f"Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index}")
    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹": st.info("ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
    elif selected_farm_geom_json:
        ts_end_date = today_date.strftime('%Y-%m-%d'); ts_start_date = (today_date - datetime.timedelta(days=365)).strftime('%Y-%m-%d')
        ts_df_json, ts_error = get_index_time_series_data(selected_farm_geom_json, selected_index, ts_start_date, ts_end_date)
        if ts_error: st.warning(f"Ø®Ø·Ø§ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}")
        elif ts_df_json:
            try:
                ts_df = pd.read_json(ts_df_json, orient='split'); ts_df.index = pd.to_datetime(ts_df.index, format='iso')
                if not ts_df.empty:
                    fig_ts = px.line(ts_df, y=selected_index, markers=True, title=f"Ø±ÙˆÙ†Ø¯ {selected_index} Ø¨Ø±Ø§ÛŒ {selected_farm_name}", labels={'index': 'ØªØ§Ø±ÛŒØ®', selected_index: f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                    fig_ts.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                    st.plotly_chart(fig_ts, use_container_width=True)
                    csv_ts = ts_df.to_csv(encoding='utf-8-sig')
                    st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ (CSV)", data=csv_ts, file_name=f'ts_{selected_farm_name}_{selected_index}.csv', mime='text/csv')
                else: st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ù†ÛŒØ³Øª.")
            except Exception as e_plot: st.error(f"Ø®Ø·Ø§ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±: {e_plot}")
        else: st.info(f"Ø¯Ø§Ø¯Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ù†ÛŒØ³Øª.")
    else: st.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ³Øª.")

# --- Dashboard Tab (Tab 4 - Logic largely unchanged) ---
with tab4:
    st.subheader(f"Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡ ({selected_day}) - Ø´Ø§Ø®Øµ: {selected_index}")
    ranking_df_raw_dash = st.session_state.ranking_data.get('df') # Renamed for clarity
    if ranking_df_raw_dash is None or ranking_df_raw_dash.empty: st.warning(f"Ø¯Ø§Ø¯Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ {selected_day} Ùˆ {selected_index} Ù†ÛŒØ³Øª. Ø¨Ù‡ ØªØ¨ 'Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ' Ø¨Ø±ÙˆÛŒØ¯.")
    else:
        df_dash = ranking_df_raw_dash.copy()
        curr_col_raw = f'{selected_index}_curr'; prev_col_raw = f'{selected_index}_prev'; change_col_raw = f'{selected_index}_change'
        df_dash[curr_col_raw] = pd.to_numeric(df_dash[curr_col_raw], errors='coerce')
        df_dash[prev_col_raw] = pd.to_numeric(df_dash[prev_col_raw], errors='coerce')
        df_dash[change_col_raw] = pd.to_numeric(df_dash[change_col_raw], errors='coerce')
        higher_is_better_dash = index_props['higher_is_better'] # Renamed
        def get_status_dashboard(change): # Renamed
            try:
                if pd.isna(change) or math.isnan(change): return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
                if higher_is_better_dash:
                    if change > CHANGE_THRESHOLD: return "Ø¨Ù‡Ø¨ÙˆØ¯"
                    elif change < -CHANGE_THRESHOLD: return "Ú©Ø§Ù‡Ø´"
                    else: return "Ø«Ø§Ø¨Øª"
                else:
                    if change < -CHANGE_THRESHOLD: return "Ø¨Ù‡Ø¨ÙˆØ¯"
                    elif change > CHANGE_THRESHOLD: return "Ú©Ø§Ù‡Ø´"
                    else: return "Ø«Ø§Ø¨Øª"
            except: return "Ø®Ø·Ø§"
        df_dash['status'] = df_dash[change_col_raw].apply(get_status_dashboard)
        status_counts = df_dash['status'].value_counts()
        st.markdown("**Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹:**")
        col1, col2, col3, col4 = st.columns(4)
        with col1: st.metric("ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯", status_counts.get("Ø¨Ù‡Ø¨ÙˆØ¯", 0))
        with col2: st.metric("âšª Ø«Ø§Ø¨Øª", status_counts.get("Ø«Ø§Ø¨Øª", 0))
        with col3: st.metric("ğŸ”´ Ú©Ø§Ù‡Ø´", status_counts.get("Ú©Ø§Ù‡Ø´", 0))
        with col4: st.metric("âš«ï¸ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", status_counts.get("Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", 0) + status_counts.get("Ø®Ø·Ø§", 0))
        st.markdown("---")
        col_plot1, col_plot2 = st.columns(2)
        with col_plot1:
            st.markdown(f"**ØªÙˆØ²ÛŒØ¹ Ù…Ù‚Ø§Ø¯ÛŒØ± {selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)**")
            hist_data = df_dash[curr_col_raw].dropna()
            if not hist_data.empty:
                fig_hist = px.histogram(hist_data, nbins=20, title=f"ØªÙˆØ²ÛŒØ¹ {selected_index}", labels={'value': f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                fig_hist.update_layout(yaxis_title="ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹", xaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                st.plotly_chart(fig_hist, use_container_width=True)
            else: st.info("Ø¯Ø§Ø¯Ù‡ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù†ÛŒØ³Øª.")
        with col_plot2:
            st.markdown("**Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ùˆ Ù‚Ø¨Ù„**")
            scatter_data = df_dash.dropna(subset=[curr_col_raw, prev_col_raw, 'status'])
            if not scatter_data.empty:
                fig_scatter = px.scatter(scatter_data, x=prev_col_raw, y=curr_col_raw, color='status', hover_name='Ù…Ø²Ø±Ø¹Ù‡', title=f"Ù…Ù‚Ø§ÛŒØ³Ù‡ {selected_index}", labels={prev_col_raw: f"{selected_index} (Ù‚Ø¨Ù„)", curr_col_raw: f"{selected_index} (Ø¬Ø§Ø±ÛŒ)", 'status': 'ÙˆØ¶Ø¹ÛŒØª'}, color_discrete_map={'Ø¨Ù‡Ø¨ÙˆØ¯': 'green', 'Ø«Ø§Ø¨Øª': 'grey', 'Ú©Ø§Ù‡Ø´': 'red', 'Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡': 'black', 'Ø®Ø·Ø§':'orange'})
                min_val_sc = min(scatter_data[prev_col_raw].min(), scatter_data[curr_col_raw].min()) if not scatter_data.empty else 0
                max_val_sc = max(scatter_data[prev_col_raw].max(), scatter_data[curr_col_raw].max()) if not scatter_data.empty else 1
                fig_scatter.add_shape(type='line', x0=min_val_sc, y0=min_val_sc, x1=max_val_sc, y1=max_val_sc, line=dict(color='rgba(0,0,0,0.5)', dash='dash'))
                fig_scatter.update_layout(xaxis_title=f"{selected_index} (Ù‚Ø¨Ù„)", yaxis_title=f"{selected_index} (Ø¬Ø§Ø±ÛŒ)", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                st.plotly_chart(fig_scatter, use_container_width=True)
            else: st.info("Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ Ù†ÛŒØ³Øª.")
        st.markdown("---")
        st.markdown("**Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø²Ø§Ø±Ø¹ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø¯Ø§Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ):**")
        df_sorted_dash = df_dash.sort_values(by=curr_col_raw, ascending=not higher_is_better_dash, na_position='last').dropna(subset=[curr_col_raw])
        col_top, col_bottom = st.columns(2)
        with col_top: st.markdown(f"**ğŸŸ¢ Ûµ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±ØªØ±**"); st.dataframe(df_sorted_dash[['Ù…Ø²Ø±Ø¹Ù‡', curr_col_raw, change_col_raw]].head(5).style.format({curr_col_raw: "{:.3f}", change_col_raw: "{:+.3f}"}), use_container_width=True)
        with col_bottom: st.markdown(f"**ğŸ”´ Ûµ Ù…Ø²Ø±Ø¹Ù‡ Ø¶Ø¹ÛŒÙâ€ŒØªØ±**"); st.dataframe(df_sorted_dash[['Ù…Ø²Ø±Ø¹Ù‡', curr_col_raw, change_col_raw]].tail(5).sort_values(by=curr_col_raw, ascending=not higher_is_better_dash).style.format({curr_col_raw: "{:.3f}", change_col_raw: "{:+.3f}"}), use_container_width=True)

# --- Chatbot Tab (Tab 5 - Logic largely unchanged) ---
with tab5:
    st.subheader("ğŸ’¬ Ú†Øªâ€ŒØ¨Ø§Øª ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
    st.info(f"Ø¯Ø± Ù…ÙˆØ±Ø¯ ÙˆØ¶Ø¹ÛŒØª ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² **{selected_day}** Ùˆ Ø¨Ø§ Ø´Ø§Ø®Øµ **{selected_index}** Ø¨Ù¾Ø±Ø³ÛŒØ¯. Ù…Ø«Ø§Ù„: 'ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ´Ú©Ø± Û± Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ'")
    st.warning("ØªÙˆØ¬Ù‡: Ù¾Ø§Ø³Ø® Ú†Øªâ€ŒØ¨Ø§Øª Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡â€ŒØ´Ø¯Ù‡ Ø¯Ø± ØªØ¨ 'Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ' ÙˆØ§Ø¨Ø³ØªÙ‡ Ø§Ø³Øª.", icon="âš ï¸")
    for message in st.session_state.messages:
        with st.chat_message(message["role"]): st.markdown(message["content"])
    if prompt := st.chat_input(f"Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ {selected_day} Ø¨Ù¾Ø±Ø³ÛŒØ¯..."):
        with st.chat_message("user"): st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        response = "Ù…ØªØ§Ø³ÙÙ…ØŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ø´Ø¯."
        extracted_farm = extract_farm_name(prompt, available_farm_names_today)
        if not st.session_state.gemini_available: response = "AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
        elif extracted_farm:
            ranking_df_chat = st.session_state.ranking_data.get('df') # Renamed
            if ranking_df_chat is None or ranking_df_chat.empty: response = f"Ø¯Ø§Ø¯Ù‡ {selected_index} Ø¨Ø±Ø§ÛŒ {selected_day} Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯Ù‡. Ø¨Ù‡ ØªØ¨ 'Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ' Ø¨Ø±ÙˆÛŒØ¯."
            else:
                farm_data_row_chat = ranking_df_chat[ranking_df_chat['Ù…Ø²Ø±Ø¹Ù‡'] == extracted_farm] # Renamed
                if not farm_data_row_chat.empty:
                    farm_row_chat = farm_data_row_chat.iloc[0] # Renamed
                    current_val = farm_row_chat.get(f'{selected_index}_curr')
                    previous_val = farm_row_chat.get(f'{selected_index}_prev')
                    change_val = farm_row_chat.get(f'{selected_index}_change')
                    analysis_text, analysis_error = get_gemini_analysis(selected_index, extracted_farm, current_val, previous_val, change_val)
                    if analysis_error: response = f"Ø®Ø·Ø§ ØªØ­Ù„ÛŒÙ„ {extracted_farm}: {analysis_error}"
                    elif analysis_text: response = f"**ØªØ­Ù„ÛŒÙ„ {extracted_farm} ({selected_index} Ø¨Ø±Ø§ÛŒ {selected_day}):**\n\n{analysis_text}"
                    else: response = f"ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ {extracted_farm} ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯."
                else: response = f"Ø¯Ø§Ø¯Ù‡ '{extracted_farm}' Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ù†ÛŒØ³Øª."
        else:
            response = "Ù†Ø§Ù… Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª. Ù…Ø«Ø§Ù„: "
            response += ", ".join([f for f in available_farm_names_today if f != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"][:5])
            if len(available_farm_names_today) > 6: response += "..."
        with st.chat_message("assistant"): st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

# --- Footer (unchanged) ---
st.markdown("---")
st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ ğŸ’» ØªÙˆØ³Ø· Ø§Ø³Ù…Ø§Ø¹ÛŒÙ„ Ú©ÛŒØ§Ù†ÛŒ")
st.sidebar.markdown("Streamlit | GEE | Geemap | Plotly | Gemini")
if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY": st.sidebar.error("ğŸš¨ Ú©Ù„ÛŒØ¯ Gemini Ù†ÛŒØ³Øª.")
elif st.session_state.gemini_available: st.sidebar.success("âœ… Gemini API ÙØ¹Ø§Ù„.")
else: st.sidebar.warning("âš ï¸ Gemini API ØºÛŒØ±ÙØ¹Ø§Ù„.")
st.sidebar.warning("Ù‡Ø´Ø¯Ø§Ø± Ø§Ù…Ù†ÛŒØªÛŒ: Ú©Ù„ÛŒØ¯ API Ø¯Ø± Ú©Ø¯ Ø§Ø³Øª.")

# --- END OF FILE ---