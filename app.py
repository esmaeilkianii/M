import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap # Import specifically for map creation
import folium
import json
import datetime
import plotly.express as px
import plotly.graph_objects as go
import os
from io import BytesIO
import requests
import traceback
from streamlit_folium import st_folium # For displaying folium maps in Streamlit
import base64
import time
import math
import re # For simple text processing in chatbot

# --- Gemini API Integration ---
import google.generativeai as genai

# WARNING: Storing API keys directly in code is insecure!
# Use environment variables or st.secrets in production.
GEMINI_API_KEY = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ" # <-- PASTE YOUR KEY HERE

# --- Constants ---
APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø± (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ)"
CSV_FILE_PATH = 'cleaned_output.csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json' #<-- YOUR SERVICE ACCOUNT JSON FILE
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12
INDEX_INFO = {
    "NDVI": {"name": "Ø´Ø§Ø®Øµ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ", "palette": 'RdYlGn', "min": 0.0, "max": 0.9, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø³Ø¨Ø² Ø¨ÛŒØ§Ù†Ú¯Ø± Ù…Ø­ØµÙˆÙ„ Ù…ØªØ±Ø§Ú©Ù… Ùˆ Ø³Ø§Ù„Ù… Ùˆ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡â€ŒÛŒ Ù…Ø­ØµÙˆÙ„ Ú©Ù…â€ŒÙ¾Ø´Øª Ùˆ Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡ Ø§Ø³Øª."},
    "NDWI": {"name": "Ø´Ø§Ø®Øµ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ú¯ÛŒØ§Ù‡Ø§Ù†", "palette": ['#d7191c', '#fdae61', '#ffffbf', '#abd9e9', '#2c7bb6'], "min": -0.2, "max": 0.6, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¢Ø¨ÛŒ Ø¨ÛŒØ´ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù…â€ŒØ¢Ø¨ÛŒ Ø§Ø³Øª."},
    "NDRE": {"name": "Ø´Ø§Ø®Øµ Ù…ÛŒØ²Ø§Ù† Ø§Ø²Øª Ú¯ÛŒØ§Ù‡ (Ù„Ø¨Ù‡ Ù‚Ø±Ù…Ø²)", "palette": 'Purples', "min": 0.0, "max": 0.6, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¨Ù†ÙØ´ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…ÛŒØ²Ø§Ù† Ø²ÛŒØ§Ø¯ Ø§Ø²Øª/Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ùˆ Ø±Ù†Ú¯ Ø±ÙˆØ´Ù†â€ŒØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ø§Ù‡Ø´ Ø¢Ù† Ø¯Ø± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª."},
    "LAI": {"name": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)", "palette": 'YlGn', "min": 0, "max": 7, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø³Ø¨Ø² Ù¾Ø±Ø±Ù†Ú¯â€ŒØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø³Øª."},
    "CHL": {"name": "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (ØªØ®Ù…ÛŒÙ†ÛŒ)", "palette": ['#b35806','#f1a340','#fee0b6','#d8daeb','#998ec3','#542788'], "min": 0, "max": 10, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¨Ù†ÙØ´/ØªÛŒØ±Ù‡ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª Ùˆ Ø±Ù†Ú¯ Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ/Ø±ÙˆØ´Ù† Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ø§Ù‡Ø´ Ú©Ù„Ø±ÙˆÙÛŒÙ„ ÛŒØ§ ØªÙ†Ø´ Ø§Ø³Øª."}
}
CHANGE_THRESHOLD = 0.03

# --- Page Config and CSS ---
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸŒ¾", layout="wide")

# Custom CSS for colored buttons and RTL layout
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');
        body, .main, button, input, textarea, select, .stTextInput, .stSelectbox, .stDateInput, .stButton>button, .stMetric, .stDataFrame, .stPlotlyChart, .stChatMessage {
            font-family: 'Vazirmatn', sans-serif !important; direction: rtl;
        }
        .stBlock, .stHorizontalBlock { direction: rtl; }
        h1, h2, h3, h4, h5, h6 { text-align: right; color: #2c3e50; }
        .plotly .gtitle { text-align: right !important; }
        .stSelectbox > label, .stDateInput > label, .stTextInput > label, .stTextArea > label {
             text-align: right !important; width: 100%; display: block;
         }
        .dataframe { text-align: right; }

        /* Style for the custom tab buttons container */
        .tab-buttons-container > div { /* Target the columns div */
            display: flex;
            flex-direction: row;
            gap: 5px; /* Space between buttons */
            justify-content: flex-end; /* Align buttons to the right */
            margin-bottom: 20px; /* Space below buttons */
        }

        /* Style for all custom tab buttons */
        .tab-buttons-container button {
            flex-grow: 0; /* Prevent buttons from growing */
            white-space: nowrap; /* Prevent text wrapping */
            padding: 10px 15px;
            border: none;
            border-radius: 8px 8px 0 0; /* Rounded top corners */
            cursor: pointer;
            font-weight: 600;
            transition: background-color 0.2s ease, transform 0.1s ease; /* Animation */
            color: white; /* Default text color */
            box-shadow: 0 2px 5px rgba(0,0,0,0.1); /* Subtle shadow */
        }

        /* Specific colors for each tab button */
        .tab-button-map button { background-color: #4CAF50; } /* Green */
        .tab-button-ranking button { background-color: #2196F3; } /* Blue */
        .tab-button-timeseries button { background-color: #ff9800; } /* Orange */
        .tab-button-dashboard button { background-color: #9C27B0; } /* Purple */
        .tab-button-chatbot button { background-color: #00BCD4; } /* Cyan */

        /* Active button style (example - requires a way to target the active one) */
        /* This part is tricky with pure CSS on Streamlit buttons */
        /* As a workaround, we'll rely on visual cues like lack of other buttons */
        /* or potentially slightly different shadow/border if needed */

        /* Hover effect */
        .tab-buttons-container button:hover {
            opacity: 0.9;
             transform: translateY(-2px); /* Slight lift effect */
        }

        .stMetric { background-color: #f8f9fa; border-radius: 10px; padding: 1rem; box-shadow: 0 2px 4px rgba(0,0,0,0.05); text-align: center;}
        .stMetric > label { font-weight: bold; color: #495057; }
        .stMetric > div { font-size: 1.5em; color: #007bff; }
        .css-1d391kg { direction: rtl; } /* Sidebar */
        .css-1d391kg .stSelectbox > label { text-align: right !important; } /* Sidebar select label */
        /* Chat message alignment for RTL */
        .stChatMessage[data-testid="chatAvatarIcon-user"] + div { order: 1; }
        .stChatMessage[data-testid="chatAvatarIcon-assistant"] + div { order: -1; }
        .stChatMessage div[data-testid="stChatMessageContent"] p { text-align: right; }
    </style>
""", unsafe_allow_html=True)

# --- Initialize Session State ---
if 'gee_initialized' not in st.session_state: st.session_state.gee_initialized = False
if 'farm_data' not in st.session_state: st.session_state.farm_data = None
if 'ranking_data' not in st.session_state: st.session_state.ranking_data = {'df': pd.DataFrame(), 'errors': [], 'params': None}
if 'gemini_analysis' not in st.session_state: st.session_state.gemini_analysis = {'text': None, 'error': None, 'params': None}
if 'gemini_available' not in st.session_state: st.session_state.gemini_available = False
if 'gemini_model' not in st.session_state: st.session_state.gemini_model = None
if "messages" not in st.session_state: st.session_state.messages = [] # For chatbot history
# Session state for custom tabs
if 'active_tab' not in st.session_state: st.session_state.active_tab = "ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡" # Default tab

# --- GEE and Gemini Initialization ---
@st.cache_resource
def initialize_gee():
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return False
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully.")
        return True
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error(traceback.format_exc())
        return False

@st.cache_resource
def configure_gemini():
    try:
        if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY":
             print("Gemini API Key not provided.")
             return None, False # Model, Available status
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash') # Use a fast model
        print("Gemini API Configured Successfully.")
        return model, True
    except Exception as e:
        print(f"Error configuring Gemini API: {e}")
        st.warning(f"âš ï¸ Ø§Ø®Ø·Ø§Ø±: Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Gemini API ({e}). ØªØ­Ù„ÛŒÙ„ Ùˆ Ú†Øªâ€ŒØ¨Ø§Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")
        st.warning(traceback.format_exc())
        return None, False

if not st.session_state.gee_initialized:
    st.session_state.gee_initialized = initialize_gee()
    if not st.session_state.gee_initialized:
        st.stop() # Stop execution if GEE initialization fails

if st.session_state.gemini_model is None: # Configure Gemini only once
     st.session_state.gemini_model, st.session_state.gemini_available = configure_gemini()

# --- Load Farm Data ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...")
def load_farm_data(csv_path=CSV_FILE_PATH):
    try:
        df = pd.read_csv(csv_path)
        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'coordinates_missing']
        if not all(col in df.columns for col in required_cols):
            st.error(f"âŒ ÙØ§ÛŒÙ„ CSV ÙØ§Ù‚Ø¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª: {', '.join(required_cols)}")
            return None
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['coordinates_missing'] = df['coordinates_missing'].fillna(False).astype(bool)
        df = df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
        df = df[~df['coordinates_missing']]
        if df.empty:
            st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ù…Ø²Ø±Ø¹Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return None
        df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] = df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].astype(str).str.strip()
        # Add a unique ID for potential joining later
        df['farm_id'] = df['Ù…Ø²Ø±Ø¹Ù‡'].astype(str) + '_' + df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].astype(str) + '_' + df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].astype(str)
        print(f"Farm data loaded successfully: {len(df)} farms.")
        return df
    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        st.error(traceback.format_exc())
        return None

if st.session_state.farm_data is None:
    st.session_state.farm_data = load_farm_data()

if st.session_state.farm_data is None: # Stop if data loading failed
    st.stop()

# ========================= Sidebar Inputs =========================
st.sidebar.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

available_days = sorted(st.session_state.farm_data['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique())
selected_day = st.sidebar.selectbox(
    "ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡:", options=available_days,
    index=available_days.index("Ø´Ù†Ø¨Ù‡") if "Ø´Ù†Ø¨Ù‡" in available_days else 0, # Default to Saturday if exists
    key='selected_day_key'
)

filtered_farms_df = st.session_state.farm_data[st.session_state.farm_data['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()

if filtered_farms_df.empty:
    st.warning(f"âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    st.stop()

available_farm_names_today = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique())
selected_farm_name = st.sidebar.selectbox(
    "ğŸŒ¾ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡:", options=available_farm_names_today, index=0, key='selected_farm_key'
)

selected_index = st.sidebar.selectbox(
    "ğŸ“ˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø§Ø®Øµ:", options=list(INDEX_INFO.keys()),
    format_func=lambda x: f"{x} ({INDEX_INFO[x]['name']})", index=0, key='selected_index_key'
)
index_props = INDEX_INFO[selected_index]
vis_params = {'min': index_props['min'], 'max': index_props['max'], 'palette': index_props['palette']}

# --- Date Range Calculation ---
today_date_obj = datetime.date.today() # Renamed to avoid conflict
persian_to_weekday = {"Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1, "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4}
try:
    target_weekday = persian_to_weekday[selected_day]
    # Calculate days ago, ensuring it's non-negative and finds the most recent past occurrence
    today_weekday = today_date_obj.weekday()
    days_ago = (today_weekday - target_weekday + 7) % 7
    # If today is the target day, days_ago is 0. If the target day is in the future this week,
    # we need to go back to the target day of the *previous* week.
    # Let's adjust to always get the range ending on or before today.
    # Find the date of the most recent target_weekday on or before today_date_obj
    end_date_current = today_date_obj - datetime.timedelta(days=(today_weekday - target_weekday + 7) % 7)
    start_date_current = end_date_current - datetime.timedelta(days=6)

    end_date_previous = start_date_current - datetime.timedelta(days=1)
    start_date_previous = end_date_previous - datetime.timedelta(days=6)

    start_date_current_str = start_date_current.strftime('%Y-%m-%d')
    end_date_current_str = end_date_current.strftime('%Y-%m-%d')
    start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
    end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')

    st.sidebar.info(f"ğŸ—“ï¸ Ø¨Ø§Ø²Ù‡ ÙØ¹Ù„ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
    st.sidebar.info(f"ğŸ—“ï¸ Ø¨Ø§Ø²Ù‡ Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")
except KeyError: st.sidebar.error(f"Ù†Ø§Ù… Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª."); st.stop()
except Exception as e: st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}"); st.stop()


# ========================= GEE Functions (REVISED for ee.Image operations) =========================
@st.cache_data(persist="disk")
def maskS2clouds_ee(_image: ee.Image) -> ee.Image:
    try:
        qa = _image.select('QA60')
        cloudBitMask = 1 << 10; cirrusBitMask = 1 << 11
        mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))
        # Also consider the Scene Classification Layer (SCL) for more robust cloud/shadow masking
        scl = _image.select('SCL')
        # Pixels to mask out: clouds, shadows, snow/ice, cirrus, saturated
        scl_mask = scl.remap([3, 8, 9, 10, 11], [0, 0, 0, 0, 0], 1) # 3: cloud shadow, 8: cloud medium probability, 9: cloud high probability, 10: cirrus, 11: snow/ice
        # Combine QA60 mask with SCL mask
        final_mask = mask.And(scl_mask)

        # Apply scaling factor and mask
        opticalBands = _image.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12']).multiply(0.0001) # Apply scaling to relevant bands
        # Keep other bands (like QA60, SCL) without scaling if needed, or drop them
        otherBands = _image.select(['QA60', 'SCL']) # Select bands you want to keep unscaled
        # Update masked bands with scaled values, keep others as they are
        return _image.addBands(opticalBands, None, True).updateMask(final_mask).addBands(otherBands, None, True)

    except Exception as e:
        # In a mapped function, printing/logging is limited. Server-side errors are best debugged
        # using GEE's Code Editor or inspecting task errors.
        # This print won't appear in Streamlit logs for mapped functions.
        print(f"Error in maskS2clouds_ee: {e}")
        # Returning the original image or an indicator might be alternatives,
        # but ideally, mapped functions should handle errors gracefully within GEE.
        # For now, let's return the original image unmasked in case of an error in masking itself.
        return _image # Or raise a GEE error if appropriate


@st.cache_data(persist="disk")
def add_indices_ee(_image: ee.Image) -> ee.Image:
    try:
        # Calculate indices directly; missing bands will result in masked values
        ndvi = _image.normalizedDifference(['B8', 'B4']).rename('NDVI')
        ndwi = _image.normalizedDifference(['B8', 'B11']).rename('NDWI')
        ndre = _image.normalizedDifference(['B8', 'B5']).rename('NDRE')
        lai = ndvi.multiply(3.5).rename('LAI')
        chl = _image.expression(
            '(NIR / RE1) - 1',
            {
                'NIR': _image.select('B8'),
                'RE1': _image.select('B5').max(ee.Image(0.0001))
            }
        ).clamp(0, 10).rename('CHL')
        # Add all calculated indices; if bands are missing, the result will be masked
        return _image.addBands([ndvi, ndwi, ndre, lai, chl], None, True)
    except Exception as e:
        print(f"Warning: Index calculation failed for an image: {e}")
        return _image


@st.cache_data(ttl=3600, show_spinner=False, persist="disk")
def get_processed_image_serialized(_geometry_json, start_date, end_date, index_name):
    _geometry = ee.Geometry(json.loads(_geometry_json))
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_geometry)
                     .filterDate(start_date, end_date)
                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) # Filter by cloud percentage
                     .map(maskS2clouds_ee)
                     .map(add_indices_ee)
                    )

        count = s2_sr_col.size().getInfo()
        if count == 0: return None, f"No valid images after processing ({start_date} to {end_date}). Consider adjusting date range or cloud filter."

        # Select only the bands needed before taking the median to potentially reduce memory
        all_indices_bands = list(INDEX_INFO.keys())
        s2_sr_col = s2_sr_col.select(all_indices_bands)

        median_image = s2_sr_col.median()

        # Ensure the selected index band exists in the median image
        available_bands_in_median = median_image.bandNames().getInfo()
        if index_name not in available_bands_in_median:
             # This might happen if add_indices_ee failed for all images in the collection
             return None, f"Ø´Ø§Ø®Øµ '{index_name}' Ø¯Ø± ØªØµÙˆÛŒØ± median Ù†Ù‡Ø§ÛŒÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø¨Ø§Ù†Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {available_bands_in_median}. (Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø®Ø§Ù… Ø¨Ø§Ø´Ø¯)"

        output_image = median_image.select(index_name)

        # Mask the output image to the geometry bounds explicitly
        output_image = output_image.clip(_geometry)

        return output_image.serialize(), None

    except ee.EEException as e:
        # Specific GEE errors can be caught here
        return None, f"GEE Error (get_processed_image): {e}"
    except Exception as e:
        # Other potential errors during processing
        return None, f"Unknown Error (get_processed_image): {e}\n{traceback.format_exc()}"

@st.cache_data(ttl=3600, show_spinner="Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú©...")
def get_thumbnail_url(_image_serialized, _geometry_json, _vis_params):
    if not _image_serialized: return None, "No image data for thumbnail."
    try:
        image = ee.Image.deserialize(_image_serialized)
        geometry = ee.Geometry(json.loads(_geometry_json))
        # Use the geometry bounds for the thumbnail region
        thumb_region = geometry.bounds()
        thumb_url = image.getThumbURL({'region': thumb_region, 'dimensions': 256, 'params': _vis_params, 'format': 'png'})
        return thumb_url, None
    except Exception as e: return None, f"Thumbnail Error: {e}"

@st.cache_data(ttl=3600, show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ...")
def get_index_time_series_data(_point_geom_json, index_name, start_date, end_date):
    _point_geom = ee.Geometry(json.loads(_point_geom_json))
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_point_geom)
                     .filterDate(start_date, end_date)
                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) # Filter by cloud percentage
                     .map(maskS2clouds_ee)
                     .map(add_indices_ee)
                     .select([index_name]) # Select the specific index band
                    )

        # Function to extract value at point, designed for server-side map
        def extract_value(image: ee.Image):
            # Ensure the selected band exists before reducing
            if index_name not in image.bandNames().getInfo():
                 # Skip this image if the band is missing
                 return None # GEE map will filter out None results with filter(ee.Filter.notNull())

            # Reduce the image value at the point
            value_dict = image.reduceRegion(
                reducer=ee.Reducer.first(), # Use first() for a single point
                geometry=_point_geom,
                scale=10, # Set a suitable scale
                bestEffort=True, # Use bestEffort for flexible scaling
                maxPixels=1e4 # Limit max pixels
            )

            # Get the value and date
            value = value_dict.get(index_name)
            img_date = image.date().format('YYYY-MM-dd') # Use image.date()

            # Return a Feature with date and value if value is not null
            return ee.Feature(None, {'date': img_date, index_name: value})

        # Map the function and filter out failed results
        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.notNull([index_name]))

        # Get info client-side
        ts_info = ts_features.getInfo()['features']

        if not ts_info: return None, f"No valid time series data points for {index_name}."

        # Convert features to DataFrame
        ts_data = [{'date': f['properties']['date'], index_name: f['properties'][index_name]} for f in ts_info]
        ts_df = pd.DataFrame(ts_data); ts_df['date'] = pd.to_datetime(ts_df['date'])
        ts_df = ts_df.sort_values('date').set_index('date')
        ts_df[index_name] = pd.to_numeric(ts_df[index_name], errors='coerce')
        ts_df.dropna(subset=[index_name], inplace=True)

        if ts_df.empty: return None, f"No valid numeric time series for {index_name}."

        return ts_df.to_json(orient='split', date_format='iso'), None

    except ee.EEException as e: return None, f"GEE Time Series Error ({index_name}): {e}"
    except Exception as e: return None, f"Unknown Time Series Error ({index_name}): {e}\n{traceback.format_exc()}"


def calculate_all_farm_indices(farms_df, index_name, start_curr, end_curr, start_prev, end_prev):
    results = []; errors = []; total_farms = len(farms_df)
    st.markdown(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ {index_name} Ø¨Ø±Ø§ÛŒ {total_farms} Ù…Ø²Ø±Ø¹Ù‡...")
    progress_bar = st.progress(0); status_text = st.empty() # Use empty for dynamic text updates

    # Define a helper function to get mean value from serialized image
    def get_mean_value_from_serialized(geom_json, start, end, idx_name):
        image_serialized, error_img = get_processed_image_serialized(geom_json, start, end, idx_name)
        if image_serialized:
            try:
                image = ee.Image.deserialize(image_serialized)
                # Reduce the image over the point geometry
                mean_dict = image.reduceRegion(
                    reducer=ee.Reducer.mean(),
                    geometry=ee.Geometry(json.loads(geom_json)), # Use the geometry JSON
                    scale=10, # Set a suitable scale
                    bestEffort=True,
                    maxPixels=1e4
                ).getInfo() # Use getInfo() to fetch the result

                val = mean_dict.get(idx_name) if mean_dict else None
                # Check for None explicitly as the value could be 0.
                if val is None and mean_dict is not None:
                    return None, f"'{idx_name}' not in reduceRegion result dictionary."
                elif val is None:
                     return None, "ReduceRegion returned None (possible no pixels in geometry at scale)."

                # Convert to float if possible
                try:
                    return float(val), None
                except (ValueError, TypeError):
                    return None, f"Could not convert reduced value '{val}' to float."

            except ee.EEException as e_reduce:
                 # GEE specific error during reduceRegion
                 return None, f"GEE Error during reduceRegion: {e_reduce}"
            except Exception as e_other:
                 # Other Python errors during processing
                 return None, f"Unknown Error during reduceRegion or deserialization: {e_other}"
        else:
            # Error from get_processed_image_serialized itself
            return None, error_img or "Image not found for processing."

    for i, (idx, farm) in enumerate(farms_df.iterrows()):
        farm_name = farm['Ù…Ø²Ø±Ø¹Ù‡']; lat = farm['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']; lon = farm['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
        # Create a point geometry for reduction. For a farm area, you might use a polygon geometry.
        # Assuming point reduction for now based on the provided coordinates structure.
        # If farms are polygons, the CSV needs polygon GeoJSON or WKT.
        point_geom = ee.Geometry.Point([lon, lat]); point_geom_json = json.dumps(point_geom.getInfo())

        status_text.text(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø²Ø±Ø¹Ù‡ {i+1}/{total_farms}: {farm_name}")

        # Get current and previous values using the helper function
        current_val, err_curr = get_mean_value_from_serialized(point_geom_json, start_curr, end_curr, index_name)
        if err_curr: errors.append(f"{farm_name} (Ø¬Ø§Ø±ÛŒ): {err_curr}")

        previous_val, err_prev = get_mean_value_from_serialized(point_geom_json, start_prev, end_prev, index_name)
        if err_prev: errors.append(f"{farm_name} (Ù‚Ø¨Ù„): {err_prev}")

        change = None
        if current_val is not None and previous_val is not None:
            try:
                change = float(current_val) - float(previous_val)
            except (TypeError, ValueError):
                change = None # Keep change as None if values are not numeric

        results.append({'farm_id': farm['farm_id'], 'Ù…Ø²Ø±Ø¹Ù‡': farm_name, 'Ú©Ø§Ù†Ø§Ù„': farm.get('Ú©Ø§Ù†Ø§Ù„', 'N/A'), 'Ø§Ø¯Ø§Ø±Ù‡': farm.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A'),
                       'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ': lon, 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ': lat, f'{index_name}_curr': current_val, f'{index_name}_prev': previous_val, f'{index_name}_change': change})

        progress_bar.progress((i + 1) / total_farms)

    status_text.text(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù…Ù„ Ø´Ø¯."); time.sleep(1) # Keep final status for a moment
    progress_bar.empty() # Hide progress bar after completion
    status_text.empty() # Hide status text after completion

    return pd.DataFrame(results), errors

@st.cache_data(show_spinner="ğŸ§  Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
def get_gemini_analysis(_index_name, _farm_name, _current_val, _previous_val, _change_val):
    if not st.session_state.gemini_available or st.session_state.gemini_model is None: return "AI API Error.", None
    # Check if input values are valid numbers (not NaN or None)
    try:
        if pd.isna(_current_val) or pd.isna(_previous_val) or pd.isna(_change_val) or \
           not isinstance(_current_val, (int, float)) or not isinstance(_previous_val, (int, float)) or not isinstance(_change_val, (int, float)):
            return "Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ (Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¹Ø¯Ø¯ÛŒ Ù†ÛŒØ³ØªÙ†Ø¯).", None
    except Exception:
        return "Ø¯Ø§Ø¯Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± (Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡).", None

    current_str = f"{float(_current_val):.3f}"; previous_str = f"{float(_previous_val):.3f}"; change_str = f"{float(_change_val):+.3f}" # Add + for positive change
    index_details = INDEX_INFO.get(_index_name, {"name": _index_name, "desc": ""})
    interpretation = f"Ø´Ø§Ø®Øµ {_index_name} ({index_details.get('name', '')}). Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®Øµ: {index_details.get('desc', 'ØªÙˆØ¶ÛŒØ­ÛŒ Ù†ÛŒØ³Øª.')}"

    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ù‡Ø³ØªÛŒØ¯.
    Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ù†Ø§Ù… "{_farm_name}"ØŒ Ø´Ø§Ø®Øµ "{_index_name}" ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³Øª. {interpretation}
    Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ: {current_str}. Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„: {previous_str}. Ù…ÛŒØ²Ø§Ù† ØªØºÛŒÛŒØ±: {change_str}.
    Ø¢ÛŒØ§ Ù…Ù‚Ø¯Ø§Ø± Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ø§ÛŒÙ† Ø´Ø§Ø®Øµ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ØªØ± Ù…Ø­ØµÙˆÙ„ Ø§Ø³ØªØŸ {'Ø¨Ù„Ù‡' if index_details.get('higher_is_better', False) else 'Ø®ÛŒØ±'}.

    ÙˆØ¸Ø§ÛŒÙ:
    1.  **ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª:** Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯Ù‚ÛŒÙ‚ ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ø¯Ø± Ø´Ø§Ø®Øµ {_index_name} (Ø§ÙØ²Ø§ÛŒØ´ØŒ Ú©Ø§Ù‡Ø´ØŒ ÛŒØ§ Ø«Ø¨Ø§Øª) Ú†Ù‡ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…ØªØŒ Ø±Ø´Ø¯ØŒ ÛŒØ§ ØªÙ†Ø´ (Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®Øµ) Ù†ÛŒØ´Ú©Ø± Ø¯Ø± Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø§Ø±Ø¯. Ø¨Ù‡ Ø§ÛŒÙ† Ù†Ú©ØªÙ‡ Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø¢ÛŒØ§ ØªØºÛŒÛŒØ± Ù…Ø«Ø¨Øª Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ø³Øª ÛŒØ§ Ø®ÛŒØ± (Ø¨Ø± Ø§Ø³Ø§Ø³ 'Ø¢ÛŒØ§ Ù…Ù‚Ø¯Ø§Ø± Ø¨ÛŒØ´ØªØ± ...').
    2.  **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ùˆ Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®ØµØŒ ÛŒÚ© ÛŒØ§ Ø¯Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„ÛŒ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ (Ù…Ø§Ù†Ù†Ø¯ Ø¢Ø¨ÛŒØ§Ø±ÛŒØŒ Ú©ÙˆØ¯Ø¯Ù‡ÛŒØŒ Ù¾Ø§ÛŒØ´ Ø¨ÛŒØ´ØªØ±) Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.

    Ù†Ú©Ø§Øª: ØªØ­Ù„ÛŒÙ„ ÙÙ‚Ø· Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯. Ø²Ø¨Ø§Ù† Ø±Ø³Ù…ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù…. Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ØªÙ…Ø±Ú©Ø² (Ø­Ø¯ÙˆØ¯ Û±Û°Û°-Û±ÛµÛ° Ú©Ù„Ù…Ù‡). Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ. Ø§Ø² ØªÙˆØ¶ÛŒØ­ Ù…ÙØ§Ù‡ÛŒÙ… Ù¾Ø§ÛŒÙ‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯ Ù…Ú¯Ø± Ø¯Ø± Ø­Ø¯ Ø§Ø´Ø§Ø±Ù‡ Ú©ÙˆØªØ§Ù‡.

    ÙØ±Ù…Øª Ù¾Ø§Ø³Ø®:
    **ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª:** [ØªÙˆØ¶ÛŒØ­ Ø´Ù…Ø§]
    **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ:** [Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ù…Ø§]"""

    try:
        response = st.session_state.gemini_model.generate_content(prompt)
        analysis_text = response.text
        if not analysis_text or len(analysis_text.strip()) < 50: return "AI Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ ÛŒØ§ Ù†Ø§Ù…ÙÙ‡ÙˆÙ… Ø¯Ø§Ø¯.", None
        return analysis_text.strip(), None
    except Exception as e:
        print(f"Gemini API Error during analysis: {e}")
        return None, f"Gemini API Error: {e}"

def extract_farm_name(text, available_farms_list):
    # Clean and normalize farm names and input text for better matching
    def normalize(name):
        # Remove common punctuation and potentially extra spaces
        name = re.sub(r'[^\w\s]', '', name)
        name = re.sub(r'\s+', ' ', name).strip().lower()
        return name

    normalized_text = normalize(text)
    normalized_farms = {normalize(name): name for name in available_farms_list if name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"}

    # Try exact match first
    if normalized_text in normalized_farms:
        return normalized_farms[normalized_text]

    # Then try partial matching (less reliable)
    for normalized_farm, original_farm in normalized_farms.items():
        # Check if a significant part of the farm name is in the text
        if normalized_farm in normalized_text or normalized_text in normalized_farm:
            return original_farm # Return the original farm name from the list

    # If no match, return None
    return None


# ========================= Main Panel Layout =========================
st.title(APP_TITLE)
st.markdown(f"**Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§** | ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´: {today_date_obj.strftime('%Y-%m-%d')}")
st.markdown("---")

selected_farm_details = None; selected_farm_geom = None; selected_farm_geom_json = None
if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
    st.info(f"Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {len(filtered_farms_df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø± Ø±ÙˆØ² **{selected_day}**.")
    try:
        # Create a bounding box for all farms for the map center/bounds
        min_lon, min_lat = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
        max_lon, max_lat = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(), filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
        # Ensure valid coordinates before creating geometry
        if pd.notna(min_lon) and pd.notna(min_lat) and pd.notna(max_lon) and pd.notna(max_lat):
            selected_farm_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])
            selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo())
        else:
             # Fallback to a point geometry if bounds are invalid
             center_lat = filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean(); center_lon = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean()
             selected_farm_geom = ee.Geometry.Point([center_lon, center_lat])
             selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo())
             st.warning("âš ï¸ Ù…Ø®ØªØµØ§Øª Ø¨Ø±Ø®ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª. Ù†Ù…Ø§ÛŒØ´Ú¯Ø± Ù†Ù‚Ø´Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù‚Ø·Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")

    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¹ÛŒÛŒÙ† Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù†Ù‚Ø´Ù‡ Ø¨Ø±Ø§ÛŒ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹': {e}")
        # Fallback to a point geometry
        center_lat = filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean(); center_lon = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean()
        selected_farm_geom = ee.Geometry.Point([center_lon, center_lat])
        selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo())
        st.warning("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ¹ÛŒÛŒÙ† Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù†Ù‚Ø´Ù‡. Ù†Ù…Ø§ÛŒØ´Ú¯Ø± Ù†Ù‚Ø´Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù‚Ø·Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")

else:
    # Select the specific farm details
    farm_row_index = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].index
    if not farm_row_index.empty:
        selected_farm_details = filtered_farms_df.loc[farm_row_index[0]] # Use .loc for row selection
        lat = selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']; lon = selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
        # Ensure coordinates are valid numbers
        if pd.notna(lat) and pd.notna(lon):
             selected_farm_geom = ee.Geometry.Point([lon, lat])
             selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo())
        else:
             st.error(f"âŒ Ù…Ø®ØªØµØ§Øª Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
             selected_farm_geom = None
             selected_farm_geom_json = None
    else:
        st.error(f"âŒ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        selected_farm_geom = None
        selected_farm_geom_json = None

    # Display farm details if a specific farm is selected and found
    if selected_farm_details is not None:
        st.subheader(f"ğŸ“ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")
        cols = st.columns([1, 1, 1, 2])
        with cols[0]: st.metric("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", f"{selected_farm_details.get('Ù…Ø³Ø§Ø­Øª', '-'):,.2f}" if pd.notna(selected_farm_details.get('Ù…Ø³Ø§Ø­Øª')) else "-"); st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", f"{selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', '-')}")
        with cols[1]: st.metric("Ú©Ø§Ù†Ø§Ù„", f"{selected_farm_details.get('Ú©Ø§Ù†Ø§Ù„', '-')}"); st.metric("Ø³Ù†", f"{selected_farm_details.get('Ø³Ù†', '-')}")
        with cols[2]: st.metric("Ø§Ø¯Ø§Ø±Ù‡", f"{selected_farm_details.get('Ø§Ø¯Ø§Ø±Ù‡', '-')}"); st.metric("Ø±ÙˆØ² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", f"{selected_farm_details.get('Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', '-')}")
        with cols[3]:
            st.markdown("**ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú© (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ):**")
            if selected_farm_geom_json:
                # Use a smaller buffer for point geometries in thumbnail
                thumbnail_geom = ee.Geometry(json.loads(selected_farm_geom_json))
                # If it's a point, buffer it slightly for thumbnail view
                if thumbnail_geom.type().getInfo() == 'Point':
                     thumbnail_geom = thumbnail_geom.buffer(100).bounds() # Buffer point by 100 meters and get bounds

                thumb_image_serial, err_img = get_processed_image_serialized(json.dumps(thumbnail_geom.getInfo()), start_date_current_str, end_date_current_str, selected_index)
                if thumb_image_serial:
                    thumb_url, err_thumb = get_thumbnail_url(thumb_image_serial, json.dumps(thumbnail_geom.getInfo()), vis_params)
                    if thumb_url: st.image(thumb_url, caption=f"{selected_index}", width=200)
                    elif err_thumb: st.warning(f"Ø®Ø·Ø§ Thumbnail: {err_thumb}")
                elif err_img: st.warning(f"Ø®Ø·Ø§ ØªØµÙˆÛŒØ±: {err_img}")
            else: st.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¨Ø±Ø§ÛŒ ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú© Ù†ÛŒØ³Øª.")

# --- Custom Tab Buttons ---
tab_buttons = {
    "ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡": 'tab-button-map',
    "ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ": 'tab-button-ranking',
    "ğŸ“ˆ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ": 'tab-button-timeseries',
    " dashboards Ø®Ù„Ø§ØµÙ‡": 'tab-button-dashboard',
    "ğŸ’¬ Ú†Øªâ€ŒØ¨Ø§Øª": 'tab-button-chatbot'
}
cols = st.columns(len(tab_buttons))
# Use a container to apply CSS flexbox
button_container = st.container()
with button_container:
    button_cols = st.columns(len(tab_buttons))
    for i, (tab_name, css_class) in enumerate(tab_buttons.items()):
        with button_cols[i]:
            # Add a unique key to each button based on its tab name
            if st.button(tab_name, key=f"tab_button_{tab_name}"):
                st.session_state.active_tab = tab_name
            # Inject CSS class using markdown to target the button directly
            # This is a workaround and might be fragile depending on Streamlit's internal HTML structure
            st.markdown(f"""
            <style>
                /* Find the button by its text content (fragile) or parent structure */
                /* A more reliable way is to target based on the key if possible, or inject CSS */
                div[data-testid="column"]:nth-child({i+1}) button {{
                    background-color: {"#f0f2f6" if st.session_state.active_tab != tab_name else tab_buttons[tab_name].split('-')[-1]}; /* Default inactive or active color */
                    color: {"#333" if st.session_state.active_tab != tab_name else "white"};
                     border-bottom: 3px solid {"transparent" if st.session_state.active_tab != tab_name else tab_buttons[tab_name].split('-')[-1]}; /* Underline active tab */
                }}
                /* Reapply the specific colors for active tabs for clarity */
                div[data-testid="column"]:nth-child({i+1}) button {{
                     background-color: {tab_buttons[tab_name].split('-')[-1]} !important; /* Force specific button color */
                     color: white !important;
                     border-bottom: 3px solid {"transparent" if st.session_state.active_tab != tab_name else "white"}; /* White underline for active */
                }}
                 div[data-testid="column"]:nth-child({i+1}) button:hover {{
                     opacity: 0.9;
                     transform: translateY(-2px);
                 }}
            </style>
            """, unsafe_allow_html=True)
            # This dynamic CSS injection per button within columns is complex and might not work reliably.
            # Let's simplify and rely on the general CSS injected at the start.
            # The general CSS above targets buttons within .tab-buttons-container.
            # We can add a class to the button or its container if possible.
            # Streamlit buttons don't allow easy class addition. Let's remove the per-button CSS injection.

# We will rely on the general CSS class `.tab-buttons-container button` and the specific color classes defined at the top.
# The challenge is visually highlighting the *active* button with pure CSS and Streamlit's default buttons.
# A common workaround is to change the button's label slightly or its container style, but it's hacky.
# Let's proceed with the basic colored buttons and rely on the content below to indicate the active tab.


# --- Conditional Content Display based on Active Tab ---

if st.session_state.active_tab == "ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡": # Map Tab
    st.subheader(f"Ù†Ù‚Ø´Ù‡ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ - Ø´Ø§Ø®Øµ: {selected_index}")
    # Re-initialize map only when needed or parameters change
    map_key = f"map_display_key_{selected_index}_{selected_farm_name}_{start_date_current_str}_{end_date_current_str}"
    if map_key not in st.session_state: st.session_state[map_key] = None # Initialize key if not exists

    if st.session_state[map_key] is None:
        m = geemap.Map(location=[INITIAL_LAT, INITIAL_LON], zoom=INITIAL_ZOOM, add_google_map=False)
        m.add_basemap("HYBRID")
        map_data_placeholder = st.empty()
        if selected_farm_geom_json:
            map_data_placeholder.info("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„Ø§ÛŒÙ‡ Ø´Ø§Ø®Øµ...")
            gee_image_serialized, error_msg_current = get_processed_image_serialized(selected_farm_geom_json, start_date_current_str, end_date_current_str, selected_index)
            if gee_image_serialized:
                try:
                    gee_image_current = ee.Image.deserialize(gee_image_serialized)
                    m.addLayer(gee_image_current, vis_params, f"{selected_index} ({start_date_current_str} to {end_date_current_str})")
                    legend_title = f"{selected_index} ({index_props['name']})"
                    m.add_legend(legend_title=legend_title, palette=index_props['palette'], min=index_props['min'], max=index_props['max'])

                    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                        # Add markers for all farms
                        points = filtered_farms_df[['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ù…Ø²Ø±Ø¹Ù‡']].to_dict('records')
                        # Create a list of Folium Markers
                        for point in points:
                            if pd.notna(point['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) and pd.notna(point['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']):
                                folium.Marker(
                                    location=[point['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], point['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']],
                                    popup=f"<b>{point['Ù…Ø²Ø±Ø¹Ù‡']}</b>",
                                    tooltip=point['Ù…Ø²Ø±Ø¹Ù‡'],
                                    icon=folium.Icon(color='blue', icon='info-sign') # Use info-sign icon
                                ).add_to(m)

                        # Fit map to the bounds of all farms if selected_farm_geom is a bounds rectangle
                        if isinstance(selected_farm_geom, ee.geometry.Geometry) and selected_farm_geom.type().getInfo() == 'Rectangle':
                             try:
                                 bounds = selected_farm_geom.bounds().getInfo()
                                 m.fit_bounds([[bounds['coordinates'][0][1], bounds['coordinates'][0][0]], [bounds['coordinates'][0][3], bounds['coordinates'][0][2]]])
                             except Exception as e_fit: print(f"Error fitting bounds: {e_fit}")
                        elif isinstance(selected_farm_geom, ee.geometry.Geometry):
                             m.center_object(selected_farm_geom, zoom=INITIAL_ZOOM) # Center on point if bounds failed

                    else: # Single farm selected
                        if selected_farm_details is not None and pd.notna(selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) and pd.notna(selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']):
                            folium.Marker(location=[selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=f"<b>{selected_farm_name}</b>", tooltip=selected_farm_name, icon=folium.Icon(color='red', icon='star')).add_to(m)
                            # Center map on the selected farm with a slightly higher zoom
                            if isinstance(selected_farm_geom, ee.geometry.Geometry):
                                m.center_object(selected_farm_geom, zoom=15)

                    m.add_layer_control()
                    map_data_placeholder.empty()
                    st_folium(m, width=None, height=600, use_container_width=True, key=map_key) # Use the dynamic key
                    st.session_state[map_key] = True # Mark map as rendered
                except Exception as map_err:
                    map_data_placeholder.error(f"Ø®Ø·Ø§ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡: {map_err}\n{traceback.format_exc()}")
                    st.session_state[map_key] = False # Mark map rendering as failed
            else:
                 map_data_placeholder.warning(f"ØªØµÙˆÛŒØ± Ù†Ù‚Ø´Ù‡ Ù†ÛŒØ³Øª. {error_msg_current}")
                 st.session_state[map_key] = False # Mark map rendering as failed
        else:
            map_data_placeholder.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ù†Ù‚Ø´Ù‡ Ù†ÛŒØ³Øª.")
            st.session_state[map_key] = False # Mark map rendering as failed
    else:
        # If map was already rendered for these parameters, display it from session state
        # Note: st_folium doesn't store the map object itself in session state easily for re-rendering
        # We trigger a re-render by calling st_folium again with the same key,
        # relying on Streamlit's caching or re-execution to build the map.
        # If initialization failed, just show the warning again.
        if st.session_state[map_key] is False: # If previous attempt failed
             if selected_farm_geom_json:
                 map_data_placeholder = st.empty()
                 map_data_placeholder.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯.")
             else:
                 map_data_placeholder = st.empty()
                 map_data_placeholder.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ù†Ù‚Ø´Ù‡ Ù†ÛŒØ³Øª.")
        else:
             # Re-render the map by calling st_folium with the cached key
             m = geemap.Map(location=[INITIAL_LAT, INITIAL_LON], zoom=INITIAL_ZOOM, add_google_map=False)
             m.add_basemap("HYBRID")
             # Need to re-add layers and markers to the map object before calling st_folium
             # This requires re-fetching or storing layer info, which adds complexity.
             # For simplicity in this example, let's assume re-running the block builds the map correctly.
             # A more robust solution might involve storing the generated Folium map object or its components.

             # Re-fetch the image and add layers for display
             gee_image_serialized, error_msg_current = get_processed_image_serialized(selected_farm_geom_json, start_date_current_str, end_date_current_str, selected_index)
             if gee_image_serialized:
                 try:
                     gee_image_current = ee.Image.deserialize(gee_image_serialized)
                     m.addLayer(gee_image_current, vis_params, f"{selected_index} ({start_date_current_str} to {end_date_current_str})")
                     legend_title = f"{selected_index} ({index_props['name']})"
                     m.add_legend(legend_title=legend_title, palette=index_props['palette'], min=index_props['min'], max=index_props['max'])

                     if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                        points = filtered_farms_df[['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ù…Ø²Ø±Ø¹Ù‡']].to_dict('records')
                        for point in points:
                             if pd.notna(point['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) and pd.notna(point['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']):
                                folium.Marker(
                                    location=[point['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], point['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']],
                                    popup=f"<b>{point['Ù…Ø²Ø±Ø¹Ù‡']}</b>",
                                    tooltip=point['Ù…Ø²Ø±Ø¹Ù‡'],
                                    icon=folium.Icon(color='blue', icon='info-sign')
                                ).add_to(m)
                        if isinstance(selected_farm_geom, ee.geometry.Geometry) and selected_farm_geom.type().getInfo() == 'Rectangle':
                             try:
                                 bounds = selected_farm_geom.bounds().getInfo()
                                 m.fit_bounds([[bounds['coordinates'][0][1], bounds['coordinates'][0][0]], [bounds['coordinates'][0][3], bounds['coordinates'][0][2]]])
                             except Exception as e_fit: print(f"Error fitting bounds: {e_fit}")
                        elif isinstance(selected_farm_geom, ee.geometry.Geometry):
                             m.center_object(selected_farm_geom, zoom=INITIAL_ZOOM)

                     else:
                         if selected_farm_details is not None and pd.notna(selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) and pd.notna(selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']):
                            folium.Marker(location=[selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], popup=f"<b>{selected_farm_name}</b>", tooltip=selected_farm_name, icon=folium.Icon(color='red', icon='star')).add_to(m)
                            if isinstance(selected_farm_geom, ee.geometry.Geometry):
                                m.center_object(selected_farm_geom, zoom=15)

                     m.add_layer_control()
                     st_folium(m, width=None, height=600, use_container_width=True, key=map_key)

                 except Exception as map_err:
                     st.error(f"Ø®Ø·Ø§ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ø¯Ø± Ø­Ø§Ù„Øª Ú©Ø´ Ø´Ø¯Ù‡: {map_err}\n{traceback.format_exc()}")
                     st.session_state[map_key] = False # Mark as failed if error occurs during re-render


if st.session_state.active_tab == "ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ": # Ranking Table Tab
    st.subheader(f"Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} ({selected_day})")
    st.markdown("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„.")
    # Define parameters that affect the ranking table
    ranking_params = (selected_index, start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str, selected_day)

    # Check if ranking data needs to be recalculated
    if st.session_state.ranking_data['params'] != ranking_params or st.session_state.ranking_data['df'].empty:
        print(f"Recalculating ranking table for: {ranking_params}")
        # Reset ranking and analysis data when parameters change
        st.session_state.ranking_data = {'df': pd.DataFrame(), 'errors': [], 'params': None}
        st.session_state.gemini_analysis = {'text': None, 'error': None, 'params': None} # Reset AI analysis
        st.session_state.messages = [] # Reset chatbot history

        # Perform the calculation
        ranking_df_raw, calculation_errors = calculate_all_farm_indices(filtered_farms_df, selected_index, start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str)

        # Store results in session state
        st.session_state.ranking_data['df'] = ranking_df_raw
        st.session_state.ranking_data['errors'] = calculation_errors
        st.session_state.ranking_data['params'] = ranking_params

        # Rerun to display the results after calculation is complete
        st.rerun()
    else:
        # Use cached ranking data from session state
        print("Using cached ranking data from session state.")
        ranking_df_raw = st.session_state.ranking_data['df']
        calculation_errors = st.session_state.ranking_data['errors']

    # Display the ranking table if data exists
    if not ranking_df_raw.empty:
        ranking_df_display = ranking_df_raw.copy()
        curr_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)'; prev_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)'; change_col = 'ØªØºÛŒÛŒØ±'
        ranking_df_display = ranking_df_display.rename(columns={f'{selected_index}_curr': curr_col, f'{selected_index}_prev': prev_col, f'{selected_index}_change': change_col})

        higher_is_better = index_props['higher_is_better']

        def determine_status_tab2(change_val):
            try:
                # Check for pandas NaN or None
                if pd.isna(change_val): return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
                # Convert to float and check for math NaN or infinity
                change_val_float = float(change_val)
                if math.isnan(change_val_float) or math.isinf(change_val_float): return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"

                if higher_is_better:
                    if change_val_float > CHANGE_THRESHOLD: return "ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯"
                    elif change_val_float < -CHANGE_THRESHOLD: return "ğŸ”´ Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´"
                    else: return "âšª Ø«Ø§Ø¨Øª"
                else: # Lower is better
                    if change_val_float < -CHANGE_THRESHOLD: return "ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯"
                    elif change_val_float > CHANGE_THRESHOLD: return "ğŸ”´ Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´"
                    else: return "âšª Ø«Ø§Ø¨Øª"
            except (TypeError, ValueError): return "Ø®Ø·Ø§ Ø¯Ø± Ù…Ù‚Ø¯Ø§Ø±" # Handle cases where change_val is not convertible to float

        ranking_df_display['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_display[change_col].apply(determine_status_tab2)

        # Sort the DataFrame for ranking
        ranking_df_sorted = ranking_df_display.sort_values(by=curr_col, ascending=not higher_is_better, na_position='last').reset_index(drop=True)
        ranking_df_sorted.index = ranking_df_sorted.index + 1 # Start index from 1
        ranking_df_sorted.index.name = 'Ø±ØªØ¨Ù‡' # Rename index column

        # Format numeric columns for display
        cols_to_format = [curr_col, prev_col, change_col]
        for col_name_fmt in cols_to_format:
            if col_name_fmt in ranking_df_sorted.columns:
                ranking_df_sorted[col_name_fmt] = ranking_df_sorted[col_name_fmt].apply(lambda x: f"{float(x):.3f}" if pd.notna(x) and isinstance(x, (int, float, str)) and str(x).replace('.', '', 1).replace('-', '', 1).lstrip('-').isdigit() else ("-" if pd.isna(x) else str(x))) # Handle non-numeric values gracefully

        # Display the dataframe
        st.dataframe(ranking_df_sorted[['Ù…Ø²Ø±Ø¹Ù‡', 'Ú©Ø§Ù†Ø§Ù„', 'Ø§Ø¯Ø§Ø±Ù‡', curr_col, prev_col, change_col, 'ÙˆØ¶Ø¹ÛŒØª']], use_container_width=True, height=400)

        # Download button for CSV
        try:
            csv_data = ranking_df_sorted.to_csv(index=True, encoding='utf-8-sig') # Include index (RØªØ¨Ù‡)
            st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ (CSV)", data=csv_data, file_name=f'ranking_{selected_index}_{selected_day}_{end_date_current_str}.csv', mime='text/csv')
        except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV: {e}")

        # Display calculation errors if any
        if calculation_errors:
            with st.expander("âš ï¸ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ", expanded=False):
                # Filter unique errors and display a limited number
                unique_errors = sorted(list(set(str(e) for e in calculation_errors)))
                st.warning(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ù†Ø­ØµØ±Ø¨ÙØ±Ø¯ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡: {len(unique_errors)}")
                for i, error_msg in enumerate(unique_errors):
                    st.error(f"- {error_msg}")
                    if i >= 15: # Limit the number of displayed errors to avoid clutter
                        st.warning("... Ùˆ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±. Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ø§Ù…Ù„ØŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
                        break
    else:
        # Message if ranking data is empty after calculation attempt
        st.info(f"Ø¯Ø§Ø¯Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{selected_index}' Ùˆ Ø±ÙˆØ² '{selected_day}' Ù¾Ø³ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ÛŒØ³Øª.")
        if calculation_errors: st.error("Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¬Ø¯ÙˆÙ„ (Ø¨Ø§Ù„Ø§).")


if st.session_state.active_tab == "ğŸ“ˆ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ": # Time Series Tab
    st.subheader(f"Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index}")
    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù†ÙˆØ§Ø± Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif selected_farm_geom_json:
        # Define the date range for the time series (e.g., last year)
        ts_end_date = today_date_obj.strftime('%Y-%m-%d')
        ts_start_date = (today_date_obj - datetime.timedelta(days=365)).strftime('%Y-%m-%d') # Last 365 days

        # Check if time series data for this farm/index/date range is cached
        ts_params = (selected_farm_name, selected_index, ts_start_date, ts_end_date)
        ts_data_key = f"ts_data_{'_'.join(ts_params).replace(' ', '_')}"

        if ts_data_key not in st.session_state:
             st.session_state[ts_data_key] = {'json': None, 'error': None}
             # Fetch data if not cached
             ts_df_json, ts_error = get_index_time_series_data(selected_farm_geom_json, selected_index, ts_start_date, ts_end_date)
             st.session_state[ts_data_key] = {'json': ts_df_json, 'error': ts_error}
             # Rerun to display after fetching
             st.rerun()
        else:
            # Use cached data
            ts_df_json = st.session_state[ts_data_key]['json']
            ts_error = st.session_state[ts_data_key]['error']


        if ts_error:
            st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}")
        elif ts_df_json:
            try:
                # Load data from JSON
                ts_df = pd.read_json(ts_df_json, orient='split')
                ts_df.index = pd.to_datetime(ts_df.index, format='iso') # Ensure datetime index

                if not ts_df.empty:
                    # Create Plotly line chart
                    fig_ts = px.line(ts_df, y=selected_index, markers=True, title=f"Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}", labels={'index': 'ØªØ§Ø±ÛŒØ®', selected_index: f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                    # Update layout for RTL and font
                    fig_ts.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                    # Display the chart
                    st.plotly_chart(fig_ts, use_container_width=True)

                    # Download button for time series data
                    csv_ts = ts_df.to_csv(encoding='utf-8-sig')
                    st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ (CSV)", data=csv_ts, file_name=f'ts_{selected_farm_name}_{selected_index}.csv', mime='text/csv')
                else:
                    st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{selected_index}' Ùˆ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            except Exception as e_plot:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡: {e_plot}\n{traceback.format_exc()}")
        else:
            # Message when ts_df_json is None and there was no specific error message from GEE
            st.info(f"Ø¯Ø§Ø¯Ù‡ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{selected_index}' Ùˆ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ù†ÛŒØ³Øª.")
    else:
        st.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª.")

if st.session_state.active_tab == " dashboards Ø®Ù„Ø§ØµÙ‡": # Dashboard Tab
    st.subheader(f"Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡ ({selected_day}) - Ø´Ø§Ø®Øµ: {selected_index}")
    # Get ranking data from session state
    ranking_df_raw_dash = st.session_state.ranking_data.get('df')

    # Check if ranking data is available
    if ranking_df_raw_dash is None or ranking_df_raw_dash.empty:
        st.warning(f"Ø¯Ø§Ø¯Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² **{selected_day}** Ùˆ Ø´Ø§Ø®Øµ **{selected_index}** Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø¨Ù‡ ØªØ¨ 'ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ' Ø¨Ø±ÙˆÛŒØ¯ ØªØ§ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.")
    else:
        # Process data for dashboard
        df_dash = ranking_df_raw_dash.copy()
        curr_col_raw = f'{selected_index}_curr'; prev_col_raw = f'{selected_index}_prev'; change_col_raw = f'{selected_index}_change'

        # Ensure columns exist and are numeric
        for col in [curr_col_raw, prev_col_raw, change_col_raw]:
            if col in df_dash.columns:
                 df_dash[col] = pd.to_numeric(df_dash[col], errors='coerce')
            else:
                 df_dash[col] = pd.NA # Add column with missing values if it doesn't exist

        higher_is_better_dash = index_props['higher_is_better']

        # Determine status for dashboard visualization
        def get_status_dashboard(change):
            try:
                if pd.isna(change) or math.isnan(change) or math.isinf(change): return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
                if higher_is_better_dash:
                    if change > CHANGE_THRESHOLD: return "Ø¨Ù‡Ø¨ÙˆØ¯"
                    elif change < -CHANGE_THRESHOLD: return "Ú©Ø§Ù‡Ø´"
                    else: return "Ø«Ø§Ø¨Øª"
                else: # Lower is better
                    if change < -CHANGE_THRESHOLD: return "Ø¨Ù‡Ø¨ÙˆØ¯"
                    elif change > CHANGE_THRESHOLD: return "Ú©Ø§Ù‡Ø´"
                    else: return "Ø«Ø§Ø¨Øª"
            except: return "Ø®Ø·Ø§" # Catch any other unexpected errors

        df_dash['status'] = df_dash[change_col_raw].apply(get_status_dashboard)

        # Count statuses
        status_counts = df_dash['status'].value_counts().to_dict() # Convert to dictionary for easier access

        st.markdown("**Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹:**")
        col1, col2, col3, col4 = st.columns(4)
        # Display metrics using get() with a default of 0 for statuses that might not exist
        with col1: st.metric("ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯", status_counts.get("Ø¨Ù‡Ø¨ÙˆØ¯", 0))
        with col2: st.metric("âšª Ø«Ø§Ø¨Øª", status_counts.get("Ø«Ø§Ø¨Øª", 0))
        with col3: st.metric("ğŸ”´ Ú©Ø§Ù‡Ø´", status_counts.get("Ú©Ø§Ù‡Ø´", 0))
        with col4: st.metric("âš«ï¸ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡ / Ø®Ø·Ø§", status_counts.get("Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", 0) + status_counts.get("Ø®Ø·Ø§", 0)) # Combine "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" and "Ø®Ø·Ø§"

        st.markdown("---")

        # Plotting
        col_plot1, col_plot2 = st.columns(2)

        with col_plot1:
            st.markdown(f"**ØªÙˆØ²ÛŒØ¹ Ù…Ù‚Ø§Ø¯ÛŒØ± {selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)**")
            # Drop NA values for histogram plotting
            hist_data = df_dash[curr_col_raw].dropna()
            if not hist_data.empty:
                fig_hist = px.histogram(hist_data, nbins=20, title=f"ØªÙˆØ²ÛŒØ¹ Ù…Ù‚Ø§Ø¯ÛŒØ± {selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)", labels={'value': f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                fig_hist.update_layout(yaxis_title="ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹", xaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                st.plotly_chart(fig_hist, use_container_width=True)
            else:
                st.info(f"Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ø´Ø§Ø®Øµ {selected_index} Ù†ÛŒØ³Øª.")

        with col_plot2:
            st.markdown("**Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ùˆ Ù‚Ø¨Ù„**")
            # Drop rows with missing values for scatter plot
            scatter_data = df_dash.dropna(subset=[curr_col_raw, prev_col_raw, 'status'])
            if not scatter_data.empty:
                fig_scatter = px.scatter(scatter_data, x=prev_col_raw, y=curr_col_raw, color='status', hover_name='Ù…Ø²Ø±Ø¹Ù‡', title=f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø§Ø®Øµ {selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ù‚Ø¨Ù„)", labels={prev_col_raw: f"{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)", curr_col_raw: f"{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)", 'status': 'ÙˆØ¶Ø¹ÛŒØª'}, color_discrete_map={'Ø¨Ù‡Ø¨ÙˆØ¯': 'green', 'Ø«Ø§Ø¨Øª': 'grey', 'Ú©Ø§Ù‡Ø´': 'red', 'Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡': 'black', 'Ø®Ø·Ø§':'orange'})

                # Add 1:1 line (y=x)
                # Determine the range for the line based on data
                min_val_sc = min(scatter_data[prev_col_raw].min(), scatter_data[curr_col_raw].min())
                max_val_sc = max(scatter_data[prev_col_raw].max(), scatter_data[curr_col_raw].max())
                # Add a small buffer to the range
                range_buffer = (max_val_sc - min_val_sc) * 0.1
                line_start = min_val_sc - range_buffer
                line_end = max_val_sc + range_buffer

                fig_scatter.add_shape(type='line', x0=line_start, y0=line_start, x1=line_end, y1=line_end, line=dict(color='rgba(0,0,0,0.5)', dash='dash'))

                fig_scatter.update_layout(xaxis_title=f"{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)", yaxis_title=f"{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                st.plotly_chart(fig_scatter, use_container_width=True)
            else:
                st.info(f"Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ Ø´Ø§Ø®Øµ {selected_index} Ù†ÛŒØ³Øª ( Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ùˆ Ù‚Ø¨Ù„).")

        st.markdown("---")

        st.markdown("**Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø²Ø§Ø±Ø¹ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø¯Ø§Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ):**")
        # Sort data for top/bottom lists, dropping rows where current value is NA
        df_sorted_dash = df_dash.sort_values(by=curr_col_raw, ascending=not higher_is_better_dash, na_position='last').dropna(subset=[curr_col_raw])

        col_top, col_bottom = st.columns(2)

        with col_top:
            st.markdown(f"**ğŸŸ¢ Ûµ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±ØªØ±**")
            if not df_sorted_dash.empty:
                st.dataframe(df_sorted_dash[['Ù…Ø²Ø±Ø¹Ù‡', curr_col_raw, change_col_raw]].head(5).style.format({curr_col_raw: "{:.3f}", change_col_raw: "{:+.3f}" if pd.notna else "-"}), use_container_width=True, hide_index=True) # Hide index
            else:
                st.info("Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øª Ø¨Ø±ØªØ±ÛŒÙ† Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ³Øª.")

        with col_bottom:
            st.markdown(f"**ğŸ”´ Ûµ Ù…Ø²Ø±Ø¹Ù‡ Ø¶Ø¹ÛŒÙâ€ŒØªØ±**")
            if not df_sorted_dash.empty:
                # Sort descending for bottom list, then take the head
                st.dataframe(df_sorted_dash[['Ù…Ø²Ø±Ø¹Ù‡', curr_col_raw, change_col_raw]].tail(5).sort_values(by=curr_col_raw, ascending=higher_is_better_dash).style.format({curr_col_raw: "{:.3f}", change_col_raw: "{:+.3f}" if pd.notna else "-"}), use_container_width=True, hide_index=True) # Hide index
            else:
                st.info("Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øª Ø¶Ø¹ÛŒÙâ€ŒØªØ±ÛŒÙ† Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ³Øª.")


if st.session_state.active_tab == "ğŸ’¬ Ú†Øªâ€ŒØ¨Ø§Øª": # Chatbot Tab
    st.subheader("ğŸ’¬ Ú†Øªâ€ŒØ¨Ø§Øª ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
    st.info(f"Ø¯Ø± Ù…ÙˆØ±Ø¯ ÙˆØ¶Ø¹ÛŒØª ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² **{selected_day}** Ùˆ Ø¨Ø§ Ø´Ø§Ø®Øµ **{selected_index}** Ø¨Ù¾Ø±Ø³ÛŒØ¯. Ù…Ø«Ø§Ù„: 'ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ´Ú©Ø± Û± Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ'")

    # Check if Gemini is available and ranking data is present for analysis
    if not st.session_state.gemini_available:
         st.warning("âš ï¸ Ú†Øªâ€ŒØ¨Ø§Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Gemini API ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª.", icon="âš ï¸")
    else:
        ranking_df_chat_check = st.session_state.ranking_data.get('df')
        if ranking_df_chat_check is None or ranking_df_chat_check.empty:
             st.warning("âš ï¸ Ù¾Ø§Ø³Ø® Ú†Øªâ€ŒØ¨Ø§Øª Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡â€ŒØ´Ø¯Ù‡ Ø¯Ø± ØªØ¨ 'ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ' ÙˆØ§Ø¨Ø³ØªÙ‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø¨Ù‡ Ø¢Ù† ØªØ¨ Ø¨Ø±ÙˆÛŒØ¯.", icon="âš ï¸")

    # Display chat messages from history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Chat input
    if prompt := st.chat_input(f"Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ {selected_day} Ø¨Ù¾Ø±Ø³ÛŒØ¯..."):
        # Add user message to chat history and display it
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        response_text = "Ù…ØªØ§Ø³ÙÙ…ØŒ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†Ù…." # Default response

        if not st.session_state.gemini_available:
             response_text = "AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø² ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Gemini API Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯."
        else:
             # Try to extract farm name from the prompt
             extracted_farm = extract_farm_name(prompt, available_farm_names_today)

             if extracted_farm:
                 # Get ranking data for analysis
                 ranking_df_chat = st.session_state.ranking_data.get('df')

                 if ranking_df_chat is None or ranking_df_chat.empty:
                      response_text = f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ '{selected_index}' Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø¨Ù‡ ØªØ¨ 'ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ' Ø¨Ø±ÙˆÛŒØ¯ ØªØ§ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯."
                 else:
                     # Find the row for the extracted farm
                     farm_data_row_chat = ranking_df_chat[ranking_df_chat['Ù…Ø²Ø±Ø¹Ù‡'] == extracted_farm]

                     if not farm_data_row_chat.empty:
                         # Get the relevant data for the farm
                         farm_row_chat = farm_data_row_chat.iloc[0]
                         current_val = farm_row_chat.get(f'{selected_index}_curr')
                         previous_val = farm_row_chat.get(f'{selected_index}_prev')
                         change_val = farm_row_chat.get(f'{selected_index}_change')

                         # Perform AI analysis using Gemini
                         # Cache analysis results based on farm, index, and dates to avoid re-calling API for same params
                         analysis_params = (extracted_farm, selected_index, current_val, previous_val, change_val)
                         if st.session_state.gemini_analysis['params'] == analysis_params and st.session_state.gemini_analysis['text'] is not None:
                              print("Using cached Gemini analysis.")
                              analysis_text = st.session_state.gemini_analysis['text']
                              analysis_error = st.session_state.gemini_analysis['error']
                         else:
                             print("Generating new Gemini analysis.")
                             analysis_text, analysis_error = get_gemini_analysis(selected_index, extracted_farm, current_val, previous_val, change_val)
                             # Store the new analysis in session state
                             st.session_state.gemini_analysis = {'text': analysis_text, 'error': analysis_error, 'params': analysis_params}

                         if analysis_error:
                             response_text = f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{extracted_farm}': {analysis_error}"
                         elif analysis_text:
                             response_text = f"**ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ {extracted_farm} ({selected_index} Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² {selected_day}):**\n\n{analysis_text}"
                         else:
                             response_text = f"ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{extracted_farm}' Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯ (Ù¾Ø§Ø³Ø® Ø®Ø§Ù„ÛŒ)."

                     else:
                         response_text = f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ '{selected_index}' Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{extracted_farm}' Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯."
             else:
                 # If no farm name was extracted
                 response_text = "Ù†Ø§Ù… Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª ÛŒØ§ Ø¯Ø± Ø³ÙˆØ§Ù„ Ø´Ù…Ø§ Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ù†Ø§Ù… ÛŒÚ©ÛŒ Ø§Ø² Ù…Ø²Ø§Ø±Ø¹ Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ Ø°Ú©Ø± Ú©Ù†ÛŒØ¯. Ù…Ø«Ø§Ù„: 'ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ **Ù…Ø²Ø±Ø¹Ù‡ Û±** Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ'"
                 # Add a few example farm names to help the user
                 example_farms = [f for f in available_farm_names_today if f != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"][:5]
                 if example_farms:
                     response_text += "\n\nÙ†Ù…ÙˆÙ†Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø§Ù…Ø±ÙˆØ²: " + ", ".join(example_farms)
                     if len(available_farm_names_today) > 6: response_text += "..."


        # Display the assistant's response and add to chat history
        with st.chat_message("assistant"):
            st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})

# --- Footer ---
st.markdown("---")
st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ ğŸ’» ØªÙˆØ³Ø· Ø§Ø³Ù…Ø§Ø¹ÛŒÙ„ Ú©ÛŒØ§Ù†ÛŒ")
st.sidebar.markdown("Streamlit | GEE | Geemap | Plotly | Gemini")

# Display API status in sidebar
if not st.session_state.gee_initialized:
    st.sidebar.error("ğŸš¨ Google Earth Engine ØºÛŒØ±ÙØ¹Ø§Ù„.")
elif st.session_state.gee_initialized:
    st.sidebar.success("âœ… Google Earth Engine ÙØ¹Ø§Ù„.")

if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY":
    st.sidebar.error("ğŸš¨ Ú©Ù„ÛŒØ¯ Gemini Ù†ÛŒØ³Øª ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
elif st.session_state.gemini_available:
    st.sidebar.success("âœ… Gemini API ÙØ¹Ø§Ù„.")
else:
    st.sidebar.warning("âš ï¸ Gemini API ØºÛŒØ±ÙØ¹Ø§Ù„.")

st.sidebar.warning("Ù‡Ø´Ø¯Ø§Ø± Ø§Ù…Ù†ÛŒØªÛŒ: Ú©Ù„ÛŒØ¯ API Ø¯Ø± Ú©Ø¯ Ø§Ø³Øª (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡/ØªØ³Øª).")

# --- END OF FILE ---