import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
import plotly.express as px
import os
from io import BytesIO
import requests # Needed for getThumbUrl download
import traceback
from streamlit_folium import st_folium
import base64

# --- Custom CSS ---
st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±",
    page_icon="ğŸŒ¾",
    layout="wide"
)

# Custom CSS for Persian text alignment and professional styling
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');
        
        /* Main container */
        .main {
            font-family: 'Vazirmatn', sans-serif;
        }
        
        /* Headers */
        h1, h2, h3 {
            font-family: 'Vazirmatn', sans-serif;
            color: #2c3e50;
            text-align: right;
        }
        
        /* Metrics */
        .css-1xarl3l { /* This selector might change with Streamlit versions */
            font-family: 'Vazirmatn', sans-serif;
            background-color: #f8f9fa;
            border-radius: 10px;
            padding: 1rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        /* Tabs */
        .stTabs [data-baseweb="tab-list"] {
            gap: 2px;
            direction: rtl;
        }
        
        .stTabs [data-baseweb="tab"] {
            height: 50px;
            padding: 10px 20px;
            background-color: #f8f9fa;
            border-radius: 5px 5px 0 0;
            font-family: 'Vazirmatn', sans-serif;
            font-weight: 600;
        }
        
        /* Tables */
        .dataframe {
            font-family: 'Vazirmatn', sans-serif;
            text-align: right;
        }
        
        /* Sidebar */
        .css-1d391kg { /* This selector might change with Streamlit versions for sidebar */
            font-family: 'Vazirmatn', sans-serif;
            direction: rtl;
        }
        
        /* Custom status badges */
        .status-badge {
            padding: 4px 8px;
            border-radius: 15px;
            font-size: 0.8em;
            font-weight: bold;
        }
        .status-positive {
            background-color: #d4edda;
            color: #155724;
        }
        .status-neutral {
            background-color: #fff3cd;
            color: #856404;
        }
        .status-negative {
            background-color: #f8d7da;
            color: #721c24;
        }
    </style>
""", unsafe_allow_html=True)

# --- Configuration ---
APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±"
APP_SUBTITLE = "Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 11 # Adjusted default zoom

# --- File Paths (Relative to the script location in Hugging Face) ---
# CSV_FILE_PATH = 'cleaned_output.csv' # No longer used
GEE_ASSET_PATH = 'projects/ee-esmaeilkiani13877/assets/Croplogging-Farm'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json' # Ensure this file is present

# --- GEE Authentication ---
@st.cache_resource # Cache the GEE initialization
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully using Service Account.")
        return True
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª ÙØ§ÛŒÙ„ Service Account Ùˆ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø¢Ù† Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ GEE Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.stop()


# --- Load Farm Data from GEE Asset ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø§Ø² Google Earth Engine...")
def load_farm_data(asset_path=GEE_ASSET_PATH):
    """Loads farm data from the specified GEE FeatureCollection asset."""
    try:
        ee_fc = ee.FeatureCollection(asset_path)

        # Function to extract properties and add centroid coordinates and GeoJSON geometry
        def process_feature(feature):
            geom = feature.geometry()
            # Calculate centroid, ensure it's robust (maxError for complex geometries)
            centroid = geom.centroid(maxError=1).coordinates()
            props = feature.toDictionary() # Get all properties from the feature
            
            # Set new properties: centroid coordinates and GeoJSON string of the geometry
            props = props.set('longitude_centroid', centroid.get(0))
            props = props.set('latitude_centroid', centroid.get(1))
            props = props.set('geojson_geometry', geom.toGeoJSONString()) # Store full geometry
            
            # Return a new feature with no geometry (to avoid issues with ee_to_df) 
            # but with all properties including new ones.
            return ee.Feature(None, props)

        # Apply the processing function to each feature
        processed_fc = ee_fc.map(process_feature)
        
        # Convert the processed FeatureCollection to a Pandas DataFrame
        df = geemap.ee_to_df(processed_fc)

        if df.empty:
            st.error(f"âŒ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² GEE Asset '{asset_path}' Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯ ÛŒØ§ Asset Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
            return None

        # Rename columns to match the application's expected Persian names
        # Original GEE columns: Age, Area, Day, Field, Variety, edare, farm, group, system:index, Feature Index
        # Derived columns: longitude_centroid, latitude_centroid, geojson_geometry
        column_mapping = {
            'farm': 'Ù…Ø²Ø±Ø¹Ù‡',
            'longitude_centroid': 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ',
            'latitude_centroid': 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ',
            'Day': 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡',
            'Area': 'Ù…Ø³Ø§Ø­Øª', # Area (Float)
            'Variety': 'ÙˆØ§Ø±ÛŒØªÙ‡', # Variety (String)
            'Field': 'Ú©Ø§Ù†Ø§Ù„',   # Field (Long) - mapping to 'Ú©Ø§Ù†Ø§Ù„'
            'Age': 'Ø³Ù†',       # Age (String)
            'edare': 'Ø§Ø¯Ø§Ø±Ù‡',    # edare (String)
            'geojson_geometry': 'geojson_geometry' # Keep this for actual geometry
            # 'group' is not currently used by the app
            # 'Feature Index' and 'system:index' are GEE identifiers, not directly used in UI display names
        }
        
        # Select and rename relevant columns
        # Ensure all keys in column_mapping exist in df.columns before trying to rename
        rename_map_filtered = {k: v for k, v in column_mapping.items() if k in df.columns}
        df = df.rename(columns=rename_map_filtered)
        
        # Keep only the columns that are in the values of rename_map_filtered
        required_df_cols = list(rename_map_filtered.values())
        # Check if essential columns like 'Ù…Ø²Ø±Ø¹Ù‡' are present after renaming
        if 'Ù…Ø²Ø±Ø¹Ù‡' not in df.columns or 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ' not in df.columns or 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ' not in df.columns:
            st.error(f"âŒ Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ ('farm', 'Day', centroid coordinates) Ø¯Ø± GEE Asset ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ù†Ø§Ù…Ú¯Ø°Ø§Ø±ÛŒ Ø¢Ù†Ù‡Ø§ ØµØ­ÛŒØ­ Ù†ÛŒØ³Øª.")
            st.error(f"Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± DataFrame Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´: {', '.join(df.columns.tolist())}")
            return None

        df = df[required_df_cols]


        # Basic validation for essential columns (already implicitly done by selection)
        # Convert coordinate columns to numeric
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        
        # Convert 'Ù…Ø³Ø§Ø­Øª' to numeric if it exists
        if 'Ù…Ø³Ø§Ø­Øª' in df.columns:
            df['Ù…Ø³Ø§Ø­Øª'] = pd.to_numeric(df['Ù…Ø³Ø§Ø­Øª'], errors='coerce')

        # Drop rows where essential coordinates are missing after coercion
        df = df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ù…Ø²Ø±Ø¹Ù‡'])

        if df.empty:
            st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø±).")
            return None

        # Ensure 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' is string type for consistent filtering
        if 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' in df.columns:
            df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] = df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].astype(str).str.strip()
        else:
            st.warning("âš ï¸ Ø³ØªÙˆÙ† 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' (Day) Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯. ÙÛŒÙ„ØªØ± Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ø§Ø± Ù†Ú©Ù†Ø¯.")
            # Add a dummy column if it's critical for downstream logic, or handle absence
            df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] = "Ù†Ø§Ù…Ø´Ø®Øµ"


        st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {len(df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø² GEE Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return df
    except ee.EEException as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Google Earth Engine Asset: {e}")
        st.error(f"Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª Ù…Ø³ÛŒØ± Asset ('{asset_path}') Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        st.error(traceback.format_exc())
        return None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø§Ø² GEE: {e}")
        st.error(traceback.format_exc())
        return None

# Initialize GEE and Load Data
if initialize_gee():
    farm_data_df = load_farm_data()
else:
    st.error("âŒ Ø§Ù…Ú©Ø§Ù† Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø¨Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    st.stop()

if farm_data_df is None or farm_data_df.empty:
    st.error("âŒ Ø§Ù…Ú©Ø§Ù† Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø± Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    st.stop()


# ==============================================================================
# Sidebar Filters
# ==============================================================================
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

# --- Day of the Week Selection ---
if 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' in farm_data_df.columns:
    available_days = sorted(farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique())
    if not available_days: # Handle case where 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' column exists but has no valid unique values
        st.sidebar.warning("Ù‡ÛŒÚ† Ø±ÙˆØ²ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
        st.stop()
    selected_day = st.sidebar.selectbox(
        "ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        options=available_days,
        index=0, # Default to the first day
        help="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø±ÙˆØ² ÙÛŒÙ„ØªØ± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯."
    )
    # --- Filter Data Based on Selected Day ---
    filtered_farms_df = farm_data_df[farm_data_df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()
else:
    st.sidebar.warning("Ø³ØªÙˆÙ† 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡' Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª. Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.")
    filtered_farms_df = farm_data_df.copy() # Use all farms if day filtering is not possible
    selected_day = "Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§" # Placeholder

if filtered_farms_df.empty:
    st.warning(f"âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    st.stop()

# --- Farm Selection ---
available_farms = sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique())
farm_options = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + available_farms
selected_farm_name = st.sidebar.selectbox(
    "ğŸŒ¾ Ù…Ø²Ø±Ø¹Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
    options=farm_options,
    index=0, # Default to "All Farms"
    help="Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¢Ù† Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯ ÛŒØ§ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ."
)

# --- Index Selection ---
index_options = {
    "NDVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªÙØ§Ø¶Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡",
    "EVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡",
    "NDMI": "Ø´Ø§Ø®Øµ Ø±Ø·ÙˆØ¨Øª ØªÙØ§Ø¶Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡",
    "LAI": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
    "MSI": "Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ",
    "CVI": "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
}
selected_index = st.sidebar.selectbox(
    "ğŸ“ˆ Ø´Ø§Ø®Øµ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡:",
    options=list(index_options.keys()),
    format_func=lambda x: f"{x} ({index_options[x]})",
    index=0 # Default to NDVI
)

# --- Date Range Calculation ---
today = datetime.date.today()
persian_to_weekday = {
    "Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1,
    "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4, "Ù†Ø§Ù…Ø´Ø®Øµ": -1 # Handle "Ù†Ø§Ù…Ø´Ø®Øµ"
}
try:
    if selected_day != "Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§" and selected_day != "Ù†Ø§Ù…Ø´Ø®Øµ" and selected_day in persian_to_weekday:
        target_weekday = persian_to_weekday[selected_day]
        days_ago = (today.weekday() - target_weekday + 7) % 7
        end_date_current = today - datetime.timedelta(days=days_ago if days_ago != 0 else 0)
    else: # Default to today if day is not specific or mapping fails
        end_date_current = today
        st.sidebar.warning(f"Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯. Ø§Ø² ØªØ§Ø±ÛŒØ® Ø§Ù…Ø±ÙˆØ² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

    start_date_current = end_date_current - datetime.timedelta(days=6)
    end_date_previous = start_date_current - datetime.timedelta(days=1)
    start_date_previous = end_date_previous - datetime.timedelta(days=6)

    start_date_current_str = start_date_current.strftime('%Y-%m-%d')
    end_date_current_str = end_date_current.strftime('%Y-%m-%d')
    start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
    end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')

    st.sidebar.info(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÙØ¹Ù„ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
    st.sidebar.info(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")

except KeyError:
    st.sidebar.error(f"Ù†Ø§Ù… Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ù‚Ø§Ø¨Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    st.stop()
except Exception as e:
    st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}")
    st.stop()


# ==============================================================================
# Google Earth Engine Functions
# ==============================================================================

def maskS2clouds(image):
    qa = image.select('QA60')
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))
    
    scl = image.select('SCL')
    good_quality_scl = scl.remap([4, 5, 6, 7, 11], [1, 1, 1, 1, 1], 0) # Vegetation, Not Vegetated, Water, Snow/Ice, Bare Soil

    opticalBands = image.select('B.*').multiply(0.0001)
    
    return image.addBands(opticalBands, None, True)\
                .updateMask(mask).updateMask(good_quality_scl)

def add_indices(image):
    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')
    evi = image.expression(
        '2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1)', {
            'NIR': image.select('B8'), 'RED': image.select('B4'), 'BLUE': image.select('B2')
        }).rename('EVI')
    ndmi = image.normalizedDifference(['B8', 'B11']).rename('NDMI')
    msi = image.expression('SWIR1 / NIR', {
        'SWIR1': image.select('B11'), 'NIR': image.select('B8')
    }).rename('MSI')
    lai = ndvi.multiply(3.5).rename('LAI') # Placeholder
    green_safe = image.select('B3').max(ee.Image(0.0001))
    cvi = image.expression('(NIR / GREEN) * (RED / GREEN)', {
        'NIR': image.select('B8'), 'GREEN': green_safe, 'RED': image.select('B4')
    }).rename('CVI')
    return image.addBands([ndvi, evi, ndmi, msi, lai, cvi])

@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ...", persist=True)
def get_processed_image(_geometry, start_date, end_date, index_name):
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_geometry)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds))
        count = s2_sr_col.size().getInfo()
        if count == 0:
            return None, f"No cloud-free Sentinel-2 images found for {start_date} to {end_date} for the given geometry."
        indexed_col = s2_sr_col.map(add_indices)
        median_image = indexed_col.median()
        output_image = median_image.select(index_name)
        return output_image, None
    except ee.EEException as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Google Earth Engine Ø¯Ø± get_processed_image: {e}"
        try:
            error_details = e.args[0] if e.args else str(e)
            if isinstance(error_details, str) and 'computation timed out' in error_details.lower():
                 error_message += "\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ)"
            elif isinstance(error_details, str) and 'user memory limit exceeded' in error_details.lower():
                 error_message += "\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø²Ø±Ú¯ ÛŒØ§ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡)"
        except Exception: pass
        return None, error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ GEE (get_processed_image): {e}\n{traceback.format_exc()}"
        return None, error_message

@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ...", persist=True)
def get_index_time_series(_point_geom, index_name, start_date='2023-01-01', end_date=today.strftime('%Y-%m-%d')):
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_point_geom)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds)
                     .map(add_indices))
        def extract_value(image):
            value = image.reduceRegion(
                reducer=ee.Reducer.first(), geometry=_point_geom, scale=10
            ).get(index_name)
            return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd'), index_name: value})
        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.notNull([index_name]))
        ts_info = ts_features.getInfo()['features']
        if not ts_info:
            return pd.DataFrame(columns=['date', index_name]), "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
        ts_data = [{'date': f['properties']['date'], index_name: f['properties'][index_name]} for f in ts_info]
        ts_df = pd.DataFrame(ts_data)
        ts_df['date'] = pd.to_datetime(ts_df['date'])
        ts_df = ts_df.sort_values('date').set_index('date')
        return ts_df, None
    except ee.EEException as e:
        return pd.DataFrame(columns=['date', index_name]), f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"
    except Exception as e:
        return pd.DataFrame(columns=['date', index_name]), f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}\n{traceback.format_exc()}"

# ==============================================================================
# Main Panel Display
# ==============================================================================

selected_farm_details = None
selected_farm_aoi_geom = None # Area of Interest Geometry (can be Point or Polygon)
selected_farm_point_geom_for_timeseries = None # Always a Point (centroid) for time series

if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
    if not filtered_farms_df.empty and 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ' in filtered_farms_df.columns:
        min_lon = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
        min_lat = filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
        max_lon = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
        max_lat = filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
        selected_farm_aoi_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])
    else: # Fallback if no farms or no coordinates
        selected_farm_aoi_geom = ee.Geometry.Point([INITIAL_LON, INITIAL_LAT]).buffer(10000).bounds() # Default region
    st.subheader(f"Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ²: {selected_day}")
    st.info(f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ²: {len(filtered_farms_df)}")
else:
    selected_farm_details_series = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name]
    if not selected_farm_details_series.empty:
        selected_farm_details = selected_farm_details_series.iloc[0]
        
        # Centroid coordinates (already in DataFrame)
        lat_centroid = selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
        lon_centroid = selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
        selected_farm_point_geom_for_timeseries = ee.Geometry.Point([lon_centroid, lat_centroid])

        # Actual farm geometry (from GeoJSON string)
        if 'geojson_geometry' in selected_farm_details and pd.notna(selected_farm_details['geojson_geometry']):
            try:
                geojson_str = selected_farm_details['geojson_geometry']
                selected_farm_aoi_geom = ee.Geometry(json.loads(geojson_str))
            except Exception as e:
                st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}: {e}. Ø§Ø² Ù†Ù‚Ø·Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
                selected_farm_aoi_geom = selected_farm_point_geom_for_timeseries # Fallback to centroid point
        else:
            st.warning(f"Ù‡Ù†Ø¯Ø³Ù‡ Ø¯Ù‚ÛŒÙ‚ (geojson_geometry) Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name} ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² Ù†Ù‚Ø·Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            selected_farm_aoi_geom = selected_farm_point_geom_for_timeseries # Fallback

        st.subheader(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name} (Ø±ÙˆØ²: {selected_day})")
        details_cols = st.columns(3)
        with details_cols[0]:
            area_val = selected_farm_details.get('Ù…Ø³Ø§Ø­Øª', 'N/A')
            st.metric("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", f"{area_val:,.2f}" if pd.notna(area_val) and isinstance(area_val, (int, float)) else "N/A")
            st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", f"{selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}")
        with details_cols[1]:
            st.metric("Ú©Ø§Ù†Ø§Ù„", f"{selected_farm_details.get('Ú©Ø§Ù†Ø§Ù„', 'N/A')}")
            st.metric("Ø³Ù†", f"{selected_farm_details.get('Ø³Ù†', 'N/A')}")
        with details_cols[2]:
            st.metric("Ø§Ø¯Ø§Ø±Ù‡", f"{selected_farm_details.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')}")
            st.metric("Ù…Ø®ØªØµØ§Øª Ù…Ø±Ú©Ø²", f"{lat_centroid:.5f}, {lon_centroid:.5f}")
    else:
        st.error(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()

# --- Map Display ---
st.markdown("---")
st.subheader(" Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")

vis_params = {
    'NDVI': {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']},
    'EVI': {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']},
    'NDMI': {'min': -1, 'max': 1, 'palette': ['brown', 'white', 'blue']},
    'LAI': {'min': 0, 'max': 6, 'palette': ['white', 'lightgreen', 'darkgreen']},
    'MSI': {'min': 0, 'max': 3, 'palette': ['blue', 'white', 'brown']},
    'CVI': {'min': 0, 'max': 20, 'palette': ['yellow', 'lightgreen', 'darkgreen']},
}

map_center_lat = INITIAL_LAT
map_center_lon = INITIAL_LON
map_initial_zoom = INITIAL_ZOOM

if selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" and selected_farm_point_geom_for_timeseries:
    map_center_lat = selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    map_center_lon = selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    map_initial_zoom = 14 # Zoom closer for single farm

m = geemap.Map(location=[map_center_lat, map_center_lon], zoom=map_initial_zoom, add_google_map=False)
m.add_basemap("HYBRID")

if selected_farm_aoi_geom:
    gee_image_current, error_msg_current = get_processed_image(
        selected_farm_aoi_geom, start_date_current_str, end_date_current_str, selected_index
    )

    if gee_image_current:
        try:
            m.addLayer(
                gee_image_current,
                vis_params.get(selected_index, {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']}),
                f"{selected_index} ({start_date_current_str} to {end_date_current_str})"
            )
            # Custom Legend
            legend_html_template = '''
            <div style="position: fixed; bottom: 50px; right: 50px; z-index: 1000; background-color: white; padding: 10px; border: 2px solid grey; border-radius: 5px;">
                <p style="margin: 0;"><strong>{index_name} Legend</strong></p> {items}
            </div>'''
            legend_items_html = ""
            if selected_index in ['NDVI', 'EVI', 'LAI', 'CVI']:
                legend_items_html = """<p style="margin: 0; color: red;">Ø¨Ø­Ø±Ø§Ù†ÛŒ/Ù¾Ø§ÛŒÛŒÙ†</p>
                                     <p style="margin: 0; color: yellow;">Ù…ØªÙˆØ³Ø·</p>
                                     <p style="margin: 0; color: green;">Ø³Ø§Ù„Ù…/Ø¨Ø§Ù„Ø§</p>"""
            elif selected_index in ['NDMI', 'MSI']:
                legend_items_html = """<p style="margin: 0; color: blue;">Ù…Ø±Ø·ÙˆØ¨/Ø¨Ø§Ù„Ø§</p>
                                     <p style="margin: 0; color: white; background-color: grey;">Ù…ØªÙˆØ³Ø·</p>
                                     <p style="margin: 0; color: brown;">Ø®Ø´Ú©/Ù¾Ø§ÛŒÛŒÙ†</p>"""
            else:
                legend_items_html = "<p style='margin: 0;'>Low</p><p style='margin: 0;'>Medium</p><p style='margin: 0;'>High</p>"
            
            m.get_root().html.add_child(folium.Element(legend_html_template.format(index_name=selected_index, items=legend_items_html)))

            # Add markers
            if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                 for idx, farm_row in filtered_farms_df.iterrows():
                     folium.Marker(
                         location=[farm_row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm_row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], # Centroid
                         popup=f"Ù…Ø²Ø±Ø¹Ù‡: {farm_row['Ù…Ø²Ø±Ø¹Ù‡']}<br>Ú©Ø§Ù†Ø§Ù„: {farm_row.get('Ú©Ø§Ù†Ø§Ù„', 'N/A')}<br>Ø§Ø¯Ø§Ø±Ù‡: {farm_row.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')}",
                         tooltip=farm_row['Ù…Ø²Ø±Ø¹Ù‡'],
                         icon=folium.Icon(color='blue', icon='info-sign')
                     ).add_to(m)
                 if selected_farm_aoi_geom: m.center_object(selected_farm_aoi_geom, zoom=map_initial_zoom)
            elif selected_farm_details is not None: # Single farm
                 folium.Marker(
                     location=[selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']], # Centroid
                     popup=f"Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}",
                     tooltip=selected_farm_name,
                     icon=folium.Icon(color='red', icon='star')
                 ).add_to(m)
                 if selected_farm_aoi_geom: m.center_object(selected_farm_aoi_geom, zoom=map_initial_zoom)
            
            m.add_layer_control()
        except Exception as map_err:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ Ø¨Ù‡ Ù†Ù‚Ø´Ù‡: {map_err}")
            st.error(traceback.format_exc())
    else:
        st.warning(f"ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯. {error_msg_current}")
else:
    st.warning("Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")

st_folium(m, width=None, height=500, use_container_width=True)
st.caption("Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ø±ÙˆÛŒ Ù…Ø§Ø±Ú©Ø±Ù‡Ø§ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯. Ø§Ø² Ú©Ù†ØªØ±Ù„ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ù†Ù‚Ø´Ù‡ Ù¾Ø§ÛŒÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
st.info("ğŸ’¡ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‚Ø´Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§Ø¨Ø²Ø§Ø± Ø¹Ú©Ø³ Ú¯Ø±ÙØªÙ† Ø§Ø² ØµÙØ­Ù‡ (Screenshot) Ù…Ø±ÙˆØ±Ú¯Ø± ÛŒØ§ Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„ Ø®ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")

# --- Time Series Chart ---
st.markdown("---")
st.subheader(f"ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index}")

if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
    st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
elif selected_farm_point_geom_for_timeseries: # Use the centroid point geometry
    timeseries_end_date = today.strftime('%Y-%m-%d')
    timeseries_start_date = (today - datetime.timedelta(days=365*2)).strftime('%Y-%m-%d') # 2 years of data

    ts_df, ts_error = get_index_time_series(
        selected_farm_point_geom_for_timeseries,
        selected_index,
        start_date=timeseries_start_date,
        end_date=timeseries_end_date
    )

    if ts_error:
        st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}")
    elif not ts_df.empty:
        fig = px.line(ts_df, x=ts_df.index, y=selected_index, labels={'index':'ØªØ§Ø±ÛŒØ®', selected_index:f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
        fig.update_layout(title_text=f"Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}", title_x=0.5, xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}")
        st.plotly_chart(fig, use_container_width=True)
        st.caption(f"Ù†Ù…ÙˆØ¯Ø§Ø± ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name} Ø¯Ø± 2 Ø³Ø§Ù„ Ú¯Ø°Ø´ØªÙ‡.")
    else:
        st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
else:
    st.warning("Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª (Ù†Ù‚Ø·Ù‡ Ù…Ø±Ú©Ø²ÛŒ Ù…Ø²Ø±Ø¹Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯).")

# --- Ranking Table ---
st.markdown("---")
st.subheader(f"ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} (Ø±ÙˆØ²: {selected_day})")
st.markdown("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„.")

@st.cache_data(show_spinner=f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...", persist=True)
def calculate_weekly_indices(_farms_df_input, index_name_calc, start_curr, end_curr, start_prev, end_prev):
    results = []
    errors = []
    
    # Ensure we don't modify the original DataFrame passed to the cached function
    _farms_df = _farms_df_input.copy()

    if 'geojson_geometry' not in _farms_df.columns:
        errors.append("Ø³ØªÙˆÙ† 'geojson_geometry' Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚ÛŒÙ‚ Ø´Ø§Ø®Øµ Ù…Ø²Ø§Ø±Ø¹ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø§Ø³Øª Ùˆ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return pd.DataFrame(results), errors

    total_farms = len(_farms_df)
    if total_farms == 0:
        return pd.DataFrame(results), errors
        
    progress_bar = st.progress(0)

    for i, (idx_row, farm_row) in enumerate(_farms_df.iterrows()):
        farm_name = farm_row['Ù…Ø²Ø±Ø¹Ù‡']
        current_farm_ee_geometry = None

        try:
            geojson_str = farm_row['geojson_geometry']
            if pd.isna(geojson_str):
                raise ValueError("GeoJSON string is missing.")
            current_farm_ee_geometry = ee.Geometry(json.loads(geojson_str))
        except Exception as e:
            errors.append(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù†Ø¯Ø³Ù‡ Ø¨Ø±Ø§ÛŒ {farm_name}: {e}. Ø§Ø² Ù†Ù‚Ø·Ù‡ Ù…Ø±Ú©Ø²ÛŒ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ÛŒØ§ Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            # Try to use centroid if full geometry fails
            if 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ' in farm_row and 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ' in farm_row and \
               pd.notna(farm_row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']) and pd.notna(farm_row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']):
                current_farm_ee_geometry = ee.Geometry.Point([farm_row['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], farm_row['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']])
            else: # Skip this farm if no geometry at all
                results.append({'Ù…Ø²Ø±Ø¹Ù‡': farm_name, f'{index_name_calc} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': None, f'{index_name_calc} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': None, 'ØªØºÛŒÛŒØ±': None,
                                'Ú©Ø§Ù†Ø§Ù„': farm_row.get('Ú©Ø§Ù†Ø§Ù„', 'N/A'), 'Ø§Ø¯Ø§Ø±Ù‡': farm_row.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')})
                progress_bar.progress((i + 1) / total_farms)
                continue
        
        # Inner function to get mean value for a specific geometry and period
        def get_mean_value_for_geom(geometry_to_process, start_date_str, end_date_str):
            try:
                image, error_img = get_processed_image(geometry_to_process, start_date_str, end_date_str, index_name_calc)
                if image:
                    mean_dict = image.reduceRegion(
                        reducer=ee.Reducer.mean(),
                        geometry=geometry_to_process,
                        scale=10, # 10m for Sentinel-2
                        maxPixels=1e9
                    ).getInfo()
                    return mean_dict.get(index_name_calc) if mean_dict else None, None
                else:
                    return None, error_img or f"No image for {farm_name} ({start_date_str}-{end_date_str})"
            except Exception as e_reduce:
                 return None, f"Error reducing region for {farm_name} ({start_date_str}-{end_date_str}): {e_reduce}"

        current_val, err_curr = get_mean_value_for_geom(current_farm_ee_geometry, start_curr, end_curr)
        if err_curr: errors.append(f"{farm_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ): {err_curr}")

        previous_val, err_prev = get_mean_value_for_geom(current_farm_ee_geometry, start_prev, end_prev)
        if err_prev: errors.append(f"{farm_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„): {err_prev}")

        change = None
        if current_val is not None and previous_val is not None:
            try: change = current_val - previous_val
            except TypeError: change = None

        results.append({
            'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
            'Ú©Ø§Ù†Ø§Ù„': farm_row.get('Ú©Ø§Ù†Ø§Ù„', 'N/A'),
            'Ø§Ø¯Ø§Ø±Ù‡': farm_row.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A'),
            f'{index_name_calc} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': current_val,
            f'{index_name_calc} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': previous_val,
            'ØªØºÛŒÛŒØ±': change
        })
        progress_bar.progress((i + 1) / total_farms)
    progress_bar.empty()
    return pd.DataFrame(results), errors

# Calculate and display the ranking table
ranking_df, calculation_errors = calculate_weekly_indices(
    filtered_farms_df, # Pass a copy to avoid modifying the original if calculate_weekly_indices did so
    selected_index,
    start_date_current_str,
    end_date_current_str,
    start_date_previous_str,
    end_date_previous_str
)

if calculation_errors:
    st.warning("âš ï¸ Ø¨Ø±Ø®ÛŒ Ø®Ø·Ø§Ù‡Ø§ Ø¯Ø± Ø­ÛŒÙ† Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø±Ø® Ø¯Ø§Ø¯:")
    for error_idx, error_msg in enumerate(calculation_errors[:10]):
        st.caption(f" - {error_msg}")
    if len(calculation_errors) > 10:
        st.caption(f"... Ùˆ {len(calculation_errors) - 10} Ø®Ø·Ø§ÛŒ Ø¯ÛŒÚ¯Ø± (Ø¨Ø±Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨Ù‡ Ú©Ù†Ø³ÙˆÙ„ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯).")


if not ranking_df.empty:
    ascending_sort = selected_index in ['MSI']
    ranking_df_sorted = ranking_df.sort_values(
        by=f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)',
        ascending=ascending_sort,
        na_position='last'
    ).reset_index(drop=True)
    ranking_df_sorted.index = ranking_df_sorted.index + 1
    ranking_df_sorted.index.name = 'Ø±ØªØ¨Ù‡'

    def determine_status(row, index_name_status):
        change_val = row['ØªØºÛŒÛŒØ±']
        if pd.isna(change_val) or pd.isna(row[f'{index_name_status} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)']) or pd.isna(row[f'{index_name_status} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)']):
            return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
        threshold = 0.05 # General threshold, might need adjustment per index
        if index_name_status in ['NDVI', 'EVI', 'LAI', 'CVI']: # Higher is better
            if change_val > threshold: return "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª"
            elif change_val < -threshold: return "ØªÙ†Ø´/Ú©Ø§Ù‡Ø´"
            else: return "Ø«Ø§Ø¨Øª"
        elif index_name_status in ['MSI', 'NDMI']: # Lower is better (for MSI higher means more stress; NDMI higher means more moisture)
                                                   # For NDMI, higher change means more moisture = improvement.
                                                   # For MSI, higher change means more stress = deterioration.
            if index_name_status == 'NDMI': # Higher change is better
                 if change_val > threshold: return "Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø·ÙˆØ¨Øª"
                 elif change_val < -threshold: return "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª"
                 else: return "Ø«Ø§Ø¨Øª"
            elif index_name_status == 'MSI': # Lower change is better (less stress)
                 if change_val < -threshold: return "Ú©Ø§Ù‡Ø´ ØªÙ†Ø´ (Ø¨Ù‡Ø¨ÙˆØ¯)" # e.g. MSI from 1.5 to 1.0 -> change = -0.5
                 elif change_val > threshold: return "Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†Ø´ (Ø¨Ø¯ØªØ± Ø´Ø¯Ù†)"
                 else: return "Ø«Ø§Ø¨Øª"
        return "Ù†Ø§Ù…Ø´Ø®Øµ"

    ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_sorted.apply(lambda row: determine_status(row, selected_index), axis=1)
    
    cols_to_format = [f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±']
    for col_format in cols_to_format:
        if col_format in ranking_df_sorted.columns:
             ranking_df_sorted[col_format] = ranking_df_sorted[col_format].map(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")
    
    st.dataframe(ranking_df_sorted, use_container_width=True)
    
    # Summary metrics
    st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
    status_counts = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].value_counts()
    col1, col2, col3, col4 = st.columns(4) # Added one more for flexibility

    positive_statuses = ["Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª", "Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø·ÙˆØ¨Øª", "Ú©Ø§Ù‡Ø´ ØªÙ†Ø´ (Ø¨Ù‡Ø¨ÙˆØ¯)"]
    negative_statuses = ["ØªÙ†Ø´/Ú©à¤¾à¤¹Ø´", "Ú©Ø§Ù‡Ø´ Ø±Ø·ÙˆØ¨Øª", "Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†Ø´ (Ø¨Ø¯ØªØ± Ø´Ø¯Ù†)"]
    
    positive_count = sum(status_counts.get(s, 0) for s in positive_statuses)
    negative_count = sum(status_counts.get(s, 0) for s in negative_statuses)
    neutral_count = status_counts.get("Ø«Ø§Ø¨Øª", 0)
    nodata_count = status_counts.get("Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", 0)

    with col1: st.metric("ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡", positive_count)
    with col2: st.metric("âšª Ø«Ø§Ø¨Øª", neutral_count)
    with col3: st.metric("ğŸ”´ Ø¨Ø¯ØªØ± Ø´Ø¯Ù‡", negative_count)
    with col4: st.metric("â“ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", nodata_count)
    
    st.info("""
    **ØªÙˆØ¶ÛŒØ­Ø§Øª ÙˆØ¶Ø¹ÛŒØª:**
    - **Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¢Ù†Ù‡Ø§ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ù‡ØªØ± Ø´Ø¯Ù‡ (Ù…Ø«Ù„Ø§Ù‹ NDVI Ø¨ÛŒØ´ØªØ±ØŒ MSI Ú©Ù…ØªØ±).
    - **Ø«Ø§Ø¨Øª**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ ØªØºÛŒÛŒØ± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯.
    - **Ø¨Ø¯ØªØ± Ø´Ø¯Ù‡**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ ÙˆØ¶Ø¹ÛŒØª Ø¢Ù†Ù‡Ø§ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ù†Ø§Ù…Ø·Ù„ÙˆØ¨â€ŒØªØ± Ø´Ø¯Ù‡ Ø§Ø³Øª.
    - **Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ø§Ù…Ú©Ø§Ù† Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¢Ù†Ù‡Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª.
    """)

    csv_data = ranking_df_sorted.to_csv(index=True).encode('utf-8-sig') # utf-8-sig for Excel compatibility with Persian
    st.download_button(
        label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (CSV)",
        data=csv_data,
        file_name=f'ranking_{selected_index}_{selected_day.replace(" ", "_")}_{end_date_current_str}.csv',
        mime='text/csv',
    )
else:
    st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.")

st.markdown("---")
st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Streamlit, Google Earth Engine, Ùˆ geemap")
st.sidebar.markdown(f"<p style='text-align: right;'>Ù†Ø³Ø®Ù‡ 1.1.0</p>", unsafe_allow_html=True)