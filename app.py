# --- START OF FILE app_enhanced.py ---

import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
import plotly.express as px
import plotly.graph_objects as go # For 3D plots if needed later, using scatter now
import os
from io import BytesIO
import requests
import traceback
from streamlit_folium import st_folium
import base64
import time
import math # For checking NaN

# --- Gemini API Integration ---
import google.generativeai as genai

# WARNING: Storing API keys directly in code is insecure!
# Use environment variables or st.secrets in production.
# Replace "YOUR_GEMINI_API_KEY" with your actual key for this specific implementation.
GEMINI_API_KEY = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ" # <-- PASTE YOUR KEY HERE

# --- Constants ---
APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø± (Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡)"
CSV_FILE_PATH = 'cleaned_output.csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12
# Indices and their properties
INDEX_INFO = {
    "NDVI": {"name": "Ø´Ø§Ø®Øµ ØªØ±Ø§Ú©Ù… Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ", "palette": 'RdYlGn', "min": 0.0, "max": 0.9, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø³Ø¨Ø² Ø¨ÛŒØ§Ù†Ú¯Ø± Ù…Ø­ØµÙˆÙ„ Ù…ØªØ±Ø§Ú©Ù… Ùˆ Ø³Ø§Ù„Ù… Ùˆ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡â€ŒÛŒ Ù…Ø­ØµÙˆÙ„ Ú©Ù…â€ŒÙ¾Ø´Øª Ùˆ Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡ Ø§Ø³Øª."},
    "NDWI": {"name": "Ø´Ø§Ø®Øµ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ú¯ÛŒØ§Ù‡Ø§Ù†", "palette": ['#d7191c', '#fdae61', '#ffffbf', '#abd9e9', '#2c7bb6'], "min": -0.2, "max": 0.6, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¢Ø¨ÛŒ Ø¨ÛŒØ´ØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ø¨ÛŒ Ø¨ÛŒØ´ØªØ± Ùˆ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù…â€ŒØ¢Ø¨ÛŒ Ø§Ø³Øª."},
    "NDRE": {"name": "Ø´Ø§Ø®Øµ Ù…ÛŒØ²Ø§Ù† Ø§Ø²Øª Ú¯ÛŒØ§Ù‡ (Ù„Ø¨Ù‡ Ù‚Ø±Ù…Ø²)", "palette": 'Purples', "min": 0.0, "max": 0.6, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¨Ù†ÙØ´ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù…ÛŒØ²Ø§Ù† Ø²ÛŒØ§Ø¯ Ø§Ø²Øª/Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ùˆ Ø±Ù†Ú¯ Ø±ÙˆØ´Ù†â€ŒØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ø§Ù‡Ø´ Ø¢Ù† Ø¯Ø± Ú¯ÛŒØ§Ù‡ Ø§Ø³Øª."},
    "LAI": {"name": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)", "palette": 'YlGn', "min": 0, "max": 7, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø³Ø¨Ø² Ù¾Ø±Ø±Ù†Ú¯â€ŒØªØ± Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø³Ø·Ø­ Ø¨Ø±Ú¯ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ø§Ø³Øª."},
    "CHL": {"name": "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (ØªØ®Ù…ÛŒÙ†ÛŒ)", "palette": ['#b35806','#f1a340','#fee0b6','#d8daeb','#998ec3','#542788'], "min": 0, "max": 10, "higher_is_better": True, "desc": "Ø±Ù†Ú¯ Ø¨Ù†ÙØ´/ØªÛŒØ±Ù‡ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ù„Ø±ÙˆÙÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª Ùˆ Ø±Ù†Ú¯ Ù‚Ù‡ÙˆÙ‡â€ŒØ§ÛŒ/Ø±ÙˆØ´Ù† Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ú©Ø§Ù‡Ø´ Ú©Ù„Ø±ÙˆÙÛŒÙ„ ÛŒØ§ ØªÙ†Ø´ Ø§Ø³Øª."}
}
# Default threshold for significant change
CHANGE_THRESHOLD = 0.03

# --- Page Config and CSS ---
st.set_page_config(
    page_title=APP_TITLE,
    page_icon="ğŸŒ¾",
    layout="wide"
)

# Custom CSS (remains mostly the same, ensure Vazirmatn is loaded)
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');
        body, .main, button, input, textarea, select, .stTextInput, .stSelectbox, .stDateInput, .stButton>button, .stTabs [data-baseweb="tab"], .stMetric, .stDataFrame, .stPlotlyChart {
            font-family: 'Vazirmatn', sans-serif !important;
            direction: rtl; /* Ensure consistent RTL */
        }
        /* Ensure elements within columns/containers also inherit RTL */
        .stBlock, .stHorizontalBlock { direction: rtl; }
        /* Align headers right */
        h1, h2, h3, h4, h5, h6 { text-align: right; color: #2c3e50; }
        /* Align Plotly titles (might need specific Plotly config too) */
        .plotly .gtitle { text-align: right !important; }
        /* Specific alignment for Streamlit components if needed */
        .stSelectbox > label, .stDateInput > label, .stTextInput > label, .stTextArea > label {
             text-align: right !important; width: 100%; display: block;
         }
        /* Right-align text in dataframes */
        .dataframe { text-align: right; }
        .stTabs [data-baseweb="tab-list"] { gap: 5px; }
        .stTabs [data-baseweb="tab"] { height: 50px; padding: 10px 20px; background-color: #f0f2f6; border-radius: 8px 8px 0 0; font-weight: 600; }
        .stTabs [aria-selected="true"] { background-color: #e6f2ff; } /* Highlight selected tab */
        .stMetric { background-color: #f8f9fa; border-radius: 10px; padding: 1rem; box-shadow: 0 2px 4px rgba(0,0,0,0.05); text-align: center;}
        .stMetric > label { font-weight: bold; color: #495057; } /* Style metric label */
        .stMetric > div { font-size: 1.5em; color: #007bff; } /* Style metric value */
         /* Ensure sidebar is RTL */
        .css-1d391kg { direction: rtl; }
        .css-1d391kg .stSelectbox > label { text-align: right !important; } /* Fix sidebar select label */
    </style>
""", unsafe_allow_html=True)

# --- Initialize Session State ---
if 'gee_initialized' not in st.session_state:
    st.session_state.gee_initialized = False
if 'farm_data' not in st.session_state:
    st.session_state.farm_data = None
if 'ranking_data' not in st.session_state:
    st.session_state.ranking_data = {'df': pd.DataFrame(), 'errors': [], 'params': None}
if 'gemini_analysis' not in st.session_state:
    st.session_state.gemini_analysis = {'text': None, 'error': None, 'params': None}
if 'gemini_available' not in st.session_state:
    st.session_state.gemini_available = False
if 'gemini_model' not in st.session_state:
    st.session_state.gemini_model = None

# --- GEE and Gemini Initialization ---
@st.cache_resource
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return False
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully.")
        return True
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        return False

@st.cache_resource
def configure_gemini():
    """Configures the Gemini API."""
    try:
        if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY":
             print("Gemini API Key not provided.")
             return None, False # Model, Available status
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash') # Use a fast model
        print("Gemini API Configured Successfully.")
        return model, True
    except Exception as e:
        print(f"Error configuring Gemini API: {e}")
        st.warning(f"âš ï¸ Ø§Ø®Ø·Ø§Ø±: Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Gemini API ({e}). ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")
        return None, False

# Initialize only once
if not st.session_state.gee_initialized:
    st.session_state.gee_initialized = initialize_gee()
    if not st.session_state.gee_initialized:
        st.error("âŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
        st.stop()

if st.session_state.gemini_model is None:
     st.session_state.gemini_model, st.session_state.gemini_available = configure_gemini()

# --- Load Farm Data ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...")
def load_farm_data(csv_path=CSV_FILE_PATH):
    """Loads and validates farm data from CSV."""
    try:
        df = pd.read_csv(csv_path)
        required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'coordinates_missing']
        if not all(col in df.columns for col in required_cols):
            st.error(f"âŒ ÙØ§ÛŒÙ„ CSV Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø§Ø´Ø¯: {', '.join(required_cols)}")
            return None
        df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'] = pd.to_numeric(df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], errors='coerce')
        df['coordinates_missing'] = df['coordinates_missing'].fillna(False).astype(bool)
        df = df.dropna(subset=['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'])
        df = df[~df['coordinates_missing']]
        if df.empty:
            st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return None
        df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] = df['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].astype(str).str.strip()
        # Add a unique ID for potential joining later
        df['farm_id'] = df['Ù…Ø²Ø±Ø¹Ù‡'] + '_' + df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].astype(str) + '_' + df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].astype(str)
        print(f"Farm data loaded successfully: {len(df)} farms.")
        return df
    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ CSV: {e}")
        st.error(traceback.format_exc())
        return None

# Load data only once or if it's not in session state
if st.session_state.farm_data is None:
    st.session_state.farm_data = load_farm_data()

if st.session_state.farm_data is None:
    st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")
    st.stop()

# ========================= Sidebar Inputs =========================
st.sidebar.header("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

# --- Day Selection ---
available_days = sorted(st.session_state.farm_data['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'].unique())
selected_day = st.sidebar.selectbox(
    "ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡:",
    options=available_days,
    index=available_days.index("Ø´Ù†Ø¨Ù‡") if "Ø´Ù†Ø¨Ù‡" in available_days else 0, # Default to Saturday
    key='selected_day_key' # Add key to help manage state
)

# --- Filter Data Based on Selected Day ---
filtered_farms_df = st.session_state.farm_data[st.session_state.farm_data['Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡'] == selected_day].copy()

if filtered_farms_df.empty:
    st.warning(f"âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    st.stop()

# --- Farm Selection ---
available_farms = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique())
selected_farm_name = st.sidebar.selectbox(
    "ğŸŒ¾ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡:",
    options=available_farms,
    index=0, # Default to "All Farms"
    key='selected_farm_key'
)

# --- Index Selection ---
selected_index = st.sidebar.selectbox(
    "ğŸ“ˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø§Ø®Øµ:",
    options=list(INDEX_INFO.keys()),
    format_func=lambda x: f"{x} ({INDEX_INFO[x]['name']})",
    index=0, # Default to NDVI
    key='selected_index_key'
)
# Get index properties
index_props = INDEX_INFO[selected_index]
vis_params = {'min': index_props['min'], 'max': index_props['max'], 'palette': index_props['palette']}

# --- Date Range Calculation ---
# Perform calculation only if needed (e.g., day changes)
# Using inputs directly, no need to cache this simple calculation
today = datetime.date.today()
persian_to_weekday = {"Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1, "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4}
try:
    target_weekday = persian_to_weekday[selected_day]
    days_ago = (today.weekday() - target_weekday + 7) % 7
    end_date_current = today - datetime.timedelta(days=days_ago) if days_ago != 0 else today
    start_date_current = end_date_current - datetime.timedelta(days=6)
    end_date_previous = start_date_current - datetime.timedelta(days=1)
    start_date_previous = end_date_previous - datetime.timedelta(days=6)

    start_date_current_str = start_date_current.strftime('%Y-%m-%d')
    end_date_current_str = end_date_current.strftime('%Y-%m-%d')
    start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
    end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')

    st.sidebar.info(f"ğŸ—“ï¸ Ø¨Ø§Ø²Ù‡ ÙØ¹Ù„ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
    st.sidebar.info(f"ğŸ—“ï¸ Ø¨Ø§Ø²Ù‡ Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")

except KeyError:
    st.sidebar.error(f"Ù†Ø§Ù… Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
    st.stop()
except Exception as e:
    st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}")
    st.stop()

# ========================= GEE Functions (Cached) =========================

@st.cache_data(persist=True) # Cache cloud masking logic
def maskS2clouds(image_dict):
    """Masks clouds using QA band and SCL. Input/Output: Dictionary representation."""
    image = ee.Image.fromDictionary(image_dict) # Reconstruct image object
    qa = image.select('QA60')
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))
    scl = image.select('SCL')
    good_quality = scl.remap([4, 5, 6], [1, 1, 1], 0) # Keep Veg, Bare Soil, Water
    opticalBands = image.select('B.*').multiply(0.0001)
    masked_image = image.addBands(opticalBands, None, True).updateMask(mask).updateMask(good_quality)
    return masked_image.toDictionary() # Return dictionary

@st.cache_data(persist=True) # Cache index calculation logic
def add_indices_dict(image_dict):
    """Calculates indices. Input/Output: Dictionary representation."""
    image = ee.Image.fromDictionary(image_dict)
    try:
        # Calculate all indices - ensure bands exist implicitly (GEE handles errors later)
        ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')
        ndwi = image.normalizedDifference(['B8', 'B11']).rename('NDWI')
        ndre = image.normalizedDifference(['B8', 'B5']).rename('NDRE')
        lai = ndvi.multiply(3.5).rename('LAI') # Simple estimation
        re1_safe = image.select('B5').max(ee.Image(0.0001))
        chl = image.expression('(NIR / RE1) - 1', {'NIR': image.select('B8'), 'RE1': re1_safe}).rename('CHL')
        return image.addBands([ndvi, ndwi, ndre, lai, chl]).toDictionary()
    except Exception as e:
        # print(f"Warning: Could not calculate indices for image {image.id().getInfo()}: {e}")
        # Return original image dictionary if calculation fails for any reason
        return image.toDictionary()

@st.cache_data(ttl=3600, show_spinner=False, persist=True) # Cache image retrieval for 1 hour
def get_processed_image_gee(_geometry_json, start_date, end_date, index_name):
    """Gets processed GEE image. Input geometry as JSON, returns Image JSON or error."""
    _geometry = ee.Geometry(json.loads(_geometry_json)) # Recreate geometry
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_geometry)
                     .filterDate(start_date, end_date))

        # Serialize/Deserialize for caching cloud masking and index calculation
        s2_list = s2_sr_col.toList(s2_sr_col.size())
        s2_dicts = [img.toDictionary() for img in ee.List(s2_list).getInfo()] # GetInfo here is necessary

        masked_dicts = [maskS2clouds(img_dict) for img_dict in s2_dicts]
        indexed_dicts = [add_indices_dict(img_dict) for img_dict in masked_dicts]

        # Filter out dicts where masking/indexing might have failed (e.g., missing essential bands)
        # Reconstruct ImageCollection from valid dictionaries
        valid_images = [ee.Image.fromDictionary(d) for d in indexed_dicts if 'B8' in d.get('bands', [])] # Check a common band

        if not valid_images:
             return None, f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ± Ù…Ø¹ØªØ¨Ø±ÛŒ Ù¾Ø³ Ø§Ø² Ù…Ø§Ø³Ú© Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ ÛŒØ§ÙØª Ù†Ø´Ø¯ ({start_date} ØªØ§ {end_date})."

        indexed_col = ee.ImageCollection.fromImages(valid_images)

        # Ensure the target index exists in the collection
        # sample_bands = indexed_col.first().bandNames().getInfo() # Check bands on first image
        # if index_name not in sample_bands:
        #      return None, f"Ø´Ø§Ø®Øµ '{index_name}' Ø¯Ø± ØªØµØ§ÙˆÛŒØ± Ø§ÛŒÙ† Ø¯ÙˆØ±Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯."

        median_image = indexed_col.select(list(INDEX_INFO.keys())).median() # Select all known indices before median

        # Final check if the specific index exists after median
        final_bands = median_image.bandNames().getInfo()
        if index_name not in final_bands:
             return None, f"Ø´Ø§Ø®Øµ '{index_name}' Ù¾Ø³ Ø§Ø² ØªØ±Ú©ÛŒØ¨ median Ø¯Ø± ØªØµÙˆÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."

        output_image = median_image.select(index_name)
        # Return image info for caching, not the object itself
        return output_image.serialize(), None

    except ee.EEException as e:
        error_message = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± get_processed_image: {e}"
        # Add more specific error parsing if needed
        return None, error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± get_processed_image: {e}\n{traceback.format_exc()}"
        return None, error_message

# --- Function to get thumbnail URL ---
@st.cache_data(ttl=3600, show_spinner="Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú©...")
def get_thumbnail_url(_image_serialized, _geometry_json, _vis_params):
    """Gets a thumbnail URL for a GEE image."""
    if not _image_serialized:
        return None, "No image data for thumbnail."
    try:
        image = ee.Image.deserialize(_image_serialized)
        geometry = ee.Geometry(json.loads(_geometry_json))
        thumb_url = image.getThumbURL({
            'region': geometry.buffer(500).bounds(), # Buffer point slightly and get bounds
            'dimensions': 256,
            'params': _vis_params,
            'format': 'png'
        })
        return thumb_url, None
    except Exception as e:
        return None, f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ thumbnail: {e}"

# --- Function to get time series ---
@st.cache_data(ttl=3600, show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ...")
def get_index_time_series_data(_point_geom_json, index_name, start_date, end_date):
    """Gets time series data, returns DataFrame JSON or error."""
    _point_geom = ee.Geometry(json.loads(_point_geom_json))
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_point_geom)
                     .filterDate(start_date, end_date))

        # Use the cached masking/indexing functions
        s2_list = s2_sr_col.toList(s2_sr_col.size())
        s2_dicts = [img.toDictionary() for img in ee.List(s2_list).getInfo()]
        masked_dicts = [maskS2clouds(img_dict) for img_dict in s2_dicts]
        indexed_dicts = [add_indices_dict(img_dict) for img_dict in masked_dicts]

        # Filter, reconstruct, and map to extract values
        valid_images = [ee.Image.fromDictionary(d) for d in indexed_dicts if index_name in [b['id'] for b in d.get('bands', [])]]

        if not valid_images:
             return None, f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name} ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù¾Ø³ Ø§Ø² ÙÛŒÙ„ØªØ±)."

        indexed_col = ee.ImageCollection.fromImages(valid_images)

        def extract_value(image):
            value = image.select(index_name).reduceRegion(
                reducer=ee.Reducer.first(),
                geometry=_point_geom,
                scale=10
            ).get(index_name)
            # Ensure date is properly formatted
            img_date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')
            return ee.Feature(None, {'date': img_date, index_name: value})

        ts_features = indexed_col.map(extract_value).filter(ee.Filter.notNull([index_name]))
        ts_info = ts_features.getInfo()['features']

        if not ts_info:
            return None, f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name} ÛŒØ§ÙØª Ù†Ø´Ø¯."

        # Convert to DataFrame and then to JSON for caching
        ts_data = [{'date': f['properties']['date'], index_name: f['properties'][index_name]} for f in ts_info]
        ts_df = pd.DataFrame(ts_data)
        ts_df['date'] = pd.to_datetime(ts_df['date'])
        ts_df = ts_df.sort_values('date').set_index('date')
        # Ensure numeric type before returning JSON
        ts_df[index_name] = pd.to_numeric(ts_df[index_name], errors='coerce')
        ts_df.dropna(subset=[index_name], inplace=True)

        if ts_df.empty:
             return None, f"Ø¯Ø§Ø¯Ù‡ Ø¹Ø¯Ø¯ÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name} ÛŒØ§ÙØª Ù†Ø´Ø¯."

        return ts_df.to_json(orient='split', date_format='iso'), None

    except ee.EEException as e:
        return None, f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ({index_name}): {e}"
    except Exception as e:
        return None, f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ({index_name}): {e}"

# --- Function to calculate indices for ranking table ---
# This is the slowest part - use spinner and session state
def calculate_all_farm_indices(farms_df, index_name, start_curr, end_curr, start_prev, end_prev):
    results = []
    errors = []
    total_farms = len(farms_df)

    # Use st.expander for progress, as spinner blocks interaction
    with st.expander(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ {index_name} Ø¨Ø±Ø§ÛŒ {total_farms} Ù…Ø²Ø±Ø¹Ù‡...", expanded=True):
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, (idx, farm) in enumerate(farms_df.iterrows()):
            farm_name = farm['Ù…Ø²Ø±Ø¹Ù‡']
            lat = farm['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
            lon = farm['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
            point_geom = ee.Geometry.Point([lon, lat])
            point_geom_json = json.dumps(point_geom.getInfo()) # Serialize for cached function

            status_text.text(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø²Ø±Ø¹Ù‡ {i+1}/{total_farms}: {farm_name}")

            def get_mean_value_cached(geom_json, start, end):
                image_serialized, error_img = get_processed_image_gee(geom_json, start, end, index_name)
                if image_serialized:
                    try:
                        image = ee.Image.deserialize(image_serialized)
                        mean_dict = image.reduceRegion(
                            reducer=ee.Reducer.mean(),
                            geometry=ee.Geometry(json.loads(geom_json)),
                            scale=10
                        ).getInfo()
                        val = mean_dict.get(index_name) if mean_dict else None
                        if val is None and mean_dict is not None:
                            return None, f"'{index_name}' Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ reduceRegion ÛŒØ§ÙØª Ù†Ø´Ø¯."
                        elif val is None:
                            return None, "ReduceRegion Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ù†Ø¯Ø§Ø´Øª."
                        return val, None # Return value and no error
                    except ee.EEException as e_reduce:
                        return None, f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± reduceRegion: {e_reduce}"
                    except Exception as e_other:
                        return None, f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± reduceRegion: {e_other}"
                else:
                    return None, error_img or "ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯."

            # Calculate for current week
            current_val, err_curr = get_mean_value_cached(point_geom_json, start_curr, end_curr)
            if err_curr: errors.append(f"{farm_name} (Ø¬Ø§Ø±ÛŒ): {err_curr}")

            # Calculate for previous week
            previous_val, err_prev = get_mean_value_cached(point_geom_json, start_prev, end_prev)
            if err_prev: errors.append(f"{farm_name} (Ù‚Ø¨Ù„): {err_prev}")

            # Calculate change
            change = None
            if current_val is not None and previous_val is not None:
                try: change = float(current_val) - float(previous_val)
                except (TypeError, ValueError): change = None

            results.append({
                'farm_id': farm['farm_id'], # Use unique ID
                'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
                'Ú©Ø§Ù†Ø§Ù„': farm.get('Ú©Ø§Ù†Ø§Ù„', 'N/A'),
                'Ø§Ø¯Ø§Ø±Ù‡': farm.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A'),
                'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ': lon,
                'Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ': lat,
                f'{index_name}_curr': current_val,
                f'{index_name}_prev': previous_val,
                f'{index_name}_change': change
            })
            progress_bar.progress((i + 1) / total_farms)
            # time.sleep(0.01) # Avoid potential GEE rate limits if needed

        status_text.text(f"Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ù…Ù„ Ø´Ø¯.")
        time.sleep(1) # Keep message visible briefly

    return pd.DataFrame(results), errors


# --- Gemini AI Analysis Function ---
@st.cache_data(show_spinner="ğŸ§  Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
def get_gemini_analysis(_index_name, _farm_name, _current_val, _previous_val, _change_val):
    """Generates analysis and recommendations using Gemini API."""
    if not st.session_state.gemini_available or st.session_state.gemini_model is None:
        return "ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ API Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.", None

    if pd.isna(_current_val) or pd.isna(_previous_val) or pd.isna(_change_val) or \
       math.isnan(float(_current_val)) or math.isnan(float(_previous_val)) or math.isnan(float(_change_val)): # Check for actual NaN
         return "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ (Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¹Ø¯Ø¯ÛŒ ÙØ¹Ù„ÛŒØŒ Ù‚Ø¨Ù„ÛŒ Ùˆ ØªØºÛŒÛŒØ±) ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.", None

    current_str = f"{float(_current_val):.3f}"
    previous_str = f"{float(_previous_val):.3f}"
    change_str = f"{float(_change_val):.3f}"

    index_details = INDEX_INFO.get(_index_name, {"name": _index_name, "desc": ""})
    interpretation = f"Ø´Ø§Ø®Øµ {_index_name} ({index_details['name']}) {index_details['desc']}"

    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ù‡Ø³ØªÛŒØ¯.
    Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ´Ú©Ø± Ø¨Ø§ Ù†Ø§Ù… "{_farm_name}"ØŒ Ø´Ø§Ø®Øµ "{_index_name}" ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³Øª.
    {interpretation}

    Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ: {current_str}
    Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„: {previous_str}
    Ù…ÛŒØ²Ø§Ù† ØªØºÛŒÛŒØ± Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„: {change_str}

    ÙˆØ¸Ø§ÛŒÙ Ø´Ù…Ø§:
    1.  **ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª:** Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯Ù‚ÛŒÙ‚ ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ø¯Ø± Ù…Ù‚Ø¯Ø§Ø± Ø´Ø§Ø®Øµ {_index_name} Ú†Ù‡ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…ØªØŒ Ø±Ø´Ø¯ØŒ ÛŒØ§ ØªÙ†Ø´ (Ù…Ø§Ù†Ù†Ø¯ ØªÙ†Ø´ Ø¢Ø¨ÛŒ ÛŒØ§ Ú©Ù…Ø¨ÙˆØ¯ Ù…ÙˆØ§Ø¯ Ù…ØºØ°ÛŒ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ø´Ø§Ø®Øµ) Ù†ÛŒØ´Ú©Ø± Ø¯Ø± Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø§Ø±Ø¯. Ø¨Ù‡ Ù…Ø«Ø¨Øª ÛŒØ§ Ù…Ù†ÙÛŒ Ø¨ÙˆØ¯Ù† ØªØºÛŒÛŒØ± Ùˆ Ù…Ù‚Ø¯Ø§Ø± Ø¢Ù† Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†ÛŒØ¯.
    2.  **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ùˆ Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®Øµ (Ø¨Ù‡â€ŒØ®ØµÙˆØµ NDWI ÛŒØ§ NDVI)ØŒ ÛŒÚ© Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„ÛŒ Ùˆ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ø¯Ø± Ù‡ÙØªÙ‡ Ù¾ÛŒØ´ Ø±Ùˆ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯. (Ù…Ø«Ù„Ø§Ù‹ "Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± ÙˆØ¶Ø¹ÛŒØª Ø±Ø·ÙˆØ¨Øª Ø®Ø§Ú© Ùˆ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø§ÙØ²Ø§ÛŒØ´ Ø¢Ø¨ÛŒØ§Ø±ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯" ÛŒØ§ "ÙˆØ¶Ø¹ÛŒØª Ø¢Ø¨ÛŒ Ú¯ÛŒØ§Ù‡ Ù…Ø·Ù„ÙˆØ¨ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ØŒ Ø±ÙˆÙ†Ø¯ ÙØ¹Ù„ÛŒ Ø­ÙØ¸ Ø´ÙˆØ¯").
    3.  **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† ØªØºÛŒÛŒØ± Ùˆ Ù…Ø§Ù‡ÛŒØª Ø´Ø§Ø®Øµ (Ø¨Ù‡â€ŒØ®ØµÙˆØµ NDREØŒ CHL ÛŒØ§ NDVI)ØŒ ÛŒÚ© Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„ÛŒ Ùˆ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ú©ÙˆØ¯Ø¯Ù‡ÛŒ (Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ Ù†ÛŒØªØ±ÙˆÚ˜Ù†) Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯. (Ù…Ø«Ù„Ø§Ù‹ "Ú©Ø§Ù‡Ø´ Ø´Ø§Ø®Øµ NDRE Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØºØ°ÛŒÙ‡ Ùˆ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ Ù†ÛŒØªØ±ÙˆÚ˜Ù†Ù‡ Ø¨Ø§Ø´Ø¯" ÛŒØ§ "Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ú©Ù„Ø±ÙˆÙÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ù†ÛŒØ§Ø² ÙÙˆØ±ÛŒ Ø¨Ù‡ ØªØºÛŒÛŒØ± Ø¯Ø± Ú©ÙˆØ¯Ø¯Ù‡ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯").

    Ù†Ú©Ø§Øª Ù…Ù‡Ù…:
    -   ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø§ÛŒØ¯ **ÙÙ‚Ø·** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.
    -   Ø²Ø¨Ø§Ù† Ù†ÙˆØ´ØªØ§Ø± Ø±Ø³Ù…ÛŒ Ùˆ Ø¹Ù„Ù…ÛŒ Ø§Ù…Ø§ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ø¨Ø§Ø´Ø¯.
    -   Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ØªÙ…Ø±Ú©Ø² Ø¨Ø§Ø´Ø¯.
    -   Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ø¯.

    ÙØ±Ù…Øª Ù¾Ø§Ø³Ø®:
    **ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª:** [ØªÙˆØ¶ÛŒØ­ Ø´Ù…Ø§]
    **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** [Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ù…Ø§]
    **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ:** [Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ù…Ø§]
    """

    try:
        response = st.session_state.gemini_model.generate_content(prompt)
        analysis_text = response.text
        # Simple check for empty or placeholder response
        if not analysis_text or len(analysis_text) < 50:
            return "Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾Ø§Ø³Ø®ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ú©Ø±Ø¯ ÛŒØ§ Ù¾Ø§Ø³Ø® Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡ Ø¨ÙˆØ¯.", None
        return analysis_text, None
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API: {e}"
        # Don't show error directly here, return it
        return None, error_message

# ========================= Main Panel Layout =========================
st.title(APP_TITLE)
st.markdown(f"**Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§** | ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´: {datetime.date.today().strftime('%Y-%m-%d')}")
st.markdown("---")

# --- Display Selected Farm Info ---
selected_farm_details = None
selected_farm_geom = None
selected_farm_geom_json = None # For caching

if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
    st.info(f"Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {len(filtered_farms_df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¯Ø± Ø±ÙˆØ² **{selected_day}**.")
    # Define a bounding box geometry for map centering/zooming if needed
    try:
        min_lon, min_lat = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min(), filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].min()
        max_lon, max_lat = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max(), filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].max()
        selected_farm_geom = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])
        selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo()) # Serialize
    except Exception as e:
        st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ bounding box Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹: {e}")
        # Fallback geometry (e.g., center of the area)
        center_lat = filtered_farms_df['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean()
        center_lon = filtered_farms_df['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'].mean()
        selected_farm_geom = ee.Geometry.Point([center_lon, center_lat])
        selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo())

else:
    selected_farm_details = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
    lat = selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    lon = selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']
    selected_farm_geom = ee.Geometry.Point([lon, lat])
    selected_farm_geom_json = json.dumps(selected_farm_geom.getInfo()) # Serialize

    st.subheader(f"ğŸ“ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")
    cols = st.columns([1, 1, 1, 2]) # Adjust column widths
    with cols[0]:
        st.metric("Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)", f"{selected_farm_details.get('Ù…Ø³Ø§Ø­Øª', 'N/A'):,.2f}" if pd.notna(selected_farm_details.get('Ù…Ø³Ø§Ø­Øª')) else "N/A")
        st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", f"{selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}")
    with cols[1]:
        st.metric("Ú©Ø§Ù†Ø§Ù„", f"{selected_farm_details.get('Ú©Ø§Ù†Ø§Ù„', 'N/A')}")
        st.metric("Ø³Ù†", f"{selected_farm_details.get('Ø³Ù†', 'N/A')}")
    with cols[2]:
        st.metric("Ø§Ø¯Ø§Ø±Ù‡", f"{selected_farm_details.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A')}")
        st.metric("Ø±ÙˆØ² Ø¢Ø¨ÛŒØ§Ø±ÛŒ", f"{selected_farm_details.get('Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡', 'N/A')}")

    # --- Display Thumbnail ---
    with cols[3]:
        st.markdown("**ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú© (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ):**")
        # Get the current image for the thumbnail
        thumb_image_serial, err_img = get_processed_image_gee(
            selected_farm_geom_json, start_date_current_str, end_date_current_str, selected_index
        )
        if thumb_image_serial:
            thumb_url, err_thumb = get_thumbnail_url(thumb_image_serial, selected_farm_geom_json, vis_params)
            if thumb_url:
                st.image(thumb_url, caption=f"{selected_index} - {start_date_current_str} to {end_date_current_str}", width=200)
            elif err_thumb:
                st.warning(f"Thumbnail Error: {err_thumb}")
        elif err_img:
             st.warning(f"Image Error: {err_img}")


# --- Main Content Tabs ---
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡", "ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ", "ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ", " dashboards Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø®Ù„Ø§ØµÙ‡"])

with tab1:
    st.subheader(f"Ù†Ù‚Ø´Ù‡ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ - Ø´Ø§Ø®Øµ: {selected_index}")
    m = geemap.Map(location=[INITIAL_LAT, INITIAL_LON], zoom=INITIAL_ZOOM, add_google_map=False)
    m.add_basemap("HYBRID")

    map_data_placeholder = st.empty() # Placeholder for map rendering status

    if selected_farm_geom_json:
        map_data_placeholder.info("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„Ø§ÛŒÙ‡ Ø´Ø§Ø®Øµ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡...")
        gee_image_serial, error_msg_current = get_processed_image_gee(
            selected_farm_geom_json, start_date_current_str, end_date_current_str, selected_index
        )

        if gee_image_serial:
            try:
                gee_image_current = ee.Image.deserialize(gee_image_serial) # Deserialize for map
                m.addLayer(
                    gee_image_current,
                    vis_params,
                    f"{selected_index} ({start_date_current_str} to {end_date_current_str})"
                )

                # Add Legend
                legend_title = f"{selected_index} ({index_props['name']})"
                m.add_legend(legend_title=legend_title, palette=index_props['palette'], min=index_props['min'], max=index_props['max'], layer_name=legend_title)


                # Add Markers
                if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
                    points = filtered_farms_df[['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ', 'Ù…Ø²Ø±Ø¹Ù‡']].to_dict('records')
                    # Create GeoJSON for geemap (more efficient for many points)
                    features = []
                    for p in points:
                         features.append({
                             'type': 'Feature',
                             'geometry': {'type': 'Point', 'coordinates': [p['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], p['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']]},
                             'properties': {'name': p['Ù…Ø²Ø±Ø¹Ù‡']}
                         })
                    farm_geojson = {'type': 'FeatureCollection', 'features': features}
                    m.add_geojson(farm_geojson, layer_name="Ù…Ø²Ø§Ø±Ø¹", info_mode='on_hover', style={'color': 'blue', 'fillColor': 'blue', 'opacity': 0.7, 'weight': 1, 'radius': 3})
                    # Center map on the bounding box or center point
                    if isinstance(selected_farm_geom, ee.geometry.Geometry):
                         m.center_object(selected_farm_geom, zoom=INITIAL_ZOOM)
                else:
                     # Single marker for selected farm
                     folium.Marker(
                         location=[selected_farm_details['Ø¹Ø±Ø¶ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ'], selected_farm_details['Ø·ÙˆÙ„ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ']],
                         popup=f"<b>{selected_farm_name}</b><br>{selected_index} (Ø¬Ø§Ø±ÛŒ): Ù…Ø­Ø§Ø³Ø¨Ù‡...",
                         tooltip=selected_farm_name,
                         icon=folium.Icon(color='red', icon='star')
                     ).add_to(m)
                     if isinstance(selected_farm_geom, ee.geometry.Geometry):
                          m.center_object(selected_farm_geom, zoom=15) # Zoom closer

                m.add_layer_control()
                map_data_placeholder.empty() # Remove loading message
                st_folium(m, width=None, height=600, use_container_width=True, key="map1") # Add key
            except Exception as map_err:
                 map_data_placeholder.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡: {map_err}")
                 st.error(traceback.format_exc())
        else:
            map_data_placeholder.warning(f"ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯. {error_msg_current}")
    else:
         map_data_placeholder.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡ ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")


with tab2:
    st.subheader(f"Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} ({selected_day})")
    st.markdown("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· Ø´Ø§Ø®Øµ Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„.")

    # --- Calculate or Retrieve Ranking Data ---
    ranking_params = (selected_index, start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str, selected_day)

    # Check if calculation is needed (parameters changed or data is empty)
    if st.session_state.ranking_data['params'] != ranking_params or st.session_state.ranking_data['df'].empty:
        print(f"Recalculating ranking table for: {ranking_params}")
        # Clear previous results before recalculating
        st.session_state.ranking_data = {'df': pd.DataFrame(), 'errors': [], 'params': None}
        ranking_df_raw, calculation_errors = calculate_all_farm_indices(
            filtered_farms_df, selected_index,
            start_date_current_str, end_date_current_str,
            start_date_previous_str, end_date_previous_str
        )
        # Store results in session state
        st.session_state.ranking_data['df'] = ranking_df_raw
        st.session_state.ranking_data['errors'] = calculation_errors
        st.session_state.ranking_data['params'] = ranking_params
        # Clear Gemini cache as ranking data changed
        st.session_state.gemini_analysis = {'text': None, 'error': None, 'params': None}
    else:
        print("Using cached ranking data from session state.")
        ranking_df_raw = st.session_state.ranking_data['df']
        calculation_errors = st.session_state.ranking_data['errors']

    # --- Display Ranking Table ---
    if not ranking_df_raw.empty:
        ranking_df_display = ranking_df_raw.copy()
        
        # Rename columns for display clarity
        curr_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)'
        prev_col = f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)'
        change_col = 'ØªØºÛŒÛŒØ±'
        ranking_df_display = ranking_df_display.rename(columns={
            f'{selected_index}_curr': curr_col,
            f'{selected_index}_prev': prev_col,
            f'{selected_index}_change': change_col
        })
        
        # Determine Status
        higher_is_better = index_props['higher_is_better']
        def determine_status(change_val):
            if pd.isna(change_val) or math.isnan(float(change_val)):
                 return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"

            change_val = float(change_val) # Ensure float

            if higher_is_better:
                if change_val > CHANGE_THRESHOLD: return "ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯"
                elif change_val < -CHANGE_THRESHOLD: return "ğŸ”´ Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´"
                else: return "âšª Ø«Ø§Ø¨Øª"
            else: # Lower is better (not used for current indices, but for future)
                if change_val < -CHANGE_THRESHOLD: return "ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯ / Ø±Ø´Ø¯"
                elif change_val > CHANGE_THRESHOLD: return "ğŸ”´ Ú©Ø§Ù‡Ø´ / ØªÙ†Ø´"
                else: return "âšª Ø«Ø§Ø¨Øª"

        ranking_df_display['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_display[change_col].apply(determine_status)

        # Sort table
        ranking_df_sorted = ranking_df_display.sort_values(
            by=curr_col,
            ascending=not higher_is_better, # Sort descending if higher is better
            na_position='last'
        ).reset_index(drop=True)
        ranking_df_sorted.index = ranking_df_sorted.index + 1
        ranking_df_sorted.index.name = 'Ø±ØªØ¨Ù‡'

        # Format numbers
        cols_to_format = [curr_col, prev_col, change_col]
        for col in cols_to_format:
            if col in ranking_df_sorted.columns:
                 ranking_df_sorted[col] = ranking_df_sorted[col].apply(lambda x: f"{float(x):.3f}" if pd.notna(x) and isinstance(x, (int, float, str)) and str(x).replace('.', '', 1).isdigit() else ("-" if pd.isna(x) else x))


        # Display table
        st.dataframe(ranking_df_sorted[[
            'Ù…Ø²Ø±Ø¹Ù‡', 'Ú©Ø§Ù†Ø§Ù„', 'Ø§Ø¯Ø§Ø±Ù‡', curr_col, prev_col, change_col, 'ÙˆØ¶Ø¹ÛŒØª'
            ]], use_container_width=True, height=400) # Set height for scroll

        # Download Button
        try:
            csv_data = ranking_df_sorted.to_csv(index=True, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ (CSV)", data=csv_data,
                file_name=f'ranking_{selected_index}_{selected_day}_{end_date_current_str}.csv', mime='text/csv'
            )
        except Exception as e: st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {e}")

        # Display Errors during calculation
        if calculation_errors:
            with st.expander("âš ï¸ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§", expanded=False):
                 unique_errors = sorted(list(set(calculation_errors)))
                 st.warning(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø®Ø·Ø§Ù‡Ø§: {len(calculation_errors)} (Ù†Ù…Ø§ÛŒØ´ Ù…ÙˆØ§Ø±Ø¯ Ù…Ù†Ø­ØµØ±Ø¨ÙØ±Ø¯)")
                 for i, error in enumerate(unique_errors):
                     st.error(f"- {error}")
                     if i > 15: # Limit displayed errors
                          st.warning(f"... Ùˆ {len(unique_errors) - i} Ø®Ø·Ø§ÛŒ Ù…Ù†Ø­ØµØ±Ø¨ÙØ±Ø¯ Ø¯ÛŒÚ¯Ø±.")
                          break
    else:
        st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ {selected_index} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯.")
        # Also show errors if the dataframe is empty but errors exist
        if calculation_errors:
             st.error("Ø®Ø·Ø§Ù‡Ø§ÛŒÛŒ Ø¯Ø± Ø­ÛŒÙ† ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª (Ø¬Ø²Ø¦ÛŒØ§Øª Ø¯Ø± Ø¨Ø§Ù„Ø§).")


with tab3:
    st.subheader(f"Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index}")

    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif selected_farm_geom_json:
        # Define time series period (e.g., last 12 months)
        ts_end_date = today.strftime('%Y-%m-%d')
        ts_start_date = (today - datetime.timedelta(days=365)).strftime('%Y-%m-%d')

        # Get time series data (returns DataFrame JSON)
        ts_df_json, ts_error = get_index_time_series_data(
            selected_farm_geom_json, selected_index, ts_start_date, ts_end_date
        )

        if ts_error:
            st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}")
        elif ts_df_json:
            try:
                # Read DataFrame from JSON
                ts_df = pd.read_json(ts_df_json, orient='split')
                ts_df.index = pd.to_datetime(ts_df.index, format='iso') # Ensure datetime index

                if not ts_df.empty:
                     fig_ts = px.line(ts_df, y=selected_index, markers=True,
                                      title=f"Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name}",
                                      labels={'index': 'ØªØ§Ø±ÛŒØ®', selected_index: f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                     fig_ts.update_layout(xaxis_title="ØªØ§Ø±ÛŒØ®", yaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                     st.plotly_chart(fig_ts, use_container_width=True)
                     st.caption("Ù†Ù‚Ø§Ø· Ø¯Ø§Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.")
                     # Optional: Download time series data
                     csv_ts = ts_df.to_csv(encoding='utf-8-sig')
                     st.download_button(label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ (CSV)", data=csv_ts, file_name=f'timeseries_{selected_farm_name}_{selected_index}.csv', mime='text/csv')

                else:
                     st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            except Exception as e_plot:
                 st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e_plot}")
                 st.error(traceback.format_exc())

        else:
             st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    else:
         st.warning("Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ Ù†ÛŒØ³Øª.")

with tab4:
    st.subheader(f"Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡ ({selected_day}) - Ø´Ø§Ø®Øµ: {selected_index}")

    # Ensure ranking data is calculated and available
    ranking_df_raw = st.session_state.ranking_data.get('df')
    if ranking_df_raw is None or ranking_df_raw.empty:
        st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² {selected_day} Ùˆ Ø´Ø§Ø®Øµ {selected_index} Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø¨Ù‡ ØªØ¨ 'Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ' Ø¨Ø±ÙˆÛŒØ¯ ØªØ§ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.")
        # Optionally trigger calculation here if desired, but could be slow
        # st.button("Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ") -> would need logic to call calculate_all_farm_indices
    else:
        # Use the processed dataframe from the ranking tab if possible, or re-process raw data
        # For simplicity, let's re-use the sorted/formatted df if available in session state,
        # otherwise re-process the raw data stored in session state.
        # Note: This assumes the ranking tab was visited or calculation triggered.

        # Reprocess raw data for dashboard (ensures consistency)
        df_dash = ranking_df_raw.copy()
        curr_col_raw = f'{selected_index}_curr'
        prev_col_raw = f'{selected_index}_prev'
        change_col_raw = f'{selected_index}_change'
        
        # Convert to numeric, coercing errors
        df_dash[curr_col_raw] = pd.to_numeric(df_dash[curr_col_raw], errors='coerce')
        df_dash[prev_col_raw] = pd.to_numeric(df_dash[prev_col_raw], errors='coerce')
        df_dash[change_col_raw] = pd.to_numeric(df_dash[change_col_raw], errors='coerce')

        # --- Summary Metrics ---
        st.markdown("**Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹:**")
        higher_is_better = index_props['higher_is_better']

        def get_status_dash(change):
            if pd.isna(change) or math.isnan(change): return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
            if higher_is_better:
                 if change > CHANGE_THRESHOLD: return "Ø¨Ù‡Ø¨ÙˆØ¯"
                 elif change < -CHANGE_THRESHOLD: return "Ú©Ø§Ù‡Ø´"
                 else: return "Ø«Ø§Ø¨Øª"
            else:
                 if change < -CHANGE_THRESHOLD: return "Ø¨Ù‡Ø¨ÙˆØ¯"
                 elif change > CHANGE_THRESHOLD: return "Ú©Ø§Ù‡Ø´"
                 else: return "Ø«Ø§Ø¨Øª"

        df_dash['status'] = df_dash[change_col_raw].apply(get_status_dash)
        status_counts = df_dash['status'].value_counts()

        col1, col2, col3, col4 = st.columns(4)
        with col1: st.metric("ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯", status_counts.get("Ø¨Ù‡Ø¨ÙˆØ¯", 0))
        with col2: st.metric("âšª Ø«Ø§Ø¨Øª", status_counts.get("Ø«Ø§Ø¨Øª", 0))
        with col3: st.metric("ğŸ”´ Ú©Ø§Ù‡Ø´", status_counts.get("Ú©Ø§Ù‡Ø´", 0))
        with col4: st.metric("âš«ï¸ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", status_counts.get("Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", 0))
        st.markdown("---")


        # --- Plots ---
        col_plot1, col_plot2 = st.columns(2)

        with col_plot1:
            st.markdown(f"**ØªÙˆØ²ÛŒØ¹ Ù…Ù‚Ø§Ø¯ÛŒØ± {selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)**")
            # Filter out NaNs for histogram
            hist_data = df_dash[curr_col_raw].dropna()
            if not hist_data.empty:
                 fig_hist = px.histogram(hist_data, nbins=20, title=f"ØªÙˆØ²ÛŒØ¹ {selected_index}", labels={'value': f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'})
                 fig_hist.update_layout(yaxis_title="ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹", xaxis_title=f"Ù…Ù‚Ø¯Ø§Ø± {selected_index}", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                 st.plotly_chart(fig_hist, use_container_width=True)
            else:
                 st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

        with col_plot2:
            st.markdown("**Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ùˆ Ù‚Ø¨Ù„**")
            # Filter out NaNs for scatter plot
            scatter_data = df_dash.dropna(subset=[curr_col_raw, prev_col_raw, 'status'])
            if not scatter_data.empty:
                 fig_scatter = px.scatter(
                     scatter_data, x=prev_col_raw, y=curr_col_raw,
                     color='status', hover_name='Ù…Ø²Ø±Ø¹Ù‡',
                     title=f"Ù…Ù‚Ø§ÛŒØ³Ù‡ {selected_index}: Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„",
                     labels={prev_col_raw: f"{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)", curr_col_raw: f"{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)", 'status': 'ÙˆØ¶Ø¹ÛŒØª'},
                     color_discrete_map={ # Map status to colors
                         'Ø¨Ù‡Ø¨ÙˆØ¯': 'green',
                         'Ø«Ø§Ø¨Øª': 'grey',
                         'Ú©Ø§Ù‡Ø´': 'red',
                         'Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡': 'black'
                     }
                 )
                 # Add a y=x line for reference
                 min_val_sc = min(scatter_data[prev_col_raw].min(), scatter_data[curr_col_raw].min())
                 max_val_sc = max(scatter_data[prev_col_raw].max(), scatter_data[curr_col_raw].max())
                 fig_scatter.add_shape(type='line', x0=min_val_sc, y0=min_val_sc, x1=max_val_sc, y1=max_val_sc, line=dict(color='rgba(0,0,0,0.5)', dash='dash'))
                 fig_scatter.update_layout(xaxis_title=f"{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)", yaxis_title=f"{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)", title_x=0.5, title_font_family="Vazirmatn", font_family="Vazirmatn")
                 st.plotly_chart(fig_scatter, use_container_width=True)
                 st.caption("Ù†Ù‚Ø§Ø· Ø¨Ø§Ù„Ø§ÛŒ Ø®Ø· Ú†ÛŒÙ† Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡â€ŒØ§Ù†Ø¯ØŒ Ù†Ù‚Ø§Ø· Ù¾Ø§ÛŒÛŒÙ† Ø®Ø· Ú©Ø§Ù‡Ø´ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯.")
            else:
                 st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

        st.markdown("---")

        # --- Top/Bottom Farms ---
        st.markdown("**Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø²Ø§Ø±Ø¹ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø¯Ø§Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ):**")
        df_sorted_dash = df_dash.sort_values(by=curr_col_raw, ascending=not higher_is_better, na_position='last').dropna(subset=[curr_col_raw])

        col_top, col_bottom = st.columns(2)
        with col_top:
            st.markdown(f"**ğŸŸ¢ Ûµ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±ØªØ±**")
            st.dataframe(df_sorted_dash[['Ù…Ø²Ø±Ø¹Ù‡', curr_col_raw, change_col_raw]].head(5).style.format({curr_col_raw: "{:.3f}", change_col_raw: "{:+.3f}"}), use_container_width=True)
        with col_bottom:
            st.markdown(f"**ğŸ”´ Ûµ Ù…Ø²Ø±Ø¹Ù‡ Ø¶Ø¹ÛŒÙâ€ŒØªØ±**")
            st.dataframe(df_sorted_dash[['Ù…Ø²Ø±Ø¹Ù‡', curr_col_raw, change_col_raw]].tail(5).sort_values(by=curr_col_raw, ascending=not higher_is_better).style.format({curr_col_raw: "{:.3f}", change_col_raw: "{:+.3f}"}), use_container_width=True)


# --- AI Analysis Section (if single farm selected) ---
if selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
    st.markdown("---")
    st.subheader(f"ğŸ§  ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ({selected_index}) Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")

    # Check if ranking data is available for the farm
    ranking_df_raw = st.session_state.ranking_data.get('df')
    if ranking_df_raw is not None and not ranking_df_raw.empty:
        farm_analysis_data = ranking_df_raw[ranking_df_raw['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name]

        if not farm_analysis_data.empty:
            farm_row = farm_analysis_data.iloc[0]
            current_val = farm_row.get(f'{selected_index}_curr')
            previous_val = farm_row.get(f'{selected_index}_prev')
            change_val = farm_row.get(f'{selected_index}_change')

            # Check if analysis is needed or already cached
            gemini_params = (selected_index, selected_farm_name, current_val, previous_val, change_val)
            if st.session_state.gemini_analysis.get('params') != gemini_params:
                print(f"Requesting new Gemini analysis for: {gemini_params}")
                analysis_text, analysis_error = get_gemini_analysis(
                    selected_index, selected_farm_name, current_val, previous_val, change_val
                )
                # Store result in session state
                st.session_state.gemini_analysis['text'] = analysis_text
                st.session_state.gemini_analysis['error'] = analysis_error
                st.session_state.gemini_analysis['params'] = gemini_params
            else:
                print("Using cached Gemini analysis from session state.")
                analysis_text = st.session_state.gemini_analysis.get('text')
                analysis_error = st.session_state.gemini_analysis.get('error')

            # Display analysis or error
            if analysis_error:
                 st.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ: {analysis_error}")
            elif analysis_text:
                 st.markdown(analysis_text)
                 st.caption("ØªÙˆØ¬Ù‡: Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ ØµØ±ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ø§ Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ù…ÛŒØ¯Ø§Ù†ÛŒ ØªÙ„ÙÛŒÙ‚ Ø´ÙˆØ¯.")
            elif st.session_state.gemini_available: # Check if API was available but no text returned
                  st.info("ØªØ­Ù„ÛŒÙ„ÛŒ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯.")
            else: # API was not available
                  st.warning("ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ØµØ­ÛŒØ­ API Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

        else:
             st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¬Ù‡Øª ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ø´Ø¯).")
    else:
        st.info("Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒØŒ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ Ùˆ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ØªØ¨ 'Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ' Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")


# --- Footer ---
st.markdown("---")
st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ ğŸ’» ØªÙˆØ³Ø· Ø§Ø³Ù…Ø§Ø¹ÛŒÙ„ Ú©ÛŒØ§Ù†ÛŒ")
st.sidebar.markdown("Streamlit | GEE | Geemap | Plotly | Gemini")
if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY":
    st.sidebar.error("ğŸš¨ Ú©Ù„ÛŒØ¯ API Gemini Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
elif st.session_state.gemini_available:
    st.sidebar.success("âœ… Gemini API ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
else:
     st.sidebar.warning("âš ï¸ Gemini API ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
st.sidebar.warning("Ù‡Ø´Ø¯Ø§Ø± Ø§Ù…Ù†ÛŒØªÛŒ: Ú©Ù„ÛŒØ¯ API Ø¯Ø± Ú©Ø¯ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯.")

# --- END OF FILE ---