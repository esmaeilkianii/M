import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
from folium.plugins import MarkerCluster # For clustering markers on classified maps
import json
import datetime
import plotly.express as px
import plotly.graph_objects as go
import os
import traceback
from streamlit_folium import st_folium
import google.generativeai as genai # Gemini API
import time # Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡ Ø³Ø§Ø²ÛŒ ØªØ§Ø®ÛŒØ± (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
import random # For color generation
from collections import Counter # For counting statuses
import numpy as np # For NaN handling

# --- Custom CSS ---
st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±",
    page_icon="ğŸŒ¾",
    layout="wide"
)

# Modern CSS with enhanced styles (Unchanged from your original code)
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');
        @import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css');

        /* General Styles */
        html, body, .main, .stApp {
            font-family: 'Vazirmatn', sans-serif !important;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); /* Very light gray gradient */
            color: #212529; /* Bootstrap dark gray */
        }

        /* Header Styles */
        .main-header {
            display: flex;
            align-items: center;
            gap: 20px; /* Increased gap */
            margin-bottom: 1rem;
            padding-bottom: 15px;
            border-bottom: 3px solid #6f42c1; /* Bootstrap Purple */
        }
        .main-header h1 {
            color: #6f42c1; /* Bootstrap Purple */
            margin: 0;
            font-weight: 700;
            font-size: 2.2em; /* Slightly larger title */
        }
         .main-header h4 {
            color: #fd7e14; /* Bootstrap Orange */
            margin-top: 5px; /* Adjust spacing */
            font-weight: 500; /* Medium weight */
            font-size: 1.1em;
        }
        .main-logo {
            width: 60px;
            height: 60px;
            border-radius: 18px; /* Rounded square */
            margin-left: 12px;
            vertical-align: middle;
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
            border: 2px solid #ffffff; /* White border */
        }

        /* Sidebar Styles */
        .stSidebar {
             background: #ffffff; /* Clean white */
             border-right: 1px solid #dee2e6; /* Lighter border */
        }
        .sidebar-logo {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 1.5rem;
            padding-top: 1.5rem;
        }
        .sidebar-logo img {
            width: 110px;
            height: 110px;
            border-radius: 22px;
            box-shadow: 0 5px 18px rgba(111, 66, 193, 0.2); /* Purple shadow */
        }
        .stSidebar .stSelectbox label, .stSidebar .stSlider label, .stSidebar .stExpander label, .stSidebar h3 {
             color: #6f42c1 !important; /* Purple labels */
             font-weight: 700;
             font-size: 1.05em;
        }
        .stSidebar .stExpander { /* Style expanders */
             background-color: #f8f9fa;
             border-radius: 10px;
             border: 1px solid #e9ecef;
             margin-bottom: 10px;
        }

        /* Modern card style - Enhanced */
        .modern-card {
            background: #ffffff;
            color: #212529;
            border-radius: 16px;
            padding: 25px 20px;
            margin: 12px 0;
            box-shadow: 0 6px 20px rgba(111, 66, 193, 0.09); /* Subtle purple shadow */
            text-align: center;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            border: 1px solid #f0f0f0;
            position: relative; /* For potential pseudo-elements */
            overflow: hidden; /* Hide overflow for effects */
        }
        /* Optional: Add a subtle top border color */
        .modern-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 5px; /* Height of the color bar */
            background: linear-gradient(90deg, #6f42c1, #fd7e14); /* Purple to Orange gradient */
            opacity: 0.8;
        }
        .modern-card:hover {
            transform: translateY(-6px) scale(1.01); /* Slightly more lift */
            box-shadow: 0 10px 30px rgba(111, 66, 193, 0.15);
        }
        .modern-card h5 { /* Label */
             color: #6c757d; /* Bootstrap gray */
             font-weight: 500;
             font-size: 0.95em;
             margin-bottom: 8px;
        }
         .modern-card h3 { /* Value */
             color: #6f42c1; /* Purple value */
             margin: 0;
             font-weight: 700;
             font-size: 1.8em; /* Larger value */
             line-height: 1.2;
         }
         .modern-card i { /* Icon */
            font-size: 2em; /* Larger icon */
            margin-bottom: 15px;
            color: #fd7e14; /* Orange icon color */
         }

        /* Status Badges - Enhanced */
        .status-badge {
            padding: 6px 15px;
            border-radius: 20px;
            font-weight: 700; /* Bolder */
            font-size: 0.8em; /* Smaller text */
            white-space: nowrap;
            border: none;
            display: inline-block;
            text-align: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1); /* Subtle shadow on badges */
            transition: transform 0.2s ease;
        }
        .status-badge:hover {
            transform: scale(1.05);
        }
        /* Using Bootstrap-like colors */
        .status-positive { background-color: #d1e7dd; color: #0f5132; } /* Light Green / Dark Green */
        .status-negative { background-color: #f8d7da; color: #842029; } /* Light Red / Dark Red */
        .status-neutral { background-color: #fff3cd; color: #664d03; } /* Light Yellow / Dark Yellow */
        .status-nodata { background-color: #e9ecef; color: #495057; } /* Light Gray / Dark Gray */
        .status-unknown { background-color: #f8f9fa; color: #6c757d; }
        .status-new { background-color: #cff4fc; color: #055160; } /* Light Cyan / Dark Cyan */
        .status-removed { background-color: #dee2e6; color: #495057; } /* Gray */

        /* Plotly Chart Background */
        .plotly-chart { background-color: transparent !important; }

        /* Dataframe styling */
        .dataframe { width: 100% !important; box-shadow: 0 4px 10px rgba(0,0,0,0.05); border-radius: 8px; overflow: hidden;}
        th { background-color: #f8f9fa !important; color: #6f42c1 !important; font-weight: bold; text-align: right !important; border-bottom: 2px solid #dee2e6 !important;}
        td { text-align: right !important; vertical-align: middle !important; border-bottom: 1px solid #f1f1f1 !important;}
        tr:hover { background-color: #f1f3ff !important; } /* Light purple hover */

        /* Folium Map Popup Style */
        .folium-popup .leaflet-popup-content-wrapper {
             background-color: #ffffff;
             border-radius: 10px;
             box-shadow: 0 3px 8px rgba(0,0,0,0.15);
             border: 1px solid #e0e0e0;
         }
        .folium-popup .leaflet-popup-content {
             font-family: 'Vazirmatn', sans-serif !important;
             color: #333;
             font-size: 0.95em;
             line-height: 1.6;
         }
         .folium-popup .leaflet-popup-content b {
             color: #6f42c1; /* Purple for bold text */
         }


        /* Dark mode support - Needs careful color matching */
        @media (prefers-color-scheme: dark) {
            html, body, .main, .stApp {
                background: linear-gradient(135deg, #212529 0%, #343a40 100%); /* Darker gradient */
                color: #f8f9fa;
            }
            .stSidebar {
                 background: #212529; /* Dark background */
                 border-right: 1px solid #495057; /* Darker border */
            }
            .stSidebar .stSelectbox label, .stSidebar .stSlider label, .stSidebar .stExpander label, .stSidebar h3 {
                 color: #bf9dfc !important; /* Lighter Purple */
            }
            .stSidebar .stExpander {
                 background-color: #343a40;
                 border: 1px solid #495057;
            }

            .main-header { border-bottom-color: #bf9dfc; }
            .main-header h1 { color: #bf9dfc; }
            .main-header h4 { color: #ffab70; } /* Lighter Orange */
            .main-logo { border-color: #495057; box-shadow: 0 6px 12px rgba(255, 255, 255, 0.1); }


            .modern-card {
                 background: #343a40; /* Dark card background */
                 color: #f1f1f1;
                 border: 1px solid #495057;
                 box-shadow: 0 6px 20px rgba(0, 0, 0, 0.25);
            }
             .modern-card:hover { box-shadow: 0 10px 30px rgba(0, 0, 0, 0.35); }
             .modern-card::before { background: linear-gradient(90deg, #bf9dfc, #ffab70); } /* Lighter gradient */
             .modern-card h5 { color: #adb5bd; }
             .modern-card h3 { color: #bf9dfc; }
             .modern-card i { color: #ffab70; }

             th { background-color: #495057 !important; color: #bf9dfc !important; border-bottom-color: #6c757d !important;}
             td { border-bottom-color: #495057 !important;}
             tr:hover { background-color: #483d8b !important; } /* Dark Slate Blue hover */


           /* Dark mode badges */
           .status-positive { background-color: #0b2d1e; color: #75b798; box-shadow: 0 2px 5px rgba(255,255,255,0.1); }
           .status-negative { background-color: #3e1116; color: #f1aeb5; box-shadow: 0 2px 5px rgba(255,255,255,0.1); }
           .status-neutral { background-color: #332701; color: #ffda6a; box-shadow: 0 2px 5px rgba(255,255,255,0.1); }
           .status-nodata { background-color: #343a40; color: #adb5bd; box-shadow: 0 2px 5px rgba(255,255,255,0.1); }
           .status-new { background-color: #022a33; color: #6edff6; box-shadow: 0 2px 5px rgba(255,255,255,0.1); }
           .status-removed { background-color: #495057; color: #adb5bd; box-shadow: 0 2px 5px rgba(255,255,255,0.1); }

            /* Dark mode popup */
            .folium-popup .leaflet-popup-content-wrapper {
                 background-color: #343a40;
                 border: 1px solid #495057;
                 box-shadow: 0 3px 8px rgba(0,0,0,0.3);
            }
            .folium-popup .leaflet-popup-content { color: #f8f9fa; }
            .folium-popup .leaflet-popup-content b { color: #bf9dfc; } /* Lighter Purple */

        }
    </style>
""", unsafe_allow_html=True)

# --- Sidebar Logo ---
# --- NOTE: Ensure this path is correct relative to where you run the script ---
logo_path = 'logo (1).png'
if os.path.exists(logo_path):
    st.sidebar.image(logo_path, use_column_width=True)
    # st.sidebar.markdown(f"<div class='sidebar-logo'><img src='{logo_path}' alt='Ù„ÙˆÚ¯Ùˆ Ø³Ø§Ù…Ø§Ù†Ù‡' /></div>", unsafe_allow_html=True) # Use st.image for better handling
else:
    st.sidebar.warning(f"Ù„ÙˆÚ¯Ùˆ Ø¯Ø± Ù…Ø³ÛŒØ± '{logo_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")

# --- Main Header ---
st.markdown("<div class='main-header'>", unsafe_allow_html=True)
# Using st.image is generally safer and handles path/display better
if os.path.exists(logo_path):
     # Create columns to control logo size and alignment better
     h_cols = st.columns([1, 10]) # Adjust ratio as needed
     with h_cols[0]:
          st.image(logo_path, width=60) # Adjust width as needed
     with h_cols[1]:
         st.markdown(
             """
             <div>
                 <h1>Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±</h1>
                 <h4>Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§</h4>
             </div>
             """,
             unsafe_allow_html=True
         )
else:
     st.markdown(
         f"""
         <span class='main-logo' style='font-size: 40px; line-height: 60px; text-align: center; background: #eee; display: inline-block;'>ğŸŒ¾</span>
         <div>
             <h1>Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±</h1>
             <h4>Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§</h4>
         </div>
         """,
         unsafe_allow_html=True
     )
st.markdown("</div>", unsafe_allow_html=True)


# --- Configuration ---
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 11

# --- File Paths ---
# --- WARNING: Hardcoding paths like this might not be portable. Consider relative paths or config files. ---
# --- Make sure this file exists in the *same directory* as your script, or provide the full path ---
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'
FARM_GEOJSON_PATH = 'farm_geodata_fixed.geojson' # Assumed to contain 'Ø§Ø¯Ø§Ø±Ù‡' now (or handle its absence)

# --- GEE Authentication ---
@st.cache_resource
def initialize_gee():
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¯Ø± Ú©Ù†Ø§Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯ ÛŒØ§ Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
            st.stop()
        # --- WARNING: Using Service Account Credentials directly ---
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully.")
        return True
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error(traceback.format_exc()) # Print full traceback for debugging
        st.stop()

# --- Load Farm Data ---
@st.cache_data(show_spinner="Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...")
def load_farm_data_from_geojson(geojson_path):
    if not os.path.exists(geojson_path):
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{geojson_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¯Ø± Ú©Ù†Ø§Ø± Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯ ÛŒØ§ Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
        st.stop()
    try:
        with open(geojson_path, 'r', encoding='utf-8') as f:
            gj = json.load(f)
        features = gj.get('features', []) # Use .get() for safety
        if not features:
            st.error("âŒ ÙØ§ÛŒÙ„ GeoJSON Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª Ø§Ù…Ø§ Ù‡ÛŒÚ† 'feature' Ø§ÛŒ Ø¯Ø± Ø¢Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()

        records = []
        # --- MODIFIED: Removed 'Ø§Ø¯Ø§Ø±Ù‡' from strictly required properties for loading ---
        # 'Ø§Ø¯Ø§Ø±Ù‡' is useful but not essential to load the basic farm data.
        # The rest of the code will handle its potential absence.
        required_props = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø±ÙˆØ²', 'Ú¯Ø±ÙˆÙ‡']
        optional_props = ['Ø§Ø¯Ø§Ø±Ù‡', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†', 'Ù…Ø³Ø§Ø­Øª'] # Properties we want but might be missing
        has_warned_missing_req_props = False
        has_warned_invalid_coords = False

        for i, feat in enumerate(features):
            props = feat.get('properties', {})
            geom = feat.get('geometry')
            centroid_lon, centroid_lat = None, None

            # Check for essential properties needed for identification and grouping
            missing_req = [p for p in required_props if p not in props or props[p] is None or str(props[p]).strip() == ""]
            if missing_req:
                 if not has_warned_missing_req_props:
                      st.warning(f"Ø¨Ø±Ø®ÛŒ Ù…Ø²Ø§Ø±Ø¹ (Ø§ÙˆÙ„ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ø±Ø¯ÛŒÙ {i+1} ÙØ§ÛŒÙ„ GeoJSON) ÙØ§Ù‚Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ ({', '.join(missing_req)}) Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.", icon="âš ï¸")
                      has_warned_missing_req_props = True
                 continue # Skip this feature

            # Calculate Centroid
            try:
                if geom and geom['type'] == 'Polygon' and geom.get('coordinates'):
                    # Handling potential nesting [[]] vs []
                    coords = geom['coordinates'][0] if isinstance(geom['coordinates'][0], list) else geom['coordinates']
                    # Ensure coordinates are valid points
                    valid_coords = [pt for pt in coords if isinstance(pt, (list, tuple)) and len(pt) >= 2 and all(isinstance(c, (int, float)) for c in pt[:2])]
                    if valid_coords:
                        lons = [pt[0] for pt in valid_coords]
                        lats = [pt[1] for pt in valid_coords]
                        if lons and lats:
                            centroid_lon = sum(lons) / len(lons)
                            centroid_lat = sum(lats) / len(lats)
                elif geom and geom['type'] == 'Point' and geom.get('coordinates'):
                     coords = geom['coordinates']
                     if isinstance(coords, (list, tuple)) and len(coords) == 2 and all(isinstance(c, (int, float)) for c in coords):
                         centroid_lon, centroid_lat = coords
            except Exception as e:
                 # Catch potential errors during coordinate processing
                 if not has_warned_invalid_coords:
                     st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø®ØªØµØ§Øª Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{props.get('Ù…Ø²Ø±Ø¹Ù‡', 'Ù†Ø§Ø´Ù†Ø§Ø³')}' (Ø±Ø¯ÛŒÙ {i+1}): {e}. Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.", icon="ğŸ—ºï¸")
                     has_warned_invalid_coords = True
                 continue # Skip if coordinates cause error

            # Only add if centroid is valid
            if centroid_lon is not None and centroid_lat is not None:
                record = {prop: props.get(prop) for prop in required_props} # Add required props
                record.update({prop: props.get(prop) for prop in optional_props}) # Add optional props if they exist
                record['geometry_type'] = geom.get('type')
                # Storing coordinates can make the dataframe huge, maybe skip if not needed later?
                # record['coordinates'] = geom.get('coordinates')
                record['centroid_lon'] = centroid_lon
                record['centroid_lat'] = centroid_lat
                records.append(record)
            elif not has_warned_invalid_coords: # Warn only once if geometry/centroid calculation fails silently
                 st.warning(f"Ù…Ø²Ø±Ø¹Ù‡ '{props.get('Ù…Ø²Ø±Ø¹Ù‡', 'Ù†Ø§Ø´Ù†Ø§Ø³')}' (Ø±Ø¯ÛŒÙ {i+1}) ÙØ§Ù‚Ø¯ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± ÛŒØ§ Ù‚Ø§Ø¨Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø³Øª Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.", icon="ğŸ—ºï¸")
                 has_warned_invalid_coords = True

        if not records:
            st.error("âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ùˆ Ù…Ø®ØªØµØ§Øª Ù…Ø¹ØªØ¨Ø± Ø¯Ø± ÙØ§ÛŒÙ„ GeoJSON ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            st.stop()

        df = pd.DataFrame(records)

        # --- Basic Cleaning ---
        # Apply cleaning only if column exists
        if 'Ø±ÙˆØ²' in df.columns:
             df['Ø±ÙˆØ²'] = df['Ø±ÙˆØ²'].astype(str).str.replace(r'\s+', ' ', regex=True).str.strip()
        if 'Ú¯Ø±ÙˆÙ‡' in df.columns:
             df['Ú¯Ø±ÙˆÙ‡'] = df['Ú¯Ø±ÙˆÙ‡'].astype(str).str.strip()
        if 'Ø§Ø¯Ø§Ø±Ù‡' in df.columns: # Clean 'Ø§Ø¯Ø§Ø±Ù‡' only if it exists
             df['Ø§Ø¯Ø§Ø±Ù‡'] = df['Ø§Ø¯Ø§Ø±Ù‡'].astype(str).str.strip().replace('None', pd.NA).replace('', pd.NA)
             if df['Ø§Ø¯Ø§Ø±Ù‡'].isna().all(): # Drop if all values became NA (was likely useless)
                 del df['Ø§Ø¯Ø§Ø±Ù‡']
                 st.info("Ø³ØªÙˆÙ† 'Ø§Ø¯Ø§Ø±Ù‡' ÙÙ‚Ø· Ø´Ø§Ù…Ù„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯ Ùˆ Ø­Ø°Ù Ø´Ø¯.", icon="â„¹ï¸")
        if 'Ù…Ø³Ø§Ø­Øª' in df.columns:
            df['Ù…Ø³Ø§Ø­Øª'] = pd.to_numeric(df['Ù…Ø³Ø§Ø­Øª'], errors='coerce')
        if 'Ø³Ù†' in df.columns:
             # Handle non-numeric age like 'R2' -> NaN -> 0
             df['Ø³Ù†'] = pd.to_numeric(df['Ø³Ù†'], errors='coerce').fillna(0).astype(int)

        # Final check for essential columns after loading
        if 'Ù…Ø²Ø±Ø¹Ù‡' not in df.columns or 'Ø±ÙˆØ²' not in df.columns or 'centroid_lon' not in df.columns or 'centroid_lat' not in df.columns:
             st.error("Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ: Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ ('Ù…Ø²Ø±Ø¹Ù‡', 'Ø±ÙˆØ²', 'centroid_lon', 'centroid_lat') Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯Ù†Ø¯.")
             st.stop()

        st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {len(df)} Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return df
    except json.JSONDecodeError as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ GeoJSON Ø¯Ø± Ø®Ø· {e.lineno} Ø³ØªÙˆÙ† {e.colno}: {e.msg}")
        st.stop()
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ GeoJSON: {e}")
        st.error(traceback.format_exc())
        st.stop()


# --- HTML Helper Functions (Unchanged) ---
def modern_metric_card(label, value, icon="fa-info-circle", color="#fd7e14"): # Default icon color Orange
    value_display = value if pd.notna(value) and value != "" else "N/A"
    # Format numbers with commas if applicable
    if isinstance(value_display, (int, float)) and value_display != "N/A":
         value_display = f"{value_display:,.0f}" if value_display == int(value_display) else f"{value_display:,.2f}"

    return f"""
    <div class="modern-card">
        <i class="fas {icon}" style="color: {color};"></i>
        <h5>{label}</h5>
        <h3>{value_display}</h3>
    </div>
    """

def status_badge(status_text):
    status_text_str = str(status_text) # Convert to string first
    status_text_lower = status_text_str.lower()
    css_class = "status-unknown"
    if pd.isna(status_text) or "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡" in status_text_lower or "n/a" in status_text_lower or status_text_str == "nan": css_class = "status-nodata"
    elif "Ø¨Ù‡Ø¨ÙˆØ¯" in status_text_lower or "Ù…Ø«Ø¨Øª" in status_text_lower: css_class = "status-positive"
    elif "ØªÙ†Ø´" in status_text_lower or "Ú©Ø§Ù‡Ø´" in status_text_lower or "Ø¨Ø¯ØªØ±" in status_text_lower or "Ø®Ø·Ø§" in status_text_lower or "Ù…Ù†ÙÛŒ" in status_text_lower : css_class = "status-negative"
    elif "Ø«Ø§Ø¨Øª" in status_text_lower: css_class = "status-neutral"
    elif "Ø¬Ø¯ÛŒØ¯" in status_text_lower: css_class = "status-new"
    elif "Ø­Ø°Ù" in status_text_lower: css_class = "status-removed"
    return f'<span class="status-badge {css_class}">{status_text_str}</span>'

# Function to generate a randomish color based on a string (for variety/age maps)
def generate_color(input_string):
    random.seed(input_string) # Seed random number generator
    return "#{:06x}".format(random.randint(0, 0xFFFFFF))

# --- Initialize GEE and Load Data ---
if initialize_gee():
    farm_data_df = load_farm_data_from_geojson(FARM_GEOJSON_PATH)
else:
    st.error("Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    st.stop()

# Add a check here AFTER loading to ensure farm_data_df is valid
if 'farm_data_df' not in locals() or not isinstance(farm_data_df, pd.DataFrame) or farm_data_df.empty:
    st.error("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    st.stop()

# ==============================================================================
# Sidebar Filters (Enhanced with Expander and Ø§Ù„Ø§Ø¯Ø§Ø±Ù‡ Filter)
# ==============================================================================
st.sidebar.header("ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ ÙÛŒÙ„ØªØ±Ù‡Ø§")

with st.sidebar.expander("ğŸ“… Ø§Ù†ØªØ®Ø§Ø¨ Ø±ÙˆØ² Ùˆ Ø§Ø¯Ø§Ø±Ù‡", expanded=True):
    # Day Selection
    if 'Ø±ÙˆØ²' not in farm_data_df.columns:
        st.sidebar.error("Ø³ØªÙˆÙ† 'Ø±ÙˆØ²' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. ÙÛŒÙ„ØªØ± Ø±ÙˆØ² ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
        st.stop()
    available_days = sorted(farm_data_df['Ø±ÙˆØ²'].dropna().unique())
    if not available_days:
        st.sidebar.error("Ù‡ÛŒÚ† Ù…Ù‚Ø¯Ø§Ø± Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± Ø³ØªÙˆÙ† 'Ø±ÙˆØ²' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    selected_day = st.selectbox(
        "Ø±ÙˆØ² Ù‡ÙØªÙ‡:", options=available_days, index=0
    )

    # Filter by Day first
    daily_farms_df = farm_data_df[farm_data_df['Ø±ÙˆØ²'] == selected_day].copy()
    if daily_farms_df.empty:
        st.warning(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop() # Stop if no farms for the selected day

    # Ø§Ù„Ø§Ø¯Ø§Ø±Ù‡ Selection (Department/Unit) - Check if 'Ø§Ø¯Ø§Ø±Ù‡' column exists
    if 'Ø§Ø¯Ø§Ø±Ù‡' in daily_farms_df.columns and daily_farms_df['Ø§Ø¯Ø§Ø±Ù‡'].notna().any():
        available_edareh = sorted(daily_farms_df['Ø§Ø¯Ø§Ø±Ù‡'].dropna().unique())
        edareh_options = ["Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª"] + available_edareh
        selected_edareh = st.selectbox(
            "Ø§Ø¯Ø§Ø±Ù‡:", options=edareh_options, index=0,
            help="ÙÛŒÙ„ØªØ± Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø¯Ø§Ø±Ù‡ Ù…Ø±Ø¨ÙˆØ·Ù‡ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡)."
        )
    else:
        # st.sidebar.info("Ø³ØªÙˆÙ† 'Ø§Ø¯Ø§Ø±Ù‡' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. ÙÛŒÙ„ØªØ± Ø§Ø¯Ø§Ø±Ù‡ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª.", icon="â„¹ï¸")
        selected_edareh = "Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª" # Default if column is missing or empty

    # Apply Ø§Ù„Ø§Ø¯Ø§Ø±Ù‡ filter
    if selected_edareh == "Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª":
        filtered_farms_df = daily_farms_df
    elif 'Ø§Ø¯Ø§Ø±Ù‡' in daily_farms_df.columns: # Ensure column exists before filtering
        filtered_farms_df = daily_farms_df[daily_farms_df['Ø§Ø¯Ø§Ø±Ù‡'] == selected_edareh]
        if filtered_farms_df.empty:
            st.warning(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ '{selected_edareh}' Ø¯Ø± Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            # Don't stop here, maybe user wants to see the empty state
            # st.stop()
    else:
        # Should not happen if selected_edareh != "Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª" but added as safety
        filtered_farms_df = daily_farms_df

    # --- Add a final check ---
    if filtered_farms_df.empty and selected_edareh != "Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª":
         st.warning(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ (Ø±ÙˆØ²: {selected_day}, Ø§Ø¯Ø§Ø±Ù‡: {selected_edareh}) ÛŒØ§ÙØª Ù†Ø´Ø¯.")
         # Consider stopping or allowing continuation with empty data
         # st.stop()
    elif filtered_farms_df.empty:
         st.warning(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ø±ÙˆØ²: {selected_day} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
         # st.stop()


with st.sidebar.expander("ğŸŒ¾ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø²Ø±Ø¹Ù‡ Ùˆ Ø´Ø§Ø®Øµ", expanded=True):
    # Farm Selection (based on filtered data)
    if filtered_farms_df.empty:
        st.markdown("`Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.`")
        selected_farm_name = "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" # Default needed even if empty
    else:
        available_farms = sorted(filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'].unique())
        farm_options = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + available_farms
        default_farm_index = 0 # Always default to 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹'
        selected_farm_name = st.selectbox(
            "Ù…Ø²Ø±Ø¹Ù‡:", options=farm_options, index=default_farm_index,
            help="ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ÛŒØ§ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯ Ú©Ù„ÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯."
        )

    # Index Selection
    index_options = {
        "NDVI": "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ (NDVI)", "NDMI": "Ø±Ø·ÙˆØ¨Øª Ú¯ÛŒØ§Ù‡ (NDMI)", "EVI": "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ (EVI)",
        "SAVI": "Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªØ¹Ø¯ÛŒÙ„ Ø®Ø§Ú© (SAVI)", "MSI": "ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ (MSI)", "LAI": "Ø³Ø·Ø­ Ø¨Ø±Ú¯ (LAI)", "CVI": "Ú©Ù„Ø±ÙˆÙÛŒÙ„ (CVI)"
    }
    selected_index = st.selectbox(
        "Ø´Ø§Ø®Øµ Ù†Ù‚Ø´Ù‡ Ø§ØµÙ„ÛŒ:", options=list(index_options.keys()), format_func=lambda x: f"{index_options[x]}", index=0
    )

# --- Date Range Calculation ---
today = datetime.date.today()
# Map Persian day names to Python's weekday() (Monday=0, Sunday=6)
persian_to_weekday = {"Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1, "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4}
try:
    target_weekday = persian_to_weekday[selected_day] # Get target weekday (0-6)
    today_weekday = today.weekday() # Get today's weekday (0-6)

    # Calculate days ago for the *most recent* occurrence of target_weekday
    days_ago = (today_weekday - target_weekday + 7) % 7
    if days_ago == 0: # If today is the target day
         end_date_current = today
    else:
         end_date_current = today - datetime.timedelta(days=days_ago)

    # Define the 7-day window ending on end_date_current
    start_date_current = end_date_current - datetime.timedelta(days=6)

    # Define the previous 7-day window
    end_date_previous = start_date_current - datetime.timedelta(days=1)
    start_date_previous = end_date_previous - datetime.timedelta(days=6)

    # Format dates as strings
    start_date_current_str, end_date_current_str = start_date_current.strftime('%Y-%m-%d'), end_date_current.strftime('%Y-%m-%d')
    start_date_previous_str, end_date_previous_str = start_date_previous.strftime('%Y-%m-%d'), end_date_previous.strftime('%Y-%m-%d')

    st.sidebar.markdown("---")
    st.sidebar.caption(f"Ø¨Ø§Ø²Ù‡ ÙØ¹Ù„ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
    st.sidebar.caption(f"Ø¨Ø§Ø²Ù‡ Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")
    st.sidebar.markdown("---")
except KeyError:
    st.sidebar.error(f"Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ø¯Ø± Ù…Ù¾ÛŒÙ†Ú¯ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    st.stop()
except Exception as e:
    st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}")
    st.stop()


# ==============================================================================
# Google Earth Engine Functions (Mostly Unchanged)
# ==============================================================================
def maskS2clouds(image):
    """Masks clouds and shadows in Sentinel-2 SR images using QA60 and SCL bands."""
    qa = image.select('QA60')
    # Bits 10 and 11 are clouds and cirrus, respectively.
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    # Get Scene Classification Layer (SCL)
    scl = image.select('SCL')

    # Both flags should be zero (clear) based on QA60
    clear_mask_qa = qa.bitwiseAnd(cloudBitMask).eq(0).And(
        qa.bitwiseAnd(cirrusBitMask).eq(0))

    # SCL values for good data (vegetation, bare soils, water, snow/ice)
    # Values: 4 (Vegetation), 5 (Bare Soils), 6 (Water), 11 (Snow/Ice), 7 (Unclassified - sometimes ok)
    # Excluding: 1 (Saturated/Defective), 2 (Dark Area Pixels), 3 (Cloud Shadows),
    #            8 (Cloud Medium Probability), 9 (Cloud High Probability), 10 (Cirrus)
    good_quality_scl = scl.remap([4, 5, 6, 7, 11], [1, 1, 1, 1, 1], 0) # Remap good values to 1, others to 0

    # Combine masks - both QA and SCL should indicate clear conditions
    combined_mask = clear_mask_qa.And(good_quality_scl)

    # Scale optical bands to reflectance values (0-1) and apply mask
    opticalBands = image.select('B.*').multiply(0.0001)

    return image.addBands(opticalBands, None, True).updateMask(combined_mask)


def add_indices(image):
    """Calculates and adds common spectral indices to an image."""
    # Ensure bands exist before calculating indices to avoid errors
    # Add dummy bands with value 0 if they don't exist (or handle differently)
    image = image.addBands(ee.Image(0).rename('B8'), overwrite=False) # NIR
    image = image.addBands(ee.Image(0).rename('B4'), overwrite=False) # Red
    image = image.addBands(ee.Image(0).rename('B2'), overwrite=False) # Blue
    image = image.addBands(ee.Image(0).rename('B11'),overwrite=False) # SWIR1
    image = image.addBands(ee.Image(0.0001).rename('B3'),overwrite=False) # Green (add small constant to avoid division by zero)


    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')
    # EVI calculation requires Blue band (B2)
    evi = image.expression(
        '2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1)', {
            'NIR': image.select('B8'), 'RED': image.select('B4'), 'BLUE': image.select('B2')
        }).rename('EVI')
    # NDMI calculation requires SWIR1 band (B11)
    ndmi = image.normalizedDifference(['B8', 'B11']).rename('NDMI')
    # SAVI calculation
    savi = image.expression(
        '((NIR - RED) / (NIR + RED + L)) * (1 + L)', {
            'NIR': image.select('B8'), 'RED': image.select('B4'), 'L': 0.5 # L is the soil adjustment factor
        }).rename('SAVI')
    # MSI calculation requires SWIR1 (B11) and NIR (B8)
    msi = image.expression(
        'SWIR1 / NIR', { # Avoid division by zero? GEE might handle it. Add small constant if needed.
            'SWIR1': image.select('B11'), 'NIR': image.select('B8').max(ee.Image(0.0001)) # Add small constant to NIR
        }).rename('MSI')
    # LAI - Simple estimation based on NDVI, can be improved with more complex models
    # Clamp LAI to be non-negative
    lai = ndvi.multiply(3.5).max(0).rename('LAI')
     # CVI - Chlorophyll Vegetation Index requires Green (B3), Red (B4), NIR (B8)
    # Ensure Green band has a minimum value > 0 to avoid division by zero
    green_safe = image.select('B3').max(ee.Image(0.0001))
    cvi = image.expression(
        '(NIR / GREEN_SAFE) * (RED / GREEN_SAFE)', {
            'NIR': image.select('B8'), 'GREEN_SAFE': green_safe, 'RED': image.select('B4')
        }).rename('CVI')

    return image.addBands([ndvi, evi, ndmi, msi, lai, cvi, savi])

# Function to get a single processed image (median) for a given geometry and date range
@st.cache_data(show_spinner="Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ...", persist=True)
def get_processed_image(_geometry, start_date, end_date, index_name):
    """Gets the median GEE image for a given index, dates, and geometry."""
    try:
        if _geometry is None:
            return None, "Ù…Ù†Ø·Ù‚Ù‡ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ (Geometry) Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª."

        s2_sr_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
            .filterBounds(_geometry) \
            .filterDate(start_date, end_date) \
            .map(maskS2clouds) # Apply cloud masking first

        # Check image count after masking
        count = s2_sr_col.size().getInfo()
        if count == 0:
            return None, f"ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ø± Ø¯Ø± Ø¨Ø§Ø²Ù‡ ({start_date} ØªØ§ {end_date}) ÛŒØ§ÙØª Ù†Ø´Ø¯."

        # Add indices to the cloud-masked collection
        indexed_col = s2_sr_col.map(add_indices)

        # Select the desired index and compute the median
        median_image = indexed_col.median().select(index_name) # Select the specific index

        # --- Optional: Check if the resulting image has valid data in the region ---
        # This adds an extra GEE call but can prevent adding empty layers
        try:
            # Reduce the region to get a sample value (using firstNonNull)
            test_val = median_image.reduceRegion(
                reducer=ee.Reducer.firstNonNull(),
                geometry=_geometry.centroid(maxError=1) if _geometry else ee.Geometry.Point([INITIAL_LON, INITIAL_LAT]), # Use centroid or default point
                scale=30, # Use a slightly coarser scale for check
                maxPixels=1e6
            ).get(index_name).getInfo()

            if test_val is None:
                return None, f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ '{index_name}' Ø¯Ø± Ù…Ø±Ú©Ø² Ù…Ù†Ø·Ù‚Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù…Ù‚Ø¯Ø§Ø± Null)."
        except ee.EEException as ee_err:
             # Handle cases where reduceRegion might fail (e.g., complex geometry)
             # Don't stop the process, just warn
             st.warning(f"Ø§Ø®Ø·Ø§Ø± Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¹ØªØ¨Ø§Ø± Ø¯Ø§Ø¯Ù‡ '{index_name}': {ee_err.args[0] if ee_err.args else str(ee_err)}. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù„Ø§ÛŒÙ‡ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯.")
        except Exception as e:
             st.warning(f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¹ØªØ¨Ø§Ø± Ø¯Ø§Ø¯Ù‡ '{index_name}': {e}")

        # If the checks pass (or warnings occurred), return the image
        return median_image, None

    except ee.EEException as e:
        # Detailed GEE error
        error_message = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±: {e.args[0] if e.args else str(e)}"
        print(error_message) # Log for debugging
        return None, error_message
    except Exception as e:
        # Other errors
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± get_processed_image: {e}"
        print(error_message)
        print(traceback.format_exc()) # Log traceback
        return None, error_message


@st.cache_data(show_spinner="Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ...", persist=True)
def get_index_time_series(_point_geom, index_name, start_date='2023-01-01', end_date=today.strftime('%Y-%m-%d')):
    """Gets GEE time series for an index at a specific point."""
    try:
        if not isinstance(_point_geom, ee.Geometry):
             return pd.DataFrame(columns=['date', index_name]), "ÙˆØ±ÙˆØ¯ÛŒ _point_geom Ø¨Ø§ÛŒØ¯ Ø§Ø² Ù†ÙˆØ¹ ee.Geometry Ø¨Ø§Ø´Ø¯."

        s2_sr_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
            .filterBounds(_point_geom) \
            .filterDate(start_date, end_date) \
            .map(maskS2clouds) \
            .map(add_indices) \
            .select(index_name) # Select the index

        def extract_value(image):
            # Use reduceRegion with firstNonNull for potentially masked pixels
            value = image.reduceRegion(
                reducer=ee.Reducer.firstNonNull(), # More robust than .mean() for single point if masked
                geometry=_point_geom,
                scale=10 # Scale of Sentinel-2 bands used
            ).get(index_name)

            # Return a feature with date and value, only if value is not null
            return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd'), index_name: value}) \
                     .set('hasValue', value) # Set a property to filter nulls server-side

        # Filter out images where the value couldn't be extracted (null)
        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.neq('hasValue', None))

        # Get the results as a list of features
        ts_info = ts_features.getInfo()['features']

        if not ts_info:
            return pd.DataFrame(columns=['date', index_name]), f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name} Ø¯Ø± Ø¨Ø§Ø²Ù‡ ({start_date} ØªØ§ {end_date}) ÛŒØ§ÙØª Ù†Ø´Ø¯."

        # Convert to Pandas DataFrame
        ts_data = [{'date': f['properties']['date'], index_name: f['properties'][index_name]} for f in ts_info]
        ts_df = pd.DataFrame(ts_data)
        ts_df['date'] = pd.to_datetime(ts_df['date'])

        # Handle potential duplicate dates (e.g., multiple orbits same day) by averaging
        ts_df = ts_df.groupby('date').mean().reset_index()

        ts_df = ts_df.sort_values('date').set_index('date')
        return ts_df, None

    except ee.EEException as e:
        error_msg = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e.args[0] if e.args else str(e)}"
        print(error_msg)
        return pd.DataFrame(columns=['date', index_name]), error_msg
    except Exception as e:
        error_msg = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± get_index_time_series: {e}"
        print(error_msg)
        print(traceback.format_exc())
        return pd.DataFrame(columns=['date', index_name]), error_msg

# --- NEW Helper Function: Calculate Weekly Indices (Needed for Ranking Table/Map) ---
@st.cache_data(show_spinner="Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...", persist=True)
def calculate_weekly_indices(farms_df_subset, index_name, start_curr, end_curr, start_prev, end_prev):
    """Calculates current and previous week's mean index value for multiple farms."""
    results = []
    errors = []

    def get_mean_value_for_farm(geometry, start_date, end_date):
        """Helper to get mean index value for one farm and period."""
        try:
            s2_sr_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
                .filterBounds(geometry) \
                .filterDate(start_date, end_date) \
                .map(maskS2clouds)

            count = s2_sr_col.size().getInfo()
            if count == 0:
                return None, f"Ø¨ÛŒâ€ŒØªØµÙˆÛŒØ± ({start_date}-{end_date})"

            indexed_col = s2_sr_col.map(add_indices)
            median_image = indexed_col.median().select(index_name)

            mean_val = median_image.reduceRegion(
                reducer=ee.Reducer.mean(),
                geometry=geometry,
                scale=10, # Use appropriate scale
                maxPixels=1e9
            ).get(index_name).getInfo()

            return mean_val, None # Return value can be None if region has no valid data
        except ee.EEException as e:
            return None, f"Ø®Ø·Ø§ÛŒ GEE ({start_date}-{end_date}): {e.args[0] if e.args else str(e)}"
        except Exception as e:
            return None, f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ ({start_date}-{end_date}): {e}"

    # Iterate through the farms in the provided subset DataFrame
    required_cols = ['Ù…Ø²Ø±Ø¹Ù‡', 'centroid_lon', 'centroid_lat']
    if not all(col in farms_df_subset.columns for col in required_cols):
         missing = [col for col in required_cols if col not in farms_df_subset.columns]
         st.error(f"Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ: Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ({', '.join(missing)}) Ø¯Ø± DataFrame ÙˆØ±ÙˆØ¯ÛŒ calculate_weekly_indices ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
         return pd.DataFrame(), [f"Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ({', '.join(missing)}) ÛŒØ§ÙØª Ù†Ø´Ø¯."]


    progress_bar = st.progress(0)
    total_farms = len(farms_df_subset)

    for i, farm in farms_df_subset.iterrows():
        farm_name = farm['Ù…Ø²Ø±Ø¹Ù‡']
        lon, lat = farm['centroid_lon'], farm['centroid_lat']
        point_geom = ee.Geometry.Point([lon, lat]) # Use centroid point

        # Get current period value
        current_val, err_curr = get_mean_value_for_farm(point_geom, start_curr, end_curr)
        if err_curr:
            errors.append(f"{farm_name} (Ø¬Ø§Ø±ÛŒ): {err_curr}")

        # Get previous period value
        previous_val, err_prev = get_mean_value_for_farm(point_geom, start_prev, end_prev)
        if err_prev:
            errors.append(f"{farm_name} (Ù‚Ø¨Ù„ÛŒ): {err_prev}")

        # Calculate change
        change = None
        if isinstance(current_val, (int, float)) and isinstance(previous_val, (int, float)):
             # Avoid division by zero if previous_val is very small or zero
             if abs(previous_val) > 1e-9:
                  change = ((current_val - previous_val) / abs(previous_val)) * 100
             elif current_val == previous_val: # Both zero or very small
                  change = 0.0
             # else: change remains None (cannot calculate percentage change from zero)

        farm_result = {
            'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
            f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)': current_val,
            f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)': previous_val,
            'ØªØºÛŒÛŒØ±': change # Percentage change or None
        }
        # Add other identifying columns from the input df if needed
        for col in ['Ú¯Ø±ÙˆÙ‡', 'Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'centroid_lat', 'centroid_lon']:
            if col in farm.index:
                farm_result[col] = farm[col]

        results.append(farm_result)
        progress_bar.progress((i + 1) / total_farms)

    progress_bar.empty() # Remove progress bar
    return pd.DataFrame(results), errors


# --- NEW Helper Function: Determine Status (Needed for Ranking Table/Map) ---
def determine_status(row, index_name, change_threshold=5.0):
    """Determines a descriptive status based on current, previous index values and change."""
    current_col = f'{index_name} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)'
    prev_col = f'{index_name} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)'
    change_col = 'ØªØºÛŒÛŒØ±' # Assumes 'ØªØºÛŒÛŒØ±' is percentage change

    if current_col not in row or prev_col not in row or change_col not in row:
        return "Ø®Ø·Ø§ Ø¯Ø± Ø³ØªÙˆÙ†" # Missing necessary columns

    current_val = row[current_col]
    prev_val = row[prev_col]
    change_pct = row[change_col]

    is_stress_index = index_name in ['MSI'] # Indices where higher value means more stress

    # Handle cases with missing data
    if pd.isna(current_val) and pd.isna(prev_val): return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"
    if pd.isna(current_val) and pd.notna(prev_val): return "Ø­Ø°Ù Ø´Ø¯Ù‡ØŸ" # Data loss
    if pd.notna(current_val) and pd.isna(prev_val): return "Ø¬Ø¯ÛŒØ¯"     # New data

    # Handle cases where change couldn't be calculated (e.g., division by zero)
    if pd.isna(change_pct):
         if current_val == prev_val: change_pct = 0.0 # Treat as no change if values are equal
         else: return "Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù…Ø¹ØªØ¨Ø±" # Cannot determine status reliably

    # Determine status based on change percentage
    if abs(change_pct) < change_threshold:
        return "Ø«Ø§Ø¨Øª"
    elif change_pct > 0: # Positive change
        if is_stress_index: return "ØªÙ†Ø´ / Ø¨Ø¯ØªØ± Ø´Ø¯Ù†" # Increase in stress index is bad
        else: return "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯" # Increase in vegetation index is good
    elif change_pct < 0: # Negative change
        if is_stress_index: return "Ø¨Ù‡Ø¨ÙˆØ¯ / Ú©Ø§Ù‡Ø´ ØªÙ†Ø´" # Decrease in stress index is good
        else: return "ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´"       # Decrease in vegetation index is bad
    else:
        return "Unknown" # Should not happen if logic above is correct

# ==============================================================================
# Needs Analysis Function (using GEE) - Modified to reuse index calculation logic
# ==============================================================================
@st.cache_data(show_spinner="Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ...", persist=True)
def get_farm_needs_data(_point_geom, start_curr, end_curr, start_prev, end_prev):
    """Gets key indices (NDVI, NDMI, EVI, SAVI) for current and previous periods for needs analysis."""
    results = {f'{idx}_{p}': None for idx in ['NDVI', 'NDMI', 'EVI', 'SAVI'] for p in ['curr', 'prev']}
    results['error'] = None
    indices_to_get = ['NDVI', 'NDMI', 'EVI', 'SAVI']

    def get_mean_values(start, end):
        """Helper to get mean index values for a specific period."""
        vals = {index: None for index in indices_to_get}
        error_msg = None
        try:
            s2_sr_col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \
                .filterBounds(_point_geom) \
                .filterDate(start, end) \
                .map(maskS2clouds)

            count = s2_sr_col.size().getInfo()
            if count == 0:
                return vals, f"Ø¨ÛŒâ€ŒØªØµÙˆÛŒØ± ({start}-{end})"

            # Add all indices needed
            indexed_col = s2_sr_col.map(add_indices)

            # Compute median image containing all needed indices
            median_image = indexed_col.median().select(indices_to_get)

            # Reduce region to get mean values for all indices at once
            mean_dict = median_image.reduceRegion(
                reducer=ee.Reducer.mean(),
                geometry=_point_geom,
                scale=10,
                maxPixels=1e9
            ).getInfo() # Get the dictionary of results

            if mean_dict:
                for index in indices_to_get:
                    vals[index] = mean_dict.get(index) # Returns None if index not found or null
            return vals, None
        except ee.EEException as e:
            error_msg = f"Ø®Ø·Ø§ÛŒ GEE ({start}-{end}): {e.args[0] if e.args else str(e)}"
            print(error_msg)
            return vals, error_msg
        except Exception as e:
            error_msg = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ ({start}-{end}): {e}"
            print(error_msg)
            print(traceback.format_exc())
            return vals, error_msg

    # Get current period values
    curr_vals, err_curr = get_mean_values(start_curr, end_curr)
    if err_curr:
        results['error'] = err_curr
    for idx in indices_to_get:
        results[f'{idx}_curr'] = curr_vals.get(idx)

    # Get previous period values
    prev_vals, err_prev = get_mean_values(start_prev, end_prev)
    if err_prev:
        # Append previous error to current error if exists
        results['error'] = f"{results.get('error', '')} | {err_prev}" if results.get('error') else err_prev
    for idx in indices_to_get:
        results[f'{idx}_prev'] = prev_vals.get(idx)

    return results


# ==============================================================================
# Gemini AI Helper Functions (Enhanced)
# ==============================================================================
@st.cache_resource
def configure_gemini():
    try:
        # --- WARNING: Hardcoding API keys is insecure! Use Streamlit secrets in production. ---
        # --- Replace with your actual Gemini API Key ---
        api_key = "YOUR_GEMINI_API_KEY" # <-- PASTE YOUR KEY HERE
        # --- End of Warning ---

        # Basic check if the key looks like a placeholder
        if not api_key or api_key == "YOUR_GEMINI_API_KEY":
            st.warning("âš ï¸ Ú©Ù„ÛŒØ¯ API Ø¬Ù…ÛŒÙ†Ø§ÛŒ ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ù‡Ù†ÙˆØ² Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³Øª. ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.", icon="ğŸ¤–")
            return None

        genai.configure(api_key=api_key)
        # Choose a model - 'gemini-1.5-flash' is often fast and capable
        model = genai.GenerativeModel('gemini-1.5-flash')
        print("Gemini Configured Successfully.")
        # Perform a simple test call (optional, but good for verification)
        try:
            _ = model.generate_content("Test")
            print("Gemini test call successful.")
        except Exception as test_e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Gemini API Ù¾Ø³ Ø§Ø² ØªÙ†Ø¸ÛŒÙ…: {test_e}. Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯ API Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ø´Ø¨Ú©Ù‡ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
            return None
        return model
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… Gemini API: {e}")
        st.error(traceback.format_exc())
        return None

@st.cache_data(show_spinner="Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ...", persist=True)
def get_ai_needs_analysis(_model, farm_name, index_data, recommendations):
    if _model is None:
        return "Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
    # Helper to format numbers, handling None
    def fmt(val):
        return f"{val:.3f}" if isinstance(val, (int, float)) and pd.notna(val) else "N/A"

    # Prepare data string, explicitly handling potential None values
    data_lines = []
    for idx in ['NDVI', 'NDMI', 'EVI', 'SAVI']:
        curr_val = index_data.get(f'{idx}_curr')
        prev_val = index_data.get(f'{idx}_prev')
        data_lines.append(f"{idx}: {fmt(curr_val)} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„: {fmt(prev_val)})")
    data_str = "\n".join(data_lines)

    # Prepare recommendations string
    rec_str = ', '.join(recommendations) if recommendations else 'Ù†ÛŒØ§Ø² Ø®Ø§ØµÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.'

    prompt = f"""
Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ù†ÛŒØ´Ú©Ø± Ù‡Ø³ØªÛŒØ¯. Ù„Ø·ÙØ§Ù‹ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ Ù†Ø§Ù… '{farm_name}' Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø²ÛŒØ±ØŒ Ø¯Ø± 3 ØªØ§ 5 Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.

ØªÙ…Ø±Ú©Ø² Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø¨Ø± **Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ ØªØºØ°ÛŒÙ‡** Ø¨Ø§Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯Ù„Ø§ÛŒÙ„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØºÛŒÛŒØ±Ø§Øª Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù…Ø§Ù†Ù†Ø¯ Ú©Ø§Ù‡Ø´ NDMI Ø¨Ø±Ø§ÛŒ Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ ÛŒØ§ Ø§ÙØª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ NDVI Ø¨Ø±Ø§ÛŒ Ù…Ø´Ú©Ù„Ø§Øª ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´) Ø¨Ù‡ Ø·ÙˆØ± Ø®Ù„Ø§ØµÙ‡ ØªÙˆØ¶ÛŒØ­ Ø¯Ù‡ÛŒØ¯.

**Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ (Ù…Ù‚Ø¯Ø§Ø± ÙØ¹Ù„ÛŒ / Ù…Ù‚Ø¯Ø§Ø± Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„):**
{data_str}

**ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø³ÛŒØ³ØªÙ…:**
{rec_str}

**ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ (3-5 Ø¬Ù…Ù„Ù‡):**
"""
    try:
        # Adding safety configurations (optional but recommended)
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        ]
        response = _model.generate_content(prompt, safety_settings=safety_settings)

        # Accessing response text safely
        if hasattr(response, 'text'):
            return response.text
        elif hasattr(response, 'parts') and response.parts:
            return response.parts[0].text
        else:
            # Handle unexpected response structure or blocked content
            try:
                 # Attempt to access prompt feedback if available
                 feedback = response.prompt_feedback
                 block_reason = feedback.block_reason if feedback else 'Ù†Ø§Ù…Ø´Ø®Øµ'
                 return f"Ù¾Ø§Ø³Ø®ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø­ØªÙˆØ§ Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ (Ø¯Ù„ÛŒÙ„: {block_reason})."
            except Exception:
                 return "Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² Gemini Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª."

    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ: {e}")
        return f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ: {str(e)}"


# NEW Gemini function for map summary
@st.cache_data(show_spinner="Ø¯Ø±ÛŒØ§ÙØª Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹...", persist=True)
def get_ai_map_summary(_model, status_counts, edareh_filter, day_filter):
    """Generates AI summary for the classified map."""
    if _model is None:
        return "Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    if not status_counts or sum(status_counts.values()) == 0:
        return "Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."

    total_farms = sum(status_counts.values())
    status_lines = []
    # Sort status counts for consistent output (optional)
    sorted_statuses = sorted(status_counts.items(), key=lambda item: item[1], reverse=True)

    for status, count in sorted_statuses:
        if count > 0:
            percent = (count / total_farms) * 100
            status_lines.append(f"- {status}: {count} Ù…Ø²Ø±Ø¹Ù‡ ({percent:.1f}Ùª)")

    status_summary = "\n".join(status_lines)
    edareh_context = f"Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ '{edareh_filter}'" if edareh_filter != "Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª" else "Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª"

    prompt = f"""
Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ù‡Ø³ØªÛŒØ¯. Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ø®Ù„Ø§ØµÙ‡ Ú©ÙˆØªØ§Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ (2 ØªØ§ 4 Ø¬Ù…Ù„Ù‡) Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯. Ø§ÛŒÙ† Ø®Ù„Ø§ØµÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù‡ÙØªÙ‡ Ú¯Ø°Ø´ØªÙ‡ ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.

**Ø²Ù…ÛŒÙ†Ù‡ ØªØ­Ù„ÛŒÙ„:**
- **Ø±ÙˆØ²:** {day_filter}
- **ÙÛŒÙ„ØªØ± Ø§Ø¯Ø§Ø±Ù‡:** {edareh_context}
- **ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø²Ø§Ø±Ø¹ ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡:** {total_farms}

**ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹:**
{status_summary}

**ÙˆØ¸ÛŒÙÙ‡:**
Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ú©Ù‡ Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø±Ø§ Ø¨Ø±Ø¬Ø³ØªÙ‡ Ú©Ù†Ø¯. Ø¨Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ù…Ù‡Ù… Ù…Ø§Ù†Ù†Ø¯:
- Ø¯Ø±ØµØ¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª "ØªÙ†Ø´/Ú©Ø§Ù‡Ø´" ÛŒØ§ ÙˆØ¶Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø·Ù„ÙˆØ¨ Ø¯ÛŒÚ¯Ø±.
- Ø¯Ø±ØµØ¯ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ ÙˆØ¶Ø¹ÛŒØª "Ø¨Ù‡Ø¨ÙˆØ¯".
- Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ø±ÙˆÙ†Ø¯ ÛŒØ§ Ø§Ù„Ú¯ÙˆÛŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ Ø¯ÛŒÚ¯Ø± Ø¯Ø± ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØªâ€ŒÙ‡Ø§.

**Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ (2-4 Ø¬Ù…Ù„Ù‡):**
"""
    try:
        # Adding safety configurations
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        ]
        response = _model.generate_content(prompt, safety_settings=safety_settings)

        # Safe access to response text
        if hasattr(response, 'text'):
            return response.text
        elif hasattr(response, 'parts') and response.parts:
            return response.parts[0].text
        else:
            try:
                 feedback = response.prompt_feedback
                 block_reason = feedback.block_reason if feedback else 'Ù†Ø§Ù…Ø´Ø®Øµ'
                 return f"Ù¾Ø§Ø³Ø®ÛŒ Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ù†Ù‚Ø´Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø­ØªÙˆØ§ Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ (Ø¯Ù„ÛŒÙ„: {block_reason})."
            except Exception:
                 return "Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² Gemini Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ù†Ù‚Ø´Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª."

    except Exception as e:
        st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ù†Ù‚Ø´Ù‡: {e}")
        return f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª: {str(e)}"


# ==============================================================================
# Main Application Layout (Tabs)
# ==============================================================================
gemini_model = configure_gemini() # Configure Gemini once
tab1, tab2 = st.tabs(["ğŸ“Š Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹", "ğŸ’§ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ Ú©ÙˆØ¯ Ùˆ Ø¢Ø¨ÛŒØ§Ø±ÛŒ"])

with tab1:
    # ==========================================================================
    # Main Panel Display (Monitoring)
    # ==========================================================================
    st.subheader(f"ğŸ—“ï¸ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ø±ÙˆØ²: {selected_day}")
    if selected_edareh != "Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª":
        st.markdown(f"##### Ø§Ø¯Ø§Ø±Ù‡: {selected_edareh}")
    elif 'Ø§Ø¯Ø§Ø±Ù‡' not in filtered_farms_df.columns and len(farm_data_df['Ø§Ø¯Ø§Ø±Ù‡'].unique()) > 1:
        st.info("ÙÛŒÙ„ØªØ± 'Ø§Ø¯Ø§Ø±Ù‡' Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.", icon="â„¹ï¸")


    selected_farm_details = None
    selected_farm_geom = None # Will be ee.Geometry.Point or ee.Geometry.Rectangle
    map_center_lat = INITIAL_LAT
    map_center_lon = INITIAL_LON
    map_zoom = INITIAL_ZOOM

    # --- Handle case where filtered_farms_df might be empty after filtering ---
    if filtered_farms_df.empty:
         st.warning("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
         # Set a default geometry to avoid errors later
         selected_farm_geom = ee.Geometry.Point([INITIAL_LON, INITIAL_LAT])
         # Stop execution in this tab might be desired, or show empty map
         # st.stop() # Uncomment if you want to stop if no farms
    else:
        # --- Setup Geometry and Initial Info ---
        if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
            num_farms = len(filtered_farms_df)
            avg_area = filtered_farms_df['Ù…Ø³Ø§Ø­Øª'].mean() if 'Ù…Ø³Ø§Ø­Øª' in filtered_farms_df.columns and filtered_farms_df['Ù…Ø³Ø§Ø­Øª'].notna().any() else None
            avg_age = filtered_farms_df['Ø³Ù†'].mean() if 'Ø³Ù†' in filtered_farms_df.columns and filtered_farms_df['Ø³Ù†'].notna().any() else None
            # Calculate common variety carefully, handling potential NAs
            common_variety = "Ù…ØªÙ†ÙˆØ¹"
            if 'ÙˆØ§Ø±ÛŒØªÙ‡' in filtered_farms_df.columns and filtered_farms_df['ÙˆØ§Ø±ÛŒØªÙ‡'].notna().any():
                mode_result = filtered_farms_df['ÙˆØ§Ø±ÛŒØªÙ‡'].dropna().mode()
                if not mode_result.empty:
                    common_variety = mode_result[0]

            # Display Summary Cards
            summary_cols = st.columns(4)
            with summary_cols[0]:
                 st.markdown(modern_metric_card("ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹", num_farms, icon="fa-layer-group"), unsafe_allow_html=True)
            with summary_cols[1]:
                 st.markdown(modern_metric_card("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø³Ø§Ø­Øª (ha)", avg_area, icon="fa-chart-area"), unsafe_allow_html=True) # Added unit
            with summary_cols[2]:
                 st.markdown(modern_metric_card("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ù†", avg_age, icon="fa-calendar-days"), unsafe_allow_html=True)
            with summary_cols[3]:
                 st.markdown(modern_metric_card("ÙˆØ§Ø±ÛŒØªÙ‡ ØºØ§Ù„Ø¨", common_variety, icon="fa-star"), unsafe_allow_html=True)

            # Define the bounding box for "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" view
            min_lon, min_lat = filtered_farms_df['centroid_lon'].min(), filtered_farms_df['centroid_lat'].min()
            max_lon, max_lat = filtered_farms_df['centroid_lon'].max(), filtered_farms_df['centroid_lat'].max()
            # Add a small buffer to the bounds
            buffer = 0.005 # Adjust buffer as needed
            try:
                selected_farm_geom = ee.Geometry.Rectangle(
                    [min_lon - buffer, min_lat - buffer, max_lon + buffer, max_lat + buffer]
                )
                map_center_lat = (min_lat + max_lat) / 2
                map_center_lon = (min_lon + max_lon) / 2
                # Adjust zoom based on number of farms or extent
                map_zoom = 11 if num_farms > 5 else 12 # Zoom out more for many farms
            except Exception as e_geom:
                 st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ø¨Ø±Ø§ÛŒ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹': {e_geom}")
                 selected_farm_geom = ee.Geometry.Point([INITIAL_LON, INITIAL_LAT]) # Fallback


        else: # A specific farm is selected
            selection = filtered_farms_df[filtered_farms_df['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name]
            if not selection.empty:
                selected_farm_details = selection.iloc[0]
                lat = selected_farm_details['centroid_lat']
                lon = selected_farm_details['centroid_lon']
                # Use the Point geometry for single farm analysis
                try:
                    selected_farm_geom = ee.Geometry.Point([lon, lat])
                    map_center_lat, map_center_lon, map_zoom = lat, lon, 14 # Zoom in for single farm

                    # Display Farm Details
                    edareh_val = selected_farm_details.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A') if 'Ø§Ø¯Ø§Ø±Ù‡' in selected_farm_details else 'N/A'
                    st.write(f"**Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}** (Ø§Ø¯Ø§Ø±Ù‡: {edareh_val})")
                    details_cols = st.columns(4)
                    details_cols[0].markdown(modern_metric_card("Ù…Ø³Ø§Ø­Øª (ha)", selected_farm_details.get('Ù…Ø³Ø§Ø­Øª'), icon="fa-vector-square"), unsafe_allow_html=True)
                    details_cols[1].markdown(modern_metric_card("ÙˆØ§Ø±ÛŒØªÙ‡", selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A'), icon="fa-seedling"), unsafe_allow_html=True)
                    details_cols[2].markdown(modern_metric_card("Ú¯Ø±ÙˆÙ‡", selected_farm_details.get('Ú¯Ø±ÙˆÙ‡', 'N/A'), icon="fa-users"), unsafe_allow_html=True)
                    details_cols[3].markdown(modern_metric_card("Ø³Ù†", selected_farm_details.get('Ø³Ù†'), icon="fa-hourglass-half"), unsafe_allow_html=True)
                except Exception as e_geom:
                    st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}': {e_geom}")
                    selected_farm_geom = ee.Geometry.Point([INITIAL_LON, INITIAL_LAT]) # Fallback

            else:
                 st.error(f"Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                 selected_farm_geom = ee.Geometry.Point([INITIAL_LON, INITIAL_LAT]) # Fallback


    # --- Map Display (Enhanced with Layers) ---
    st.markdown("---")
    st.subheader(f"ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹ - Ø´Ø§Ø®Øµ: {index_options[selected_index]}")

    # Define Visualization Parameters (Consistent palettes)
    vis_params = {
        'NDVI': {'min': 0.0, 'max': 0.9, 'palette': ['#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901', '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01', '#012E01', '#011D01', '#011301']},
        'EVI': {'min': 0.0, 'max': 0.9, 'palette': ['#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901', '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01', '#012E01', '#011D01', '#011301']}, # Same as NDVI
        'NDMI': {'min': -0.5, 'max': 0.8, 'palette': ['#b2182b', '#d6604d', '#f4a582', '#fddbc7', '#f7f7f7', '#d1e5f0', '#92c5de', '#4393c3', '#2166ac']}, # Blue is wetter
        'SAVI': {'min': 0.0, 'max': 0.9, 'palette': ['#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901', '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01', '#012E01', '#011D01', '#011301']}, # Same as NDVI
        'LAI': {'min': 0, 'max': 7, 'palette': ['#EFEFEF', '#FFFFE5', '#FFF7BC', '#FEE391', '#FEC44F', '#FE9929', '#EC7014', '#CC4C02', '#993404', '#662506']}, # Yellow to brown
        'MSI': {'min': 0, 'max': 3, 'palette': ['#2166ac', '#67a9cf', '#d1e5f0', '#fddbc7', '#ef8a62', '#b2182b'][::-1]}, # Reversed: Blue (low stress) to Red (high stress)
        'CVI': {'min': 0, 'max': 25, 'palette': ['#FFFFE5', '#FFF7BC', '#FEE391', '#FEC44F', '#FE9929', '#EC7014', '#CC4C02', '#993404', '#662506']}, # Similar to LAI
    }
    current_vis = vis_params.get(selected_index, {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']}) # Default vis


    # Initialize the map
    m = geemap.Map(location=[map_center_lat, map_center_lon], zoom=map_zoom, add_google_map=True)
    m.add_basemap("SATELLITE") # Default to Satellite view

    # Add GEE Layer (Selected Index)
    gee_image_current, error_msg_current = None, None
    if selected_farm_geom: # Check if geometry is valid
        with st.spinner(f"Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {selected_index}..."):
            gee_image_current, error_msg_current = get_processed_image(
                selected_farm_geom, start_date_current_str, end_date_current_str, selected_index
            )
        map_layer_name = f"{index_options[selected_index]} ({end_date_current_str})"
        if gee_image_current:
            try:
                # Clip the layer to the selected geometry for better visualization
                # clipped_image = gee_image_current.clip(selected_farm_geom)
                # m.addLayer(clipped_image, current_vis, map_layer_name)
                # Clipping might hide context, add full layer instead
                m.addLayer(gee_image_current, current_vis, map_layer_name)
                m.add_colorbar(current_vis, label=f"{index_options[selected_index]}", layer_name=map_layer_name)
            except Exception as map_err:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ GEE Ø¨Ù‡ Ù†Ù‚Ø´Ù‡: {map_err}")
        elif error_msg_current:
            st.warning(f"Ø¹Ø¯Ù… Ù†Ù…Ø§ÛŒØ´ Ù„Ø§ÛŒÙ‡ {selected_index}: {error_msg_current}", icon="ğŸ›°ï¸")
    else:
         st.warning("Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù„Ø§ÛŒÙ‡ GEE ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")


    # --- Calculate Ranking Data for Map Layers ---
    # Use the currently filtered DataFrame (daily, possibly edareh)
    # Select only necessary columns for the calculation function
    cols_for_ranking = ['Ù…Ø²Ø±Ø¹Ù‡', 'centroid_lon', 'centroid_lat']
    # Add optional columns if they exist, for inclusion in the result
    for col in ['Ú¯Ø±ÙˆÙ‡', 'Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡']:
         if col in filtered_farms_df.columns:
              cols_for_ranking.append(col)

    # Check if the filtered DataFrame is empty before calculating
    ranking_df_map = pd.DataFrame() # Initialize empty DataFrame
    map_calc_errors = []
    if not filtered_farms_df.empty:
        ranking_df_map, map_calc_errors = calculate_weekly_indices(
            filtered_farms_df[cols_for_ranking], # Pass only needed columns
            selected_index, start_date_current_str, end_date_current_str,
            start_date_previous_str, end_date_previous_str
        )
        if map_calc_errors:
             st.warning(f"Ø®Ø·Ø§Ù‡Ø§ÛŒÛŒ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ {len(map_calc_errors)} Ù…ÙˆØ±Ø¯ Ø±Ø® Ø¯Ø§Ø¯. (Ø¬Ø²Ø¦ÛŒØ§Øª Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ)")

        if not ranking_df_map.empty:
            # --- Determine Status ---
            # Define a sensible threshold for significant change (e.g., 5%)
            change_threshold_for_status = 5.0
            ranking_df_map['ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†'] = ranking_df_map.apply(
                lambda row: determine_status(row, selected_index, change_threshold_for_status),
                axis=1
            )
            # Merge back details ONLY IF they weren't included by calculate_weekly_indices
            # (The modified calculate_weekly_indices should already include them if present)
            # ranking_df_map = pd.merge(ranking_df_map,
            #                           filtered_farms_df[['Ù…Ø²Ø±Ø¹Ù‡', 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø§Ø¯Ø§Ø±Ù‡', 'Ú¯Ø±ÙˆÙ‡', 'centroid_lat', 'centroid_lon']],
            #                           on='Ù…Ø²Ø±Ø¹Ù‡', how='left', suffixes=('', '_dup'))
            # ranking_df_map = ranking_df_map.loc[:, ~ranking_df_map.columns.str.endswith('_dup')]
        else:
             st.warning("Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù‡ÙØªÚ¯ÛŒ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ù†Ø¯Ø§Ø´Øª. Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ù‚Ø´Ù‡ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.")
             # Use base filtered_farms_df for age/variety if ranking fails, assign default status
             ranking_df_map = filtered_farms_df.copy()
             ranking_df_map['ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†'] = 'Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡'
    else:
         st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ù‚Ø´Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")


    # --- Define Layer Styles ---
    # Status Layer Styles
    status_map_colors = {
        "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯": ('green', 'fa-arrow-up'),
        "Ø¨Ù‡Ø¨ÙˆØ¯ / Ú©Ø§Ù‡Ø´ ØªÙ†Ø´": ('blue', 'fa-arrow-down'), # Blue for less stress/more water
        "Ø«Ø§Ø¨Øª": ('orange', 'fa-equals'),
        "ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´": ('red', 'fa-arrow-down'),
        "ØªÙ†Ø´ / Ø¨Ø¯ØªØ± Ø´Ø¯Ù†": ('darkred', 'fa-arrow-up'),
        "Ø¬Ø¯ÛŒØ¯": ('lightblue', 'fa-star'),
        "Ø­Ø°Ù Ø´Ø¯Ù‡?": ('gray', 'fa-question'),
        "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡": ('lightgray', 'fa-circle-notch'),
        "Ø®Ø·Ø§ Ø¯Ø± Ø³ØªÙˆÙ†": ('black', 'fa-exclamation-triangle'),
        "Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù…Ø¹ØªØ¨Ø±": ('lightgray', 'fa-minus'),
        "Unknown": ('purple', 'fa-question-circle') # Default/fallback
    }
    # Simplified Legend for Status Map
    status_legend_map = {
        "Ø¨Ù‡Ø¨ÙˆØ¯": ('#28a745', 'ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ØªØ± (Ø±Ø´Ø¯ Ø¨ÛŒØ´ØªØ± / ØªÙ†Ø´ Ú©Ù…ØªØ±)'), # Green
        "Ø«Ø§Ø¨Øª": ('#ffc107', 'ÙˆØ¶Ø¹ÛŒØª ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ù…Ø´Ø§Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„'),     # Yellow/Orange
        "ØªÙ†Ø´/Ú©Ø§Ù‡Ø´": ('#dc3545', 'ÙˆØ¶Ø¹ÛŒØª Ø¨Ø¯ØªØ± (Ø±Ø´Ø¯ Ú©Ù…ØªØ± / ØªÙ†Ø´ Ø¨ÛŒØ´ØªØ±)'), # Red
        "Ø¬Ø¯ÛŒØ¯": ('#17a2b8', 'Ù…Ø²Ø±Ø¹Ù‡ Ø¬Ø¯ÛŒØ¯ (Ø¯Ø§Ø¯Ù‡ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù‡ÙØªÙ‡)'), # Cyan
        "Ù†Ø§Ù…Ø´Ø®Øµ/Ø®Ø·Ø§": ('#6c757d', 'Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒØŒ Ø®Ø·Ø§ ÛŒØ§ ØªØºÛŒÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø±') # Gray
    }
    # Age Layer Styles
    age_bins = [-1, 0, 1, 2, 3, 5, 10, 1000] # Bins: 0, 1, 2, 3, 4-5, 6-10, 10+ (Use -1 for edge)
    age_labels = ['Ø³Ù† 0', 'Ø³Ù† 1', 'Ø³Ù† 2', 'Ø³Ù† 3', 'Ø³Ù† 4-5', 'Ø³Ù† 6-10', 'Ø³Ù† +10']
    age_colors_palette = px.colors.qualitative.Pastel # Color palette
    age_color_map = {label: age_colors_palette[i % len(age_colors_palette)] for i, label in enumerate(age_labels)}
    # Variety Layer: Colors generated dynamically


    # --- Create Feature Groups for Layers ---
    age_groups = {}
    variety_groups = {}
    status_groups = {} # Group by simplified status for cleaner LayerControl

    # Check if ranking_df_map has data and required columns
    if not ranking_df_map.empty and all(c in ranking_df_map.columns for c in ['centroid_lat', 'centroid_lon', 'Ù…Ø²Ø±Ø¹Ù‡']):
        for idx, farm in ranking_df_map.iterrows():
            lat, lon = farm['centroid_lat'], farm['centroid_lon']
            if pd.isna(lat) or pd.isna(lon): continue # Skip if coords are missing

            # Base Popup HTML (Common for all layers)
            popup_html = f"<div class='folium-popup'>" \
                         f"<b>Ù…Ø²Ø±Ø¹Ù‡:</b> {farm.get('Ù…Ø²Ø±Ø¹Ù‡', 'N/A')}<br>"
            if 'Ø§Ø¯Ø§Ø±Ù‡' in farm and pd.notna(farm['Ø§Ø¯Ø§Ø±Ù‡']): popup_html += f"<b>Ø§Ø¯Ø§Ø±Ù‡:</b> {farm['Ø§Ø¯Ø§Ø±Ù‡']}<br>"
            if 'Ú¯Ø±ÙˆÙ‡' in farm and pd.notna(farm['Ú¯Ø±ÙˆÙ‡']): popup_html += f"<b>Ú¯Ø±ÙˆÙ‡:</b> {farm['Ú¯Ø±ÙˆÙ‡']}<br>"
            if 'Ø³Ù†' in farm and pd.notna(farm['Ø³Ù†']): popup_html += f"<b>Ø³Ù†:</b> {farm['Ø³Ù†']:.0f}<br>"
            if 'ÙˆØ§Ø±ÛŒØªÙ‡' in farm and pd.notna(farm['ÙˆØ§Ø±ÛŒØªÙ‡']): popup_html += f"<b>ÙˆØ§Ø±ÛŒØªÙ‡:</b> {farm['ÙˆØ§Ø±ÛŒØªÙ‡']}<br>"
            popup_html += f"<b>ÙˆØ¶Ø¹ÛŒØª:</b> {farm.get('ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†', 'N/A')}<br>"
            # Add current/previous index values to popup
            curr_val_pop = farm.get(f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)')
            prev_val_pop = farm.get(f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)')
            popup_html += f"<b>{selected_index} ÙØ¹Ù„ÛŒ:</b> {curr_val_pop:.3f}" if pd.notna(curr_val_pop) else f"<b>{selected_index} ÙØ¹Ù„ÛŒ:</b> N/A"
            popup_html += "<br>"
            popup_html += f"<b>{selected_index} Ù‚Ø¨Ù„ÛŒ:</b> {prev_val_pop:.3f}" if pd.notna(prev_val_pop) else f"<b>{selected_index} Ù‚Ø¨Ù„ÛŒ:</b> N/A"
            popup_html += "</div>"


            # 1. Age Layer (Optional)
            if 'Ø³Ù†' in farm and pd.notna(farm['Ø³Ù†']):
                try:
                    age_int = int(farm['Ø³Ù†'])
                    bin_label = pd.cut([age_int], bins=age_bins, labels=age_labels, right=False)[0]
                    age_group_name = bin_label
                    if age_group_name not in age_groups:
                         age_groups[age_group_name] = folium.FeatureGroup(name=f"{age_group_name}", show=False) # Initially hidden
                    color = age_color_map.get(age_group_name, '#CCCCCC') # Fallback color
                    folium.CircleMarker(
                        location=[lat, lon], radius=5, popup=folium.Popup(popup_html, max_width=300),
                        tooltip=f"{farm['Ù…Ø²Ø±Ø¹Ù‡']} (Ø³Ù† {age_int})",
                        color=color, fill=True, fill_color=color, fill_opacity=0.7
                    ).add_to(age_groups[age_group_name])
                except ValueError: pass # Ignore if age cannot be converted to int


            # 2. Variety Layer (Optional)
            if 'ÙˆØ§Ø±ÛŒØªÙ‡' in farm and pd.notna(farm['ÙˆØ§Ø±ÛŒØªÙ‡']):
                 variety_name = str(farm['ÙˆØ§Ø±ÛŒØªÙ‡']).strip()
                 if not variety_name: variety_name = "Ù†Ø§Ù…Ø´Ø®Øµ"
                 if variety_name not in variety_groups:
                      variety_groups[variety_name] = folium.FeatureGroup(name=f"ÙˆØ§Ø±ÛŒØªÙ‡: {variety_name}", show=False) # Initially hidden
                 color = generate_color(variety_name) # Generate color based on name
                 folium.CircleMarker(
                     location=[lat, lon], radius=5, popup=folium.Popup(popup_html, max_width=300),
                     tooltip=f"{farm['Ù…Ø²Ø±Ø¹Ù‡']} ({variety_name})",
                     color=color, fill=True, fill_color=color, fill_opacity=0.7
                 ).add_to(variety_groups[variety_name])


            # 3. Status Layer (Core classified layer)
            status_text_raw = farm.get('ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†', 'Unknown')
            # Map raw status to simplified legend category for grouping
            simplified_status = "Ù†Ø§Ù…Ø´Ø®Øµ/Ø®Ø·Ø§" # Default
            if "Ø¨Ù‡Ø¨ÙˆØ¯" in status_text_raw: simplified_status = "Ø¨Ù‡Ø¨ÙˆØ¯"
            elif "Ø«Ø§Ø¨Øª" in status_text_raw: simplified_status = "Ø«Ø§Ø¨Øª"
            elif any(s in status_text_raw for s in ["ØªÙ†Ø´", "Ú©Ø§Ù‡Ø´", "Ø¨Ø¯ØªØ±"]): simplified_status = "ØªÙ†Ø´/Ú©Ø§Ù‡Ø´"
            elif "Ø¬Ø¯ÛŒØ¯" in status_text_raw: simplified_status = "Ø¬Ø¯ÛŒØ¯"
            # Keep "Ù†Ø§Ù…Ø´Ø®Øµ/Ø®Ø·Ø§" for "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡", "Ø­Ø°Ù Ø´Ø¯Ù‡?", "Ø®Ø·Ø§", "Unknown", etc.

            if simplified_status not in status_groups:
                 status_groups[simplified_status] = folium.FeatureGroup(name=f"ÙˆØ¶Ø¹ÛŒØª: {simplified_status}", show=True) # Show status layer by default

            # Get marker style from raw status text for visual detail
            color_name, icon = status_map_colors.get(status_text_raw, status_map_colors["Unknown"])

            folium.Marker(
                location=[lat, lon],
                popup=folium.Popup(popup_html, max_width=300),
                tooltip=f"{farm.get('Ù…Ø²Ø±Ø¹Ù‡', 'N/A')}: {status_text_raw}",
                # Use folium AwesomeIcon for FontAwesome icons
                icon=folium.Icon(color=color_name, icon=icon, prefix='fa')
            ).add_to(status_groups[simplified_status])

        # Add FeatureGroups to the map (add Status groups last so they are on top)
        for group in age_groups.values(): group.add_to(m)
        for group in variety_groups.values(): group.add_to(m)
        for group in status_groups.values(): group.add_to(m)

        # Add Layer Control
        folium.LayerControl(collapsed=False).add_to(m) # Keep it open initially

    else:
        st.info("Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (Ø³Ù†ØŒ ÙˆØ§Ø±ÛŒØªÙ‡ØŒ ÙˆØ¶Ø¹ÛŒØª) Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.")


    # Display Map
    try:
        st_folium_output = st_folium(m, width=None, height=600, use_container_width=True, returned_objects=[]) # Increased height
        st.caption("Ø§Ø² Ú©Ù†ØªØ±Ù„ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ (Ø¨Ø§Ù„Ø§ Ø³Ù…Øª Ø±Ø§Ø³Øª Ù†Ù‚Ø´Ù‡) Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´/Ù¾Ù†Ù‡Ø§Ù† Ú©Ø±Ø¯Ù† Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®ØµØŒ ÙˆØ¶Ø¹ÛŒØªØŒ Ø³Ù† Ùˆ ÙˆØ§Ø±ÛŒØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
    except Exception as display_err:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ù†Ù‚Ø´Ù‡: {display_err}")
        st.error(traceback.format_exc())


    # --- Classified Status Map Summary ---
    st.markdown("---")
    st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ù…Ø²Ø§Ø±Ø¹")
    if not ranking_df_map.empty and 'ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†' in ranking_df_map.columns:
        status_counts_raw = ranking_df_map['ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†'].value_counts().to_dict()
        # Map raw statuses to simplified legend categories for reporting
        simplified_status_counts = Counter()
        for status, count in status_counts_raw.items():
             status_key = "Ù†Ø§Ù…Ø´Ø®Øµ/Ø®Ø·Ø§" # Default
             if "Ø¨Ù‡Ø¨ÙˆØ¯" in status: status_key = "Ø¨Ù‡Ø¨ÙˆØ¯"
             elif "Ø«Ø§Ø¨Øª" in status: status_key = "Ø«Ø§Ø¨Øª"
             elif any(s in status for s in ["ØªÙ†Ø´", "Ú©Ø§Ù‡Ø´", "Ø¨Ø¯ØªØ±"]): status_key = "ØªÙ†Ø´/Ú©Ø§Ù‡Ø´"
             elif "Ø¬Ø¯ÛŒØ¯" in status: status_key = "Ø¬Ø¯ÛŒØ¯"
             simplified_status_counts[status_key] += count

        if sum(simplified_status_counts.values()) > 0:
            # Display counts using Plotly Bar Chart
            status_df = pd.DataFrame(simplified_status_counts.items(), columns=['ÙˆØ¶Ø¹ÛŒØª', 'ØªØ¹Ø¯Ø§Ø¯']).sort_values('ØªØ¹Ø¯Ø§Ø¯', ascending=False)
            # Get colors from the legend map
            status_colors = [status_legend_map.get(s, status_legend_map["Ù†Ø§Ù…Ø´Ø®Øµ/Ø®Ø·Ø§"])[0] for s in status_df['ÙˆØ¶Ø¹ÛŒØª']]

            fig_status = px.bar(status_df, x='ÙˆØ¶Ø¹ÛŒØª', y='ØªØ¹Ø¯Ø§Ø¯', color='ÙˆØ¶Ø¹ÛŒØª',
                                title=f"ØªÙˆØ²ÛŒØ¹ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹ ({selected_edareh if selected_edareh != 'Ù‡Ù…Ù‡ Ø§Ø¯Ø§Ø±Ø§Øª' else 'Ú©Ù„'}) - Ø±ÙˆØ²: {selected_day}",
                                text_auto=True, color_discrete_map={k: v[0] for k, v in status_legend_map.items()}) # Use legend colors
            fig_status.update_layout(xaxis_title="ÙˆØ¶Ø¹ÛŒØª", yaxis_title="ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹", showlegend=False,
                                     height=350, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
            st.plotly_chart(fig_status, use_container_width=True)

            # Display AI Summary
            if gemini_model:
                 ai_map_summary = get_ai_map_summary(gemini_model, simplified_status_counts, selected_edareh, selected_day)
                 st.markdown("**Ø®Ù„Ø§ØµÙ‡ ØªØ­Ù„ÛŒÙ„ÛŒ (Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ):**")
                 with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´Ù…Ù†Ø¯..."):
                      st.markdown(f"> {ai_map_summary}") # Display the summary inside a blockquote
            else:
                 st.info("Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. (Ú©Ù„ÛŒØ¯ API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ØŸ)")

            # Display Legend Manually using simplified categories
            st.markdown("**Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª:**")
            legend_html = "<div style='display: flex; flex-wrap: wrap; gap: 20px; align-items: center;'>"
            # Use simplified legend map
            for status_name, (color, desc) in status_legend_map.items():
                 # Find the *most representative* icon for this simplified status group
                 icon_class = 'fa-question-circle' # Default
                 if status_name == "Ø¨Ù‡Ø¨ÙˆØ¯": icon_class = 'fa-arrow-up' # Or down based on index? Use generic up for now
                 elif status_name == "Ø«Ø§Ø¨Øª": icon_class = 'fa-equals'
                 elif status_name == "ØªÙ†Ø´/Ú©Ø§Ù‡Ø´": icon_class = 'fa-arrow-down' # Generic down for decrease/stress
                 elif status_name == "Ø¬Ø¯ÛŒØ¯": icon_class = 'fa-star'
                 elif status_name == "Ù†Ø§Ù…Ø´Ø®Øµ/Ø®Ø·Ø§": icon_class = 'fa-circle-notch' # Spinner for no data

                 # Use the color defined in status_map_colors matching the icon if possible, else use legend color
                 marker_color = next((mc[0] for r_stat, mc in status_map_colors.items() if mc[1] == icon_class), color) # Find color by icon

                 legend_html += f"<div style='display: flex; align-items: center; gap: 5px;'>" \
                                f"<i class='fas {icon_class}' style='color:{marker_color}; font-size: 1.2em;'></i>" \
                                f"<span style='background-color:{color}; color: {'white' if color in ['#dc3545', '#6c757d'] else 'black'}; padding: 2px 6px; border-radius: 4px;'>{status_name}</span>: " \
                                f"<span>{desc}</span>" \
                                f"</div>"
            legend_html += "</div>"
            st.markdown(legend_html, unsafe_allow_html=True)
            st.caption("Ø±Ù†Ú¯ Ø¢ÛŒÚ©ÙˆÙ†â€ŒÙ‡Ø§ Ø¯Ø± Ù†Ù‚Ø´Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ¶Ø¹ÛŒØª Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯ (Ù…Ø«Ù„Ø§Ù‹ ÙÙ„Ø´ Ø³Ø¨Ø² Ø¨Ø±Ø§ÛŒ Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª).")

        else:
             st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    else:
        st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯ØŸ).")


    # --- Time Series Chart ---
    st.markdown("---")
    st.subheader(f"ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ: {index_options[selected_index]}")
    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.info("ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif selected_farm_geom and selected_farm_details is not None:
        # Check if selected_farm_geom is a Point (required for time series)
        is_point = isinstance(selected_farm_geom, ee.geometry.Geometry) and selected_farm_geom.type().getInfo() == 'Point'

        if is_point:
            with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¨Ø±Ø§ÛŒ {selected_farm_name}..."):
                # Define time range (e.g., last 12 months)
                timeseries_end_date = today.strftime('%Y-%m-%d')
                timeseries_start_date = (today - datetime.timedelta(days=365)).strftime('%Y-%m-%d') # Last year

                ts_df, ts_error = get_index_time_series(
                    selected_farm_geom, selected_index,
                    start_date=timeseries_start_date, end_date=timeseries_end_date
                )

            if ts_error:
                st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}", icon="ğŸ“‰")
            elif not ts_df.empty:
                # Resample to weekly or bi-weekly means for smoother plot? (Optional)
                # ts_df_resampled = ts_df.resample('W').mean() # Weekly mean
                ts_df_resampled = ts_df # Or plot raw data

                fig_ts = px.line(ts_df_resampled, x=ts_df_resampled.index, y=selected_index,
                                 title=f"Ø±ÙˆÙ†Ø¯ {index_options[selected_index]} - Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name} (12 Ù…Ø§Ù‡ Ø§Ø®ÛŒØ±)",
                                 labels={'date': 'ØªØ§Ø±ÛŒØ®', selected_index: f'Ù…Ù‚Ø¯Ø§Ø± {selected_index}'}, markers=True)
                fig_ts.update_traces(line=dict(color='#6f42c1', width=2), marker=dict(color='#fd7e14', size=6))
                fig_ts.update_layout(hovermode="x unified", height=400,
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)',
                                     yaxis_title=f"{selected_index}", xaxis_title="ØªØ§Ø±ÛŒØ®")
                st.plotly_chart(fig_ts, use_container_width=True)
            else:
                st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¯Ø± 12 Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        else:
            st.warning("Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù…Ù†ÙØ±Ø¯ (Ø¨Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ) Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª.")
    else:
        st.warning("Ø¬Ø²Ø¦ÛŒØ§Øª ÛŒØ§ Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")


    # ==========================================================================
    # Ranking Table
    # ==========================================================================
    st.markdown("---")
    st.subheader(f"ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {index_options[selected_index]}")
    st.markdown(f"Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ ({end_date_current_str}) Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ ({end_date_previous_str}). Ø§Ø¯Ø§Ø±Ù‡: **{selected_edareh}**")

    # Display errors from the ranking calculation
    if map_calc_errors: # Reuse errors from map calculation
        with st.expander("âš ï¸ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯)", expanded=False):
            error_dict = {}
            for error_str in map_calc_errors:
                try:
                    # Try to extract farm name (assuming format "FarmName (period): Error")
                    farm_name_err = error_str.split(" (")[0]
                except Exception:
                    farm_name_err = "Ù…Ø²Ø±Ø¹Ù‡ Ù†Ø§Ø´Ù†Ø§Ø³"
                error_dict.setdefault(farm_name_err, []).append(error_str)

            # Display errors grouped by farm name
            for farm_name_err, err_list in error_dict.items():
                 st.error(f"**Ù…Ø²Ø±Ø¹Ù‡: {farm_name_err}**")
                 unique_errors = list(set(err_list)) # Show only unique errors per farm
                 for err in unique_errors:
                     st.caption(f"- {err}")


    # Display the ranking table if data exists
    if not ranking_df_map.empty and f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)' in ranking_df_map.columns:
        # Sort the table
        # Lower MSI is better, higher for others (usually)
        ascending_sort = selected_index in ['MSI']
        ranking_df_map_sorted = ranking_df_map.sort_values(
            by=f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)',
            ascending=ascending_sort,
            na_position='last' # Put farms with no data at the bottom
        ).reset_index(drop=True)

        # Add Rank column (starting from 1)
        ranking_df_map_sorted.index = ranking_df_map_sorted.index + 1
        ranking_df_map_sorted.index.name = 'Ø±ØªØ¨Ù‡'

        # Apply status badge HTML formatting
        if 'ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†' in ranking_df_map_sorted.columns:
             ranking_df_map_sorted['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_map_sorted['ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†'].apply(status_badge)
        else:
             ranking_df_map_sorted['ÙˆØ¶Ø¹ÛŒØª'] = status_badge("N/A") # Fallback

        # Format numeric columns for display
        cols_to_format = [f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±']
        for col in cols_to_format:
            if col in ranking_df_map_sorted.columns:
                 # Format numbers, keep strings/NAs as they are
                 if col == 'ØªØºÛŒÛŒØ±': # Format percentage change
                      ranking_df_map_sorted[col] = ranking_df_map_sorted[col].apply(
                           lambda x: f"{x:+.1f}%" if pd.notna(x) and isinstance(x, (int, float)) else ("-" if pd.isna(x) else x)
                      )
                 else: # Format index values
                      ranking_df_map_sorted[col] = ranking_df_map_sorted[col].apply(
                           lambda x: f"{x:.3f}" if pd.notna(x) and isinstance(x, (int, float)) else ("N/A" if pd.isna(x) else x)
                      )

        # Select and order columns for display
        display_columns_order = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø§Ø¯Ø§Ø±Ù‡', 'Ú¯Ø±ÙˆÙ‡', 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡',
                                 f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)',
                                 'ØªØºÛŒÛŒØ±', 'ÙˆØ¶Ø¹ÛŒØª']
        # Filter list to only include columns that actually exist in the dataframe
        display_columns = [col for col in display_columns_order if col in ranking_df_map_sorted.columns]

        # Display the HTML table
        st.markdown("<style> td, th { text-align: right !important; vertical-align: middle; } </style>", unsafe_allow_html=True)
        # Use st.dataframe for better interactivity or st.write for HTML rendering
        # st.dataframe(ranking_df_map_sorted[display_columns]) # Interactive
        st.write(ranking_df_map_sorted[display_columns].to_html(escape=False, index=True, classes='dataframe table table-striped table-hover', justify='right', border=0), unsafe_allow_html=True) # Render HTML

        # Download Button
        try:
            # Prepare DataFrame for CSV export (use raw data, remove HTML badge)
            csv_df = ranking_df_map_sorted.copy()
            # Keep the text status, drop the HTML badge column if it exists
            if 'ÙˆØ¶Ø¹ÛŒØª' in csv_df.columns:
                csv_df = csv_df.drop(columns=['ÙˆØ¶Ø¹ÛŒØª'])
            # Rename text status column for clarity in CSV
            if 'ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†' in csv_df.columns:
                 csv_df.rename(columns={'ÙˆØ¶Ø¹ÛŒØª_Ù…ØªÙ†': 'Status_Description'}, inplace=True)

            # Convert float columns back to numeric if they were formatted as strings
            for col in [f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)', f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)', 'ØªØºÛŒÛŒØ±']:
                 if col in csv_df.columns:
                      csv_df[col] = pd.to_numeric(csv_df[col].astype(str).str.replace('%', '').str.replace('+', ''), errors='coerce')


            csv_data = csv_df.to_csv(index=True, encoding='utf-8-sig') # Use utf-8-sig for Excel compatibility
            st.download_button(
                label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (CSV)",
                data=csv_data,
                file_name=f'ranking_{selected_edareh.replace(" ","_")}_{selected_index}_{selected_day}_{end_date_current_str}.csv',
                mime='text/csv'
            )
        except Exception as e_csv:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ CSV Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯: {e_csv}")

    elif filtered_farms_df.empty:
         st.info(f"Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    else:
        st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ({selected_index}) Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø´Ø¯ ÛŒØ§ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


# --- Tab 2: Needs Analysis ---
with tab2:
    st.header("ğŸ’§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ ØªØºØ°ÛŒÙ‡")

    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ (Ø¯Ø± ØªØ¨ 'Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹') Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif selected_farm_details is not None and selected_farm_geom is not None:
        # Ensure geometry is a point for needs analysis
        is_point = isinstance(selected_farm_geom, ee.geometry.Geometry) and selected_farm_geom.type().getInfo() == 'Point'

        if not is_point:
            st.warning("ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù…Ù†ÙØ±Ø¯ (Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ù†Ù‚Ø·Ù‡ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯) Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø§Ø² Ù„ÛŒØ³Øª Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
        else:
            edareh_val_tab2 = selected_farm_details.get('Ø§Ø¯Ø§Ø±Ù‡', 'N/A') if 'Ø§Ø¯Ø§Ø±Ù‡' in selected_farm_details else 'N/A'
            st.subheader(f"ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name} (Ø§Ø¯Ø§Ø±Ù‡: {edareh_val_tab2})")

            # --- User-defined Thresholds ---
            st.markdown("**ØªÙ†Ø¸ÛŒÙ… Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ø´Ø¯Ø§Ø±:**")
            thresh_cols = st.columns(2)
            # Define reasonable defaults and ranges
            ndmi_threshold = thresh_cols[0].slider(
                label="Ø¢Ø³ØªØ§Ù†Ù‡ NDMI (Ú©Ù… Ø¢Ø¨ÛŒ):",
                min_value=-0.2, max_value=0.5, value=0.25, step=0.01,
                format="%.2f", key="ndmi_thresh_tab2",
                help="Ù…Ù‚Ø§Ø¯ÛŒØ± NDMI Ú©Ù…ØªØ± Ø§Ø² Ø§ÛŒÙ† Ø¢Ø³ØªØ§Ù†Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ ØªÙ†Ø´ Ø¢Ø¨ÛŒ Ø¨Ø§Ø´Ø¯."
            )
            ndvi_drop_threshold = thresh_cols[1].slider(
                label="Ø¢Ø³ØªØ§Ù†Ù‡ Ø§ÙØª NDVI (ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´):",
                min_value=0.0, max_value=20.0, value=7.0, step=0.5,
                format="%.1f%%", key="ndvi_thresh_tab2",
                help="Ø§ÙØª NDVI Ø¨ÛŒØ´ØªØ± Ø§Ø² Ø§ÛŒÙ† Ø¯Ø±ØµØ¯ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ØªØºØ°ÛŒÙ‡ ÛŒØ§ Ø³Ø§ÛŒØ± ØªÙ†Ø´â€ŒÙ‡Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯."
            )

            # --- Get Data for Needs Analysis ---
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ..."):
                farm_needs_data = get_farm_needs_data(
                    selected_farm_geom,
                    start_date_current_str, end_date_current_str,
                    start_date_previous_str, end_date_previous_str
                )

            # --- Display Results and Analysis ---
            if farm_needs_data.get('error'):
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„: {farm_needs_data['error']}")
            # Check if essential current data is missing
            elif pd.isna(farm_needs_data.get('NDMI_curr')) or pd.isna(farm_needs_data.get('NDVI_curr')):
                st.warning("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ú©Ù„ÛŒØ¯ÛŒ (NDMI/NDVI) Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ Ø¬Ù‡Øª ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.", icon="âš ï¸")
            else:
                # Display Indices Metrics
                st.markdown("**Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÙØªÚ¯ÛŒ):**")
                idx_cols = st.columns(4)

                # Helper function to calculate delta safely
                def calc_delta(curr, prev):
                    if pd.notna(curr) and pd.notna(prev) and isinstance(curr, (int, float)) and isinstance(prev, (int, float)):
                        return curr - prev
                    return None # Return None if any value is missing or not numeric

                # Calculate deltas
                ndvi_d = calc_delta(farm_needs_data.get('NDVI_curr'), farm_needs_data.get('NDVI_prev'))
                ndmi_d = calc_delta(farm_needs_data.get('NDMI_curr'), farm_needs_data.get('NDMI_prev'))
                evi_d = calc_delta(farm_needs_data.get('EVI_curr'), farm_needs_data.get('EVI_prev'))
                savi_d = calc_delta(farm_needs_data.get('SAVI_curr'), farm_needs_data.get('SAVI_prev'))

                # Display metrics
                idx_cols[0].metric("NDVI", f"{farm_needs_data['NDVI_curr']:.3f}" if pd.notna(farm_needs_data.get('NDVI_curr')) else "N/A",
                                   f"{ndvi_d:+.3f}" if ndvi_d is not None else None, delta_color="normal")
                idx_cols[1].metric("NDMI", f"{farm_needs_data['NDMI_curr']:.3f}" if pd.notna(farm_needs_data.get('NDMI_curr')) else "N/A",
                                   f"{ndmi_d:+.3f}" if ndmi_d is not None else None, delta_color="normal")
                idx_cols[2].metric("EVI", f"{farm_needs_data.get('EVI_curr'):.3f}" if pd.notna(farm_needs_data.get('EVI_curr')) else "N/A",
                                   f"{evi_d:+.3f}" if evi_d is not None else None, delta_color="normal")
                idx_cols[3].metric("SAVI", f"{farm_needs_data.get('SAVI_curr'):.3f}" if pd.notna(farm_needs_data.get('SAVI_curr')) else "N/A",
                                   f"{savi_d:+.3f}" if savi_d is not None else None, delta_color="normal")

                # --- Rule-Based Recommendations ---
                recommendations = []
                issues_found = False

                # 1. Check NDMI for water stress
                ndmi_curr = farm_needs_data.get('NDMI_curr')
                if pd.notna(ndmi_curr) and ndmi_curr < ndmi_threshold:
                    recommendations.append(f"ğŸ’§ **Ù†ÛŒØ§Ø² Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ:** Ù…Ù‚Ø¯Ø§Ø± NDMI ({ndmi_curr:.3f}) Ú©Ù…ØªØ± Ø§Ø² Ø¢Ø³ØªØ§Ù†Ù‡ ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡ ({ndmi_threshold:.2f}) Ø§Ø³Øª.")
                    issues_found = True

                # 2. Check NDVI drop for nutrition/stress issues
                ndvi_curr = farm_needs_data.get('NDVI_curr')
                ndvi_prev = farm_needs_data.get('NDVI_prev')
                if pd.notna(ndvi_curr) and pd.notna(ndvi_prev):
                     try:
                         # Calculate percentage change only if prev value is not close to zero
                         if abs(ndvi_prev) > 1e-6:
                             change_pct = ((ndvi_curr - ndvi_prev) / abs(ndvi_prev)) * 100
                             # Check if the drop exceeds the threshold (negative change)
                             if change_pct < -ndvi_drop_threshold: # Note the negative sign
                                 recommendations.append(f"âš ï¸ **Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´:** Ø§ÙØª Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ NDVI ({change_pct:.1f}%) Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯.")
                                 issues_found = True
                         elif ndvi_curr < ndvi_prev: # Handle case where previous was zero/small
                             # Check if the absolute drop is significant (e.g. > 0.05)
                             if (ndvi_prev - ndvi_curr) > 0.05:
                                   recommendations.append(f"âš ï¸ **Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´:** Ø§ÙØª NDVI Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯ (Ù…Ù‚Ø¯Ø§Ø± Ù‚Ø¨Ù„ÛŒ: {ndvi_prev:.3f}).")
                                   issues_found = True

                     except Exception as e_ndvi:
                          print(f"Error calculating NDVI change: {e_ndvi}") # Log error
                          pass # Ignore calculation errors

                # 3. Check absolute low NDVI value
                if pd.notna(ndvi_curr) and ndvi_curr < 0.35: # Example threshold for low vegetation
                    # Avoid duplicating warning if already flagged by drop %
                    if not any("ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´" in r for r in recommendations):
                        recommendations.append(f"ğŸ“‰ **Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¶Ø¹ÛŒÙ:** Ù…Ù‚Ø¯Ø§Ø± NDVI ({ndvi_curr:.3f}) Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø±Ø¯.")
                        issues_found = True

                # 4. If no issues found
                if not issues_found:
                    recommendations.append("âœ… **ÙˆØ¶Ø¹ÛŒØª Ù…Ø·Ù„ÙˆØ¨:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ØŒ Ù‡Ø´Ø¯Ø§Ø± Ø®Ø§ØµÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯.")

                # Display Recommendations with appropriate styling
                st.markdown("**ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡:**")
                for rec in recommendations:
                    if "Ø¢Ø¨ÛŒØ§Ø±ÛŒ" in rec: st.error(rec)
                    elif "ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´" in rec or "Ø¶Ø¹ÛŒÙ" in rec: st.warning(rec)
                    else: st.success(rec) # For "ÙˆØ¶Ø¹ÛŒØª Ù…Ø·Ù„ÙˆØ¨"

                # --- AI Analysis (Gemini) ---
                st.markdown("---")
                st.markdown("**ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (Gemini):**")
                if gemini_model:
                    # Prepare concise recommendations for the AI prompt
                    concise_recs = []
                    for r in recommendations:
                         if r.startswith("ğŸ’§"): concise_recs.append("Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ")
                         elif r.startswith("âš ï¸"): concise_recs.append("Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ØªØºØ°ÛŒÙ‡/ØªÙ†Ø´")
                         elif r.startswith("ğŸ“‰"): concise_recs.append("Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¶Ø¹ÛŒÙ")
                         elif r.startswith("âœ…"): concise_recs.append("ÙˆØ¶Ø¹ÛŒØª Ù…Ø·Ù„ÙˆØ¨")

                    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯..."):
                         ai_needs_summary = get_ai_needs_analysis(gemini_model, selected_farm_name, farm_needs_data, concise_recs)
                    st.markdown(f"> {ai_needs_summary}") # Display inside blockquote
                else:
                     st.info("Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. (Ú©Ù„ÛŒØ¯ API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ØŸ)")

    elif not selected_farm_details and selected_farm_name != "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.error(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ù„ÛŒØ³Øª Ù…Ø¹ØªØ¨Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
    else: # Should cover initial state or error states
        st.warning("Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø¹ØªØ¨Ø± Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø¯Ø± ØªØ¨ 'Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹' Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")


# --- Footer ---
st.markdown("---")
st.sidebar.markdown("---")
st.sidebar.info("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ ğŸ’š ØªÙˆØ³Ø· Ø§Ø³Ù…Ø§Ø¹ÛŒÙ„ Ú©ÛŒØ§Ù†ÛŒ")
# st.sidebar.markdown("[GitHub](https://your-link-here)") # Add link if available