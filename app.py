import streamlit as st
import pandas as pd
import geopandas as gpd # <-- Import GeoPandas
import ee
import geemap.foliumap as geemap
import folium
# import json # Not strictly needed if geopandas handles GeoJSON reading
import datetime
import plotly.express as px
import plotly.graph_objects as go
import os
from io import BytesIO
import requests
import traceback
from streamlit_folium import st_folium
import base64
import google.generativeai as genai # Gemini API
from shapely.geometry import Point, Polygon # For type checking if needed

# --- Custom CSS ---
st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±",
    page_icon="ğŸŒ¾",
    layout="wide"
)

# Custom CSS for Persian text alignment and professional styling
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap');

        /* Main container */
        .main {
            font-family: 'Vazirmatn', sans-serif;
        }

        /* Headers */
        h1, h2, h3 {
            font-family: 'Vazirmatn', sans-serif;
            color: #2c3e50;
            text-align: right;
        }

        /* Metrics */
        .css-1xarl3l { /* This selector might change with Streamlit versions */
            font-family: 'Vazirmatn', sans-serif;
            background-color: #f8f9fa;
            border-radius: 10px;
            padding: 1rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        /* Tabs */
        .stTabs [data-baseweb="tab-list"] {
            gap: 2px;
            direction: rtl;
        }

        .stTabs [data-baseweb="tab"] {
            height: 50px;
            padding: 10px 20px;
            background-color: #f8f9fa;
            border-radius: 5px 5px 0 0;
            font-family: 'Vazirmatn', sans-serif;
            font-weight: 600;
        }

        /* Tables */
        .dataframe {
            font-family: 'Vazirmatn', sans-serif;
            text-align: right;
        }

        /* Sidebar */
        .css-1d391kg { /* This selector might change */
            font-family: 'Vazirmatn', sans-serif;
            direction: rtl;
        }

        /* Custom status badges */
        .status-badge {
            padding: 4px 8px;
            border-radius: 15px;
            font-size: 0.8em;
            font-weight: bold;
        }
        .status-positive {
            background-color: #d4edda;
            color: #155724;
        }
        .status-neutral {
            background-color: #fff3cd;
            color: #856404;
        }
        .status-negative {
            background-color: #f8d7da;
            color: #721c24;
        }
    </style>
""", unsafe_allow_html=True)

# --- Configuration ---
APP_TITLE = "Ø³Ø§Ù…Ø§Ù†Ù‡ Ù¾Ø§ÛŒØ´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ÛŒØ´Ú©Ø±"
APP_SUBTITLE = "Ù…Ø·Ø§Ù„Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø´Ø±Ú©Øª Ú©Ø´Øª Ùˆ ØµÙ†Ø¹Øª Ø¯Ù‡Ø®Ø¯Ø§"
# Initial map center might be adjusted later based on data bounds
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 11 # Adjusted zoom for potentially wider area

# --- File Paths ---
# CSV_FILE_PATH = 'Ø¨Ø±Ù†Ø§Ù…Ù‡_Ø±ÛŒØ²ÛŒ_Ø¨Ø§_Ù…Ø®ØªØµØ§Øª (1).csv' # <-- Old CSV path
GEOJSON_FILE_PATH = 'farm_geodata_fixed.geojson' # <-- New GeoJSON path
ANALYSIS_CSV_PATH = 'Ù…Ø­Ø§Ø³Ø¨Ø§Øª 2.csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'

# --- GEE Authentication ---
@st.cache_resource # Cache the GEE initialization
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.error(f"Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Service Account Ø¯Ø± Ù…Ø³ÛŒØ± '{SERVICE_ACCOUNT_FILE}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            st.stop()
        credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully using Service Account.")
        return True
    except ee.EEException as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Google Earth Engine: {e}")
        st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª ÙØ§ÛŒÙ„ Service Account Ùˆ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ø¢Ù† Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ GEE Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
        st.stop()
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„ Ø¨Ù‡ GEE: {e}")
        st.stop()

# --- Helper Function to Convert Shapely Geometry to EE Geometry ---
def shapely_to_ee_geometry(geometry):
    """Converts a Shapely geometry object to an ee.Geometry object."""
    if geometry is None or not hasattr(geometry, '__geo_interface__'):
        return None
    geo_interface = geometry.__geo_interface__
    geom_type = geo_interface.get('type')
    coordinates = geo_interface.get('coordinates')

    if not geom_type or coordinates is None:
        # Handle potential empty geometries gracefully if needed
        return None # Or raise an error

    try:
        if geom_type == 'Point':
            return ee.Geometry.Point(coordinates)
        elif geom_type == 'Polygon':
            # EE Polygons expect a list of rings, where each ring is a list of [lon, lat] pairs.
            # The first ring is the exterior, subsequent rings are interiors (holes).
            return ee.Geometry.Polygon(coordinates)
        elif geom_type == 'LineString':
             return ee.Geometry.LineString(coordinates)
        elif geom_type == 'MultiPoint':
             return ee.Geometry.MultiPoint(coordinates)
        elif geom_type == 'MultiPolygon':
             return ee.Geometry.MultiPolygon(coordinates)
        elif geom_type == 'MultiLineString':
             return ee.Geometry.MultiLineString(coordinates)
        # Add other types if necessary (GeometryCollection, etc.)
        else:
            st.warning(f"Unsupported geometry type for EE conversion: {geom_type}")
            return None
    except Exception as e:
        st.error(f"Error converting Shapely {geom_type} to ee.Geometry: {e}")
        st.error(f"Coordinates causing error: {coordinates}") # Log coordinates for debugging
        return None

# --- Load Farm Data from GeoJSON ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ (GeoJSON)...")
def load_farm_data(geojson_path=GEOJSON_FILE_PATH):
    """Loads farm data from the specified GeoJSON file."""
    try:
        if not os.path.exists(geojson_path):
             st.error(f"âŒ ÙØ§ÛŒÙ„ '{geojson_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ GeoJSON Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
             st.stop()

        gdf = gpd.read_file(geojson_path)
        st.success(f"âœ… ÙØ§ÛŒÙ„ GeoJSON '{geojson_path}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯ ({len(gdf)} features).")

        # Basic validation of properties
        required_props = ['Ù…Ø²Ø±Ø¹Ù‡', 'Ø±ÙˆØ²', 'Ú¯Ø±ÙˆÙ‡'] # Removed 'Ø³Ù†', 'ÙˆØ§Ø±ÛŒØªÙ‡' as maybe not always needed for filtering? Add back if essential for filtering.
        if not all(prop in gdf.columns for prop in required_props):
            missing_cols = [p for p in required_props if p not in gdf.columns]
            st.error(f"âŒ ÙØ§ÛŒÙ„ GeoJSON Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ PropertyÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø§Ø´Ø¯: {', '.join(missing_cols)} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
            st.stop()

        # --- CRS Handling ---
        if gdf.crs is None:
            st.warning("âš ï¸ Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª (CRS) Ø¯Ø± ÙØ§ÛŒÙ„ GeoJSON Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. ÙØ±Ø¶ Ø¨Ø± WGS84 (EPSG:4326) Ú¯Ø°Ø§Ø´ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            gdf.set_crs("EPSG:4326", inplace=True)
        elif gdf.crs.to_epsg() != 4326:
            st.warning(f"âš ï¸ Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª ÙØ§ÛŒÙ„ {gdf.crs.to_string()} Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ WGS84 (EPSG:4326)...")
            try:
                gdf = gdf.to_crs("EPSG:4326")
                st.success("âœ… ØªØ¨Ø¯ÛŒÙ„ Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª Ø¨Ù‡ WGS84 Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª: {e}")
                st.error("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª Ø³ÛŒØ³ØªÙ… Ù…Ø®ØªØµØ§Øª Ù…Ø¨Ø¯Ø£ Ø¯Ø± ÙØ§ÛŒÙ„ GeoJSON Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.")
                st.stop()

        # Drop rows with invalid or empty geometries
        initial_count = len(gdf)
        gdf = gdf[gdf.geometry.is_valid & ~gdf.geometry.is_empty]
        dropped_count = initial_count - len(gdf)
        if dropped_count > 0:
            st.warning(f"âš ï¸ {dropped_count} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯.")

        if gdf.empty:
            st.warning("âš ï¸ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù¾Ø³ Ø§Ø² Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù†Ø¯Ø³Ù‡).")
            st.stop()

        # Ensure 'Ø±ÙˆØ²' is string type and normalize spaces
        gdf['Ø±ÙˆØ²'] = gdf['Ø±ÙˆØ²'].astype(str).str.replace(r'\s+', ' ', regex=True).str.strip()
        # Ensure 'Ú¯Ø±ÙˆÙ‡' is treated appropriately
        gdf['Ú¯Ø±ÙˆÙ‡'] = gdf['Ú¯Ø±ÙˆÙ‡'].astype(str).str.strip()
        # Ensure 'Ù…Ø²Ø±Ø¹Ù‡' is string
        gdf['Ù…Ø²Ø±Ø¹Ù‡'] = gdf['Ù…Ø²Ø±Ø¹Ù‡'].astype(str)

        # --- Calculate Centroids (used for point-based analysis like time series) ---
        try:
             gdf['centroid'] = gdf.geometry.centroid
             # Extract lat/lon from centroid for potential fallback display or point needs
             gdf['centroid_lon'] = gdf.centroid.x
             gdf['centroid_lat'] = gdf.centroid.y
        except Exception as e:
             st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù‡Ù†Ø¯Ø³Ù‡â€ŒÙ‡Ø§: {e}")
             # Decide how to handle - stop or continue without centroids?
             st.warning("Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ù†ØªØ±ÙˆÛŒØ¯...")
             gdf['centroid'] = None
             gdf['centroid_lon'] = None
             gdf['centroid_lat'] = None


        st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ {len(gdf)} Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯.")
        return gdf

    except FileNotFoundError: # Should be caught by os.path.exists, but just in case
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{geojson_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ GeoJSON: {e}")
        st.error(traceback.format_exc())
        st.stop()


# --- Load Analysis Data (No Changes Needed Here) ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª...")
def load_analysis_data(csv_path=ANALYSIS_CSV_PATH):
    """Loads and preprocesses data from the analysis CSV file."""
    try:
        # Read the raw lines to identify sections
        with open(csv_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # Find the headers and split points
        headers_indices = [i for i, line in enumerate(lines) if 'Ø§Ø¯Ø§Ø±Ù‡,Ø³Ù†,' in line or 'ØªÙˆÙ„ÛŒØ¯,Ø³Ù†,' in line]
        if len(headers_indices) < 2:
            # Fallback if only one section header is found (less robust)
            headers_indices = [i for i, line in enumerate(lines) if ',Ø³Ù†,' in line]
            if len(headers_indices) < 1:
                st.error(f"âŒ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„ '{csv_path}' Ù‚Ø§Ø¨Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ³Øª. Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                return None, None # Return None instead of st.stop()
            st.warning("âš ï¸ ÙÙ‚Ø· ÛŒÚ© Ø¨Ø®Ø´ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯.")
            section1_start = headers_indices[0] + 1
            section2_start = None
            # Try to find a likely separator (e.g., a mostly blank line)
            blank_lines = [i for i, line in enumerate(lines[section1_start:]) if len(line.strip()) < 5]
            if blank_lines:
                section2_start = section1_start + blank_lines[0] + 1 # Heuristic guess
        else:
            section1_start = headers_indices[0] + 1
            section2_start = headers_indices[1] + 1 # Line after the second header

        # Read the first section (Area)
        df_area = pd.read_csv(csv_path, skiprows=headers_indices[0], nrows=(section2_start - section1_start - 2) if section2_start else None, encoding='utf-8')
        df_area.rename(columns={'Ø§Ø¯Ø§Ø±Ù‡': 'Ù…Ø³Ø§Ø­Øª_Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True) # Rename first col for clarity
        # Check if the first column is unnamed and likely 'Ø§Ø¯Ø§Ø±Ù‡'
        if df_area.columns[0].startswith('Unnamed'):
             df_area.rename(columns={df_area.columns[0]: 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)


        # Read the second section (Production) if found
        df_prod = None
        if section2_start:
            # Skip rows until the second header, read until end or grand total
            end_row_prod = None
            for i in range(section2_start, len(lines)):
                if "Grand Total" in lines[i]:
                    end_row_prod = i
                    break
            nrows_prod = (end_row_prod - section2_start) if end_row_prod else None
            df_prod = pd.read_csv(csv_path, skiprows=section2_start-1, nrows=nrows_prod, encoding='utf-8') # Read including header
            # The first column name in the second section might be 'ØªÙˆÙ„ÛŒØ¯' or unnamed
            if df_prod.columns[0].startswith('Unnamed') or df_prod.columns[0] == 'ØªÙˆÙ„ÛŒØ¯':
                 df_prod.rename(columns={df_prod.columns[0]: 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)


        # --- Preprocessing Function ---
        def preprocess_df(df, section_name):
            if df is None:
                return None
            # Ensure 'Ø§Ø¯Ø§Ø±Ù‡' is the first column if it got misplaced
            if 'Ø§Ø¯Ø§Ø±Ù‡' not in df.columns and len(df.columns) > 0 and not df.columns[0].startswith('Unnamed'):
                 # This case might indicate a parsing issue earlier
                 st.warning(f"âš ï¸ Ø³ØªÙˆÙ† 'Ø§Ø¯Ø§Ø±Ù‡' Ø¯Ø± Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ø± Ø¨Ø®Ø´ '{section_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                 # Attempt to find it, otherwise return None
                 if 'Ø§Ø¯Ø§Ø±Ù‡' in df.columns:
                      pass # Already exists
                 else:
                     # Try to intelligently find it - heuristic: find column before 'Ø³Ù†'
                     try:
                         sen_index = df.columns.get_loc('Ø³Ù†')
                         if sen_index > 0:
                             df.rename(columns={df.columns[sen_index-1]: 'Ø§Ø¯Ø§Ø±Ù‡'}, inplace=True)
                         else:
                              st.error(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ ÑÑ‚Ğ¾Ğ»Ğ±ĞµÑ† 'Ø§Ø¯Ø§Ø±Ù‡' Ğ² Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğµ '{section_name}'.")
                              return None
                     except KeyError:
                         st.error(f"Ğ¡Ñ‚Ğ¾Ğ»Ğ±ĞµÑ† 'Ø³Ù†' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½, Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ 'Ø§Ø¯Ø§Ø±Ù‡' Ğ² Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğµ '{section_name}'.")
                         return None


            # Check for required columns
            if not all(col in df.columns for col in ['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†']):
                 st.warning(f"âš ï¸ Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ 'Ø§Ø¯Ø§Ø±Ù‡' ÛŒØ§ 'Ø³Ù†' Ø¯Ø± Ø¨Ø®Ø´ '{section_name}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                 return None

            # Forward fill 'Ø§Ø¯Ø§Ø±Ù‡'
            df['Ø§Ø¯Ø§Ø±Ù‡'] = df['Ø§Ø¯Ø§Ø±Ù‡'].ffill()

            # Filter out 'total' and 'Grand Total' rows in 'Ø³Ù†' and 'Ø§Ø¯Ø§Ø±Ù‡'
            df = df[~df['Ø³Ù†'].astype(str).str.contains('total', case=False, na=False)]
            df = df[~df['Ø§Ø¯Ø§Ø±Ù‡'].astype(str).str.contains('total|Ø¯Ù‡Ø®Ø¯Ø§', case=False, na=False)] # Filter Grand Total/summary rows in Ø§Ø¯Ø§Ø±Ù‡

            # Remove rows where 'Ø§Ø¯Ø§Ø±Ù‡' is NaN after ffill (first rows before a number)
            df = df.dropna(subset=['Ø§Ø¯Ø§Ø±Ù‡'])

            # Convert 'Ø§Ø¯Ø§Ø±Ù‡' to integer where possible
            df['Ø§Ø¯Ø§Ø±Ù‡_str'] = df['Ø§Ø¯Ø§Ø±Ù‡'].astype(str) # Keep original string if needed
            df['Ø§Ø¯Ø§Ø±Ù‡'] = pd.to_numeric(df['Ø§Ø¯Ø§Ø±Ù‡'], errors='coerce')
            df = df.dropna(subset=['Ø§Ø¯Ø§Ø±Ù‡']) # Drop if conversion failed
            df['Ø§Ø¯Ø§Ø±Ù‡'] = df['Ø§Ø¯Ø§Ø±Ù‡'].astype(int)


            # Convert numeric columns, coerce errors to NaN
            value_cols = [col for col in df.columns if col not in ['Ø§Ø¯Ø§Ø±Ù‡', 'Ø§Ø¯Ø§Ø±Ù‡_str', 'Ø³Ù†', 'Ø¯Ø±ØµØ¯', 'Grand Total']]
            for col in value_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            # Drop Grand Total and Ø¯Ø±ØµØ¯ columns if they exist
            df = df.drop(columns=['Grand Total', 'Ø¯Ø±ØµØ¯'], errors='ignore')

            # Set multi-index for easier access
            if 'Ø§Ø¯Ø§Ø±Ù‡' in df.columns and 'Ø³Ù†' in df.columns:
                try:
                    df = df.set_index(['Ø§Ø¯Ø§Ø±Ù‡', 'Ø³Ù†'])
                except KeyError as e:
                     st.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… Ø§ÛŒÙ†Ø¯Ú©Ø³ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡ ({e}). Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯: {df.columns}")
                     return None # Stop processing this df
            else:
                 st.warning(f"âš ï¸ Ø§Ù…Ú©Ø§Ù† ØªÙ†Ø¸ÛŒÙ… Ø§ÛŒÙ†Ø¯Ú©Ø³ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡ Ø¯Ø± Ø¨Ø®Ø´ '{section_name}' ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")


            return df

        df_area_processed = preprocess_df(df_area, "Ù…Ø³Ø§Ø­Øª")
        df_prod_processed = preprocess_df(df_prod, "ØªÙˆÙ„ÛŒØ¯")

        if df_area_processed is not None or df_prod_processed is not None:
            st.success(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯.")
        else:
             st.warning("âš ï¸ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÛŒØ² Ù†Ø¨ÙˆØ¯.")

        return df_area_processed, df_prod_processed

    except FileNotFoundError:
        st.error(f"âŒ ÙØ§ÛŒÙ„ '{csv_path}' ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ CSV Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        return None, None
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª CSV: {e}")
        st.error(traceback.format_exc()) # Print detailed error
        return None, None


# Initialize GEE and Load Data
if initialize_gee():
    farm_data_gdf = load_farm_data() # Now loads GeoDataFrame

# Load Analysis Data
analysis_area_df, analysis_prod_df = load_analysis_data()

# ==============================================================================
# Sidebar Filters
# ==============================================================================
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

# --- Day of the Week Selection ---
if farm_data_gdf is not None:
    available_days = sorted(farm_data_gdf['Ø±ÙˆØ²'].unique())
    if not available_days:
        st.sidebar.warning("Ù‡ÛŒÚ† Ø±ÙˆØ²ÛŒ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()

    selected_day = st.sidebar.selectbox(
        "ğŸ“… Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        options=available_days,
        index=0, # Default to the first day
        help="Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø±ÙˆØ² ÙÛŒÙ„ØªØ± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯."
    )

    # --- Filter Data Based on Selected Day ---
    filtered_farms_gdf = farm_data_gdf[farm_data_gdf['Ø±ÙˆØ²'] == selected_day].copy()

    if filtered_farms_gdf.empty:
        st.warning(f"âš ï¸ Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ² '{selected_day}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop() # Stop if no farms for the selected day

    # --- Farm Selection ---
    available_farms = sorted(filtered_farms_gdf['Ù…Ø²Ø±Ø¹Ù‡'].unique())
    farm_options = ["Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹"] + available_farms
    selected_farm_name = st.sidebar.selectbox(
        "ğŸŒ¾ Ù…Ø²Ø±Ø¹Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        options=farm_options,
        index=0, # Default to "All Farms"
        help="Ù…Ø²Ø±Ø¹Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¢Ù† Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯ ÛŒØ§ 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ."
    )

else:
    st.error("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§ Ø´Ú©Ø³Øª Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
    st.stop()


# --- Index Selection ---
index_options = {
    "NDVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªÙØ§Ø¶Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡",
    "EVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡",
    "NDMI": "Ø´Ø§Ø®Øµ Ø±Ø·ÙˆØ¨Øª ØªÙØ§Ø¶Ù„ÛŒ Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡ (ÙˆØ¶Ø¹ÛŒØª Ø¢Ø¨ÛŒ)",
    "LAI": "Ø´Ø§Ø®Øµ Ø³Ø·Ø­ Ø¨Ø±Ú¯ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
    "MSI": "Ø´Ø§Ø®Øµ ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ",
    "CVI": "Ø´Ø§Ø®Øµ Ú©Ù„Ø±ÙˆÙÛŒÙ„ (ØªØ®Ù…ÛŒÙ†ÛŒ)",
    "SAVI": "Ø´Ø§Ø®Øµ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ Ø¨Ø§ Ø®Ø§Ú©" # Added SAVI here too
}
selected_index = st.sidebar.selectbox(
    "ğŸ“ˆ Ø´Ø§Ø®Øµ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±ÙˆÛŒ Ù†Ù‚Ø´Ù‡:",
    options=list(index_options.keys()),
    format_func=lambda x: f"{x} ({index_options[x]})",
    index=0 # Default to NDVI
)

# --- Date Range Calculation ---
today = datetime.date.today()
persian_to_weekday = {
    "Ø´Ù†Ø¨Ù‡": 5, "ÛŒÚ©Ø´Ù†Ø¨Ù‡": 6, "Ø¯ÙˆØ´Ù†Ø¨Ù‡": 0, "Ø³Ù‡ Ø´Ù†Ø¨Ù‡": 1,
    "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡": 2, "Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡": 3, "Ø¬Ù…Ø¹Ù‡": 4,
}
try:
    target_weekday = persian_to_weekday[selected_day]
    days_ago = (today.weekday() - target_weekday + 7) % 7
    if days_ago == 0:
         end_date_current = today
    else:
         end_date_current = today - datetime.timedelta(days=days_ago)

    start_date_current = end_date_current - datetime.timedelta(days=6)
    end_date_previous = start_date_current - datetime.timedelta(days=1)
    start_date_previous = end_date_previous - datetime.timedelta(days=6)

    start_date_current_str = start_date_current.strftime('%Y-%m-%d')
    end_date_current_str = end_date_current.strftime('%Y-%m-%d')
    start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
    end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')

    st.sidebar.info(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÙØ¹Ù„ÛŒ: {start_date_current_str} ØªØ§ {end_date_current_str}")
    st.sidebar.info(f"Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù‚Ø¨Ù„ÛŒ: {start_date_previous_str} ØªØ§ {end_date_previous_str}")

except KeyError:
    st.sidebar.error(f"Ù†Ø§Ù… Ø±ÙˆØ² Ù‡ÙØªÙ‡ '{selected_day}' Ù‚Ø§Ø¨Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†ÛŒØ³Øª.")
    st.stop()
except Exception as e:
    st.sidebar.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {e}")
    st.stop()


# ==============================================================================
# Google Earth Engine Functions
# ==============================================================================

# --- Cloud Masking Function for Sentinel-2 ---
def maskS2clouds(image):
    """Masks clouds in a Sentinel-2 SR image using the QA band."""
    qa = image.select('QA60')
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(
             qa.bitwiseAnd(cirrusBitMask).eq(0))
    try:
        # Use SCL band for more robust masking if available
        scl = image.select('SCL')
        # Define good quality pixel values based on SCL documentation
        # 4: Vegetation, 5: Bare Soils, 6: Water, 7: Unclassified -> treat as good? Maybe not. 11: Snow/Ice
        # Keep 4, 5, 6, 11. Mask out others (Clouds, Shadows, etc.)
        good_quality = scl.remap([4, 5, 6, 11], [1, 1, 1, 1], 0) # Map good classes to 1, others to 0
        combined_mask = mask.And(good_quality)
    except ee.EEException as e:
        # Handle cases where SCL might be missing (though unlikely for S2_SR_HARMONIZED)
        # st.warning(f"Could not apply SCL mask: {e}. Using QA60 mask only.")
        combined_mask = mask # Fallback to QA60 mask


    opticalBands = image.select('B.*').multiply(0.0001)

    return image.addBands(opticalBands, None, True)\
                .updateMask(combined_mask) # Apply combined mask


# --- Index Calculation Functions ---
def add_indices(image):
    """Calculates and adds various indices as bands to an image."""
    # Ensure required bands exist before calculating indices
    required_bands = ['B2', 'B3', 'B4', 'B8', 'B11'] # Blue, Green, Red, NIR, SWIR1
    # Create a default image with 0s for missing bands to avoid errors downstream
    # This might slightly affect results if bands are genuinely missing, but prevents crashes
    band_names = image.bandNames()
    default_values = ee.Image(0).rename(required_bands).cast(image.select(band_names.get(0)).dataType())
    image = image.addBands(default_values, None, True) # Add defaults, overwrite=False (keep original if exists)


    # NDVI
    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')
    # EVI
    evi = image.expression(
        '2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1)', {
            'NIR': image.select('B8'), 'RED': image.select('B4'), 'BLUE': image.select('B2')
        }).rename('EVI')
    # NDMI
    ndmi = image.normalizedDifference(['B8', 'B11']).rename('NDMI')
    # SAVI
    savi = image.expression(
        '((NIR - RED) / (NIR + RED + L)) * (1 + L)',
        {'NIR': image.select('B8'), 'RED': image.select('B4'), 'L': 0.5}
    ).rename('SAVI')
    # MSI
    msi = image.expression('SWIR1 / NIR', {
        'SWIR1': image.select('B11').max(ee.Image(0.0001)), # Avoid division by zero/very small NIR
        'NIR': image.select('B8').max(ee.Image(0.0001))
    }).rename('MSI')
    # LAI (Placeholder)
    lai = ndvi.multiply(3.5).rename('LAI') # Placeholder - Needs proper calibration
    # CVI (Handle potential division by zero)
    green_safe = image.select('B3').max(ee.Image(0.0001))
    cvi = image.expression('(NIR / GREEN) * (RED / GREEN)', {
        'NIR': image.select('B8'), 'GREEN': green_safe, 'RED': image.select('B4')
    }).rename('CVI')

    return image.addBands([ndvi, evi, ndmi, msi, lai, cvi, savi])


# --- Function to get processed image for a date range and geometry ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ...", persist=True)
def get_processed_image(_ee_geometry, start_date, end_date, index_name):
    """
    Gets cloud-masked, index-calculated Sentinel-2 median composite for a given ee.Geometry and date range.
    _ee_geometry: ee.Geometry object (Point, Polygon, etc.)
    start_date, end_date: YYYY-MM-DD strings
    index_name: Name of the primary index band to return (e.g., 'NDVI')
    """
    if not isinstance(_ee_geometry, ee.geometry.Geometry):
         st.error(f"Ø®Ø·Ø§: ÙˆØ±ÙˆØ¯ÛŒ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ get_processed_image. Ù†ÙˆØ¹ Ø¯Ø±ÛŒØ§ÙØªÛŒ: {type(_ee_geometry)}")
         return None, "Invalid geometry input."
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_ee_geometry)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds)) # Apply cloud masking

        count = s2_sr_col.size().getInfo()
        if count == 0:
            return None, f"No cloud-free Sentinel-2 images found for {start_date} to {end_date} in the area."

        indexed_col = s2_sr_col.map(add_indices)
        median_image = indexed_col.median().setDefaultProjection(s2_sr_col.first().projection()) # Keep projection info

        output_image = median_image.select(index_name)

        return output_image, None # Return the image and no error message
    except ee.EEException as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Google Earth Engine Ø¯Ø± get_processed_image: {e}"
        # st.error(error_message) # Show error in main app area if needed
        try:
            error_details = e.args[0] if e.args else str(e)
            if isinstance(error_details, str):
                if 'computation timed out' in error_details.lower():
                     error_message += "\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø­Ø¬Ù… Ø¨Ø§Ù„Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ)"
                elif 'user memory limit exceeded' in error_details.lower():
                     error_message += "\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø²Ø±Ú¯ ÛŒØ§ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡)"
                elif 'geometryconstructors polygon':
                     error_message += "\n(Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù…Ø®ØªØµØ§Øª Ù‡Ù†Ø¯Ø³Ù‡ ÙˆØ±ÙˆØ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)"

        except Exception: pass
        return None, error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ GEE (get_processed_image): {e}\n{traceback.format_exc()}"
        # st.error(error_message)
        return None, error_message


# --- Function to get time series data for a point ---
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ...", persist=True)
def get_index_time_series(_ee_point_geom, index_name, start_date='2023-01-01', end_date=today.strftime('%Y-%m-%d')):
    """Gets a time series of a specified index for a POINT geometry."""
    if not isinstance(_ee_point_geom, ee.geometry.Point):
        st.warning("ØªØ§Ø¨Ø¹ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù‡Ù†Ø¯Ø³Ù‡ Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ (Point) Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.")
        return pd.DataFrame(columns=['date', index_name]), "ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§ÛŒØ¯ ee.Geometry.Point Ø¨Ø§Ø´Ø¯."

    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_ee_point_geom)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds)
                     .map(add_indices))

        def extract_value(image):
            # Extract value at the point, scale=10m for Sentinel-2
            try:
                value = image.reduceRegion(
                    reducer=ee.Reducer.firstNonNull(), # Get first non-null pixel touching the point
                    geometry=_ee_point_geom,
                    scale=10
                ).get(index_name)
                # Return feature only if value is not null
                return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd'), index_name: value}).set('dummy', 1) # Add dummy prop for filter
            except Exception:
                # If reduceRegion fails for an image, return null feature
                 return ee.Feature(None).set('dummy', None)


        # Map and filter null features more robustly
        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.notNull(['dummy', index_name])) # Filter based on dummy and index value

        ts_info = ts_features.getInfo()['features']

        if not ts_info:
            return pd.DataFrame(columns=['date', index_name]), f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {index_name} ÛŒØ§ÙØª Ù†Ø´Ø¯."

        ts_data = [{'date': f['properties']['date'], index_name: f['properties'][index_name]} for f in ts_info if index_name in f.get('properties', {})]
        if not ts_data:
             return pd.DataFrame(columns=['date', index_name]), f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± {index_name} Ø¯Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."

        ts_df = pd.DataFrame(ts_data)
        ts_df['date'] = pd.to_datetime(ts_df['date'])
        # Handle potential duplicate dates (e.g., multiple orbits same day) by taking the mean
        ts_df = ts_df.groupby('date')[index_name].mean().reset_index()
        ts_df = ts_df.sort_values('date').set_index('date')


        return ts_df, None # Return DataFrame and no error
    except ee.EEException as e:
        error_message = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}"
        # st.error(error_message)
        return pd.DataFrame(columns=['date', index_name]), error_message
    except Exception as e:
        error_message = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {e}\n{traceback.format_exc()}"
        # st.error(error_message)
        return pd.DataFrame(columns=['date', index_name]), error_message


# ==============================================================================
# Function to get all relevant indices for a farm POINT for two periods
# (Used for Needs Analysis)
# ==============================================================================
@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù†ÛŒØ§Ø²Ø³Ù†Ø¬ÛŒ...", persist=True)
def get_farm_needs_data(_ee_point_geom, start_curr, end_curr, start_prev, end_prev):
    """Calculates mean NDVI, NDMI, EVI, SAVI for current and previous periods using a POINT geometry."""
    results = {
        'NDVI_curr': None, 'NDMI_curr': None, 'EVI_curr': None, 'SAVI_curr': None,
        'NDVI_prev': None, 'NDMI_prev': None, 'EVI_prev': None, 'SAVI_prev': None,
        'error': None
    }
    indices_to_get = ['NDVI', 'NDMI', 'EVI', 'SAVI']

    if not isinstance(_ee_point_geom, ee.geometry.Point):
        results['error'] = "get_farm_needs_data requires an ee.Geometry.Point."
        return results

    def get_mean_values_for_period(start, end):
        period_values = {index: None for index in indices_to_get}
        error_msg = None
        try:
            s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                         .filterBounds(_ee_point_geom)
                         .filterDate(start, end)
                         .map(maskS2clouds)
                         .map(add_indices))

            count = s2_sr_col.size().getInfo()
            if count == 0:
                return period_values, f"Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end} ÛŒØ§ÙØª Ù†Ø´Ø¯"

            median_image = s2_sr_col.median()

            # Reduce region using the point geometry
            mean_dict = median_image.select(indices_to_get).reduceRegion(
                reducer=ee.Reducer.firstNonNull(), # Use firstNonNull for point geometry
                geometry=_ee_point_geom,
                scale=10  # Scale in meters
            ).getInfo()

            if mean_dict:
                for index in indices_to_get:
                    period_values[index] = mean_dict.get(index) # Returns None if key missing
            else:
                 error_msg = f"reduceRegion did not return results for {start}-{end}."

            return period_values, error_msg # Return error if reduceRegion failed

        except ee.EEException as e:
            error_msg = f"Ø®Ø·Ø§ÛŒ GEE Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end}: {e}"
            return period_values, error_msg
        except Exception as e:
            error_msg = f"Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ Ø¯Ø± Ø¨Ø§Ø²Ù‡ {start}-{end}: {e}"
            return period_values, error_msg

    # Get data for current period
    curr_values, err_curr = get_mean_values_for_period(start_curr, end_curr)
    if err_curr:
        results['error'] = err_curr
    else:
        results['NDVI_curr'] = curr_values.get('NDVI')
        results['NDMI_curr'] = curr_values.get('NDMI')
        results['EVI_curr'] = curr_values.get('EVI')
        results['SAVI_curr'] = curr_values.get('SAVI')

    # Get data for previous period
    prev_values, err_prev = get_mean_values_for_period(start_prev, end_prev)
    if err_prev:
        results['error'] = f"{results.get('error', '')} | {err_prev}" if results.get('error') else err_prev # Append errors
    else:
        results['NDVI_prev'] = prev_values.get('NDVI')
        results['NDMI_prev'] = prev_values.get('NDMI')
        results['EVI_prev'] = prev_values.get('EVI')
        results['SAVI_prev'] = prev_values.get('SAVI')


    # Check if essential current data is missing even if no specific error was raised
    if results['NDVI_curr'] is None or results['NDMI_curr'] is None:
         if not results['error']: # Add a generic error if no specific one exists
              results['error'] = f"Essential index data (NDVI/NDMI) could not be retrieved for the current period ({start_curr}-{end_curr})."
         elif "Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡" not in results['error']: # Don't overwrite the 'no image' error
              results['error'] += f" | Essential index data (NDVI/NDMI) missing for current period."


    return results

# ==============================================================================
# Gemini AI Helper Functions (No changes needed here)
# ==============================================================================
@st.cache_resource
def configure_gemini():
    """Configures the Gemini API client using a hardcoded API key (NOT RECOMMENDED)."""
    try:
        # --- WARNING: Hardcoding API keys is insecure! Use Streamlit secrets instead. ---
        # Replace with your actual key or load from secrets
        api_key = os.environ.get("GEMINI_API_KEY", "YOUR_API_KEY_HERE") # Example: Load from env var or hardcode
        # api_key = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ" # Direct hardcoding (Bad practice)

        if not api_key or api_key == "YOUR_API_KEY_HERE":
             st.warning(" Ú©Ù„ÛŒØ¯ API Ø¬Ù…ÛŒÙ†Ø§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")
             st.info("Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒØŒ Ú©Ù„ÛŒØ¯ Ø®ÙˆØ¯ Ø±Ø§ Ø¯Ø± Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ GEMINI_API_KEY Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯ ÛŒØ§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¯Ø± Ú©Ø¯ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯ (ØªÙˆØµÛŒÙ‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯).")
             return None

        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash') # Use the latest flash model
        print("Gemini Configured Successfully.")
        return model
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… Gemini API: {e}")
        return None

@st.cache_data(show_spinner="Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...", persist=True)
def get_ai_analysis(_model, farm_name, index_data, recommendations):
    """Generates AI analysis for the farm's condition."""
    if _model is None:
        return "Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    # Format current and previous values safely
    def format_val(val):
        return f"{val:.3f}" if isinstance(val, (int, float)) else "N/A"

    data_str = ""
    if 'NDVI_curr' in index_data: data_str += f"NDVI ÙØ¹Ù„ÛŒ: {format_val(index_data['NDVI_curr'])} (Ù‚Ø¨Ù„ÛŒ: {format_val(index_data.get('NDVI_prev'))})\n"
    if 'NDMI_curr' in index_data: data_str += f"NDMI ÙØ¹Ù„ÛŒ: {format_val(index_data['NDMI_curr'])} (Ù‚Ø¨Ù„ÛŒ: {format_val(index_data.get('NDMI_prev'))})\n"
    if 'EVI_curr' in index_data: data_str += f"EVI ÙØ¹Ù„ÛŒ: {format_val(index_data['EVI_curr'])} (Ù‚Ø¨Ù„ÛŒ: {format_val(index_data.get('EVI_prev'))})\n"
    if 'SAVI_curr' in index_data: data_str += f"SAVI ÙØ¹Ù„ÛŒ: {format_val(index_data['SAVI_curr'])} (Ù‚Ø¨Ù„ÛŒ: {format_val(index_data.get('SAVI_prev'))})\n"
    if not data_str: data_str = "Ø¯Ø§Ø¯Ù‡ Ø´Ø§Ø®ØµÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ®ØµØµ Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ù†ÛŒØ´Ú©Ø± Ù‡Ø³ØªÛŒØ¯. Ù„Ø·ÙØ§Ù‹ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø±Ø¹Ù‡ '{farm_name}' Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø²ÛŒØ± ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ ÛŒÚ© ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯. ØªÙ…Ø±Ú©Ø² ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ Ú©ÙˆØ¯ÛŒ Ø¨Ø§Ø´Ø¯.

    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ:
    {data_str}
    ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡:
    {', '.join(recommendations) if recommendations else 'Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.'}

    ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ (Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…Ø®ØªØµØ±):
    """

    try:
        response = _model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API: {e}")
        # Provide more specific feedback if possible (e.g., quota exceeded, API key issue)
        if "API key not valid" in str(e):
            return "Ø®Ø·Ø§: Ú©Ù„ÛŒØ¯ API Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª."
        return "Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ."


# ==============================================================================
# Main Application Layout (Using Tabs)
# ==============================================================================

# Configure Gemini Model at the start
gemini_model = configure_gemini()

tab1, tab2, tab3 = st.tabs(["ğŸ“Š Ù¾Ø§ÛŒØ´ Ù…Ø²Ø§Ø±Ø¹", "ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª", "ğŸ’§Ú©ÙˆØ¯ Ùˆ Ø¢Ø¨ÛŒØ§Ø±ÛŒ"])

with tab1:
    # ==============================================================================
    # Main Panel Display
    # ==============================================================================

    # --- Get Selected Farm Geometry and Details ---
    selected_farm_details = None
    selected_farm_shapely_geom = None # Shapely geometry from GeoDataFrame
    selected_farm_ee_geom = None # Converted ee.Geometry
    map_bounds = None # To store bounds for map centering

    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        # Use the total bounds of all filtered farms for the map view and GEE image extent
        if not filtered_farms_gdf.empty:
             # Get bounds [minx, miny, maxx, maxy]
             map_bounds = filtered_farms_gdf.total_bounds
             selected_farm_ee_geom = ee.Geometry.Rectangle(map_bounds.tolist())
             # Calculate approx center for map view
             map_center_lon = (map_bounds[0] + map_bounds[2]) / 2
             map_center_lat = (map_bounds[1] + map_bounds[3]) / 2
        else:
             # Fallback if somehow the filtered df is empty here
             map_center_lat = INITIAL_LAT
             map_center_lon = INITIAL_LON
             selected_farm_ee_geom = None # No geometry to process
             st.warning("Ù‡ÛŒÚ† Ù…Ø²Ø±Ø¹Ù‡ Ø§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø­Ø§Ù„Øª 'Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹' ÛŒØ§ÙØª Ù†Ø´Ø¯.")

        st.subheader(f"Ù†Ù…Ø§ÛŒØ´ Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ²: {selected_day}")
        st.info(f"ØªØ¹Ø¯Ø§Ø¯ Ù…Ø²Ø§Ø±Ø¹ Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ²: {len(filtered_farms_gdf)}")

    else:
        # Get details for the single selected farm
        try:
            selected_farm_details = filtered_farms_gdf[filtered_farms_gdf['Ù…Ø²Ø±Ø¹Ù‡'] == selected_farm_name].iloc[0]
            selected_farm_shapely_geom = selected_farm_details.geometry
            map_bounds = selected_farm_shapely_geom.bounds # Get bounds of the single polygon
            # Calculate center from polygon bounds
            map_center_lon = (map_bounds[0] + map_bounds[2]) / 2
            map_center_lat = (map_bounds[1] + map_bounds[3]) / 2
            # Convert the polygon to ee.Geometry for GEE processing
            selected_farm_ee_geom = shapely_to_ee_geometry(selected_farm_shapely_geom)

            if selected_farm_ee_geom is None:
                 st.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}' Ø¨Ù‡ ÙØ±Ù…Øª Earth Engine.")
                 # Optionally try using centroid as fallback?
                 if selected_farm_details['centroid'] is not None:
                      st.warning("Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†...")
                      selected_farm_ee_geom = shapely_to_ee_geometry(selected_farm_details['centroid'])
                      if selected_farm_ee_geom is None:
                           st.error("ØªØ¨Ø¯ÛŒÙ„ Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù†ÛŒØ² Ø¨Ø§ Ø´Ú©Ø³Øª Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯.")
                           selected_farm_details = None # Prevent further processing


            st.subheader(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name} (Ø±ÙˆØ²: {selected_day})")
            # Display farm details
            details_cols = st.columns(3)
            with details_cols[0]:
                # Area: Calculate from geometry if not in properties
                try:
                    # Calculate area in hectares (assuming CRS is geographic - EPSG:4326)
                    # For accurate area, reproject to a suitable projected CRS first (e.g., UTM)
                    # This is a rough estimate using geographic coordinates
                    # area_m2 = selected_farm_details.geometry.to_crs(epsg=32639).area # Example: UTM 39N
                    # area_ha = area_m2 / 10000
                    # st.metric("Ù…Ø³Ø§Ø­Øª ØªØ®Ù…ÛŒÙ†ÛŒ (Ù‡Ú©ØªØ§Ø±)", f"{area_ha:,.2f}")
                    # Or just show centroid if area calc is complex/slow
                    st.metric("Ø³Ù†ØªØ±ÙˆÛŒØ¯", f"{selected_farm_details['centroid_lat']:.5f}, {selected_farm_details['centroid_lon']:.5f}" if selected_farm_details['centroid_lat'] else "N/A")

                except Exception as e:
                    # st.metric("Ù…Ø³Ø§Ø­Øª", "Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡")
                    st.metric("Ø³Ù†ØªØ±ÙˆÛŒØ¯", f"{selected_farm_details['centroid_lat']:.5f}, {selected_farm_details['centroid_lon']:.5f}" if selected_farm_details['centroid_lat'] else "N/A")

                st.metric("ÙˆØ§Ø±ÛŒØªÙ‡", f"{selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}")
            with details_cols[1]:
                st.metric("Ú¯Ø±ÙˆÙ‡", f"{selected_farm_details.get('Ú¯Ø±ÙˆÙ‡', 'N/A')}")
                st.metric("Ø³Ù†", f"{selected_farm_details.get('Ø³Ù†', 'N/A')}")
            with details_cols[2]:
                 # Display polygon bounds or centroid
                 if map_bounds:
                      st.metric("Ù…Ø­Ø¯ÙˆØ¯Ù‡ (ØªÙ‚Ø±ÛŒØ¨ÛŒ)", f"Lon: {map_bounds[0]:.4f}-{map_bounds[2]:.4f}, Lat: {map_bounds[1]:.4f}-{map_bounds[3]:.4f}")
                 else:
                      st.metric("Ù…Ø®ØªØµØ§Øª", "N/A")

        except IndexError:
             st.error(f"Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ø§ Ù†Ø§Ù… '{selected_farm_name}' Ø¯Ø± Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
             selected_farm_details = None
             selected_farm_ee_geom = None
        except Exception as e:
             st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡ '{selected_farm_name}': {e}")
             selected_farm_details = None
             selected_farm_ee_geom = None


    # --- Map Display ---
    st.markdown("---")
    st.subheader(" Ù†Ù‚Ø´Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")

    vis_params = {
        'NDVI': {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']},
        'EVI': {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']},
        'NDMI': {'min': -1, 'max': 1, 'palette': ['brown', 'white', 'blue']},
        'LAI': {'min': 0, 'max': 6, 'palette': ['white', 'lightgreen', 'darkgreen']},
        'MSI': {'min': 0, 'max': 3, 'palette': ['blue', 'white', 'brown']}, # Lower MSI = more moisture
        'CVI': {'min': 0, 'max': 20, 'palette': ['yellow', 'lightgreen', 'darkgreen']},
        'SAVI': {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']},
    }

    # Use calculated center if available, otherwise default
    map_disp_center_lat = map_center_lat if 'map_center_lat' in locals() else INITIAL_LAT
    map_disp_center_lon = map_center_lon if 'map_center_lon' in locals() else INITIAL_LON
    map_zoom = INITIAL_ZOOM if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹" else 14 # Zoom closer for single farm


    m = geemap.Map(
        location=[map_disp_center_lat, map_disp_center_lon],
        zoom=map_zoom,
        add_google_map=False
    )
    m.add_basemap("HYBRID")

    # Get the processed GEE image layer for the current week
    gee_image_current = None
    error_msg_current = None
    if selected_farm_ee_geom:
        with st.spinner(f"Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ ({selected_index})..."):
            gee_image_current, error_msg_current = get_processed_image(
                selected_farm_ee_geom, start_date_current_str, end_date_current_str, selected_index
            )
        if error_msg_current:
            st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„Ø§ÛŒÙ‡ GEE: {error_msg_current}")
        elif gee_image_current is None:
             st.warning(f"Ù„Ø§ÛŒÙ‡ GEE Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ ({selected_index}) Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù†Ø´Ø¯.")


    # Add GEE layer to map if available
    if gee_image_current:
        try:
            m.addLayer(
                gee_image_current,
                vis_params.get(selected_index, {'palette': 'viridis'}), # Default palette
                f"{selected_index} ({start_date_current_str} to {end_date_current_str})"
            )
        except Exception as map_err:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ù„Ø§ÛŒÙ‡ GEE Ø¨Ù‡ Ù†Ù‚Ø´Ù‡: {map_err}")
            st.error(traceback.format_exc())
    elif selected_farm_ee_geom : # Only show warning if we expected an image
        st.warning(f"ØªØµÙˆÛŒØ± Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ ({selected_index}) Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯.")


    # Add Farm Geometries (Polygons) to the map
    try:
        if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
            if not filtered_farms_gdf.empty:
                 # Add all filtered farms as GeoJSON layer
                 geojson_data = filtered_farms_gdf.__geo_interface__ # Convert GDF to GeoJSON dict
                 # Define a style function for coloring polygons (optional)
                 # def style_function(feature):
                 #      return {'fillColor': '#ffaf00', 'color': 'black', 'weight': 1, 'fillOpacity': 0.5}
                 geemap.add_geojson(m, geojson_data, layer_name="Ù…Ø²Ø§Ø±Ø¹")
                 # Add tooltips/popups
                 for idx, farm in filtered_farms_gdf.iterrows():
                      if farm.geometry: # Check if geometry exists
                           # Use centroid for marker popup if polygons are too dense
                            popup_text = f"Ù…Ø²Ø±Ø¹Ù‡: {farm['Ù…Ø²Ø±Ø¹Ù‡']}<br>Ú¯Ø±ÙˆÙ‡: {farm.get('Ú¯Ø±ÙˆÙ‡', 'N/A')}<br>Ø³Ù†: {farm.get('Ø³Ù†', 'N/A')}"
                            folium.Marker(
                                location=[farm['centroid_lat'], farm['centroid_lon']],
                                popup=popup_text,
                                tooltip=farm['Ù…Ø²Ø±Ø¹Ù‡'],
                                icon=folium.Icon(color='blue', icon='info-sign')
                            ).add_to(m)

        elif selected_farm_details is not None and selected_farm_shapely_geom is not None:
             # Add the single selected farm polygon
             geojson_data = selected_farm_details.to_frame().T.__geo_interface__ # Create GeoJSON from the single row Series
             geemap.add_geojson(m, geojson_data, layer_name=selected_farm_name,
                                style_callback=lambda x: {'color': 'red', 'fillColor': 'red', 'fillOpacity': 0.1, 'weight': 2})
             # Add a marker at the centroid for popup
             if selected_farm_details['centroid']:
                    popup_text = f"Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}<br>Ú¯Ø±ÙˆÙ‡: {selected_farm_details.get('Ú¯Ø±ÙˆÙ‡', 'N/A')}<br>Ø³Ù†: {selected_farm_details.get('Ø³Ù†', 'N/A')}<br>ÙˆØ§Ø±ÛŒØªÙ‡: {selected_farm_details.get('ÙˆØ§Ø±ÛŒØªÙ‡', 'N/A')}"
                    folium.Marker(
                       location=[selected_farm_details['centroid_lat'], selected_farm_details['centroid_lon']],
                       popup=popup_text,
                       tooltip=selected_farm_name,
                       icon=folium.Icon(color='red', icon='star')
                    ).add_to(m)
             # Center map on the selected farm's bounds
             if map_bounds:
                  m.fit_bounds([[map_bounds[1], map_bounds[0]], [map_bounds[3], map_bounds[2]]]) # [[min_lat, min_lon], [max_lat, max_lon]]


    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÙØ²ÙˆØ¯Ù† Ù‡Ù†Ø¯Ø³Ù‡ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ù‡ Ù†Ù‚Ø´Ù‡: {e}")
        st.error(traceback.format_exc())


    # Add Legend (Using custom HTML as before)
    legend_html = None
    # Define legend based on index
    if selected_index in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI']:
        legend_html = '''
        <div style="position: fixed; bottom: 50px; right: 50px; z-index: 1000; background-color: white; padding: 10px; border: 2px solid grey; border-radius: 5px;">
            <p style="margin: 0;"><strong>{} Legend</strong></p>
            <p style="margin: 0;"><span style="background-color: red; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ø¨Ø­Ø±Ø§Ù†ÛŒ/Ù¾Ø§ÛŒÛŒÙ†</p>
            <p style="margin: 0;"><span style="background-color: yellow; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ù…ØªÙˆØ³Ø·</p>
            <p style="margin: 0;"><span style="background-color: green; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ø³Ø§Ù„Ù…/Ø¨Ø§Ù„Ø§</p>
        </div>
        '''.format(selected_index)
    elif selected_index == 'NDMI':
        legend_html = '''
        <div style="position: fixed; bottom: 50px; right: 50px; z-index: 1000; background-color: white; padding: 10px; border: 2px solid grey; border-radius: 5px;">
            <p style="margin: 0;"><strong>{} Legend</strong></p>
            <p style="margin: 0;"><span style="background-color: brown; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ø®Ø´Ú©/Ù¾Ø§ÛŒÛŒÙ†</p>
            <p style="margin: 0;"><span style="background-color: white; border: 1px solid #ccc; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ù…ØªÙˆØ³Ø·</p>
            <p style="margin: 0;"><span style="background-color: blue; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ù…Ø±Ø·ÙˆØ¨/Ø¨Ø§Ù„Ø§</p>
        </div>
        '''.format(selected_index)
    elif selected_index == 'MSI':
         legend_html = '''
         <div style="position: fixed; bottom: 50px; right: 50px; z-index: 1000; background-color: white; padding: 10px; border: 2px solid grey; border-radius: 5px;">
             <p style="margin: 0;"><strong>{} Legend (ØªÙ†Ø´ Ø±Ø·ÙˆØ¨ØªÛŒ)</strong></p>
             <p style="margin: 0;"><span style="background-color: blue; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ø±Ø·ÙˆØ¨Øª Ø¨Ø§Ù„Ø§ (ØªÙ†Ø´ Ú©Ù…)</p>
             <p style="margin: 0;"><span style="background-color: white; border: 1px solid #ccc; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ù…ØªÙˆØ³Ø·</p>
             <p style="margin: 0;"><span style="background-color: brown; display: inline-block; width: 12px; height: 12px; margin-right: 5px;"></span>Ø±Ø·ÙˆØ¨Øª Ù¾Ø§ÛŒÛŒÙ† (ØªÙ†Ø´ Ø²ÛŒØ§Ø¯)</p>
         </div>
         '''.format(selected_index)

    if legend_html:
        m.get_root().html.add_child(folium.Element(legend_html))


    m.add_layer_control()
    st_folium(m, width=None, height=500, use_container_width=True)
    st.caption("Ù†Ù‚Ø´Ù‡ Ø´Ø§Ù…Ù„ Ù„Ø§ÛŒÙ‡ Ù…Ø§Ù‡ÙˆØ§Ø±Ù‡â€ŒØ§ÛŒ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯) Ùˆ Ù…Ø±Ø² Ù…Ø²Ø§Ø±Ø¹ Ø§Ø³Øª. Ø±ÙˆÛŒ Ù…Ø§Ø±Ú©Ø±Ù‡Ø§/Ù…Ø²Ø§Ø±Ø¹ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯.")
    st.info("ğŸ’¡ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‚Ø´Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§Ø¨Ø²Ø§Ø± Ø¹Ú©Ø³ Ú¯Ø±ÙØªÙ† Ø§Ø² ØµÙØ­Ù‡ (Screenshot) Ù…Ø±ÙˆØ±Ú¯Ø± ÛŒØ§ Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„ Ø®ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")


    # --- Time Series Chart ---
    st.markdown("---")
    st.subheader(f"ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø´Ø§Ø®Øµ {selected_index}")

    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif selected_farm_details is not None:
        # Use the CENTROID for the time series plot
        farm_centroid_shapely = selected_farm_details.get('centroid')
        if farm_centroid_shapely and isinstance(farm_centroid_shapely, Point):
            farm_centroid_ee = shapely_to_ee_geometry(farm_centroid_shapely)

            if farm_centroid_ee:
                # Define a longer period for the time series chart (e.g., last 6 months)
                timeseries_end_date = today.strftime('%Y-%m-%d')
                timeseries_start_date = (today - datetime.timedelta(days=180)).strftime('%Y-%m-%d')

                ts_df, ts_error = get_index_time_series(
                    farm_centroid_ee,
                    selected_index,
                    start_date=timeseries_start_date,
                    end_date=timeseries_end_date
                )

                if ts_error:
                    st.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ: {ts_error}")
                elif not ts_df.empty:
                    fig_ts = px.line(ts_df, x=ts_df.index, y=selected_index,
                                    title=f'Ø±ÙˆÙ†Ø¯ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ {selected_farm_name} (6 Ù…Ø§Ù‡ Ø§Ø®ÛŒØ±)',
                                    markers=True, labels={'index':'ØªØ§Ø±ÛŒØ®'})
                    fig_ts.update_layout(xaxis_title='ØªØ§Ø±ÛŒØ®', yaxis_title=selected_index)
                    st.plotly_chart(fig_ts, use_container_width=True)
                    # st.line_chart(ts_df[selected_index]) # Simpler chart
                else:
                    st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ {selected_index} Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            else:
                st.error("Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ù‡ ÙØ±Ù…Øª GEE Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ.")
        else:
            st.warning("Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø¬Ù‡Øª Ù†Ù…Ø§ÛŒØ´ Ø³Ø±ÛŒ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    else:
         # Handle case where selected_farm_details might be None after an error
         st.warning("Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø²Ø±Ø¹Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")


    # ==============================================================================
    # Helper Function for Status Determination (No change needed)
    # ==============================================================================
    def determine_status(row, index_name):
        """Determines the status based on change in index value."""
        change_col = f'{index_name}_ØªØºÛŒÛŒØ±' # Use specific change column name
        curr_col = f'{index_name}_Ù‡ÙØªÙ‡_Ø¬Ø§Ø±ÛŒ'
        prev_col = f'{index_name}_Ù‡ÙØªÙ‡_Ù‚Ø¨Ù„'

        if pd.isna(row.get(change_col)) or pd.isna(row.get(curr_col)) or pd.isna(row.get(prev_col)):
            return "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"

        change_val = row[change_col]
        threshold = 0.05 # Threshold for significant change

        # Indices where higher is better
        if index_name in ['NDVI', 'EVI', 'LAI', 'CVI', 'NDMI', 'SAVI']:
            if change_val > threshold: return "Ø±Ø´Ø¯ Ù…Ø«Ø¨Øª / Ø¨Ù‡Ø¨ÙˆØ¯"
            elif change_val < -threshold: return "ØªÙ†Ø´ / Ú©Ø§Ù‡Ø´"
            else: return "Ø«Ø§Ø¨Øª"
        # Indices where lower is better (MSI)
        elif index_name in ['MSI']:
            if change_val < -threshold: return "Ø¨Ù‡Ø¨ÙˆØ¯" # Negative change means improvement
            elif change_val > threshold: return "ØªÙ†Ø´ / Ø¨Ø¯ØªØ± Ø´Ø¯Ù†"
            else: return "Ø«Ø§Ø¨Øª"
        else: return "Ù†Ø§Ù…Ø´Ø®Øµ" # Default case


    # ==============================================================================
    # Ranking Table
    # ==============================================================================
    st.markdown("---")
    st.subheader(f"ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} (Ø±ÙˆØ²: {selected_day})")
    st.markdown("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙˆØ³Ø· Ø´Ø§Ø®Øµ (Ø¯Ø± Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù…Ø²Ø±Ø¹Ù‡) Ø¯Ø± Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¨Ø§ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„.")

    # NOTE: This function now uses the CENTROID of each farm for calculations.
    @st.cache_data(show_spinner=f"Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ {selected_index} Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹...", persist=True)
    def calculate_weekly_indices_at_centroid(_farms_gdf, index_name, start_curr, end_curr, start_prev, end_prev):
        """Calculates the average index value AT THE CENTROID for current/previous week."""
        results = []
        errors = []
        total_farms = len(_farms_gdf)
        progress_bar = st.progress(0)
        status_placeholder = st.empty() # Placeholder for status updates

        for i, (idx, farm) in enumerate(_farms_gdf.iterrows()):
            farm_name = farm['Ù…Ø²Ø±Ø¹Ù‡']
            status_placeholder.text(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø²Ø±Ø¹Ù‡ {i+1}/{total_farms}: {farm_name}")

            centroid_shapely = farm.get('centroid')
            if not centroid_shapely or not isinstance(centroid_shapely, Point):
                errors.append(f"{farm_name}: Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù†Ø§Ù…Ø¹ØªØ¨Ø± ÛŒØ§ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯.")
                results.append({
                    'Ù…Ø²Ø±Ø¹Ù‡': farm_name, 'Ú¯Ø±ÙˆÙ‡': farm.get('Ú¯Ø±ÙˆÙ‡', 'N/A'),
                    f'{index_name}_Ù‡ÙØªÙ‡_Ø¬Ø§Ø±ÛŒ': None, f'{index_name}_Ù‡ÙØªÙ‡_Ù‚Ø¨Ù„': None,
                    f'{index_name}_ØªØºÛŒÛŒØ±': None
                })
                progress_bar.progress((i + 1) / total_farms)
                continue # Skip to next farm

            point_ee_geom = shapely_to_ee_geometry(centroid_shapely)
            if not point_ee_geom:
                errors.append(f"{farm_name}: Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ø¨Ù‡ ee.Geometry.")
                results.append({
                    'Ù…Ø²Ø±Ø¹Ù‡': farm_name, 'Ú¯Ø±ÙˆÙ‡': farm.get('Ú¯Ø±ÙˆÙ‡', 'N/A'),
                    f'{index_name}_Ù‡ÙØªÙ‡_Ø¬Ø§Ø±ÛŒ': None, f'{index_name}_Ù‡ÙØªÙ‡_Ù‚Ø¨Ù„': None,
                    f'{index_name}_ØªØºÛŒÛŒØ±': None
                })
                progress_bar.progress((i + 1) / total_farms)
                continue

            # --- Sub-function to get value for a period ---
            def get_mean_value_at_point(point_geom, start, end):
                try:
                    image, error = get_processed_image(point_geom, start, end, index_name)
                    if image:
                        mean_dict = image.reduceRegion(
                            reducer=ee.Reducer.firstNonNull(), # Use firstNonNull for point
                            geometry=point_geom,
                            scale=10
                        ).getInfo()
                        val = mean_dict.get(index_name) if mean_dict else None
                        if val is None and not error: # Check if reduceRegion failed silently
                             error = f"Ù…Ù‚Ø¯Ø§Ø± {index_name} Ø¯Ø± Ù†Ù‚Ø·Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯ ({start}-{end})."
                        return val, error
                    else:
                        # If get_processed_image returned None, use its error message
                        return None, error if error else f"ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ {start}-{end} ÛŒØ§ÙØª Ù†Ø´Ø¯."
                except Exception as e:
                     error_msg = f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ {farm_name} ({start}-{end}): {e}"
                     return None, error_msg
            # --- End sub-function ---


            # Calculate for current week
            current_val, err_curr = get_mean_value_at_point(point_ee_geom, start_curr, end_curr)
            if err_curr: errors.append(f"{farm_name} (Ø¬Ø§Ø±ÛŒ): {err_curr}")

            # Calculate for previous week
            previous_val, err_prev = get_mean_value_at_point(point_ee_geom, start_prev, end_prev)
            if err_prev: errors.append(f"{farm_name} (Ù‚Ø¨Ù„): {err_prev}")


            # Calculate change
            change = None
            if isinstance(current_val, (int, float)) and isinstance(previous_val, (int, float)):
                change = current_val - previous_val
            elif current_val is not None or previous_val is not None:
                 # If one value exists but not the other, change is undefined but not strictly None
                 pass # Keep change=None


            results.append({
                'Ù…Ø²Ø±Ø¹Ù‡': farm_name,
                'Ú¯Ø±ÙˆÙ‡': farm.get('Ú¯Ø±ÙˆÙ‡', 'N/A'),
                f'{index_name}_Ù‡ÙØªÙ‡_Ø¬Ø§Ø±ÛŒ': current_val,
                f'{index_name}_Ù‡ÙØªÙ‡_Ù‚Ø¨Ù„': previous_val,
                f'{index_name}_ØªØºÛŒÛŒØ±': change
            })

            progress_bar.progress((i + 1) / total_farms)
            # time.sleep(0.01) # Optional small delay

        progress_bar.empty() # Remove progress bar
        status_placeholder.empty() # Remove status text
        return pd.DataFrame(results), errors

    # Calculate and display the ranking table
    ranking_df, calculation_errors = calculate_weekly_indices_at_centroid(
        filtered_farms_gdf,
        selected_index,
        start_date_current_str,
        end_date_current_str,
        start_date_previous_str,
        end_date_previous_str
    )

    # Display any errors that occurred during calculation
    if calculation_errors:
        st.warning("âš ï¸ Ø¨Ø±Ø®ÛŒ Ø®Ø·Ø§Ù‡Ø§ Ø¯Ø± Ø­ÛŒÙ† Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ Ø±Ø® Ø¯Ø§Ø¯:")
        with st.expander("Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§Ù‡Ø§"):
            for error in calculation_errors:
                st.warning(f"- {error}")


    if not ranking_df.empty:
        # Define column names based on selected index
        curr_col = f'{selected_index}_Ù‡ÙØªÙ‡_Ø¬Ø§Ø±ÛŒ'
        prev_col = f'{selected_index}_Ù‡ÙØªÙ‡_Ù‚Ø¨Ù„'
        change_col = f'{selected_index}_ØªØºÛŒÛŒØ±'

        # Sort by the current week's index value
        ascending_sort = selected_index in ['MSI'] # Lower MSI is better (less stress)
        ranking_df_sorted = ranking_df.sort_values(
            by=curr_col,
            ascending=ascending_sort,
            na_position='last' # Put farms with no data at the bottom
        ).reset_index(drop=True)

        # Add rank number
        ranking_df_sorted.index = ranking_df_sorted.index + 1
        ranking_df_sorted.index.name = 'Ø±ØªØ¨Ù‡'

        # Apply the determine_status function
        ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'] = ranking_df_sorted.apply(
            lambda row: determine_status(row, selected_index), axis=1
        )

        # Format numbers for better readability
        cols_to_format = [curr_col, prev_col, change_col]
        for col in cols_to_format:
            if col in ranking_df_sorted.columns:
                 ranking_df_sorted[col] = ranking_df_sorted[col].apply(lambda x: f"{x:.3f}" if isinstance(x, (int, float)) else ("N/A" if pd.isna(x) else x))

        # Select and rename columns for display
        display_df = ranking_df_sorted[['Ù…Ø²Ø±Ø¹Ù‡', 'Ú¯Ø±ÙˆÙ‡', curr_col, prev_col, change_col, 'ÙˆØ¶Ø¹ÛŒØª']].copy()
        display_df.rename(columns={
             curr_col: f'{selected_index} (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ)',
             prev_col: f'{selected_index} (Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„)',
             change_col: 'ØªØºÛŒÛŒØ±',
        }, inplace=True)


        # Display the table
        st.dataframe(display_df, use_container_width=True)

        # --- Summary Stats ---
        st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ù…Ø²Ø§Ø±Ø¹")
        col1, col2, col3, col4 = st.columns(4)

        status_counts = ranking_df_sorted['ÙˆØ¶Ø¹ÛŒØª'].value_counts()
        positive_terms = [s for s in status_counts.index if "Ø¨Ù‡Ø¨ÙˆØ¯" in s]
        negative_terms = [s for s in status_counts.index if any(sub in s for sub in ["ØªÙ†Ø´", "Ú©Ø§Ù‡Ø´", "Ø¨Ø¯ØªØ±"])]
        neutral_term = "Ø«Ø§Ø¨Øª"
        nodata_term = "Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡"

        pos_count = sum(status_counts.get(term, 0) for term in positive_terms)
        neg_count = sum(status_counts.get(term, 0) for term in negative_terms)
        neutral_count = status_counts.get(neutral_term, 0)
        nodata_count = status_counts.get(nodata_term, 0)

        with col1:
            pos_label = positive_terms[0].split('/')[1].strip() if positive_terms else "Ø¨Ù‡Ø¨ÙˆØ¯" # Get the second part like 'Ø¨Ù‡Ø¨ÙˆØ¯'
            st.metric(f"ğŸŸ¢ {pos_label}", pos_count)
        with col2:
            st.metric(f"âšª {neutral_term}", neutral_count)
        with col3:
            neg_label = negative_terms[0].split('/')[0].strip() if negative_terms else "ØªÙ†Ø´" # Get the first part like 'ØªÙ†Ø´'
            st.metric(f"ğŸ”´ {neg_label}", neg_count)
        with col4:
            st.metric(f"âš«ï¸ {nodata_term}", nodata_count)


        st.info(f"""
        **ØªÙˆØ¶ÛŒØ­Ø§Øª:**
        - **ğŸŸ¢ Ø¨Ù‡Ø¨ÙˆØ¯**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ ({selected_index} {"Ø§ÙØ²Ø§ÛŒØ´" if not ascending_sort else "Ú©Ø§Ù‡Ø´"} ÛŒØ§ÙØªÙ‡).
        - **âšª Ø«Ø§Ø¨Øª**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ ØªØºÛŒÛŒØ± Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯.
        - **ğŸ”´ ØªÙ†Ø´/Ú©Ø§Ù‡Ø´**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ ÙˆØ¶Ø¹ÛŒØª Ù†Ø§Ù…Ø·Ù„ÙˆØ¨â€ŒØªØ±ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ ({selected_index} {"Ú©Ø§Ù‡Ø´" if not ascending_sort else "Ø§ÙØ²Ø§ÛŒØ´"} ÛŒØ§ÙØªÙ‡).
        - **âš«ï¸ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡**: Ù…Ø²Ø§Ø±Ø¹ÛŒ Ú©Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø± ÛŒÚ© ÛŒØ§ Ù‡Ø± Ø¯Ùˆ Ø¯ÙˆØ±Ù‡ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.
        """)

        # --- Download Button ---
        # Use the original dataframe with specific index names for download
        csv_data = ranking_df_sorted.to_csv(index=True).encode('utf-8')
        st.download_button(
            label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (CSV)",
            data=csv_data,
            file_name=f'ranking_{selected_index}_{selected_day}_{end_date_current_str}.csv',
            mime='text/csv',
        )
    elif not calculation_errors: # Only show if no data AND no errors were reported
        st.info(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ {selected_index} Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


    st.markdown("---")



# --- Tab for Analysis Data (No changes needed in logic) ---
with tab2:
    st.header("ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ù…Ø­Ø§Ø³Ø¨Ø§Øª")
    st.markdown("Ù†Ù…Ø§ÛŒØ´ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³Ø§Ø­Øª Ùˆ ØªÙˆÙ„ÛŒØ¯ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ø§Ø¯Ø§Ø±Ù‡ Ùˆ Ø³Ù†.")

    if analysis_area_df is None and analysis_prod_df is None:
         st.warning("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ (Ù…Ø³Ø§Ø­Øª/ØªÙˆÙ„ÛŒØ¯) Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
    else:
        # Get unique 'Ø§Ø¯Ø§Ø±Ù‡' values
        available_edareh = []
        if analysis_area_df is not None and 'Ø§Ø¯Ø§Ø±Ù‡' in analysis_area_df.index.names:
            available_edareh.extend(analysis_area_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique().tolist())
        if analysis_prod_df is not None and 'Ø§Ø¯Ø§Ø±Ù‡' in analysis_prod_df.index.names:
            available_edareh.extend(analysis_prod_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡').unique().tolist())
        available_edareh = sorted(list(set(available_edareh)))

        if not available_edareh:
            st.warning("Ù‡ÛŒÚ† 'Ø§Ø¯Ø§Ø±Ù‡' Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        else:
            selected_edareh = st.selectbox(
                "Ø§Ø¯Ø§Ø±Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
                options=available_edareh,
                key='analysis_edareh_select'
            )

            st.subheader(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡: {selected_edareh}")
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)")
                if analysis_area_df is not None and selected_edareh in analysis_area_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡'):
                    try:
                        df_area_selected = analysis_area_df.loc[selected_edareh].copy()
                        df_area_selected = df_area_selected.dropna(how='all', axis=1).dropna(how='all', axis=0) # Drop empty rows/cols

                        if not df_area_selected.empty:
                            # Prepare data for plots
                            varieties = df_area_selected.columns.tolist()
                            ages = df_area_selected.index.tolist()
                            z_data = df_area_selected.fillna(0).values # Fill NA with 0 for plotting

                            # 3D Surface Plot (if enough data)
                            if len(ages) > 1 and len(varieties) > 1 :
                                try:
                                    fig_3d_area = go.Figure(data=[go.Surface(z=z_data, x=ages, y=varieties, colorscale='Viridis')])
                                    fig_3d_area.update_layout(title=f'Surface Plot Ù…Ø³Ø§Ø­Øª - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                              scene=dict(xaxis_title='Ø³Ù†', yaxis_title='ÙˆØ§Ø±ÛŒØªÙ‡', zaxis_title='Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)'),
                                                              autosize=True, height=500)
                                    st.plotly_chart(fig_3d_area, use_container_width=True)
                                except Exception as e:
                                    st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot Ù…Ø³Ø§Ø­Øª: {e}")
                                    st.dataframe(df_area_selected) # Fallback table

                            # Histogram of Area per Variety
                            df_area_melt = df_area_selected.reset_index().melt(id_vars='Ø³Ù†', var_name='ÙˆØ§Ø±ÛŒØªÙ‡', value_name='Ù…Ø³Ø§Ø­Øª')
                            df_area_melt = df_area_melt.dropna(subset=['Ù…Ø³Ø§Ø­Øª'])
                            if not df_area_melt.empty:
                                fig_hist_area = px.histogram(df_area_melt, x='ÙˆØ§Ø±ÛŒØªÙ‡', y='Ù…Ø³Ø§Ø­Øª', color='Ø³Ù†',
                                                           title=f'Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù…Ø³Ø§Ø­Øª Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ø±ÛŒØªÙ‡ - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                           labels={'Ù…Ø³Ø§Ø­Øª':'Ù…Ø¬Ù…ÙˆØ¹ Ù…Ø³Ø§Ø­Øª (Ù‡Ú©ØªØ§Ø±)', 'ÙˆØ§Ø±ÛŒØªÙ‡':'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†':'Ø³Ù†'})
                                st.plotly_chart(fig_hist_area, use_container_width=True)
                            elif not (len(ages) > 1 and len(varieties) > 1): # Show table if only histogram fails
                                 st.info("Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ù…Ø³Ø§Ø­Øª ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
                                 st.dataframe(df_area_selected)


                        else:
                             st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

                    except KeyError:
                         st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ ÙØ±Ù…Øª Ø¢Ù† Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
                    except Exception as e:
                         st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}: {e}")

                else:
                    st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø³Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} Ø¯Ø± ÙØ§ÛŒÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

            with col2:
                st.markdown("#### ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)")
                if analysis_prod_df is not None and selected_edareh in analysis_prod_df.index.get_level_values('Ø§Ø¯Ø§Ø±Ù‡'):
                    try:
                        df_prod_selected = analysis_prod_df.loc[selected_edareh].copy()
                        df_prod_selected = df_prod_selected.dropna(how='all', axis=1).dropna(how='all', axis=0)

                        if not df_prod_selected.empty:
                            # Prepare data
                            varieties_prod = df_prod_selected.columns.tolist()
                            ages_prod = df_prod_selected.index.tolist()
                            z_data_prod = df_prod_selected.fillna(0).values

                            # 3D Surface Plot
                            if len(ages_prod) > 1 and len(varieties_prod) > 1:
                                try:
                                    fig_3d_prod = go.Figure(data=[go.Surface(z=z_data_prod, x=ages_prod, y=varieties_prod, colorscale='Plasma')])
                                    fig_3d_prod.update_layout(title=f'Surface Plot ØªÙˆÙ„ÛŒØ¯ - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                              scene=dict(xaxis_title='Ø³Ù†', yaxis_title='ÙˆØ§Ø±ÛŒØªÙ‡', zaxis_title='ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)'),
                                                              autosize=True, height=500)
                                    st.plotly_chart(fig_3d_prod, use_container_width=True)
                                except Exception as e:
                                    st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Surface Plot ØªÙˆÙ„ÛŒØ¯: {e}")
                                    st.dataframe(df_prod_selected) # Fallback

                            # Histogram of Production
                            df_prod_melt = df_prod_selected.reset_index().melt(id_vars='Ø³Ù†', var_name='ÙˆØ§Ø±ÛŒØªÙ‡', value_name='ØªÙˆÙ„ÛŒØ¯')
                            df_prod_melt = df_prod_melt.dropna(subset=['ØªÙˆÙ„ÛŒØ¯'])
                            if not df_prod_melt.empty:
                                fig_hist_prod = px.histogram(df_prod_melt, x='ÙˆØ§Ø±ÛŒØªÙ‡', y='ØªÙˆÙ„ÛŒØ¯', color='Ø³Ù†',
                                                           title=f'Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆÙ„ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ø±ÛŒØªÙ‡ - Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}',
                                                           labels={'ØªÙˆÙ„ÛŒØ¯':'Ù…Ø¬Ù…ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ (ØªÙ†)', 'ÙˆØ§Ø±ÛŒØªÙ‡':'ÙˆØ§Ø±ÛŒØªÙ‡', 'Ø³Ù†':'Ø³Ù†'})
                                st.plotly_chart(fig_hist_prod, use_container_width=True)
                            elif not (len(ages_prod) > 1 and len(varieties_prod) > 1):
                                 st.info("Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆÙ„ÛŒØ¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
                                 st.dataframe(df_prod_selected)

                        else:
                             st.info(f"Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø± ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ù…Ù‚Ø§Ø¯ÛŒØ± Ø®Ø§Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

                    except KeyError:
                        st.info(f"Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ ÙØ±Ù…Øª Ø¢Ù† Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
                    except Exception as e:
                        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh}: {e}")

                else:
                    st.info(f"Ø¯Ø§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ø§Ø±Ù‡ {selected_edareh} Ø¯Ø± ÙØ§ÛŒÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


# --- Tab for Needs Analysis (Uses Centroid) ---
with tab3:
    st.header("ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø² Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ùˆ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù…Ø²Ø±Ø¹Ù‡)")

    if selected_farm_name == "Ù‡Ù…Ù‡ Ù…Ø²Ø§Ø±Ø¹":
        st.info("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ø®Ø§Øµ Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ ØªØ§ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¢Ù† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯.")
    elif selected_farm_details is not None :
        st.subheader(f"ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡: {selected_farm_name}")

        # Get the CENTROID geometry for needs analysis
        farm_centroid_shapely = selected_farm_details.get('centroid')
        if not farm_centroid_shapely or not isinstance(farm_centroid_shapely, Point):
             st.error("Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø¬Ù‡Øª ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        else:
            farm_centroid_ee = shapely_to_ee_geometry(farm_centroid_shapely)
            if not farm_centroid_ee:
                st.error("Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ø³Ù†ØªØ±ÙˆÛŒØ¯ Ù…Ø²Ø±Ø¹Ù‡ Ø¨Ù‡ ÙØ±Ù…Øª GEE Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§.")
            else:
                # --- Thresholds ---
                st.markdown("**ØªÙ†Ø¸ÛŒÙ… Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§:**")
                ndmi_threshold = st.slider("Ø¢Ø³ØªØ§Ù†Ù‡ NDMI Ø¨Ø±Ø§ÛŒ Ù‡Ø´Ø¯Ø§Ø± Ø¢Ø¨ÛŒØ§Ø±ÛŒ:", 0.0, 0.5, 0.25, 0.01, key="ndmi_thresh",
                                         help="Ø§Ú¯Ø± NDMI Ú©Ù…ØªØ± Ø§Ø² Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø¨Ø§Ø´Ø¯ØŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ø§Ø¹Ù„Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
                ndvi_drop_threshold = st.slider("Ø¢Ø³ØªØ§Ù†Ù‡ Ø§ÙØª NDVI Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ (%):", 0.0, 20.0, 5.0, 0.5, key="ndvi_thresh",
                                            help="Ø§Ú¯Ø± NDVI Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† Ø¯Ø±ØµØ¯ Ø§ÙØª Ú©Ù†Ø¯ØŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ Ø§Ø¹Ù„Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

                # Get needs data using the centroid
                farm_needs_data = get_farm_needs_data(
                    farm_centroid_ee,
                    start_date_current_str, end_date_current_str,
                    start_date_previous_str, end_date_previous_str
                )

                if farm_needs_data.get('error'):
                    st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§: {farm_needs_data['error']}")
                elif farm_needs_data.get('NDMI_curr') is None or farm_needs_data.get('NDVI_curr') is None:
                     # This case should ideally be covered by the error check above, but double-check
                    st.warning("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ù„Ø§Ø²Ù… (NDMI/NDVI) Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø¯ÙˆØ±Ù‡ ÙØ¹Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    st.caption(f"Ø¢Ø®Ø±ÛŒÙ† Ø®Ø·Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø´Ø¯Ù‡ (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯): {farm_needs_data.get('error', 'Ù‡ÛŒÚ† Ø®Ø·Ø§ÛŒ Ù…Ø´Ø®ØµÛŒ Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡')}")
                else:
                    # Display Current Indices
                    st.markdown("**Ù…Ù‚Ø§Ø¯ÛŒØ± Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ (Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ - Ø¯Ø± Ø³Ù†ØªØ±ÙˆÛŒØ¯):**")
                    idx_cols = st.columns(4)
                    def format_metric(val):
                        return f"{val:.3f}" if isinstance(val, (int, float)) else "N/A"

                    with idx_cols[0]: st.metric("NDVI", format_metric(farm_needs_data.get('NDVI_curr')))
                    with idx_cols[1]: st.metric("NDMI", format_metric(farm_needs_data.get('NDMI_curr')))
                    with idx_cols[2]: st.metric("EVI", format_metric(farm_needs_data.get('EVI_curr')))
                    with idx_cols[3]: st.metric("SAVI", format_metric(farm_needs_data.get('SAVI_curr')))

                    # Generate Recommendations
                    recommendations = []
                    ndmi_curr = farm_needs_data.get('NDMI_curr')
                    ndvi_curr = farm_needs_data.get('NDVI_curr')
                    ndvi_prev = farm_needs_data.get('NDVI_prev')

                    # 1. Irrigation Check
                    if isinstance(ndmi_curr, (int, float)) and ndmi_curr < ndmi_threshold:
                        recommendations.append(f"ğŸ’§ Ù†ÛŒØ§Ø² Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¨Ù‡ Ø¢Ø¨ÛŒØ§Ø±ÛŒ (NDMI: {ndmi_curr:.3f} < {ndmi_threshold:.3f})")
                    elif ndmi_curr is None:
                        recommendations.append("âš ï¸ ÙˆØ¶Ø¹ÛŒØª Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ (NDMI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª)")


                    # 2. Fertilization Check (NDVI drop)
                    if isinstance(ndvi_curr, (int, float)) and isinstance(ndvi_prev, (int, float)) and ndvi_prev > 0: # Avoid division by zero
                        if ndvi_curr < ndvi_prev:
                            ndvi_change_percent = ((ndvi_prev - ndvi_curr) / ndvi_prev) * 100
                            if ndvi_change_percent > ndvi_drop_threshold:
                                recommendations.append(f"âš ï¸ Ù†ÛŒØ§Ø² Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ú©ÙˆØ¯Ø¯Ù‡ÛŒ (Ø§ÙØª {ndvi_change_percent:.1f}% Ø¯Ø± NDVI)")
                    elif ndvi_curr is not None and ndvi_prev is None:
                         st.caption("Ø¯Ø§Ø¯Ù‡ NDVI Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙØª Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
                    elif ndvi_curr is None:
                         recommendations.append("âš ï¸ ÙˆØ¶Ø¹ÛŒØª Ú©ÙˆØ¯Ø¯Ù‡ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ (NDVI ÙØ¹Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª)")


                    # 3. Overall Health (based on current NDVI/EVI) - Example thresholds
                    if isinstance(ndvi_curr, (int, float)):
                         if ndvi_curr < 0.4: recommendations.append("ğŸ“‰ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¶Ø¹ÛŒÙ (NDVI Ù¾Ø§ÛŒÛŒÙ†)")
                         # Add EVI check if available
                         evi_curr = farm_needs_data.get('EVI_curr')
                         if isinstance(evi_curr, (int, float)) and evi_curr < 0.3:
                              recommendations.append("ğŸ“‰ Ù¾ÙˆØ´Ø´ Ú¯ÛŒØ§Ù‡ÛŒ Ø¶Ø¹ÛŒÙ (EVI Ù¾Ø§ÛŒÛŒÙ†)")


                    # 4. Default if no specific issues flagged
                    if not recommendations and ndvi_curr is not None and ndmi_curr is not None:
                         recommendations.append("âœ… ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù…Ø·Ù„ÙˆØ¨ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯.")
                    elif not recommendations:
                         recommendations.append("â„¹ï¸ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù†Ø¨ÙˆØ¯ Ø¨Ø±Ø®ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª.")


                    # Display Recommendations
                    st.markdown("**ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡:**")
                    rec_container = st.container()
                    has_warning = False
                    has_error = False
                    if not recommendations:
                         rec_container.info("Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡ Ù…Ø´Ø®ØµÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ù†Ø´Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ú©Ø§ÙÛŒ).")
                    else:
                        for rec in recommendations:
                            if "Ø¢Ø¨ÛŒØ§Ø±ÛŒ" in rec or "ØªÙ†Ø´" in rec or "Ø¶Ø¹ÛŒÙ" in rec or "Ø§ÙØª" in rec :
                                rec_container.error(rec)
                                has_error = True
                            elif "Ù†Ø§Ù…Ø´Ø®Øµ" in rec or "Ø¨Ø±Ø±Ø³ÛŒ" in rec:
                                rec_container.warning(rec)
                                has_warning = True
                            else:
                                rec_container.success(rec)

                    # --- Get and Display AI Analysis ---
                    if gemini_model:
                        st.markdown("**ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:**")
                        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ..."):
                            ai_explanation = get_ai_analysis(gemini_model, selected_farm_name, farm_needs_data, recommendations)
                        st.markdown(ai_explanation)
                    else:
                        st.info("Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡ ÛŒØ§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")

    else:
        # Handle case where selected_farm_details is None
        st.info("Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© Ù…Ø²Ø±Ø¹Ù‡ Ù…Ø¹ØªØ¨Ø± Ø±Ø§ Ø§Ø² Ù¾Ù†Ù„ Ú©Ù†Ø§Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")


# --- Footer ---
st.markdown("---")
st.sidebar.markdown("---")
st.sidebar.markdown("Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Streamlit, Google Earth Engine, GeoPandas, Ùˆ geemap")