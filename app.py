import streamlit as st
import pandas as pd
import ee
import geemap.foliumap as geemap
import folium
import json
import datetime
import plotly.express as px
import plotly.graph_objects as go
import os
from io import BytesIO
import requests
import traceback
from streamlit_folium import st_folium
import base64
import google.generativeai as genai
from shapely.geometry import Polygon
import pyproj
import numpy as np # Import numpy for np.nan

# Define the source CRS (likely UTM Zone 39N for Khuzestan)
# Assuming WGS 84 / UTM zone 39N based on typical data format and region
SOURCE_CRS = "EPSG:32639"
TARGET_CRS = "EPSG:4326" # WGS 84 geographic 2D

transformer = None
try:
    transformer = pyproj.Transformer.from_crs(SOURCE_CRS, TARGET_CRS, always_xy=True)
    print(f"Coordinate transformer created: {SOURCE_CRS} to {TARGET_CRS}")
except pyproj.exceptions.CRSError as e:
    st.error(f"‚ùå ÿÆÿ∑ÿß€å Ÿæ€å⁄©ÿ±ÿ®ŸÜÿØ€å ÿ≥€åÿ≥ÿ™ŸÖ ŸÖÿÆÿ™ÿµÿßÿ™: {e}. ŸÑÿ∑ŸÅÿßŸã ⁄©ÿØŸáÿß€å EPSG {SOURCE_CRS} Ÿà {TARGET_CRS} ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ.")
except Exception as e:
     st.error(f"‚ùå ÿÆÿ∑ÿß€å ŸÜÿßÿ¥ŸÜÿßÿÆÿ™Ÿá ÿØÿ± ÿß€åÿ¨ÿßÿØ ÿ™ÿ®ÿØ€åŸÑ ⁄©ŸÜŸÜÿØŸá ŸÖÿÆÿ™ÿµÿßÿ™: {e}")


# --- HARDCODED GEMINI API KEY (SECURITY RISK - NOT RECOMMENDED) ---
# As requested, the API key is hardcoded here.
# !!! WARNING: This is a security vulnerability. Anyone with access to this code
# !!! can use your API key and potentially incur costs on your account.
# !!! It is strongly recommended to use Streamlit Secrets for API keys.
# !!! https://docs.streamlit.io/develop/concepts/secrets
GEMINI_API_KEY_HARDCODED = "AIzaSyC6ntMs3XDa3JTk07-6_BRRCduiQaRmQFQ"
# --- END OF HARDCODED API KEY ---


# --- Custom CSS for an Amazing and User-Friendly UI ---
st.set_page_config(
    page_title="ÿ≥ÿßŸÖÿßŸÜŸá Ÿæÿß€åÿ¥ ŸáŸàÿ¥ŸÖŸÜÿØ ŸÜ€åÿ¥⁄©ÿ±",
    page_icon="üåæ",
    layout="wide",
    initial_sidebar_state="expanded" # Keep sidebar expanded by default
)

st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700;900&display=swap');
        @import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css');
        @import url('https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css');

        html, body, .main, .stApp {
            font-family: 'Vazirmatn', sans-serif !important;
            background: linear-gradient(135deg, #e0f7fa 0%, #f8fafc 100%);
            color: #333;
        }

        /* Header styling with animations */
        header {
            position: sticky;
            top: 0;
            z-index: 999;
            animation: fadeIn 0.8s ease-in-out;
            backdrop-filter: blur(8px);
            -webkit-backdrop-filter: blur(8px);
            background: rgba(255, 255, 255, 0.8);
            border-bottom: 1px solid rgba(0, 0, 0, 0.1);
            padding: 0.5rem 0;
            transition: all 0.3s ease;
        }
        
        header:hover {
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
        }

        /* Dark Mode Enhancements */
        @media (prefers-color-scheme: dark) {
            html, body, .main, .stApp {
                background: linear-gradient(135deg, #1a1f36 0%, #2d3748 100%);
                color: #f8f8f8;
            }
            header {
                background: rgba(30, 41, 59, 0.8);
                border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            }
            .stTabs [data-baseweb="tab-list"] button [data-baseweb="tab"] {
                color: #bbb !important;
            }
            .stTabs [data-baseweb="tab-list"] button:hover {
                color: #f8f8f8 !important;
            }
            .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
                color: #43cea2 !important;
                border-bottom-color: #43cea2 !important;
            }
            .modern-card {
                background: linear-gradient(135deg, #1a435a 0%, #2a2a2a 100%);
                color: #f8f8f8;
                box-shadow: 0 4px 16px rgba(0,0,0,0.3);
            }
            .status-positive { background-color: #218838; }
            .status-negative { background-color: #c82333; }
            .status-neutral { background-color: #5a6268; color: #fff; }
            .status-nodata { background-color: #d39e00; color: #f8f8f8;}
        }

        h1, h2, h3, h4, h5, h6 {
            color: #185a9d;
            font-weight: 700;
        }
        .stMarkdown h1 {
            color: #185a9d !important;
            animation: fadeInDown 0.5s ease-in-out;
        }

        /* Modern animated cards */
        .modern-card {
            background: linear-gradient(135deg, #43cea2 0%, #185a9d 100%);
            color: white;
            border-radius: 18px;
            padding: 20px;
            margin: 15px 0;
            box-shadow: 0 6px 20px rgba(30,60,114,0.1);
            text-align: center;
            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
            overflow: hidden;
            position: relative;
            animation: fadeIn 0.6s ease-in-out;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .modern-card:hover {
            transform: translateY(-8px) scale(1.02);
            box-shadow: 0 15px 30px rgba(30,60,114,0.2);
        }
        .modern-card::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: linear-gradient(45deg, transparent, rgba(255,255,255,0.1), transparent);
            transform: rotate(45deg);
            transition: all 1s ease;
            opacity: 0;
        }
        .modern-card:hover::before {
            opacity: 1;
            animation: shine 1.5s ease-in-out;
        }
        .modern-card div:first-child {
            font-size: 1em;
            opacity: 0.9;
            margin-bottom: 8px;
        }
        .modern-card div:last-child {
            font-size: 2em;
            font-weight: 900;
        }

        /* Sidebar enhancements */
        .sidebar-logo {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 2rem;
            padding-top: 1rem;
            animation: pulse 2s infinite;
        }
        .sidebar-logo img {
            width: 100px;
            height: 100px;
            border-radius: 20px;
            box-shadow: 0 4px 12px rgba(30,60,114,0.15);
            transition: all 0.3s ease;
        }
        .sidebar-logo img:hover {
            transform: rotate(5deg) scale(1.05);
        }
        
        [data-testid="stSidebar"] {
            background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
            border-right: 1px solid rgba(0,0,0,0.1);
            box-shadow: 5px 0 10px rgba(0,0,0,0.05);
        }
        
        @media (prefers-color-scheme: dark) {
            [data-testid="stSidebar"] {
                background: linear-gradient(180deg, #1e2937 0%, #111827 100%);
                border-right: 1px solid rgba(255,255,255,0.1);
            }
        }

        /* Main logo animation */
        .main-logo {
            width: 55px;
            height: 55px;
            border-radius: 15px;
            margin-left: 15px;
            vertical-align: middle;
            box-shadow: 0 2px 8px rgba(30,60,114,0.1);
            transition: all 0.3s ease;
            animation: bounceIn 1s;
        }
        .main-logo:hover {
            transform: rotate(10deg) scale(1.1);
        }

        /* Tab styling enhancements */
        .stTabs [data-baseweb="tab-list"] {
            gap: 20px;
            border-bottom: 1px solid rgba(0,0,0,0.1);
            padding-bottom: 0;
            margin-bottom: 20px;
        }
        .stTabs [data-baseweb="tab-list"] button {
            background-color: transparent;
            padding: 12px 20px;
            border-radius: 8px 8px 0 0;
            border-bottom: 3px solid transparent;
            transition: all 0.3s ease;
            font-weight: 700;
            color: #555;
            position: relative;
            overflow: hidden;
        }
        .stTabs [data-baseweb="tab-list"] button:hover {
            background-color: rgba(67, 206, 162, 0.1);
            color: #185a9d;
            border-bottom-color: rgba(67, 206, 162, 0.5);
        }
        .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
            background-color: rgba(67, 206, 162, 0.15);
            border-bottom-color: #43cea2;
            color: #185a9d;
            box-shadow: 0 -2px 8px rgba(30,60,114,0.05);
        }
        .stTabs [data-baseweb="tab-list"] button[aria-selected="true"]::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 100%;
            height: 3px;
            background: linear-gradient(90deg, #43cea2, #185a9d);
            animation: slideInRight 0.3s ease-out;
        }
        .stTabs [data-baseweb="tab-panel"] {
            padding: 25px 5px;
            animation: fadeIn 0.5s ease-in-out;
        }

        /* Status badges enhancements */
        .status-badge {
            display: inline-block;
            padding: 0.4em 0.8em;
            font-size: 0.85em;
            font-weight: bold;
            line-height: 1.2;
            text-align: center;
            white-space: nowrap;
            vertical-align: middle;
            border-radius: 0.5rem;
            color: #fff;
            margin: 3px;
            transition: all 0.3s ease;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            animation: fadeIn 0.5s ease-in-out;
        }
        .status-badge:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.15);
        }
        .status-positive { 
            background: linear-gradient(90deg, #28a745, #1e7e34);
        }
        .status-negative { 
            background: linear-gradient(90deg, #dc3545, #bd2130);
        }
        .status-neutral { 
            background: linear-gradient(90deg, #6c757d, #5a6268);
            color: #fff;
        }
        .status-nodata { 
            background: linear-gradient(90deg, #ffc107, #d39e00);
            color: #212529;
        }

        /* Table enhancements */
        table {
            border-collapse: separate;
            border-spacing: 0;
            width: 100%;
            margin: 20px 0;
            box-shadow: 0 4px 15px rgba(0,0,0,0.05);
            border-radius: 10px;
            overflow: hidden;
            animation: fadeIn 0.5s ease-in-out;
        }
        
        table thead tr {
            background: linear-gradient(90deg, #43cea2, #185a9d);
            color: white;
        }
        
        table th {
            padding: 12px 15px;
            text-align: right;
            font-weight: bold;
        }
        
        table td {
            padding: 10px 15px;
            border-bottom: 1px solid rgba(0,0,0,0.05);
        }
        
        table tbody tr {
            transition: all 0.3s ease;
        }
        
        table tbody tr:hover {
            background-color: rgba(67, 206, 162, 0.05);
            transform: scale(1.005);
        }
        
        table tbody tr:last-child td {
            border-bottom: none;
        }
        
        /* Button enhancements */
        .stButton > button {
            border-radius: 8px;
            padding: 0.5rem 1rem;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(50, 50, 93, 0.11), 0 1px 3px rgba(0, 0, 0, 0.08);
            border: none;
            background: linear-gradient(135deg, #43cea2 0%, #185a9d 100%);
            color: white;
            position: relative;
            overflow: hidden;
        }
        
        .stButton > button:hover {
            transform: translateY(-2px);
            box-shadow: 0 7px 14px rgba(50, 50, 93, 0.1), 0 3px 6px rgba(0, 0, 0, 0.08);
        }
        
        .stButton > button:active {
            transform: translateY(1px);
        }
        
        .stButton > button::after {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 5px;
            height: 5px;
            background: rgba(255, 255, 255, 0.5);
            opacity: 0;
            border-radius: 100%;
            transform: scale(1, 1) translate(-50%, -50%);
            transform-origin: 50% 50%;
        }
        
        .stButton > button:hover::after {
            animation: ripple 1s ease-out;
            opacity: 0;
        }
        
        /* Select box enhancements */
        .stSelectbox {
            border-radius: 8px;
            overflow: hidden;
        }
        
        .stSelectbox > div > div[data-baseweb="select"] {
            transition: all 0.3s ease;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }
        
        .stSelectbox > div > div[data-baseweb="select"]:hover {
            box-shadow: 0 4px 10px rgba(0,0,0,0.1);
            transform: translateY(-1px);
        }
        
        /* Animation keyframes */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        
        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        @keyframes slideInRight {
            from { 
                width: 0;
            }
            to {
                width: 100%;
            }
        }
        
        @keyframes bounceIn {
            0% {
                opacity: 0;
                transform: scale(0.3);
            }
            50% {
                opacity: 1;
                transform: scale(1.05);
            }
            70% { transform: scale(0.9); }
            100% { transform: scale(1); }
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        @keyframes ripple {
            0% {
                transform: scale(0, 0);
                opacity: 0.5;
            }
            100% {
                transform: scale(100, 100);
                opacity: 0;
            }
        }
        
        @keyframes shine {
            0% {
                left: -100%;
                opacity: 0;
            }
            100% {
                left: 100%;
                opacity: 0.3;
            }
        }
    </style>
""", unsafe_allow_html=True)


def status_badge(status: str) -> str:
    """Returns HTML for a status badge with color."""
    if "ÿ®Ÿáÿ®ŸàÿØ" in status or "ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™" in status or "ÿßŸÅÿ≤ÿß€åÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™" in status: # Added NDMI positive
        badge_class = "status-positive"
    elif "ÿ™ŸÜÿ¥" in status or "⁄©ÿßŸáÿ¥" in status or "ÿ®ÿØÿ™ÿ± ÿ¥ÿØŸÜ" in status or "ŸÜ€åÿßÿ≤" in status: # Added NDMI negative
        badge_class = "status-negative"
    elif "ÿ´ÿßÿ®ÿ™" in status or "ÿ±ÿ∑Ÿàÿ®ÿ™ ÿ´ÿßÿ®ÿ™" in status or "ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿæÿß€å€åŸÜ" in status or "ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá" in status: # Added NDMI neutral/warning
        badge_class = "status-neutral"
    elif "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá" in status or "N/A" in status:
         badge_class = "status-nodata"
    else:
        badge_class = "status-neutral"

    return f'<span class="status-badge {badge_class}">{status}</span>'

def modern_metric_card(title: str, value: str, icon: str, color: str) -> str:
    """
    Returns a modern styled HTML card for displaying a metric.
    :param title: Title of the metric
    :param value: Value of the metric
    :param icon: FontAwesome icon class (e.g., 'fa-leaf')
    :param color: Accent color for the card background gradient
    :return: HTML string
    """
    return f'''
    <div class="modern-card" style="background: linear-gradient(135deg, {color} 0%, #185a9d 100%);">
        <div>{title} <i class="fa {icon}"></i></div>
        <div>{value}</div>
    </div>
    '''

def modern_progress_bar(progress: float) -> str:
    """
    Returns a modern styled HTML progress bar for Streamlit.
    :param progress: float between 0 and 1
    :return: HTML string
    """
    percent = max(0, min(100, int(progress * 100)))
    color_start = '#dc3545'
    color_mid = '#ffc107'
    color_end = '#28a745'

    if percent <= 50:
        r = int(0xdc + (0xff - 0xdc) * (percent / 50))
        g = int(0x35 + (0xc1 - 0x35) * (percent / 50))
        b = int(0x45 + (0x07 - 0x45) * (percent / 50))
        current_color = f"#{r:02x}{g:02x}{b:02x}"
        background_gradient = f"linear-gradient(90deg, {color_start} 0%, {current_color} 100%)"
    else:
        r = int(0xff + (0x28 - 0xff) * ((percent - 50) / 50))
        g = int(0xc1 + (0xa7 - 0xc1) * ((percent - 50) / 50))
        b = int(0x07 + (0x45 - 0x07) * ((percent - 50) / 50))
        current_color = f"#{r:02x}{g:02x}{b:02x}"
        background_gradient = f"linear-gradient(90deg, {color_mid} 0%, {current_color} 100%)"

    if percent == 100:
        background_gradient = f"linear-gradient(90deg, {color_end} 0%, #1a9850 100%)"


    return f'''
    <div style="width: 100%; background: #e0f7fa; border-radius: 12px; height: 22px; margin: 8px 0; box-shadow: 0 2px 8px rgba(30,60,114,0.08); overflow: hidden; position: relative;">
      <div style="width: {percent}%; background: {background_gradient}; height: 100%; border-radius: 12px; transition: width 0.3s ease-in-out;"></div>
      <span style="position: absolute; left: 50%; top: 0; transform: translateX(-50%); color: #185a9d; font-weight: bold; line-height: 22px; text-shadow: 0 0 2px rgba(255,255,255,0.5); /* Add subtle text shadow for readability */">
          {percent}%
      </span>
    </div>
    '''

st.sidebar.markdown(
    """
    <div class='sidebar-logo'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' alt='ŸÑŸà⁄ØŸà ÿ≥ÿßŸÖÿßŸÜŸá' />
    </div>
    """,
    unsafe_allow_html=True
)

st.markdown(
    """
    <div style='display: flex; align-items: center; gap: 16px; margin-bottom: 0.5rem;'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' class='main-logo' alt='ŸÑŸà⁄ØŸà' />
        <h1 style='font-family: Vazirmatn, sans-serif; color: #185a9d; margin: 0;'>ÿ≥ÿßŸÖÿßŸÜŸá Ÿæÿß€åÿ¥ ŸáŸàÿ¥ŸÖŸÜÿØ ŸÜ€åÿ¥⁄©ÿ±</h1>
    </div>
    <h4 style='color: #43cea2; margin-top: 0;'>ŸÖÿ∑ÿßŸÑÿπÿßÿ™ ⁄©ÿßÿ±ÿ®ÿ±ÿØ€å ÿ¥ÿ±⁄©ÿ™ ⁄©ÿ¥ÿ™ Ÿà ÿµŸÜÿπÿ™ ÿØŸáÿÆÿØÿß</h4>
    """,
    unsafe_allow_html=True
)

APP_TITLE = "ÿ≥ÿßŸÖÿßŸÜŸá Ÿæÿß€åÿ¥ ŸáŸàÿ¥ŸÖŸÜÿØ ŸÜ€åÿ¥⁄©ÿ±"
APP_SUBTITLE = "ŸÖÿ∑ÿßŸÑÿπÿßÿ™ ⁄©ÿßÿ±ÿ®ÿ±ÿØ€å ÿ¥ÿ±⁄©ÿ™ ⁄©ÿ¥ÿ™ Ÿà ÿµŸÜÿπÿ™ ÿØŸáÿÆÿØÿß"
INITIAL_LAT = 31.534442
INITIAL_LON = 48.724416
INITIAL_ZOOM = 12

FARM_DATA_CSV_PATH = 'merged_farm_data_renamed (1).csv'
SERVICE_ACCOUNT_FILE = 'ee-esmaeilkiani13877-cfdea6eaf411 (4).json'
ANALYSIS_CSV_PATH = 'ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ 2.csv'


@st.cache_resource(show_spinner="ÿØÿ± ÿ≠ÿßŸÑ ÿßÿ™ÿµÿßŸÑ ÿ®Ÿá Google Earth Engine...")
def initialize_gee():
    """Initializes Google Earth Engine using the Service Account."""
    try:
        if os.path.exists(SERVICE_ACCOUNT_FILE):
            credentials = ee.ServiceAccountCredentials(None, key_file=SERVICE_ACCOUNT_FILE)
            print("GEE Initialized Successfully using Service Account File.")
        else:
            try:
                if "gee_auth_json" in st.secrets:
                    auth_info = json.loads(st.secrets["gee_auth_json"])
                    credentials = ee.ServiceAccountCredentials(auth_info['client_email'], None, private_key_id=auth_info['private_key_id'], private_key=auth_info['private_key'], token_uri=auth_info['token_uri'])
                    print("GEE Initialized Successfully using Streamlit Secrets JSON.")
                else:
                     raise ValueError("GEE credentials not found in secrets ('gee_auth_json').")

            except Exception as e:
                 st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿßÿ∑ŸÑÿßÿπÿßÿ™ Service Account ÿßÿ≤ Secrets: {e}")
                 st.info("ŸÑÿ∑ŸÅÿßŸã ÿßÿ≤ ÿ™ŸÜÿ∏€åŸÖ ÿµÿ≠€åÿ≠ Secrets ÿ®ÿ±ÿß€å Google Earth Engine ÿßÿ∑ŸÖ€åŸÜÿßŸÜ ÿ≠ÿßÿµŸÑ ⁄©ŸÜ€åÿØ. (ÿ®Ÿá ÿÆÿµŸàÿµ secret 'gee_auth_json').")
                 return None

        ee.Initialize(credentials=credentials, opt_url='https://earthengine-highvolume.googleapis.com')
        print("GEE Initialized Successfully.")
        return True
    except ee.EEException as e:
        st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿßÿ™ÿµÿßŸÑ ÿ®Ÿá Google Earth Engine: {e}")
        st.error("ŸÑÿ∑ŸÅÿßŸã ÿßÿ≤ ÿµÿ≠ÿ™ ŸÅÿß€åŸÑ Service Account €åÿß ÿ™ŸÜÿ∏€åŸÖÿßÿ™ Secrets Ÿà ŸÅÿπÿßŸÑ ÿ®ŸàÿØŸÜ ÿ¢ŸÜ ÿØÿ± Ÿæÿ±Ÿà⁄òŸá GEE ÿßÿ∑ŸÖ€åŸÜÿßŸÜ ÿ≠ÿßÿµŸÑ ⁄©ŸÜ€åÿØ.")
        return None
    except Exception as e:
        st.error(f"‚ùå ÿÆÿ∑ÿß€å ÿ∫€åÿ±ŸÖŸÜÿ™ÿ∏ÿ±Ÿá ŸáŸÜ⁄ØÿßŸÖ ÿßÿ™ÿµÿßŸÑ ÿ®Ÿá GEE: {e}")
        st.error(traceback.format_exc())
        return None


@st.cache_data(show_spinner="ÿØÿ± ÿ≠ÿßŸÑ ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å Ÿà Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ...", persist="disk") # Corrected persist option
def load_farm_data_from_csv(csv_path=FARM_DATA_CSV_PATH):
    """Loads farm data from the specified CSV file and processes coordinates."""
    if transformer is None:
         st.error("‚ùå ÿ™ÿ®ÿØ€åŸÑ ⁄©ŸÜŸÜÿØŸá ŸÖÿÆÿ™ÿµÿßÿ™ Ÿæ€å⁄©ÿ±ÿ®ŸÜÿØ€å ŸÜÿ¥ÿØŸá ÿßÿ≥ÿ™. ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜ€åÿ≥ÿ™.")
         return pd.DataFrame()

    try:
        df = None
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path, encoding='utf-8')
            print(f"Loaded Farm data from local CSV: {csv_path}")
        else:
            github_raw_url = f'https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/{csv_path}'
            try:
                response = requests.get(github_raw_url)
                response.raise_for_status()
                df = pd.read_csv(BytesIO(response.content), encoding='utf-8')
                print(f"Loaded Farm data from URL: {github_raw_url}")
            except requests.exceptions.RequestException as e:
                 st.error(f"‚ùå ŸÅÿß€åŸÑ '{csv_path}' ÿØÿ± ŸÖÿ≥€åÿ± ŸÖÿ≠ŸÑ€å €åÿß ÿßÿ≤ URL ⁄Ø€åÿ™‚ÄåŸáÿßÿ® '{github_raw_url}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ €åÿß ŸÇÿßÿ®ŸÑ ÿØÿ≥ÿ™ÿ±ÿ≥€å ŸÜ€åÿ≥ÿ™: {e}")
                 return pd.DataFrame()
            except Exception as e:
                 st.error(f"‚ùå ÿÆÿ∑ÿß€å ÿ∫€åÿ±ŸÖŸÜÿ™ÿ∏ÿ±Ÿá ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ŸÅÿß€åŸÑ CSV ÿßÿ≤ URL: {e}")
                 return pd.DataFrame()


        if df is None or df.empty:
             st.error("‚ùå ŸÅÿß€åŸÑ ÿØÿßÿØŸá ŸÖÿ≤ÿßÿ±ÿπ ÿÆÿßŸÑ€å ÿßÿ≥ÿ™ €åÿß ÿÆŸàÿßŸÜÿØŸá ŸÜÿ¥ÿØ.")
             return pd.DataFrame()


        df.columns = df.columns.str.strip().str.replace('\ufeff', '')

        required_cols = ['ŸÖÿ≤ÿ±ÿπŸá', 'ÿ±Ÿàÿ≤', 'lat1', 'lon1', 'lat2', 'lon2', 'lat3', 'lon3', 'lat4', 'lon4']
        if not all(col in df.columns for col in required_cols):
            missing_cols = [col for col in required_cols if col not in df.columns]
            st.error(f"‚ùå ŸÅÿß€åŸÑ CSV ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿß€åÿØ ÿ¥ÿßŸÖŸÑ ÿ≥ÿ™ŸàŸÜ‚ÄåŸáÿß€å ÿ∂ÿ±Ÿàÿ±€å ÿ®ÿßÿ¥ÿØ. ÿ≥ÿ™ŸàŸÜ‚ÄåŸáÿß€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ: {', '.join(missing_cols)}")
            return pd.DataFrame()

        df['wgs84_centroid_lon'] = None
        df['wgs84_centroid_lat'] = None
        df['ee_geometry'] = None
        df['wgs84_polygon_coords'] = None

        processed_records = []
        skipped_farms = []

        for index, row in df.iterrows():
            farm_name = row.get('ŸÖÿ≤ÿ±ÿπŸá', f'ŸÖÿ≤ÿ±ÿπŸá ŸÜÿßÿ¥ŸÜÿßÿ≥ ÿ±ÿØ€åŸÅ {index+1}')
            try:
                points_utm = []
                valid_points = True
                for i in range(1, 5):
                    lat_col = f'lat{i}'
                    lon_col = f'lon{i}'
                    if pd.notna(row.get(lat_col)) and pd.notna(row.get(lon_col)):
                        try:
                            easting = float(row[lon_col])
                            northing = float(row[lat_col])
                            points_utm.append((easting, northing))
                        except ValueError:
                            valid_points = False
                            break
                    else:
                        valid_points = False
                        break


                if not valid_points or len(points_utm) < 4:
                    skipped_farms.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}': ŸÖÿÆÿ™ÿµÿßÿ™ ŸÜÿßŸÖÿπÿ™ÿ®ÿ± €åÿß ŸÜÿßŸÇÿµ (ŸÜ€åÿßÿ≤ ÿ®Ÿá €¥ ŸÜŸÇÿ∑Ÿá).")
                    continue


                points_wgs84 = []
                try:
                    for easting, northing in points_utm:
                         lon_wgs84, lat_wgs84 = transformer.transform(easting, northing)
                         points_wgs84.append((lon_wgs84, lat_wgs84))
                except pyproj.exceptions.TransformerError as te:
                     skipped_farms.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}': ÿÆÿ∑ÿß€å ÿ™ÿ®ÿØ€åŸÑ ŸÖÿÆÿ™ÿµÿßÿ™ UTM ÿ®Ÿá WGS84: {te}")
                     continue
                except Exception as e:
                     skipped_farms.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}': ÿÆÿ∑ÿß€å ŸÜÿßÿ¥ŸÜÿßÿÆÿ™Ÿá ÿØÿ± ÿ™ÿ®ÿØ€åŸÑ ŸÖÿÆÿ™ÿµÿßÿ™: {e}")
                     continue


                if points_wgs84[-1] != points_wgs84[0]:
                     polygon_coords_wgs84 = points_wgs84 + [points_wgs84[0]]
                else:
                     polygon_coords_wgs84 = points_wgs84

                try:
                    shapely_polygon = Polygon(polygon_coords_wgs84)
                    if not shapely_polygon.is_valid:
                         shapely_polygon = shapely_polygon.buffer(0)
                         if not shapely_polygon.is_valid:
                             skipped_farms.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}': ŸæŸÑ€å‚Äå⁄ØŸàŸÜ WGS84 ŸÜÿßŸÖÿπÿ™ÿ®ÿ± ÿ®ÿßŸÇ€å ŸÖÿßŸÜÿØ Ÿæÿ≥ ÿßÿ≤ buffer(0).")
                             continue

                    ee_polygon = ee.Geometry.Polygon(list(shapely_polygon.exterior.coords))

                    centroid_ee = ee_polygon.centroid(maxError=1)
                    centroid_coords_wgs84 = centroid_ee.getInfo()['coordinates']
                    centroid_lon_wgs84, centroid_lat_wgs84 = centroid_coords_wgs84[0], centroid_coords_wgs84[1]

                    processed_row = row.copy()
                    processed_row['wgs84_centroid_lon'] = centroid_lon_wgs84
                    processed_row['wgs84_centroid_lat'] = centroid_lat_wgs84
                    processed_row['ee_geometry'] = ee_polygon
                    processed_row['wgs84_polygon_coords'] = [list(coord) for coord in shapely_polygon.exterior.coords]

                    processed_records.append(processed_row)

                except ee.EEException as ee_geom_e:
                    skipped_farms.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}': ÿÆÿ∑ÿß€å ÿß€åÿ¨ÿßÿØ ŸáŸÜÿØÿ≥Ÿá GEE €åÿß ŸÖÿ≠ÿßÿ≥ÿ®Ÿá Centroid: {ee_geom_e}")
                    continue
                except Exception as e:
                    skipped_farms.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}': ÿÆÿ∑ÿß€å ŸÜÿßÿ¥ŸÜÿßÿÆÿ™Ÿá ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸáŸÜÿØÿ≥Ÿá: {e}")
                    continue


            except Exception as e:
                skipped_farms.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}': ÿÆÿ∑ÿß€å ÿπŸÖŸàŸÖ€å ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ±ÿØ€åŸÅ: {e}")
                continue

        processed_df = pd.DataFrame(processed_records)

        if skipped_farms:
            st.warning("‚ö†Ô∏è ÿ®ÿ±ÿÆ€å ÿßÿ≤ ŸÖÿ≤ÿßÿ±ÿπ ÿ®Ÿá ÿØŸÑ€åŸÑ ÿÆÿ∑ÿß€å Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸÖÿÆÿ™ÿµÿßÿ™ €åÿß ŸáŸÜÿØÿ≥Ÿá ŸÜÿßÿØ€åÿØŸá ⁄Øÿ±ŸÅÿ™Ÿá ÿ¥ÿØŸÜÿØ:")
            for msg in skipped_farms[:10]:
                 st.warning(f"- {msg}")
            if len(skipped_farms) > 10:
                 st.warning(f"... Ÿà {len(skipped_farms) - 10} ÿÆÿ∑ÿß€å ÿØ€å⁄Øÿ±.")


        if processed_df.empty:
            st.error("‚ùå Ÿá€å⁄Ü ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ±€å Ÿæÿ≥ ÿßÿ≤ Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸÅÿß€åŸÑ CSV ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿßŸÇ€å ŸÜŸÖÿßŸÜÿØ.")
            return pd.DataFrame()


        for col in ['ÿ±Ÿàÿ≤', '⁄Øÿ±ŸàŸá', 'Ÿàÿßÿ±€åÿ™Ÿá', 'ÿ≥ŸÜ']:
            if col in processed_df.columns:
                processed_df[col] = processed_df[col].astype(str).str.replace(r'\s+', ' ', regex=True).str.strip()
                processed_df[col] = processed_df[col].replace(['nan', ''], 'ŸÜÿßŸÖÿ¥ÿÆÿµ')
            else:
                 processed_df[col] = 'ŸÜÿßŸÖÿ¥ÿÆÿµ'

        if 'ŸÖÿ≥ÿßÿ≠ÿ™' in processed_df.columns:
             processed_df['ŸÖÿ≥ÿßÿ≠ÿ™'] = pd.to_numeric(processed_df['ŸÖÿ≥ÿßÿ≠ÿ™'], errors='coerce')
             processed_df['ŸÖÿ≥ÿßÿ≠ÿ™'] = processed_df['ŸÖÿ≥ÿßÿ≠ÿ™'].fillna(0)
        else:
            processed_df['ŸÖÿ≥ÿßÿ≠ÿ™'] = 0


        st.success(f"‚úÖ ÿØÿßÿØŸá‚ÄåŸáÿß€å {len(processed_df)} ŸÖÿ≤ÿ±ÿπŸá ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿßÿ≤ CSV ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å Ÿà Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ¥ÿØ.")
        return processed_df
    except FileNotFoundError:
        st.error(f"‚ùå ŸÅÿß€åŸÑ '{csv_path}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ŸÑÿ∑ŸÅÿßŸã ŸÅÿß€åŸÑ CSV ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ ÿ±ÿß ÿØÿ± ŸÖÿ≥€åÿ± ÿµÿ≠€åÿ≠ ŸÇÿ±ÿßÿ± ÿØŸá€åÿØ.")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å €åÿß Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸÅÿß€åŸÑ CSV: {e}")
        st.error(traceback.format_exc())
        return pd.DataFrame()


@st.cache_data(show_spinner="ÿØÿ± ÿ≠ÿßŸÑ ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™...", persist="disk") # Corrected persist option
def load_analysis_data(csv_path=ANALYSIS_CSV_PATH):
    """Loads and preprocesses data from the analysis CSV file."""
    try:
        lines = None
        if os.path.exists(csv_path):
            with open(csv_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            print(f"Loaded Analysis CSV from local path: {csv_path}")
        else:
             github_raw_url = f'https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/{csv_path}'
             try:
                 response = requests.get(github_raw_url)
                 response.raise_for_status()
                 lines = response.text.splitlines()
                 print(f"Loaded Analysis CSV from URL: {github_raw_url}")
             except requests.exceptions.RequestException as e:
                 st.error(f"‚ùå ŸÅÿß€åŸÑ '{csv_path}' ÿØÿ± ŸÖÿ≥€åÿ± ŸÖÿ≠ŸÑ€å €åÿß ÿßÿ≤ URL ⁄Ø€åÿ™‚ÄåŸáÿßÿ® '{github_raw_url}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ €åÿß ŸÇÿßÿ®ŸÑ ÿØÿ≥ÿ™ÿ±ÿ≥€å ŸÜ€åÿ≥ÿ™: {e}")
                 return None, None
             except Exception as e:
                 st.error(f"‚ùå ÿÆÿ∑ÿß€å ÿ∫€åÿ±ŸÖŸÜÿ™ÿ∏ÿ±Ÿá ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ŸÅÿß€åŸÑ CSV ÿßÿ≤ URL: {e}")
                 return None, None


        if lines is None:
             return None, None


        headers_indices = [i for i, line in enumerate(lines) if line.strip().lstrip('\ufeff').startswith('ÿßÿØÿßÿ±Ÿá,ÿ≥ŸÜ,') or line.strip().lstrip('\ufeff').startswith('ÿ™ŸàŸÑ€åÿØ,ÿ≥ŸÜ,')]

        if len(headers_indices) < 1:
            st.error(f"‚ùå ÿ≥ÿßÿÆÿ™ÿßÿ± ŸÅÿß€åŸÑ '{csv_path}' ŸÇÿßÿ®ŸÑ ÿ¥ŸÜÿßÿ≥ÿß€å€å ŸÜ€åÿ≥ÿ™. ŸáÿØÿ±Ÿáÿß€å ŸÖŸàÿ±ÿØ ÿßŸÜÿ™ÿ∏ÿßÿ± ('ÿßÿØÿßÿ±Ÿá,ÿ≥ŸÜ,' €åÿß 'ÿ™ŸàŸÑ€åÿØ,ÿ≥ŸÜ,') €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
            return None, None

        section1_start_line_num = headers_indices[0]
        section2_start_line_num = len(lines)

        if len(headers_indices) > 1:
            section2_start_line_num = headers_indices[1]

        end_row_area_line_num = section2_start_line_num

        try:
            area_section_io = BytesIO("\n".join(lines[section1_start_line_num : end_row_area_line_num]).encode('utf-8'))
            df_area = pd.read_csv(area_section_io, encoding='utf-8')
        except Exception as e:
             st.warning(f"‚ö†Ô∏è ÿÆÿ∑ÿß ÿØÿ± ÿÆŸàÿßŸÜÿØŸÜ ÿ®ÿÆÿ¥ ŸÖÿ≥ÿßÿ≠ÿ™ ÿßÿ≤ ŸÅÿß€åŸÑ ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™: {e}")
             df_area = pd.DataFrame()


        df_prod = pd.DataFrame()
        if len(headers_indices) > 1:
             end_row_prod_line_num = len(lines)
             for i in range(section2_start_line_num + 1, len(lines)):
                 if "Grand Total" in lines[i] or len(lines[i].strip()) < 5:
                     end_row_prod_line_num = i
                     break

             try:
                  prod_section_io = BytesIO("\n".join(lines[section2_start_line_num : end_row_prod_line_num]).encode('utf-8'))
                  df_prod = pd.read_csv(prod_section_io, encoding='utf-8')
             except Exception as e:
                  st.warning(f"‚ö†Ô∏è ÿÆÿ∑ÿß ÿØÿ± ÿÆŸàÿßŸÜÿØŸÜ ÿ®ÿÆÿ¥ ÿ™ŸàŸÑ€åÿØ ÿßÿ≤ ŸÅÿß€åŸÑ ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™: {e}")
                  df_prod = pd.DataFrame()


        def preprocess_df(df, section_name):
            if df is None or df.empty:
                return None

            df.columns = df.columns.str.strip().str.replace('\ufeff', '')

            if df.columns.tolist() and 'ÿßÿØÿßÿ±Ÿá' not in df.columns:
                df.rename(columns={df.columns[0]: 'ÿßÿØÿßÿ±Ÿá'}, inplace=True)


            if not all(col in df.columns for col in ['ÿßÿØÿßÿ±Ÿá', 'ÿ≥ŸÜ']):
                 st.warning(f"‚ö†Ô∏è ÿ≥ÿ™ŸàŸÜ Ÿáÿß€å ÿ∂ÿ±Ÿàÿ±€å 'ÿßÿØÿßÿ±Ÿá' €åÿß 'ÿ≥ŸÜ' ÿØÿ± ÿ®ÿÆÿ¥ '{section_name}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
                 return None

            df['ÿßÿØÿßÿ±Ÿá'] = df['ÿßÿØÿßÿ±Ÿá'].ffill()

            df = df[~df['ÿ≥ŸÜ'].astype(str).str.contains('total', case=False, na=False)].copy()
            df = df[~df['ÿßÿØÿßÿ±Ÿá'].astype(str).str.contains('total|ÿØŸáÿÆÿØÿß', case=False, na=False)].copy()

            df = df.dropna(subset=['ÿßÿØÿßÿ±Ÿá']).copy()

            df['ÿßÿØÿßÿ±Ÿá'] = pd.to_numeric(df['ÿßÿØÿßÿ±Ÿá'], errors='coerce').astype('Int64')
            df = df.dropna(subset=['ÿßÿØÿßÿ±Ÿá']).copy()

            value_cols = [col for col in df.columns if col not in ['ÿßÿØÿßÿ±Ÿá', 'ÿ≥ŸÜ', 'ÿØÿ±ÿµÿØ', 'Grand Total']]
            for col in value_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce')

            df = df.dropna(axis=1, how='all').copy()

            df = df.drop(columns=['Grand Total', 'ÿØÿ±ÿµÿØ'], errors='ignore')

            if 'ÿßÿØÿßÿ±Ÿá' in df.columns and 'ÿ≥ŸÜ' in df.columns:
                try:
                    df = df.set_index(['ÿßÿØÿßÿ±Ÿá', 'ÿ≥ŸÜ']).copy()
                except ValueError as e:
                     st.warning(f"‚ö†Ô∏è ÿÆÿ∑ÿß€å ÿ™ŸÜÿ∏€åŸÖ ÿß€åŸÜÿØ⁄©ÿ≥ ⁄ÜŸÜÿØ⁄ØÿßŸÜŸá ÿØÿ± ÿ®ÿÆÿ¥ '{section_name}': {e}. ÿßÿØÿßŸÖŸá ÿ®ÿØŸàŸÜ ÿß€åŸÜÿØ⁄©ÿ≥.")

            return df

        df_area_processed = preprocess_df(df_area, "ŸÖÿ≥ÿßÿ≠ÿ™")
        df_prod_processed = preprocess_df(df_prod, "ÿ™ŸàŸÑ€åÿØ")

        if df_area_processed is not None or df_prod_processed is not None:
             st.success(f"‚úÖ ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å Ÿà Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ¥ÿØ.")
        else:
             st.warning("‚ö†Ô∏è Ÿá€å⁄Ü ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ±€å ÿßÿ≤ ŸÅÿß€åŸÑ ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å €åÿß Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸÜÿ¥ÿØ. ŸÑÿ∑ŸÅÿßŸã ÿ≥ÿßÿÆÿ™ÿßÿ± ŸÅÿß€åŸÑ 'ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ 2.csv' ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ.")

        return df_area_processed, df_prod_processed

    except FileNotFoundError:
        st.error(f"‚ùå ŸÅÿß€åŸÑ '{csv_path}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ŸÑÿ∑ŸÅÿßŸã ŸÅÿß€åŸÑ CSV ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ ÿ±ÿß ÿØÿ± ŸÖÿ≥€åÿ± ÿµÿ≠€åÿ≠ ŸÇÿ±ÿßÿ± ÿØŸá€åÿØ.")
        return None, None
    except Exception as e:
        st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å €åÿß Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸÅÿß€åŸÑ ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ CSV: {e}")
        st.error(traceback.format_exc())
        return None, None


gee_initialized = initialize_gee()

farm_data_df = pd.DataFrame()
if transformer is not None:
    farm_data_df = load_farm_data_from_csv()
else:
     st.error("‚ùå ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ ÿ®Ÿá ÿØŸÑ€åŸÑ ÿÆÿ∑ÿß€å Ÿæ€å⁄©ÿ±ÿ®ŸÜÿØ€å ÿ≥€åÿ≥ÿ™ŸÖ ŸÖÿÆÿ™ÿµÿßÿ™ ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜ€åÿ≥ÿ™.")


analysis_area_df, analysis_prod_df = load_analysis_data()


@st.cache_resource(show_spinner="ÿØÿ± ÿ≠ÿßŸÑ Ÿæ€å⁄©ÿ±ÿ®ŸÜÿØ€å ÿ≥ÿ±Ÿà€åÿ≥ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å...")
def configure_gemini(api_key): # Accept API key as parameter
    """Configures the Gemini API client."""
    try:
        if not api_key:
             st.error("‚ùå ⁄©ŸÑ€åÿØ API ÿ¨ŸÖ€åŸÜÿß€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")
             st.info("ŸÑÿ∑ŸÅÿßŸã ⁄©ŸÑ€åÿØ API ÿ±ÿß ÿØÿ± ⁄©ÿØ ÿ®ÿ±ŸÜÿßŸÖŸá €åÿß ÿØÿ± Streamlit Secrets ÿ™ŸÜÿ∏€åŸÖ ⁄©ŸÜ€åÿØ.")
             return None

        genai.configure(api_key=api_key)

        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings)
        print("Gemini Configured Successfully.")
        return model
    except Exception as e:
        st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿ™ŸÜÿ∏€åŸÖ Gemini API: {e}")
        st.error(traceback.format_exc())
        return None


# Initialize Gemini model AFTER its definition
gemini_model = None
if gee_initialized:
    # Use the hardcoded API key
    gemini_model = configure_gemini(GEMINI_API_KEY_HARDCODED)
    if gemini_model is None:
         st.warning("‚ö†Ô∏è ÿ≥ÿ±Ÿà€åÿ≥ ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿ®Ÿá ÿØŸÑ€åŸÑ ÿÆÿ∑ÿß€å Ÿæ€å⁄©ÿ±ÿ®ŸÜÿØ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™. ŸÇÿßÿ®ŸÑ€åÿ™‚ÄåŸáÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿ∫€åÿ±ŸÅÿπÿßŸÑ ÿßÿ≥ÿ™.")
    # Add a prominent warning about hardcoding the API key
    st.warning("‚ö†Ô∏è **Ÿáÿ¥ÿØÿßÿ± ÿßŸÖŸÜ€åÿ™€å:** ⁄©ŸÑ€åÿØ API ÿ¨ŸÖ€åŸÜÿß€å ŸÖÿ≥ÿ™ŸÇ€åŸÖÿßŸã ÿØÿ± ⁄©ÿØ ŸÇÿ±ÿßÿ± ÿØÿßÿØŸá ÿ¥ÿØŸá ÿßÿ≥ÿ™. ÿß€åŸÜ ÿ±Ÿàÿ¥ **ŸÜÿßÿßŸÖŸÜ** ÿßÿ≥ÿ™ Ÿà ÿ®Ÿá ÿ¥ÿØÿ™ ÿ™Ÿàÿµ€åŸá ŸÖ€å‚Äåÿ¥ŸàÿØ ÿßÿ≤ Streamlit Secrets ÿ®ÿ±ÿß€å ŸÖÿØ€åÿ±€åÿ™ ÿßŸÖŸÜ ⁄©ŸÑ€åÿØ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ.", icon="üîí")


# --- Sidebar Logo ---
st.sidebar.markdown(
    """
    <div class='sidebar-logo'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' alt='ŸÑŸà⁄ØŸà ÿ≥ÿßŸÖÿßŸÜŸá' />
    </div>
    """,
    unsafe_allow_html=True
)

# --- Main Header with Logo ---
st.markdown(
    """
    <div style='display: flex; align-items: center; gap: 16px; margin-bottom: 0.5rem;'>
        <img src='https://raw.githubusercontent.com/esmaeilkiani13877/MonitoringSugarcane-13/main/logo%20(1).png' class='main-logo' alt='ŸÑŸà⁄ØŸà' />
        <h1 style='font-family: Vazirmatn, sans-serif; color: #185a9d; margin: 0;'>ÿ≥ÿßŸÖÿßŸÜŸá Ÿæÿß€åÿ¥ ŸáŸàÿ¥ŸÖŸÜÿØ ŸÜ€åÿ¥⁄©ÿ±</h1>
    </div>
    <h4 style='color: #43cea2; margin-top: 0;'>ŸÖÿ∑ÿßŸÑÿπÿßÿ™ ⁄©ÿßÿ±ÿ®ÿ±ÿØ€å ÿ¥ÿ±⁄©ÿ™ ⁄©ÿ¥ÿ™ Ÿà ÿµŸÜÿπÿ™ ÿØŸáÿÆÿØÿß</h4>
    """,
    unsafe_allow_html=True
)

# ==============================================================================
# Sidebar Filters (Moved here, after data loading)
# ==============================================================================
st.sidebar.header("ÿ™ŸÜÿ∏€åŸÖÿßÿ™ ŸÜŸÖÿß€åÿ¥")

selected_day = None
if not farm_data_df.empty and 'ÿ±Ÿàÿ≤' in farm_data_df.columns:
    available_days = sorted(farm_data_df['ÿ±Ÿàÿ≤'].unique())
    if not available_days or (len(available_days) == 1 and available_days[0] == 'ŸÜÿßŸÖÿ¥ÿÆÿµ'):
         st.sidebar.warning("Ÿá€å⁄Ü ÿ±Ÿàÿ≤ ŸáŸÅÿ™Ÿá‚Äåÿß€å ŸÖÿπÿ™ÿ®ÿ±€å ÿØÿ± ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
         selected_day = None
    else:
         valid_days = [d for d in available_days if d != 'ŸÜÿßŸÖÿ¥ÿÆÿµ']
         if not valid_days:
              st.sidebar.warning("Ÿá€å⁄Ü ÿ±Ÿàÿ≤ ŸáŸÅÿ™Ÿá‚Äåÿß€å ŸÖÿπÿ™ÿ®ÿ±€å ÿØÿ± ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
              selected_day = None
         else:
            selected_day = st.sidebar.selectbox(
                "üìÖ ÿ±Ÿàÿ≤ ŸáŸÅÿ™Ÿá ÿ±ÿß ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ:",
                options=valid_days,
                index=0,
                help="ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿß€åŸÜ ÿ±Ÿàÿ≤ ŸÅ€åŸÑÿ™ÿ± ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ."
            )
else:
     st.sidebar.info("‚ÑπÔ∏è ÿØÿßÿØŸá ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ±ÿß€å ŸÅ€åŸÑÿ™ÿ± ÿ±Ÿàÿ≤ ŸáŸÅÿ™Ÿá ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")
     selected_day = None


filtered_farms_df = pd.DataFrame()
if selected_day and not farm_data_df.empty:
    filtered_farms_df = farm_data_df[farm_data_df['ÿ±Ÿàÿ≤'] == selected_day].copy()

selected_farm_name = "ŸáŸÖŸá ŸÖÿ≤ÿßÿ±ÿπ"
available_farms = []
if not filtered_farms_df.empty:
    available_farms = sorted(filtered_farms_df['ŸÖÿ≤ÿ±ÿπŸá'].unique())
    farm_options = ["ŸáŸÖŸá ŸÖÿ≤ÿßÿ±ÿπ"] + available_farms
    selected_farm_name = st.sidebar.selectbox(
        "üåæ ŸÖÿ≤ÿ±ÿπŸá ŸÖŸàÿ±ÿØ ŸÜÿ∏ÿ± ÿ±ÿß ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ:",
        options=farm_options,
        index=0,
        help="ŸÖÿ≤ÿ±ÿπŸá‚Äåÿß€å ⁄©Ÿá ŸÖ€å‚ÄåÿÆŸàÿßŸá€åÿØ ÿ¨ÿ≤ÿ¶€åÿßÿ™ ÿ¢ŸÜ ÿ±ÿß ÿ®ÿ®€åŸÜ€åÿØ €åÿß 'ŸáŸÖŸá ŸÖÿ≤ÿßÿ±ÿπ' ÿ®ÿ±ÿß€å ŸÜŸÖÿß€åÿ¥ ⁄©ŸÑ€å."
    )
else:
    st.sidebar.info("‚ÑπÔ∏è ŸÖÿ≤ÿßÿ±ÿπ€å ÿ®ÿ±ÿß€å ÿ±Ÿàÿ≤ ÿßŸÜÿ™ÿÆÿßÿ®€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")


index_options = {
    "NDVI": "ÿ¥ÿßÿÆÿµ ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å ÿ™ŸÅÿßÿ∂ŸÑ€å ŸÜÿ±ŸÖÿßŸÑ ÿ¥ÿØŸá",
    "EVI": "ÿ¥ÿßÿÆÿµ ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å ÿ®Ÿáÿ®ŸàÿØ €åÿßŸÅÿ™Ÿá",
    "NDMI": "ÿ¥ÿßÿÆÿµ ÿ±ÿ∑Ÿàÿ®ÿ™€å ÿ™ŸÅÿßÿ∂ŸÑ€å ŸÜÿ±ŸÖÿßŸÑ ÿ¥ÿØŸá",
    "LAI": "ÿ¥ÿßÿÆÿµ ÿ≥ÿ∑ÿ≠ ÿ®ÿ±⁄Ø (ÿ™ÿÆŸÖ€åŸÜ€å)",
    "MSI": "ÿ¥ÿßÿÆÿµ ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å",
    "CVI": "ÿ¥ÿßÿÆÿµ ⁄©ŸÑÿ±ŸàŸÅ€åŸÑ (ÿ™ÿÆŸÖ€åŸÜ€å)",
    "SAVI": "ÿ¥ÿßÿÆÿµ ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å ÿ™ÿπÿØ€åŸÑ ÿ¥ÿØŸá ÿ®ÿß ÿÆÿß⁄©",
}
selected_index = st.sidebar.selectbox(
    "üìà ÿ¥ÿßÿÆÿµ ŸÖŸàÿ±ÿØ ŸÜÿ∏ÿ± ÿ®ÿ±ÿß€å ŸÜŸÖÿß€åÿ¥ Ÿà ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å:",
    options=list(index_options.keys()),
    format_func=lambda x: f"{x} ({index_options[x]})",
    index=0
)

today = datetime.date.today()
start_date_current_str = None
end_date_current_str = None
start_date_previous_str = None
end_date_previous_str = None

if selected_day:
    try:
        persian_to_weekday = {
            "ÿ¥ŸÜÿ®Ÿá": 5, "€å⁄©ÿ¥ŸÜÿ®Ÿá": 6, "ÿØŸàÿ¥ŸÜÿ®Ÿá": 0, "ÿ≥Ÿá ÿ¥ŸÜÿ®Ÿá": 1,
            "⁄ÜŸáÿßÿ±ÿ¥ŸÜÿ®Ÿá": 2, "ŸæŸÜÿ¨ÿ¥ŸÜÿ®Ÿá": 3, "ÿ¨ŸÖÿπŸá": 4,
        }
        target_weekday = persian_to_weekday[selected_day.strip()]
        today_weekday = today.weekday()

        days_ago = (today_weekday - target_weekday + 7) % 7
        end_date_current = today - datetime.timedelta(days=days_ago)

        start_date_current = end_date_current - datetime.timedelta(days=6)

        end_date_previous = start_date_current - datetime.timedelta(days=1)
        start_date_previous = end_date_previous - datetime.timedelta(days=6)

        # Ensure previous start date is not too far back if needed
        one_year_ago = today - datetime.timedelta(days=365)
        if start_date_previous < one_year_ago:
             start_date_previous = one_year_ago
             st.sidebar.info(f"‚ö†Ô∏è ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ŸÇÿ®ŸÑ€å ÿ®Ÿá €å⁄© ÿ≥ÿßŸÑ ŸÇÿ®ŸÑ ŸÖÿ≠ÿØŸàÿØ ÿ¥ÿØ: {start_date_previous.strftime('%Y-%m-%d')}")


        start_date_current_str = start_date_current.strftime('%Y-%m-%d')
        end_date_current_str = end_date_current.strftime('%Y-%m-%d')
        start_date_previous_str = start_date_previous.strftime('%Y-%m-%d')
        end_date_previous_str = end_date_previous.strftime('%Y-%m-%d')

        st.sidebar.info(f"**ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ŸÅÿπŸÑ€å:** {start_date_current_str} ÿ™ÿß {end_date_current_str}")
        st.sidebar.info(f"**ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ŸÇÿ®ŸÑ€å:** {start_date_previous_str} ÿ™ÿß {end_date_previous_str}")

    except KeyError:
        st.sidebar.error(f"‚ùå ŸÜÿßŸÖ ÿ±Ÿàÿ≤ ŸáŸÅÿ™Ÿá '{selected_day}' ŸÇÿßÿ®ŸÑ ÿ¥ŸÜÿßÿ≥ÿß€å€å ŸÜ€åÿ≥ÿ™. ŸÑÿ∑ŸÅÿßŸã ÿ±Ÿàÿ≤ ŸÖÿπÿ™ÿ®ÿ±€å ÿ±ÿß ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ.")
    except Exception as e:
        st.sidebar.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å: {e}")
        st.error(traceback.format_exc())

st.sidebar.markdown("---")
st.sidebar.markdown("ÿ≥ÿßÿÆÿ™Ÿá ÿ¥ÿØŸá ÿ®ÿß ‚ù§Ô∏è ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ Streamlit, Google Earth Engine, Ÿà geemap")


def maskS2clouds(image):
    qa = image.select('QA60')
    cloudBitMask = 1 << 10
    cirrusBitMask = 1 << 11
    mask_qa = qa.bitwiseAnd(cloudBitMask).eq(0).And(
             qa.bitwiseAnd(cirrusBitMask).eq(0))

    scl = image.select('SCL')
    # Sentinel-2 SCL band values:
    # 0: No Data (Mask)
    # 1: Saturated or defective pixel
    # 2: Dark Area Pixels
    # 3: Cloud Shadows
    # 4: Vegetation
    # 5: Not Vegetated
    # 6: Water
    # 7: Unclassified
    # 8: Cloud Medium Probability
    # 9: Cloud High Probability
    # 10: Thin Cirrus
    # 11: Snow/Ice
    # Masking out: No Data, Saturated, Dark Area, Cloud Shadows, Cloud High Probability, Thin Cirrus, Snow/Ice
    masked_classes_scl = [0, 1, 2, 3, 9, 10, 11]
    mask_scl = scl.remap(masked_classes_scl, [0] * len(masked_classes_scl), 1).eq(1)


    final_mask = mask_qa.And(mask_scl)
    opticalBands = image.select('B.*').multiply(0.0001)

    return image.addBands(opticalBands, None, True)\
                .updateMask(final_mask)

def add_indices(image):
    red = image.select('B4')
    nir = image.select('B8')
    blue = image.select('B2')
    green = image.select('B3')
    swir1 = image.select('B11')

    epsilon = 1e-9

    ndvi_denominator = nir.add(red)
    ndvi = image.expression(
        '(NIR - RED) / (NIR + RED)',
        {'NIR': nir, 'RED': red}
    ).rename('NDVI').updateMask(ndvi_denominator.gt(epsilon))

    evi_denominator = nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)
    evi = image.expression(
        '2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1)',
        {'NIR': nir, 'RED': red, 'BLUE': blue}
    ).rename('EVI').updateMask(evi_denominator.abs().gt(epsilon))

    ndmi_denominator = nir.add(swir1)
    ndmi = image.normalizedDifference(['B8', 'B11']).rename('NDMI').updateMask(ndmi_denominator.gt(epsilon))

    savi_denominator = nir.add(red).add(0.5)
    savi = image.expression(
        '((NIR - RED) / (NIR + RED + L)) * (1 + L)',
        {'NIR': nir, 'RED': red, 'L': 0.5}
    ).rename('SAVI').updateMask(savi_denominator.gt(epsilon))

    nir_safe = nir.max(ee.Image(epsilon))
    msi = image.expression('SWIR1 / NIR', {'SWIR1': swir1, 'NIR': nir_safe}).rename('MSI')

    lai = evi.multiply(3.618).subtract(0.118).rename('LAI').reproject(crs=image.projection().crs(), scale=10)
    lai = lai.updateMask(lai.gt(0))

    green_safe = green.max(ee.Image(epsilon))
    cvi = image.expression('(NIR / GREEN) * (RED / GREEN)',
                         {'NIR': nir, 'GREEN': green_safe, 'RED': red}
    ).rename('CVI').reproject(crs=image.projection().crs(), scale=10)

    return image.addBands([ndvi, evi, ndmi, msi, lai, cvi, savi])

@st.cache_data(show_spinner=False, persist="disk")
def get_processed_image(_geometry, start_date, end_date, index_name):
    """
    Gets cloud-masked, index-calculated Sentinel-2 median composite for a given geometry and date range.
    Includes fallback date range logic if no images are found initially.
    Ensures a non-None error message is returned if the image is None.
    """
    if not gee_initialized:
        return None, "Google Earth Engine ŸÖŸÇÿØÿßÿ±ÿØŸá€å ÿßŸàŸÑ€åŸá ŸÜÿ¥ÿØŸá ÿßÿ≥ÿ™."
    if _geometry is None:
        return None, "ŸáŸÜÿØÿ≥Ÿá ŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å Ÿæÿ±ÿØÿßÿ≤ÿ¥ GEE Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ."

    initial_start_date = start_date
    initial_end_date = end_date
    fallback_days = 30 # Increased fallback period


    def filter_and_process_collection(s_date, e_date):
        try:
            s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                         .filterBounds(_geometry)
                         .filterDate(s_date, e_date)
                         .map(maskS2clouds))

            count = s2_sr_col.size().getInfo()
            if count == 0:
                return None, 0, f"Ÿá€å⁄Ü ÿ™ÿµŸà€åÿ± Sentinel-2 ÿ®ÿØŸàŸÜ ÿßÿ®ÿ± ÿØÿ± ÿ®ÿßÿ≤Ÿá {s_date} ÿ™ÿß {e_date} €åÿßŸÅÿ™ ŸÜÿ¥ÿØ."

            indexed_col = s2_sr_col.map(add_indices)
            median_image = indexed_col.median()

            available_bands = median_image.bandNames().getInfo()
            if index_name not in available_bands:
                 # Attempt to select another common band to see if the image is valid otherwise
                 test_band = 'B4' if 'B4' in available_bands else (available_bands[0] if available_bands else None)
                 if test_band:
                     try:
                         # Test reducing a small region with the available band
                          test_region = _geometry.centroid(1).buffer(10) # Small buffer around centroid
                          median_image.select(test_band).reduceRegion(ee.Reducer.first(), test_region, 10).getInfo()
                          # If above works, the issue is band calculation/availability
                          return None, count, f"ÿ¥ÿßÿÆÿµ '{index_name}' ÿØÿ± ÿ™ÿµÿßŸà€åÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ¥ÿØŸá €åÿßŸÅÿ™ ŸÜÿ¥ÿØ (ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿÆÿ∑ÿß€å€å ÿØÿ± ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ¥ÿßÿÆÿµ ÿ±ÿÆ ÿØÿßÿØŸá ÿ®ÿßÿ¥ÿØ). ÿ®ÿßŸÜÿØŸáÿß€å ŸÖŸàÿ¨ŸàÿØ: {', '.join(available_bands)}"
                     except Exception as band_test_e:
                          # If even testing another band fails, likely a broader issue
                          return None, count, f"ÿ¥ÿßÿÆÿµ '{index_name}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ Ÿà ÿÆÿ∑ÿß€å Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ™ÿµŸà€åÿ± ŸÜ€åÿ≤ Ÿàÿ¨ŸàÿØ ÿØÿßÿ±ÿØ: {band_test_e}. ÿ®ÿßŸÜÿØŸáÿß€å ŸÖŸàÿ¨ŸàÿØ: {', '.join(available_bands)}"
                 else: # No bands available at all
                     return None, count, f"ÿ¥ÿßÿÆÿµ '{index_name}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ Ÿà Ÿá€å⁄Ü ÿ®ÿßŸÜÿØ ŸÖÿπÿ™ÿ®ÿ±€å ÿØÿ± ÿ™ÿµŸà€åÿ± Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ."


            # Select the band before returning
            output_image = median_image.select(index_name)

            # Final validity check: Ensure the selected band has data over the geometry
            try:
                test_reduction = output_image.reduceRegion(
                    reducer=ee.Reducer.firstNonNull(), # Check if there's any non-null pixel
                    geometry=_geometry,
                    scale=30, # Use slightly coarser scale for faster check
                    bestEffort=True
                ).get(index_name).getInfo()
                if test_reduction is None:
                     return None, count, f"ÿ™ÿµŸà€åÿ± ÿ®ÿ±ÿß€å ÿ¥ÿßÿÆÿµ '{index_name}' ÿØÿ± ÿ®ÿßÿ≤Ÿá {s_date}-{e_date} ÿß€åÿ¨ÿßÿØ ÿ¥ÿØ ÿßŸÖÿß Ÿá€å⁄Ü ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ±€å ÿ±Ÿà€å ŸáŸÜÿØÿ≥Ÿá ŸÖŸàÿ±ÿØ ŸÜÿ∏ÿ± ŸÜÿØÿßÿ±ÿØ (ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ŸáŸÖŸá Ÿæ€å⁄©ÿ≥ŸÑ‚ÄåŸáÿß Mask ÿ¥ÿØŸá‚ÄåÿßŸÜÿØ)."
            except ee.EEException as reduce_err:
                 # If reduction itself fails, report it
                 return None, count, f"ÿÆÿ∑ÿß ÿØÿ± ÿ™ÿ£€å€åÿØ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ™ÿµŸà€åÿ± ÿ®ÿ±ÿß€å ÿ¥ÿßÿÆÿµ '{index_name}' ÿØÿ± ÿ®ÿßÿ≤Ÿá {s_date}-{e_date}: {reduce_err}"


            return output_image, count, None

        except ee.EEException as e:
            error_message = f"ÿÆÿ∑ÿß€å Google Earth Engine ÿØÿ± ÿ®ÿßÿ≤Ÿá {s_date}-{e_date}: {e}"
            try:
                error_details = e.args[0] if e.args else str(e)
                if isinstance(error_details, str):
                     if 'computation timed out' in error_details.lower():
                         error_message += "\\n(ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ÿ®Ÿá ÿØŸÑ€åŸÑ ÿ≠ÿ¨ŸÖ ÿ®ÿßŸÑÿß€å Ÿæÿ±ÿØÿßÿ≤ÿ¥ €åÿß ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ÿ∑ŸàŸÑÿßŸÜ€å)"
                     elif 'user memory limit exceeded' in error_details.lower():
                         error_message += "\\n(ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ÿ®Ÿá ÿØŸÑ€åŸÑ Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸÖŸÜÿ∑ŸÇŸá ÿ®ÿ≤ÿ±⁄Ø €åÿß ÿπŸÖŸÑ€åÿßÿ™ Ÿæ€å⁄Ü€åÿØŸá)"
                     elif 'image.projection' in error_details.lower() and 'different projections' in error_details.lower():
                        error_message += "\\n(ÿÆÿ∑ÿß€å Ÿæÿ±Ÿàÿ¨⁄©ÿ¥ŸÜ ÿØÿßÿÆŸÑ€å ÿØÿ± GEE. ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ®ÿß ÿ™ŸÑÿßÿ¥ ŸÖÿ¨ÿØÿØ €åÿß ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ŸÖÿ™ŸÅÿßŸàÿ™ ÿ®ÿ±ÿ∑ÿ±ŸÅ ÿ¥ŸàÿØ.)"
                     elif 'geometryconstructors' in error_details.lower() or 'invalid polygon' in error_details.lower():
                         error_message += "\\n(ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ŸÖÿ¥⁄©ŸÑ€å ÿØÿ± ŸáŸÜÿØÿ≥Ÿá Ÿàÿ±ŸàÿØ€å Ÿàÿ¨ŸàÿØ ÿØÿßÿ±ÿØ)"

            except Exception:
                pass # Ignore errors during error message enhancement
            return None, 0, error_message
        except Exception as e:
            error_message = f"ÿÆÿ∑ÿß€å ŸÜÿßÿ¥ŸÜÿßÿÆÿ™Ÿá ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ GEE ÿØÿ± ÿ®ÿßÿ≤Ÿá {s_date}-{e_date}: {e}\\n{traceback.format_exc()}"
            return None, 0, error_message


    # --- Main Logic with Improved Error Handling ---
    image, count, error_msg = filter_and_process_collection(initial_start_date, initial_end_date)
    initial_error_msg = error_msg # Store the initial error message

    if image is None:
        # Attempt 2: Fallback with extended end date
        try:
            # Ensure dates are valid datetime objects before manipulation
            start_dt_obj = datetime.datetime.strptime(initial_start_date, '%Y-%m-%d')
            end_dt_obj = datetime.datetime.strptime(initial_end_date, '%Y-%m-%d')

            fallback_end_date = (end_dt_obj + datetime.timedelta(days=fallback_days)).strftime('%Y-%m-%d')
            # Use original start date for fallback range
            fallback_start_date = initial_start_date

            print(f"Attempt 1 failed for {initial_start_date}-{initial_end_date}. Error: '{initial_error_msg}'. Trying fallback range: {fallback_start_date} to {fallback_end_date}")

            # Call fallback, store result in separate variables
            fallback_image, fallback_count, fallback_error_msg = filter_and_process_collection(fallback_start_date, fallback_end_date)

            if fallback_image is not None:
                 image = fallback_image # Use fallback image if successful
                 error_msg = None # Clear error message if fallback succeeded
                 print(f"Found {fallback_count} images in fallback range {fallback_start_date}-{fallback_end_date}.")
                 # Optionally add info message: st.info(f"‚ÑπÔ∏è ÿßÿ≤ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ™ÿµŸà€åÿ±€å ÿ™ÿß ÿ™ÿßÿ±€åÿÆ {fallback_end_date} ÿ®ÿ±ÿß€å ŸÜŸÖÿß€åÿ¥ ŸÜŸÇÿ¥Ÿá ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿ¥ÿØ.")
            else:
                 # Fallback also failed. Prioritize the fallback error message if it exists and is informative, otherwise use the initial error message.
                 if fallback_error_msg and "Ÿá€å⁄Ü ÿ™ÿµŸà€åÿ±" not in fallback_error_msg: # Prioritize specific errors from fallback
                      error_msg = f"ÿ™ŸÑÿßÿ¥ ÿßŸàŸÑ ŸÜÿßŸÖŸàŸÅŸÇ ({initial_error_msg}). ÿ™ŸÑÿßÿ¥ ÿØŸàŸÖ ({fallback_start_date}-{fallback_end_date}) ŸÜ€åÿ≤ ŸÜÿßŸÖŸàŸÅŸÇ: {fallback_error_msg}"
                 else: # Use initial error if fallback error is generic "no image" or None
                      error_msg = initial_error_msg if initial_error_msg else fallback_error_msg # Fallback error only if initial was None

                 # Ensure error_msg is never None if image is None at this stage
                 if image is None and not error_msg:
                     error_msg = f"Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ™ÿµŸà€åÿ± ÿ®ÿ±ÿß€å ÿ®ÿßÿ≤Ÿá {initial_start_date}-{initial_end_date} Ÿà ÿ®ÿßÿ≤Ÿá ÿ¨ÿß€å⁄Øÿ≤€åŸÜ {fallback_start_date}-{fallback_end_date} ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØ (ÿÆÿ∑ÿß€å ŸÜÿßŸÖÿ¥ÿÆÿµ)."
                 print(f"Attempt 2 also failed for {fallback_start_date}-{fallback_end_date}. Final Error: {error_msg}")

        except ValueError as date_err:
            # Handle potential errors converting date strings
            error_msg = f"ÿÆÿ∑ÿß ÿØÿ± ÿ™ÿ®ÿØ€åŸÑ ÿ™ÿßÿ±€åÿÆ ÿ®ÿ±ÿß€å ÿ®ÿßÿ≤Ÿá ÿ¨ÿß€å⁄Øÿ≤€åŸÜ: {date_err}. ÿÆÿ∑ÿß€å ÿßŸàŸÑ€åŸá: {initial_error_msg}"
            image = None # Ensure image remains None
            print(f"Error processing fallback dates: {date_err}")
        except Exception as e:
            # Error during the fallback *attempt* itself
            error_msg = f"ÿÆÿ∑ÿß ÿØÿ± ÿ™ŸÑÿßÿ¥ ÿ¨ÿß€å⁄Øÿ≤€åŸÜ ({fallback_start_date}-{fallback_end_date}): {e}\\n{traceback.format_exc()}. ÿÆÿ∑ÿß€å ÿßŸàŸÑ€åŸá: {initial_error_msg}"
            image = None # Ensure image remains None
            print(f"Error during fallback attempt: {e}")

    # Final check: if image is None, ensure there's an error message
    if image is None and not error_msg:
        error_msg = f"Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ™ÿµŸà€åÿ± ÿ®ÿ±ÿß€å ÿ®ÿßÿ≤Ÿá {initial_start_date}-{initial_end_date} ŸÜÿßŸÖŸàŸÅŸÇ ÿ®ŸàÿØ (ÿØŸÑ€åŸÑ ŸÜÿßŸÖÿ¥ÿÆÿµ)."


    # --- Return Value ---
    return image, error_msg


@st.cache_data(show_spinner="ÿØÿ± ÿ≠ÿßŸÑ ÿØÿ±€åÿßŸÅÿ™ ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å ÿ¥ÿßÿÆÿµ...", persist="disk")
def get_index_time_series(_point_geom, index_name, start_date='2023-01-01', end_date=today.strftime('%Y-%m-%d')):
    if not gee_initialized:
        return pd.DataFrame(columns=['date', index_name]), "Google Earth Engine ŸÖŸÇÿØÿßÿ±ÿØŸá€å ÿßŸàŸÑ€åŸá ŸÜÿ¥ÿØŸá ÿßÿ≥ÿ™."
    if _point_geom is None:
        return pd.DataFrame(columns=['date', index_name]), "ŸáŸÜÿØÿ≥Ÿá ŸÜŸÇÿ∑Ÿá‚Äåÿß€å ŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ."
    try:
        s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                     .filterBounds(_point_geom)
                     .filterDate(start_date, end_date)
                     .map(maskS2clouds)
                     .map(add_indices))

        # Select the band explicitly before proceeding
        s2_sr_col = s2_sr_col.select([index_name])

        def extract_value(image):
            try:
                # Select the band again before reducing to be extra safe with projections
                value = image.select(index_name).reduceRegion(
                    reducer=ee.Reducer.first(),
                    geometry=_point_geom,
                    scale=10,
                    bestEffort=True
                ).get(index_name)
                return ee.Feature(None, {
                    'date': image.date().format('YYYY-MM-dd'),
                    index_name: value
                })
            except Exception as e:
                 # Log the error internally or print for debugging
                 print(f"Error extracting value for date {image.date().format('YYYY-MM-dd')} and index {index_name}: {e}")
                 return ee.Feature(None, {
                    'date': image.date().format('YYYY-MM-dd'),
                    index_name: None
                })

        ts_features = s2_sr_col.map(extract_value).filter(ee.Filter.notNull([index_name]))

        try:
            # Using aggregate_array might be more robust than getInfo() on features for large collections
            dates_list = ts_features.aggregate_array('date').getInfo()
            values_list = ts_features.aggregate_array(index_name).getInfo()

            if not dates_list or not values_list:
                 return pd.DataFrame(columns=['date', index_name]), "ÿØÿßÿØŸá‚Äåÿß€å ÿ®ÿ±ÿß€å ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å ÿØÿ± ÿ®ÿßÿ≤Ÿá ŸÖÿ¥ÿÆÿµ ÿ¥ÿØŸá €åÿßŸÅÿ™ ŸÜÿ¥ÿØ (ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ®Ÿá ÿØŸÑ€åŸÑ ŸæŸàÿ¥ÿ¥ ÿßÿ®ÿ±€å €åÿß ÿÆÿ∑ÿß€å Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ®ÿßÿ¥ÿØ)."


            ts_df = pd.DataFrame({
                'date': dates_list,
                index_name: values_list
            })

        except ee.EEException as e:
            return pd.DataFrame(columns=['date', index_name]), f"ÿÆÿ∑ÿß€å GEE ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å: {e}"
        except Exception as e:
            return pd.DataFrame(columns=['date', index_name]), f"ÿÆÿ∑ÿß€å ŸÜÿßÿ¥ŸÜÿßÿÆÿ™Ÿá ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å: {e}"


        if ts_df.empty:
             return pd.DataFrame(columns=['date', index_name]), "ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ±€å ÿ®ÿ±ÿß€å ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ (Ÿæÿ≥ ÿßÿ≤ ÿ≠ÿ∞ŸÅ ŸÖŸÇÿßÿØ€åÿ± ÿÆÿßŸÑ€å)."

        ts_df['date'] = pd.to_datetime(ts_df['date'])
        ts_df = ts_df.sort_values('date').set_index('date')

        return ts_df, None
    except ee.EEException as e:
        error_message = f"ÿÆÿ∑ÿß€å GEE ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å: {e}"
        st.error(error_message)
        return pd.DataFrame(columns=['date', index_name]), error_message
    except Exception as e:
        error_message = f"ÿÆÿ∑ÿß€å ŸÜÿßÿ¥ŸÜÿßÿÆÿ™Ÿá ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å: {e}\n{traceback.format_exc()}"
        st.error(error_message)
        return pd.DataFrame(columns=['date', index_name]), error_message

@st.cache_data(show_spinner=False, persist="disk")
def get_farm_needs_data(_farm_geometry, start_curr, end_curr, start_prev, end_prev):
    if not gee_initialized:
        results = {'error': "Google Earth Engine ŸÖŸÇÿØÿßÿ±ÿØŸá€å ÿßŸàŸÑ€åŸá ŸÜÿ¥ÿØŸá ÿßÿ≥ÿ™."}
        return results
    if _farm_geometry is None:
        results = {'error': "ŸáŸÜÿØÿ≥Ÿá ŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÜ€åÿßÿ≤ÿ≥ŸÜÿ¨€å Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ."}
        return results

    results = {
        'NDVI_curr': None, 'NDMI_curr': None, 'EVI_curr': None, 'SAVI_curr': None,
        'NDVI_prev': None, 'NDMI_prev': None, 'EVI_prev': None, 'SAVI_prev': None,
        'error': None
    }
    indices_to_get = ['NDVI', 'NDMI', 'EVI', 'SAVI']

    def get_mean_values_for_period(start, end):
        period_values = {index: None for index in indices_to_get}
        error_msg = None
        try:
            s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                         .filterBounds(_farm_geometry)
                         .filterDate(start, end)
                         .map(maskS2clouds))

            count = s2_sr_col.size().getInfo()
            if count == 0:
                # Fallback logic (similar to get_processed_image)
                fallback_days_needs = 30 # Fallback for needs data as well
                fallback_end_date = (datetime.datetime.strptime(end, '%Y-%m-%d') + datetime.timedelta(days=fallback_days_needs)).strftime('%Y-%m-%d')
                s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                             .filterBounds(_farm_geometry)
                             .filterDate(start, fallback_end_date)
                             .map(maskS2clouds))
                count = s2_sr_col.size().getInfo()
                if count == 0:
                    return period_values, f"Ÿá€å⁄Ü ÿ™ÿµŸà€åÿ±€å ÿØÿ± ÿ®ÿßÿ≤Ÿá {start}-{end} (Ÿà ÿ®ÿßÿ≤Ÿá ÿ¨ÿß€å⁄Øÿ≤€åŸÜ ÿ™ÿß {fallback_end_date}) €åÿßŸÅÿ™ ŸÜÿ¥ÿØ"


            indexed_col = s2_sr_col.map(add_indices)
            median_image = indexed_col.median()

            available_bands = median_image.bandNames().getInfo()
            indices_to_reduce = [idx for idx in indices_to_get if idx in available_bands]

            if not indices_to_reduce:
                 return period_values, f"Ÿá€å⁄Ü €å⁄© ÿßÿ≤ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÖŸàÿ±ÿØ ŸÜ€åÿßÿ≤ ({', '.join(indices_to_get)}) ÿØÿ± ÿ™ÿµÿßŸà€åÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ¥ÿØŸá ÿ®ÿ±ÿß€å ÿ®ÿßÿ≤Ÿá {start}-{end} €åÿßŸÅÿ™ ŸÜÿ¥ÿØ."

            # Calculate mean for each index separately to avoid projection issues with multi-band image reduction
            mean_dict = {}
            for idx in indices_to_reduce:
                try:
                    mean_value = median_image.select(idx).reduceRegion( # Select band before reduceRegion
                        reducer=ee.Reducer.mean(),
                        geometry=_farm_geometry,
                        scale=10,
                        bestEffort=True,
                        maxPixels=1e8
                    ).get(idx).getInfo()
                    mean_dict[idx] = mean_value
                except Exception as e:
                     print(f"Error calculating mean for index {idx} in period {start}-{end}: {e}") # Log error per index


            if mean_dict:
                for index in indices_to_get:
                    if index in mean_dict and mean_dict[index] is not None:
                         period_values[index] = mean_dict[index]

            return period_values, None
        except ee.EEException as e:
            error_msg = f"ÿÆÿ∑ÿß€å GEE ÿØÿ± ÿ®ÿßÿ≤Ÿá {start}-{end}: {e}"
            return period_values, error_msg
        except Exception as e:
            error_msg = f"ÿÆÿ∑ÿß€å ŸÜÿßÿ¥ŸÜÿßÿÆÿ™Ÿá ÿØÿ± ÿ®ÿßÿ≤Ÿá {start}-{end}: {e}\n{traceback.format_exc()}"
            return period_values, error_msg

    curr_values, err_curr = get_mean_values_for_period(start_curr, end_curr)
    if err_curr:
        results['error'] = f"ÿÆÿ∑ÿß ÿØÿ± ÿ®ÿßÿ≤Ÿá ÿ¨ÿßÿ±€å: {err_curr}"
    results['NDVI_curr'] = curr_values.get('NDVI')
    results['NDMI_curr'] = curr_values.get('NDMI')
    results['EVI_curr'] = curr_values.get('EVI')
    results['SAVI_curr'] = curr_values.get('SAVI')


    prev_values, err_prev = get_mean_values_for_period(start_prev, end_prev)
    if err_prev:
        if results.get('error'):
             results['error'] += f"\nÿÆÿ∑ÿß ÿØÿ± ÿ®ÿßÿ≤Ÿá ŸÇÿ®ŸÑ€å: {err_prev}"
        else:
             results['error'] = f"ÿÆÿ∑ÿß ÿØÿ± ÿ®ÿßÿ≤Ÿá ŸÇÿ®ŸÑ€å: {err_prev}"

    # Consolidate error message if both periods failed
    if results.get('error') and 'ÿÆÿ∑ÿß ÿØÿ± ÿ®ÿßÿ≤Ÿá ÿ¨ÿßÿ±€å:' in results['error'] and 'ÿÆÿ∑ÿß ÿØÿ± ÿ®ÿßÿ≤Ÿá ŸÇÿ®ŸÑ€å:' in results['error']:
         results['error'] = "ÿÆÿ∑ÿß ÿØÿ± Ÿáÿ± ÿØŸà ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ŸáŸÜ⁄ØÿßŸÖ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÜ€åÿßÿ≤ÿ≥ŸÜÿ¨€å."
    elif results.get('error'):
         pass # Keep the specific error if only one period failed
    elif pd.isna(results['NDVI_curr']) and pd.isna(results['NDMI_curr']) and pd.isna(results['EVI_curr']) and pd.isna(results['SAVI_curr']) and \
         pd.isna(results['NDVI_prev']) and pd.isna(results['NDMI_prev']) and pd.isna(results['EVI_prev']) and pd.isna(results['SAVI_prev']):
         results['error'] = "Ÿá€å⁄Ü ÿØÿßÿØŸá ÿ¥ÿßÿÆÿµ€å ÿ®ÿ±ÿß€å ÿ®ÿßÿ≤Ÿá‚ÄåŸáÿß€å ÿ≤ŸÖÿßŸÜ€å ŸÖÿ¥ÿÆÿµ ÿ¥ÿØŸá €åÿßŸÅÿ™ ŸÜÿ¥ÿØ."

    results['NDVI_prev'] = prev_values.get('NDVI')
    results['NDMI_prev'] = prev_values.get('NDMI')
    results['EVI_prev'] = prev_values.get('EVI')
    results['SAVI_prev'] = prev_values.get('SAVI')


    return results


@st.cache_data(show_spinner="ÿØÿ± ÿ≠ÿßŸÑ ÿØÿ±€åÿßŸÅÿ™ ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å...", persist="disk")
def get_ai_needs_analysis(_model, farm_name, index_data, recommendations):
    """Generates AI analysis for the farm's condition related to needs."""
    if _model is None:
        return "ÿ≥ÿ±Ÿà€åÿ≥ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™."

    data_str_parts = []
    indices_to_display = ['NDVI', 'NDMI', 'EVI', 'SAVI']
    for idx in indices_to_display:
         curr_val = index_data.get(f'{idx}_curr')
         prev_val = index_data.get(f'{idx}_prev')

         if pd.notna(curr_val):
              line = f"- {idx} ŸÅÿπŸÑ€å: {curr_val:.3f}"
              if pd.notna(prev_val):
                  line += f" (ŸÇÿ®ŸÑ€å: {prev_val:.3f}"
                  change_percent = None
                  if pd.notna(prev_val) and prev_val != 0:
                      try:
                         change_percent = ((curr_val - prev_val) / prev_val) * 100
                      except Exception:
                         change_percent = None # Handle division by zero

                  if change_percent is not None:
                      line += f", ÿ™ÿ∫€å€åÿ±: {change_percent:.1f}%)"
                      # Provide context for change based on index type
                      change_status_desc = ""
                      if idx in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI']: # Higher is better
                           if change_percent > 3: change_status_desc = "ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá"
                           elif change_percent > 0: change_status_desc = "ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™"
                           elif change_percent < -5: change_status_desc = "ÿßŸÅÿ™ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá"
                           elif change_percent < 0: change_status_desc = "⁄©ÿßŸáÿ¥"
                           else: change_status_desc = "ÿ®ÿØŸàŸÜ ÿ™ÿ∫€å€åÿ± ŸÖÿπŸÜÿßÿØÿßÿ±" # Added "ŸÖÿπŸÜÿßÿØÿßÿ±"
                      elif idx == 'MSI': # Lower is better
                           if change_percent < -3: change_status_desc = "ÿ®Ÿáÿ®ŸàÿØ (⁄©ÿßŸáÿ¥ ÿ™ŸÜÿ¥ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá)"
                           elif change_percent < 0: change_status_desc = "ÿ®Ÿáÿ®ŸàÿØ (⁄©ÿßŸáÿ¥ ÿ™ŸÜÿ¥)"
                           elif change_percent > 5: change_status_desc = "ÿßŸÅÿ≤ÿß€åÿ¥ ÿ™ŸÜÿ¥ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá"
                           elif change_percent > 0: change_status_desc = "ÿßŸÅÿ≤ÿß€åÿ¥ ÿ™ŸÜÿ¥"
                           else: change_status_desc = "ÿ®ÿØŸàŸÜ ÿ™ÿ∫€å€åÿ± ŸÖÿπŸÜÿßÿØÿßÿ±"
                      elif idx == 'NDMI': # Higher is better
                           if change_percent > 3: change_status_desc = "ÿßŸÅÿ≤ÿß€åÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá"
                           elif change_percent > 0: change_status_desc = "ÿßŸÅÿ≤ÿß€åÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™"
                           elif change_percent < -5: change_status_desc = "⁄©ÿßŸáÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá"
                           elif change_percent < 0: change_status_desc = "⁄©ÿßŸáÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™"
                           else: change_status_desc = "ÿ±ÿ∑Ÿàÿ®ÿ™ ÿ´ÿßÿ®ÿ™"

                      if change_status_desc:
                           line += f" - {change_status_desc}"
                  else:
                      line += ")" # Close parenthesis if percentage change couldn't be calculated
              data_str_parts.append(line)
         elif pd.notna(prev_val):
              data_str_parts.append(f"- {idx} ŸÇÿ®ŸÑ€å: {prev_val:.3f} (ÿØÿßÿØŸá ŸÅÿπŸÑ€å ŸÖŸàÿ¨ŸàÿØ ŸÜ€åÿ≥ÿ™)")


    data_str = "\n".join(data_str_parts) if data_str_parts else "ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¥ÿßÿÆÿµ ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™."

    recommendations_str = "\n".join([f"- {rec}" for rec in recommendations]) if recommendations else 'Ÿá€å⁄Ü ÿ™Ÿàÿµ€åŸá‚Äåÿß€å ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸÇŸàÿßŸÜ€åŸÜ ÿßŸàŸÑ€åŸá Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ.'


    prompt = f"""
    ÿ¥ŸÖÿß €å⁄© ŸÖÿ™ÿÆÿµÿµ ⁄©ÿ¥ÿßŸàÿ±ÿ≤€å ÿ®ÿßÿ™ÿ¨ÿ±ÿ®Ÿá Ÿáÿ≥ÿ™€åÿØ ⁄©Ÿá ÿØÿ± ÿ≤ŸÖ€åŸÜŸá Ÿæÿß€åÿ¥ ŸÜ€åÿ¥⁄©ÿ± ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ÿ™ÿÆÿµÿµ ÿØÿßÿ±€åÿØ. ŸÑÿ∑ŸÅÿßŸã Ÿàÿ∂ÿπ€åÿ™ ŸÖÿ≤ÿ±ÿπŸá '{farm_name}' ÿ±ÿß ÿ®ÿß ÿ¨ÿ≤ÿ¶€åÿßÿ™ Ÿà ÿØŸÇÿ™ ÿ®€åÿ¥ÿ™ÿ±€å ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¥ÿßÿÆÿµ ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å Ÿà ÿ™Ÿàÿµ€åŸá‚ÄåŸáÿß€å ÿßŸàŸÑ€åŸá ÿ≤€åÿ± ÿ™ÿ≠ŸÑ€åŸÑ ⁄©ŸÜ€åÿØ. ÿ™ÿ≠ŸÑ€åŸÑ ÿ¥ŸÖÿß ÿ®ÿß€åÿØ ÿ¨ÿßŸÖÿπÿå ⁄©ÿßÿ±ÿ®ÿ±ÿØ€å Ÿà ŸÇÿßÿ®ŸÑ ÿßÿ±ÿßÿ¶Ÿá ÿ®Ÿá ŸÖÿØ€åÿ±ÿßŸÜ €åÿß ⁄©ÿßÿ±ÿ¥ŸÜÿßÿ≥ÿßŸÜ ⁄©ÿ¥ÿßŸàÿ±ÿ≤€å ÿ®ÿßÿ¥ÿØ. ÿ®Ÿá ÿßÿ±ÿ™ÿ®ÿßÿ∑ ÿ®€åŸÜ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß (ŸÖÿ´ŸÑÿßŸã NDMI Ÿà NDVI) Ÿà ŸÜ€åÿßÿ≤Ÿáÿß€å ÿßÿ≠ÿ™ŸÖÿßŸÑ€å ŸÖÿ≤ÿ±ÿπŸá (ÿ¢ÿ®€åÿßÿ±€åÿå ⁄©ŸàÿØÿØŸá€åÿå €åÿß ÿ≥ÿß€åÿ± ÿπŸàÿßŸÖŸÑ ÿ™ŸÜÿ¥‚Äåÿ≤ÿß) ÿßÿ¥ÿßÿ±Ÿá ⁄©ŸÜ€åÿØ. ÿ™ÿ≠ŸÑ€åŸÑ ÿ¥ŸÖÿß ÿ®ÿß€åÿØ ÿ¥ÿßŸÖŸÑ ŸÖŸàÿßÿ±ÿØ ÿ≤€åÿ± ÿ®ÿßÿ¥ÿØ:

    1.  **ÿßÿ±ÿ≤€åÿßÿ®€å Ÿàÿ∂ÿπ€åÿ™ ŸÅÿπŸÑ€å:** Ÿàÿ∂ÿπ€åÿ™ ÿ≥ŸÑÿßŸÖÿ™ ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿà ÿ±ÿ∑Ÿàÿ®ÿ™ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸÖŸÇÿßÿØ€åÿ± ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÅÿπŸÑ€å (NDVI, NDMI, EVI, SAVI). ŸÖŸÇÿß€åÿ≥Ÿá ŸÖŸÇÿßÿØ€åÿ± ÿ®ÿß ÿ¢ÿ≥ÿ™ÿßŸÜŸá‚ÄåŸáÿß€å ŸÖÿπŸÖŸàŸÑ ÿ®ÿ±ÿß€å ŸÜ€åÿ¥⁄©ÿ± (ÿß⁄Øÿ± ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿØÿßÿ±€åÿØ) ŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ŸÖŸÅ€åÿØ ÿ®ÿßÿ¥ÿØ.
    2.  **ÿ™ÿ≠ŸÑ€åŸÑ ÿ±ŸàŸÜÿØ:** ŸÖŸÇÿß€åÿ≥Ÿá ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÅÿπŸÑ€å ÿ®ÿß ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ Ÿà ÿ™Ÿàÿ∂€åÿ≠ ŸÖÿπÿßŸÜ€å ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÖÿ¥ÿßŸáÿØŸá ÿ¥ÿØŸá (ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™ÿå ⁄©ÿßŸáÿ¥ÿå ÿ™ŸÜÿ¥ÿå ÿ®Ÿáÿ®ŸàÿØ ÿ±ÿ∑Ÿàÿ®ÿ™ÿå ÿßŸÅÿ≤ÿß€åÿ¥ ÿ™ŸÜÿ¥ Ÿà...). ÿ®Ÿá ÿ®ÿ≤ÿ±⁄Ø€å ÿ™ÿ∫€å€åÿ±ÿßÿ™ (ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá €åÿß ÿ¨ÿ≤ÿ¶€å) ÿßÿ¥ÿßÿ±Ÿá ⁄©ŸÜ€åÿØ.
    3.  **ÿ¥ŸÜÿßÿ≥ÿß€å€å ŸÜ€åÿßÿ≤Ÿáÿß Ÿà ÿπŸàÿßŸÖŸÑ ÿ™ŸÜÿ¥‚Äåÿ≤ÿß:** ÿ®ÿß ÿ™Ÿàÿ¨Ÿá ÿ®Ÿá ŸÖŸÇÿßÿØ€åÿ± Ÿà ÿ±ŸàŸÜÿØ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿßÿå ÿ®Ÿá ŸÜ€åÿßÿ≤Ÿáÿß€å ÿßÿ≠ÿ™ŸÖÿßŸÑ€å (ÿ¢ÿ®€åÿßÿ±€å ÿß⁄Øÿ± NDMI Ÿæÿß€å€åŸÜ ÿßÿ≥ÿ™ €åÿß ⁄©ÿßŸáÿ¥ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá€å ÿØÿßÿ¥ÿ™Ÿáÿå ⁄©ŸàÿØÿØŸá€å ÿß⁄Øÿ± NDVI/EVI ⁄©ÿßŸáÿ¥ €åÿßŸÅÿ™Ÿá ÿ®ÿß Ÿàÿ¨ŸàÿØ ÿ±ÿ∑Ÿàÿ®ÿ™ ⁄©ÿßŸÅ€åÿå ÿ®ÿ±ÿ±ÿ≥€å ÿ¢ŸÅÿßÿ™ €åÿß ÿ®€åŸÖÿßÿ±€å‚ÄåŸáÿß ÿß⁄Øÿ± ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ÿ≥ŸÑÿßŸÖÿ™ ⁄©ÿßŸáÿ¥ €åÿßŸÅÿ™Ÿá Ÿà ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÖŸÜÿßÿ≥ÿ® ÿßÿ≥ÿ™ Ÿà...) ÿßÿ¥ÿßÿ±Ÿá ⁄©ŸÜ€åÿØ. ÿ™Ÿàÿµ€åŸá‚ÄåŸáÿß€å ÿßŸàŸÑ€åŸá (ÿ≥€åÿ≥ÿ™ŸÖ ŸÇŸàÿßŸÜ€åŸÜ ÿ≥ÿßÿØŸá) ÿ±ÿß ÿØÿ± ÿ™ÿ≠ŸÑ€åŸÑ ÿÆŸàÿØ ŸÑÿ≠ÿßÿ∏ ⁄©ŸÜ€åÿØ Ÿà ÿ¢ŸÜ‚ÄåŸáÿß ÿ±ÿß ÿ®ÿ≥ÿ∑ ÿØŸá€åÿØ.
    4.  **ÿ™Ÿàÿµ€åŸá‚ÄåŸáÿß€å ⁄©ŸÑ€å:** ÿßÿ±ÿßÿ¶Ÿá ÿ±ÿßŸáŸÜŸÖÿß€å€å ⁄©ŸÑ€å ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ™ÿ≠ŸÑ€åŸÑ ÿ®ÿ±ÿß€å ÿßŸÇÿØÿßŸÖÿßÿ™ ÿ®ÿπÿØ€å (ÿ®ÿßÿ≤ÿØ€åÿØ ŸÖ€åÿØÿßŸÜ€å ÿ®ÿß ÿ™ŸÖÿ±⁄©ÿ≤ ÿ®ÿ± ŸÜŸÇÿßÿ∑ ŸÖÿ¥⁄©ŸÑ‚ÄåÿØÿßÿ±ÿå ÿ™ŸÜÿ∏€åŸÖ ÿ®ÿ±ŸÜÿßŸÖŸá ÿ¢ÿ®€åÿßÿ±€å/⁄©ŸàÿØÿØŸá€åÿå ÿ®ÿ±ÿ±ÿ≥€å ÿπŸàÿßŸÖŸÑ ŸÖÿ≠€åÿ∑€å).
    5.  **€åÿßÿØÿØÿßÿ¥ÿ™ ŸÖŸáŸÖ:** ÿß⁄Øÿ± ÿØÿßÿØŸá‚ÄåŸáÿß€å ⁄©ÿßŸÅ€å (ŸÖÿ´ŸÑÿßŸã ÿØÿßÿØŸá ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ €åÿß ÿ¨ÿßÿ±€å) ŸÖŸàÿ¨ŸàÿØ ŸÜÿ®ŸàÿØÿå ÿ®Ÿá ÿß€åŸÜ ŸÖŸàÿ∂Ÿàÿπ ÿßÿ¥ÿßÿ±Ÿá ⁄©ŸÜ€åÿØ Ÿà ÿ∞⁄©ÿ± ⁄©ŸÜ€åÿØ ⁄©Ÿá ÿ™ÿ≠ŸÑ€åŸÑ ÿ±ŸàŸÜÿØ ÿØŸÇ€åŸÇ ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜ€åÿ≥ÿ™.

    ÿ≤ÿ®ÿßŸÜ ÿ™ÿ≠ŸÑ€åŸÑ ÿ®ÿß€åÿØ ŸÅÿßÿ±ÿ≥€åÿå ÿ™ÿÆÿµÿµ€å ÿßŸÖÿß ŸÇÿßÿ®ŸÑ ŸÅŸáŸÖ ÿ®ÿßÿ¥ÿØ.

    ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¥ÿßÿÆÿµ:
{data_str}

    ÿ™Ÿàÿµ€åŸá‚ÄåŸáÿß€å ÿßŸàŸÑ€åŸá (ÿ≥€åÿ≥ÿ™ŸÖ ŸÇŸàÿßŸÜ€åŸÜ ÿ≥ÿßÿØŸá):
{recommendations_str}

    ÿ™ÿ≠ŸÑ€åŸÑ ÿ¨ÿßŸÖÿπ ÿ¥ŸÖÿß:
    """

    try:
        response = _model.generate_content(prompt)
        if response.candidates and response.candidates[0].content.parts:
            return "".join([part.text for part in response.candidates[0].content.parts])
        elif response.prompt_feedback and response.prompt_feedback.block_reason:
             block_reason = response.prompt_feedback.block_reason.name
             st.warning(f"‚ö†Ô∏è Ÿæÿßÿ≥ÿÆ Gemini ÿ®Ÿá ÿØŸÑ€åŸÑ '{block_reason}' ŸÖÿ≥ÿØŸàÿØ ÿ¥ÿØ. Ÿæÿ±ÿßŸÖŸæÿ™ ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ®ÿßÿ≤ÿ®€åŸÜ€å ÿØÿßÿ¥ÿ™Ÿá ÿ®ÿßÿ¥ÿØ.")
             return "Ÿæÿßÿ≥ÿÆ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ŸÖÿ≥ÿØŸàÿØ ÿ¥ÿØ."
        else:
             st.warning("‚ö†Ô∏è Ÿæÿßÿ≥ÿÆ ŸÖÿπÿ™ÿ®ÿ±€å ÿßÿ≤ Gemini ÿØÿ±€åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
             return "Ÿæÿßÿ≥ÿÆ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™."

    except Exception as e:
        st.warning(f"‚ö†Ô∏è ÿÆÿ∑ÿß ÿØÿ± ÿßÿ±ÿ™ÿ®ÿßÿ∑ ÿ®ÿß Gemini API ŸáŸÜ⁄ØÿßŸÖ ÿ™ÿ≠ŸÑ€åŸÑ ŸÜ€åÿßÿ≤Ÿáÿß: {e}")
        st.warning(traceback.format_exc())
        return "ÿÆÿ∑ÿß ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å."


@st.cache_data(show_spinner="ÿØÿ± ÿ≠ÿßŸÑ ÿØÿ±€åÿßŸÅÿ™ ÿÆŸÑÿßÿµŸá ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ŸÜŸÇÿ¥Ÿá...", persist="disk")
def get_ai_map_summary(_model, ranking_df_sorted, selected_index, selected_day):
    """Generates AI summary for the overall map/ranking status."""
    if _model is None:
        return "ÿ≥ÿ±Ÿà€åÿ≥ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™."

    if ranking_df_sorted.empty:
        return "ÿØÿßÿØŸá‚Äåÿß€å ÿ®ÿ±ÿß€å ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å Ÿàÿ∂ÿπ€åÿ™ ŸÖÿ≤ÿßÿ±ÿπ ÿØÿ± ÿß€åŸÜ ÿ±Ÿàÿ≤ Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ."

    # Ensure these temporary copies are made if modifications are planned, though none are here
    negative_status_farms = ranking_df_sorted[ranking_df_sorted['Ÿàÿ∂ÿπ€åÿ™'].astype(str).str.contains("ÿ™ŸÜÿ¥|⁄©ÿßŸáÿ¥|ÿ®ÿØÿ™ÿ±|ŸÜ€åÿßÿ≤", case=False, na=False)]
    positive_status_farms = ranking_df_sorted[ranking_df_sorted['Ÿàÿ∂ÿπ€åÿ™'].astype(str).str.contains("ÿ®Ÿáÿ®ŸàÿØ|ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™", case=False, na=False)]
    nodata_farms = ranking_df_sorted[ranking_df_sorted['Ÿàÿ∂ÿπ€åÿ™'].astype(str).str.contains("ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá", case=False, na=False)]
    neutral_terms_list = ["ÿ´ÿßÿ®ÿ™", "ÿ±ÿ∑Ÿàÿ®ÿ™ ÿ´ÿßÿ®ÿ™", "ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿæÿß€å€åŸÜ", "ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá"] # Define list for neutral terms
    neutral_farms = ranking_df_sorted[ranking_df_sorted['Ÿàÿ∂ÿπ€åÿ™'].astype(str).str.contains("|".join(neutral_terms_list), case=False, na=False)] # Use list here


    summary_text = f"ÿÆŸÑÿßÿµŸá Ÿàÿ∂ÿπ€åÿ™ ⁄©ŸÑ€å ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ±ÿß€å ÿ±Ÿàÿ≤ {selected_day} ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ¥ÿßÿÆÿµ {selected_index}:\n"
    summary_text += f"ÿ™ÿπÿØÿßÿØ ⁄©ŸÑ ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ±ÿ±ÿ≥€å ÿ¥ÿØŸá: {len(ranking_df_sorted)}\n"
    summary_text += f"ÿ™ÿπÿØÿßÿØ ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿß Ÿàÿ∂ÿπ€åÿ™ 'ÿ™ŸÜÿ¥/⁄©ÿßŸáÿ¥/ŸÜ€åÿßÿ≤': {len(negative_status_farms)}\n"
    summary_text += f"ÿ™ÿπÿØÿßÿØ ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿß Ÿàÿ∂ÿπ€åÿ™ 'ÿ®Ÿáÿ®ŸàÿØ/ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™': {len(positive_status_farms)}\n"
    summary_text += f"ÿ™ÿπÿØÿßÿØ ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿß Ÿàÿ∂ÿπ€åÿ™ 'ÿ´ÿßÿ®ÿ™/ÿÆŸÜÿ´€å': {len(neutral_farms)}\n"
    summary_text += f"ÿ™ÿπÿØÿßÿØ ŸÖÿ≤ÿßÿ±ÿπ 'ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá': {len(nodata_farms)}\n\n"

    if not negative_status_farms.empty:
        summary_text += "ŸÖÿ≤ÿßÿ±ÿπ€å ⁄©Ÿá ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ™Ÿàÿ¨Ÿá ŸÅŸàÿ±€å ÿØÿßÿ±ŸÜÿØ (ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ÿ™ŸÜÿ¥ €åÿß ⁄©ÿßŸáÿ¥ÿå ÿ™ÿß €µ ŸÖÿ≤ÿ±ÿπŸá ÿßŸàŸÑ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ±ÿ™ÿ®Ÿá):\n"
        # Sort negative farms by rank to get the "top" problem farms
        top_problem_farms = negative_status_farms.sort_index().head(5) # Assuming index is rank

        for idx, row in top_problem_farms.iterrows():
            farm_name_ai = row.get('ŸÖÿ≤ÿ±ÿπŸá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')
            status_html_ai = row.get('Ÿàÿ∂ÿπ€åÿ™_ŸÜŸÖÿß€åÿ¥', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')
            # Clean HTML tags from status for AI prompt
            status_text_ai = status_html_ai.replace('<span class="status-badge status-positive">', '').replace('<span class="status-badge status-negative">', '').replace('<span class="status-badge status-neutral">', '').replace('<span class="status-badge status-nodata">', '').replace('</span>', '')

            current_index_val_ai = row.get(f'{selected_index} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)', 'N/A')
            change_val_ai = row.get('ÿ™ÿ∫€å€åÿ±', 'N/A')

            current_index_display = f"{float(str(current_index_val_ai).replace('N/A', 'nan')):.3f}" if pd.notna(current_index_val_ai) and str(current_index_val_ai) != 'N/A' else 'N/A'
            change_display = f"{float(str(change_val_ai).replace('N/A', 'nan')):.3f}" if pd.notna(change_val_ai) and str(change_val_ai) != 'N/A' else 'N/A'


            summary_text += f"- ÿ±ÿ™ÿ®Ÿá {idx}: ŸÖÿ≤ÿ±ÿπŸá {farm_name_ai}, Ÿàÿ∂ÿπ€åÿ™ {status_text_ai}, ÿ¥ÿßÿÆÿµ ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å: {current_index_display}, ÿ™ÿ∫€å€åÿ±: {change_display}\n"


    if not positive_status_farms.empty and len(positive_status_farms) > 0:
         summary_text += "\nŸÖÿ≤ÿßÿ±ÿπ€å ⁄©Ÿá Ÿàÿ∂ÿπ€åÿ™ ÿ®Ÿáÿ®ŸàÿØ €åÿßŸÅÿ™Ÿá €åÿß ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™ ŸÜÿ¥ÿßŸÜ ŸÖ€å‚ÄåÿØŸáŸÜÿØ (ÿ™ÿß €µ ŸÖÿ≤ÿ±ÿπŸá ÿßŸàŸÑ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ±ÿ™ÿ®Ÿá):\n"
         # Sort positive farms by rank to get the "top" improving farms
         top_improving_farms = positive_status_farms.sort_index().head(5) # Assuming index is rank

         for idx, row in top_improving_farms.iterrows():
             farm_name_ai = row.get('ŸÖÿ≤ÿ±ÿπŸá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')
             status_html_ai = row.get('Ÿàÿ∂ÿπ€åÿ™_ŸÜŸÖÿß€åÿ¥', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')
             status_text_ai = status_html_ai.replace('<span class="status-badge status-positive">', '').replace('<span class="status-badge status-negative">', '').replace('<span class="status-badge status-neutral">', '').replace('<span class="status-badge status-nodata">', '').replace('</span>', '')

             current_index_val_ai = row.get(f'{selected_index} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)', 'N/A')
             change_val_ai = row.get('ÿ™ÿ∫€å€åÿ±', 'N/A')

             current_index_display = f"{float(str(current_index_val_ai).replace('N/A', 'nan')):.3f}" if pd.notna(current_index_val_ai) and str(current_index_val_ai) != 'N/A' else 'N/A'
             change_display = f"{float(str(change_val_ai).replace('N/A', 'nan')):.3f}" if pd.notna(change_val_ai) and str(change_val_ai) != 'N/A' else 'N/A'

             summary_text += f"- ÿ±ÿ™ÿ®Ÿá {idx}: ŸÖÿ≤ÿ±ÿπŸá {farm_name_ai}, Ÿàÿ∂ÿπ€åÿ™ {status_text_ai}, ÿ¥ÿßÿÆÿµ ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å: {current_index_display}, ÿ™ÿ∫€å€åÿ±: {change_display}\n"


    prompt = f"""
    ÿ¥ŸÖÿß €å⁄© ÿ™ÿ≠ŸÑ€åŸÑ⁄Øÿ± ÿØÿßÿØŸá‚ÄåŸáÿß€å ⁄©ÿ¥ÿßŸàÿ±ÿ≤€å Ÿáÿ≥ÿ™€åÿØ Ÿà Ÿàÿ∏€åŸÅŸá ÿØÿßÿ±€åÿØ ÿÆŸÑÿßÿµŸá‚Äåÿß€å ⁄©ÿßÿ±ÿ®ÿ±ÿØ€å Ÿà ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿßÿ≤ Ÿàÿ∂ÿπ€åÿ™ ⁄©ŸÑ€å ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ÿßÿ±ÿßÿ¶Ÿá ÿØŸá€åÿØ. ÿß€åŸÜ ÿÆŸÑÿßÿµŸá ÿ®ÿß€åÿØ ÿ®Ÿá ŸÖÿØ€åÿ±ÿßŸÜ €åÿß ⁄©ÿßÿ±ÿ¥ŸÜÿßÿ≥ÿßŸÜ ⁄©ŸÖ⁄© ⁄©ŸÜÿØ ÿ™ÿß ÿ®Ÿá ÿ≥ÿ±ÿπÿ™ Ÿàÿ∂ÿπ€åÿ™ ⁄©ŸÑ€å ÿ±ÿß ÿØÿ±⁄© ⁄©ÿ±ÿØŸá Ÿà ŸÖÿ≤ÿßÿ±ÿπ ŸÜ€åÿßÿ≤ŸÖŸÜÿØ ÿßŸÇÿØÿßŸÖ ÿ±ÿß ÿ¥ŸÜÿßÿ≥ÿß€å€å ⁄©ŸÜŸÜÿØ.

    ÿÆŸÑÿßÿµŸá ÿ¥ŸÖÿß ÿ®ÿß€åÿØ ÿ¥ÿßŸÖŸÑ ŸÖŸàÿßÿ±ÿØ ÿ≤€åÿ± ÿ®ÿßÿ¥ÿØ:
    1.  **ÿ™ÿµŸà€åÿ± ⁄©ŸÑ€å:** ÿ™ÿπÿØÿßÿØ ŸÖÿ≤ÿßÿ±ÿπ ÿØÿ± Ÿáÿ± ÿØÿ≥ÿ™Ÿá Ÿàÿ∂ÿπ€åÿ™ (ÿ™ŸÜÿ¥/⁄©ÿßŸáÿ¥ÿå ÿ®Ÿáÿ®ŸàÿØ/ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™ÿå ÿ´ÿßÿ®ÿ™ÿå ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá) Ÿà ŸÖÿπŸÜ€å ⁄©ŸÑ€å ÿß€åŸÜ ÿ™Ÿàÿ≤€åÿπ ⁄Ü€åÿ≥ÿ™ÿü
    2.  **ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ≠ÿ±ÿßŸÜ€å:** ÿßÿ¥ÿßÿ±Ÿá ÿ®Ÿá ŸÖÿ≤ÿßÿ±ÿπ€å ⁄©Ÿá ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ÿ™ŸÜÿ¥ €åÿß ⁄©ÿßŸáÿ¥ ÿ±ÿß ŸÜÿ¥ÿßŸÜ ÿØÿßÿØŸá‚ÄåÿßŸÜÿØ (ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸÑ€åÿ≥ÿ™ ÿßÿ±ÿßÿ¶Ÿá ÿ¥ÿØŸá). ÿ®ÿß ÿ™Ÿàÿ¨Ÿá ÿ®Ÿá ÿ¥ÿßÿÆÿµ {selected_index}ÿå ⁄ÜŸá ŸÜŸàÿπ ÿ™ŸÜÿ¥€å (ŸÖÿ´ŸÑÿßŸã ÿ±ÿ∑Ÿàÿ®ÿ™€åÿå ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å) ŸÖÿ≠ÿ™ŸÖŸÑ ÿßÿ≥ÿ™ Ÿà ⁄ÜŸá ÿßŸÇÿØÿßŸÖÿßÿ™€å ÿ®ÿ±ÿß€å ÿß€åŸÜ ŸÖÿ≤ÿßÿ±ÿπ ÿ™Ÿàÿµ€åŸá ŸÖ€å‚Äåÿ¥ŸàÿØÿü (ÿ®ÿßÿ≤ÿØ€åÿØ ŸÖ€åÿØÿßŸÜ€å ÿ®ÿß ÿ™ŸÖÿ±⁄©ÿ≤ ÿ®ÿ± ŸÜŸÇÿßÿ∑ ŸÖÿ¥⁄©ŸÑ‚ÄåÿØÿßÿ±ÿå ÿ®ÿ±ÿ±ÿ≥€å ÿπŸàÿßŸÖŸÑ ÿ™ŸÜÿ¥‚Äåÿ≤ÿßÿå ÿ¢ÿ≤ŸÖÿß€åÿ¥ ÿÆÿß⁄©ÿå ÿ™ŸÜÿ∏€åŸÖ ÿ®ÿ±ŸÜÿßŸÖŸá ÿ¢ÿ®€åÿßÿ±€å/⁄©ŸàÿØÿØŸá€å).
    3.  **ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿß ÿπŸÖŸÑ⁄©ÿ±ÿØ ÿÆŸàÿ®:** ÿßÿ¥ÿßÿ±Ÿá ÿ®Ÿá ŸÖÿ≤ÿßÿ±ÿπ€å ⁄©Ÿá ÿ®Ÿáÿ®ŸàÿØ €åÿß ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™ ŸÜÿ¥ÿßŸÜ ÿØÿßÿØŸá‚ÄåÿßŸÜÿØ (ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸÑ€åÿ≥ÿ™ ÿßÿ±ÿßÿ¶Ÿá ÿ¥ÿØŸá). ÿ¢€åÿß ŸÖ€å‚Äåÿ™ŸàÿßŸÜ ÿßÿ≤ ÿØŸÑÿß€åŸÑ ŸÖŸàŸÅŸÇ€åÿ™ ÿß€åŸÜ ŸÖÿ≤ÿßÿ±ÿπ ÿØÿ± ÿ≥ÿß€åÿ± ŸÜŸÇÿßÿ∑ ÿßŸÑ⁄ØŸàÿ®ÿ±ÿØÿßÿ±€å ⁄©ÿ±ÿØÿü (ÿ®ÿ±ÿ±ÿ≥€å ÿ™ÿßÿ±€åÿÆ⁄ÜŸá ÿßŸÇÿØÿßŸÖÿßÿ™ ÿ≤ÿ±ÿßÿπ€å ÿØÿ± ÿß€åŸÜ ŸÖÿ≤ÿßÿ±ÿπ).
    4.  **ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÜÿßŸÖŸàÿ¨ŸàÿØ:** ÿ™Ÿàÿ∂€åÿ≠ ⁄©Ÿàÿ™ÿßŸá ÿØÿ± ŸÖŸàÿ±ÿØ ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá Ÿà ŸÑÿ≤ŸàŸÖ ÿ®ÿ±ÿ±ÿ≥€å ÿØÿ≥ÿ™€å €åÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿØ€å⁄Øÿ± ÿ®ÿ±ÿß€å ÿ¢ŸÜ‚ÄåŸáÿß.
    5.  **ÿßŸáŸÖ€åÿ™ ÿ¥ÿßÿÆÿµ:** €åÿßÿØÿ¢Ÿàÿ±€å ⁄©Ÿàÿ™ÿßŸá ÿØÿ± ŸÖŸàÿ±ÿØ ÿß€åŸÜ⁄©Ÿá ÿ¥ÿßÿÆÿµ {selected_index} ⁄ÜŸá ÿßÿ∑ŸÑÿßÿπÿßÿ™€å ÿ®Ÿá ŸÖÿß ŸÖ€å‚ÄåÿØŸáÿØ Ÿà ⁄Üÿ±ÿß ÿ®ÿ±ÿß€å Ÿæÿß€åÿ¥ ŸÖŸáŸÖ ÿßÿ≥ÿ™.

    ÿ≤ÿ®ÿßŸÜ ÿ™ÿ≠ŸÑ€åŸÑ ÿ®ÿß€åÿØ ŸÅÿßÿ±ÿ≥€å Ÿà ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿ®ÿßÿ¥ÿØ.

    ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿÆŸÑÿßÿµŸá ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å:
{summary_text}

    ÿÆŸÑÿßÿµŸá ÿ™ÿ≠ŸÑ€åŸÑ ÿ¨ÿßŸÖÿπ ÿ¥ŸÖÿß:
    """
    try:
        response = _model.generate_content(prompt)
        if response.candidates and response.candidates[0].content.parts:
            return "".join([part.text for part in response.candidates[0].content.parts])
        elif response.prompt_feedback and response.prompt_feedback.block_reason:
             block_reason = response.prompt_feedback.block_reason.name
             st.warning(f"‚ö†Ô∏è Ÿæÿßÿ≥ÿÆ Gemini ÿ®Ÿá ÿØŸÑ€åŸÑ '{block_reason}' ŸÖÿ≥ÿØŸàÿØ ÿ¥ÿØ.")
             return "ÿÆŸÑÿßÿµŸá ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ŸÖÿ≥ÿØŸàÿØ ÿ¥ÿØ."
        else:
             st.warning("‚ö†Ô∏è Ÿæÿßÿ≥ÿÆ ŸÖÿπÿ™ÿ®ÿ±€å ÿßÿ≤ Gemini ÿ®ÿ±ÿß€å ÿÆŸÑÿßÿµŸá ŸÜŸÇÿ¥Ÿá ÿØÿ±€åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
             return "ÿÆŸÑÿßÿµŸá ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™."
    except Exception as e:
        st.warning(f"‚ö†Ô∏è ÿÆÿ∑ÿß ÿØÿ± ÿßÿ±ÿ™ÿ®ÿßÿ∑ ÿ®ÿß Gemini API ŸáŸÜ⁄ØÿßŸÖ ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å ŸÜŸÇÿ¥Ÿá: {e}")
        st.warning(traceback.format_exc())
        return "ÿÆÿ∑ÿß ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿÆŸÑÿßÿµŸá ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ŸÜŸÇÿ¥Ÿá."


def determine_status(row, index_name):
    """Determines the status based on change in index value using fixed thresholds."""
    # Fixed Thresholds (Not visible to the user)
    NDMI_IRRIGATION_THRESHOLD = 0.25 # Example threshold for low NDMI
    NDVI_DROP_PERCENT_THRESHOLD = 5.0 # Example threshold for significant NDVI drop
    # General thresholds for change significance
    ABSOLUTE_CHANGE_THRESHOLD = 0.02 # Example absolute change for significance
    PERCENT_CHANGE_THRESHOLD = 3.0 # Example percentage change for positive significance
    NEGATIVE_PERCENT_CHANGE_THRESHOLD = 5.0 # Example percentage change for negative significance (can be different)


    current_val = row.get(f'{index_name} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)')
    previous_val = row.get(f'{index_name} (ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ)')
    change_val = row.get('ÿ™ÿ∫€å€åÿ±')

    # Ensure values are floats, handling possible string representations of None or N/A
    try:
        current_val_float = float(str(current_val).replace('N/A', 'nan').replace('None', 'nan'))
    except ValueError:
        current_val_float = np.nan
    try:
        previous_val_float = float(str(previous_val).replace('N/A', 'nan').replace('None', 'nan'))
    except ValueError:
        previous_val_float = np.nan
    try:
        change_val_float = float(str(change_val).replace('N/A', 'nan').replace('None', 'nan'))
    except ValueError:
         # Recalculate change_val_float if needed, based on raw floats
         if pd.notna(current_val_float) and pd.notna(previous_val_float):
              change_val_float = current_val_float - previous_val_float
         else:
              change_val_float = np.nan


    if pd.notna(current_val_float) and pd.notna(previous_val_float) and pd.notna(change_val_float):
        percentage_change = None
        if pd.notna(previous_val_float) and previous_val_float != 0:
            try:
                 percentage_change = (change_val_float / previous_val_float) * 100
            except Exception: # Handle division by zero or other issues
                 percentage_change = None


        is_significant_positive = change_val_float > ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change > PERCENT_CHANGE_THRESHOLD)
        is_significant_negative = change_val_float < -ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change < -NEGATIVE_PERCENT_CHANGE_THRESHOLD) # Use negative threshold

        if index_name in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI']:
            if is_significant_positive:
                return "ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™ / ÿ®Ÿáÿ®ŸàÿØ"
            elif is_significant_negative:
                return "ÿ™ŸÜÿ¥ / ⁄©ÿßŸáÿ¥"
            else:
                 return "ÿ´ÿßÿ®ÿ™"
        elif index_name in ['MSI']: # Lower MSI is better
             is_significant_improvement = change_val_float < -ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change < -NEGATIVE_PERCENT_CHANGE_THRESHOLD) # Negative change in MSI is improvement
             is_significant_deterioration = change_val_float > ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change > PERCENT_CHANGE_THRESHOLD) # Positive change in MSI is deterioration

             if is_significant_improvement:
                return "ÿ®Ÿáÿ®ŸàÿØ (⁄©ÿßŸáÿ¥ ÿ™ŸÜÿ¥)"
             elif is_significant_deterioration:
                return "ÿ™ŸÜÿ¥ (ÿßŸÅÿ≤ÿß€åÿ¥ MSI)"
             else:
                return "ÿ´ÿßÿ®ÿ™"
        elif index_name == 'NDMI': # Higher NDMI is better (more moisture)
             is_low_ndmi = pd.notna(current_val_float) and current_val_float <= NDMI_IRRIGATION_THRESHOLD
             is_significant_decrease = change_val_float < -ABSOLUTE_CHANGE_THRESHOLD or (percentage_change is not None and percentage_change < -NEGATIVE_PERCENT_CHANGE_THRESHOLD)


             if is_low_ndmi and is_significant_decrease:
                  return "ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å ÿ¥ÿØ€åÿØ / ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ¢ÿ®€åÿßÿ±€å"
             elif is_low_ndmi:
                  return "ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å / ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ¢ÿ®€åÿßÿ±€å"
             elif is_significant_decrease:
                  return "⁄©ÿßŸáÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá"
             elif is_significant_positive: # Significant increase in NDMI
                 return "ÿßŸÅÿ≤ÿß€åÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ / ÿ®Ÿáÿ®ŸàÿØ"
             else:
                  return "ÿ±ÿ∑Ÿàÿ®ÿ™ ÿ´ÿßÿ®ÿ™" # Within thresholds or slight non-significant change


        else:
            return "ŸÜÿßŸÖÿ¥ÿÆÿµ"
    elif pd.notna(current_val_float) and pd.isna(previous_val_float):
         # If current data exists but previous doesn't, check current against a fixed threshold if applicable
         if index_name == 'NDMI' and pd.notna(current_val_float) and current_val_float <= NDMI_IRRIGATION_THRESHOLD:
              return "ÿßÿ≠ÿ™ŸÖÿßŸÑ ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å (ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸÇÿ®ŸÑ)"
         # Add similar checks for low values of other indices if they indicate potential issues
         elif index_name in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI'] and pd.notna(current_val_float) and current_val_float <= 0.3: # Example low threshold for these indices
              return "ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿæÿß€å€åŸÜ (ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸÇÿ®ŸÑ)"
         else:
              return "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ"

    elif pd.isna(current_val_float) and pd.notna(previous_val_float):
         return "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å"
    else:
        return "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá"


# ==============================================================================
# Main Application Layout (Using Tabs)
# ==============================================================================

tab1, tab2, tab3 = st.tabs(["üìä Ÿæÿß€åÿ¥ ŸÖÿ≤ÿßÿ±ÿπ (ŸÜŸÇÿ¥Ÿá Ÿà ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å)", "üìà ÿ™ÿ≠ŸÑ€åŸÑ ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™", "üíß ÿ™ÿ≠ŸÑ€åŸÑ ŸÜ€åÿßÿ≤ ÿ¢ÿ®€åÿßÿ±€å Ÿà ⁄©ŸàÿØÿØŸá€å"])

with tab1:
    st.header("üìä Ÿæÿß€åÿ¥ ŸÖÿ≤ÿßÿ±ÿπ (ŸÜŸÇÿ¥Ÿá Ÿà ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å)")
    st.markdown("""
    <div style="text-align: justify; margin-bottom: 20px;">
    ÿØÿ± ÿß€åŸÜ ÿ®ÿÆÿ¥ ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ Ÿàÿ∂ÿπ€åÿ™ ÿ≥ŸÑÿßŸÖÿ™ Ÿà ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÖÿ≤ÿßÿ±ÿπ ÿ±ÿß ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ŸÖÿ¥ÿßŸáÿØŸá ⁄©ŸÜ€åÿØ. ŸÜŸÇÿ¥Ÿáÿå ÿ™Ÿàÿ≤€åÿπ ŸÖ⁄©ÿßŸÜ€å ÿ¥ÿßÿÆÿµ ÿßŸÜÿ™ÿÆÿßÿ®€å ÿ±ÿß ÿØÿ± ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å ŸÜŸÖÿß€åÿ¥ ŸÖ€å‚ÄåÿØŸáÿØ Ÿà ÿ¨ÿØŸàŸÑ ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€åÿå ŸÖŸÇÿß€åÿ≥Ÿá‚Äåÿß€å ÿ®ÿß ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ ÿßÿ±ÿßÿ¶Ÿá ŸÖ€å‚ÄåÿØŸáÿØ ÿ™ÿß ŸÖÿ≤ÿßÿ±ÿπ ŸÜ€åÿßÿ≤ŸÖŸÜÿØ ÿ™Ÿàÿ¨Ÿá ÿ®€åÿ¥ÿ™ÿ± ÿ±ÿß ÿ¥ŸÜÿßÿ≥ÿß€å€å ⁄©ŸÜ€åÿØ.
    </div>
    """, unsafe_allow_html=True)


    if farm_data_df.empty:
        st.error("‚ùå ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ŸÜÿ¥ÿØ €åÿß ÿÆÿßŸÑ€å ÿßÿ≥ÿ™. ŸÑÿ∑ŸÅÿßŸã ŸÅÿß€åŸÑ CSV ŸÖÿ≤ÿßÿ±ÿπ ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ.")
    elif filtered_farms_df.empty:
        st.warning("‚ö†Ô∏è Ÿá€å⁄Ü ŸÖÿ≤ÿ±ÿπŸá‚Äåÿß€å ÿ®ÿ±ÿß€å ÿ±Ÿàÿ≤ Ÿà ŸÅ€åŸÑÿ™ÿ±Ÿáÿß€å ÿßŸÜÿ™ÿÆÿßÿ®€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ŸÜŸÖÿß€åÿ¥ ŸÜŸÇÿ¥Ÿá Ÿà ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜ€åÿ≥ÿ™. ŸÑÿ∑ŸÅÿßŸã ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ±ÿπ €åÿß ŸÅ€åŸÑÿ™ÿ±Ÿáÿß€å ÿßŸÜÿ™ÿÆÿßÿ®€å ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ.")
    elif not gee_initialized:
         st.warning("‚ö†Ô∏è ÿßÿ™ÿµÿßŸÑ ÿ®Ÿá Google Earth Engine ÿ®ÿ±ŸÇÿ±ÿßÿ± ŸÜ€åÿ≥ÿ™. ŸÜŸÖÿß€åÿ¥ ŸÜŸÇÿ¥Ÿá Ÿà ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜŸÖ€å‚Äåÿ®ÿßÿ¥ÿØ.")
    else:
        selected_farm_details = None
        selected_farm_gee_geom = None
        center_lat = INITIAL_LAT
        center_lon = INITIAL_LON
        zoom_level = INITIAL_ZOOM
        is_single_farm = (selected_farm_name != "ŸáŸÖŸá ŸÖÿ≤ÿßÿ±ÿπ")

        if is_single_farm:
            selected_farm_details_list = filtered_farms_df[filtered_farms_df['ŸÖÿ≤ÿ±ÿπŸá'] == selected_farm_name]
            if not selected_farm_details_list.empty:
                 selected_farm_details = selected_farm_details_list.iloc[0]
                 lat = selected_farm_details.get('wgs84_centroid_lat')
                 lon = selected_farm_details.get('wgs84_centroid_lon')
                 selected_farm_gee_geom = selected_farm_details.get('ee_geometry')

                 if pd.notna(lat) and pd.notna(lon) and selected_farm_gee_geom is not None:
                     center_lat = lat
                     center_lon = lon
                     zoom_level = 14
                 else:
                      st.warning(f"‚ö†Ô∏è ŸÖÿÆÿ™ÿµÿßÿ™ WGS84 €åÿß ŸáŸÜÿØÿ≥Ÿá GEE ŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å ŸÖÿ≤ÿ±ÿπŸá '{selected_farm_name}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ŸÜŸÖÿß€åÿ¥ ŸÜŸÇÿ¥Ÿá ŸÖÿ≠ÿØŸàÿØ ÿÆŸàÿßŸáÿØ ÿ®ÿßÿ¥ÿØ.")
                      selected_farm_gee_geom = None


                 st.subheader(f"ÿ¨ÿ≤ÿ¶€åÿßÿ™ ŸÖÿ≤ÿ±ÿπŸá: {selected_farm_name} (ÿ±Ÿàÿ≤: {selected_day})")
                 details_cols = st.columns(3)
                 with details_cols[0]:
                     st.markdown(modern_metric_card("ŸÖÿ≥ÿßÿ≠ÿ™ ÿØÿßÿ¥ÿ™ (Ÿá⁄©ÿ™ÿßÿ±)", f"{selected_farm_details.get('ŸÖÿ≥ÿßÿ≠ÿ™', 'N/A'):,.2f}" if pd.notna(selected_farm_details.get('ŸÖÿ≥ÿßÿ≠ÿ™')) else "N/A", icon="fa-ruler-combined", color="#43cea2"), unsafe_allow_html=True)
                     st.markdown(modern_metric_card("Ÿàÿßÿ±€åÿ™Ÿá", f"{selected_farm_details.get('Ÿàÿßÿ±€åÿ™Ÿá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')}", icon="fa-seedling", color="#43cea2"), unsafe_allow_html=True)
                 with details_cols[1]:
                     st.markdown(modern_metric_card("⁄Øÿ±ŸàŸá", f"{selected_farm_details.get('⁄Øÿ±ŸàŸá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')}", icon="fa-users", color="#43cea2"), unsafe_allow_html=True)
                     st.markdown(modern_metric_card("ÿ≥ŸÜ", f"{selected_farm_details.get('ÿ≥ŸÜ', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')}", icon="fa-hourglass-half", color="#43cea2"), unsafe_allow_html=True)
                 with details_cols[2]:
                     st.markdown(modern_metric_card("ŸÖÿÆÿ™ÿµÿßÿ™", f"{lat:.5f}, {lon:.5f}" if pd.notna(lat) and pd.notna(lon) else "N/A", icon="fa-map-marker-alt", color="#43cea2"), unsafe_allow_html=True)
            else:
                 st.error(f"‚ùå ÿ¨ÿ≤ÿ¶€åÿßÿ™ ŸÖÿ≤ÿ±ÿπŸá '{selected_farm_name}' ÿØÿ± ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÅ€åŸÑÿ™ÿ± ÿ¥ÿØŸá €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
                 is_single_farm = False


        if not is_single_farm:
            all_farm_geometries = [geom for geom in filtered_farms_df['ee_geometry'] if geom is not None]
            if all_farm_geometries:
                try:
                    selected_farm_gee_geom = ee.Geometry.MultiPolygon(all_farm_geometries)
                    center = selected_farm_gee_geom.centroid(maxError=1).getInfo()['coordinates']
                    center_lon, center_lat = center[0], center[1]
                    bounds = selected_farm_gee_geom.bounds().getInfo()
                    
                    # Fix for bounds coordinates access
                    if 'coordinates' in bounds:
                        # New GEE API format uses 'coordinates'
                        coordinates = bounds['coordinates'][0]  # First polygon's coordinates
                        # Find min/max coordinates
                        lon_vals = [coord[0] for coord in coordinates]
                        lat_vals = [coord[1] for coord in coordinates]
                        lon_min, lon_max = min(lon_vals), max(lon_vals)
                        lat_min, lat_max = min(lat_vals), max(lat_vals)
                        lon_diff = lon_max - lon_min
                        lat_diff = lat_max - lat_min
                    elif 'even' in bounds:
                        # Old format
                        lon_diff = bounds['even'][2] - bounds['even'][0]
                        lat_diff = bounds['even'][3] - bounds['even'][1]
                    else:
                        # If both formats fail, extract coordinates differently
                        bbox = selected_farm_gee_geom.bounds().getInfo()
                        if isinstance(bbox, dict) and 'type' in bbox and bbox['type'] == 'Polygon':
                            coordinates = bbox['coordinates'][0]  # First polygon's coordinates
                            lon_vals = [coord[0] for coord in coordinates]
                            lat_vals = [coord[1] for coord in coordinates]
                            lon_min, lon_max = min(lon_vals), max(lon_vals)
                            lat_min, lat_max = min(lat_vals), max(lat_vals)
                            lon_diff = lon_max - lon_min
                            lat_diff = lat_max - lat_min
                        else:
                            # If we can't determine bounds, use default values
                            lon_diff = 1.0
                            lat_diff = 1.0
                            st.info("‚ÑπÔ∏è ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ŸÖŸÇÿßÿØ€åÿ± Ÿæ€åÿ¥‚ÄåŸÅÿ±ÿ∂ ÿ®ÿ±ÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ≤ŸàŸÖ ŸÜŸÇÿ¥Ÿá.")
                    
                    # Set zoom level based on the geographic extent
                    if max(lon_diff, lat_diff) > 10: zoom_level = 6
                    elif max(lon_diff, lat_diff) > 5: zoom_level = 8
                    elif max(lon_diff, lat_diff) > 2: zoom_level = 10
                    elif max(lon_diff, lat_diff) > 0.5: zoom_level = 12
                    else: zoom_level = 13

                except Exception as e:
                     st.warning(f"‚ö†Ô∏è ÿÆÿ∑ÿß ÿØÿ± ÿß€åÿ¨ÿßÿØ ŸáŸÜÿØÿ≥Ÿá GEE ÿ®ÿ±ÿß€å ŸáŸÖŸá ŸÖÿ≤ÿßÿ±ÿπ: {e}. ŸÜŸÇÿ¥Ÿá ÿ®ÿß ŸÖÿ±⁄©ÿ≤ Ÿæ€åÿ¥‚ÄåŸÅÿ±ÿ∂ ŸÜŸÖÿß€åÿ¥ ÿØÿßÿØŸá ŸÖ€å‚Äåÿ¥ŸàÿØ.")
                     selected_farm_gee_geom = None
            else:
                st.warning("‚ö†Ô∏è Ÿá€å⁄Ü ŸáŸÜÿØÿ≥Ÿá GEE ŸÖÿπÿ™ÿ®ÿ±€å ÿ®ÿ±ÿß€å ŸÖÿ≤ÿßÿ±ÿπ ÿßŸÜÿ™ÿÆÿßÿ®€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ŸÜŸÖÿß€åÿ¥ ŸÜŸÇÿ¥Ÿá ŸÖÿ≠ÿØŸàÿØ ÿÆŸàÿßŸáÿØ ÿ®ŸàÿØ.")
                selected_farm_gee_geom = None


            st.subheader(f"ŸÜŸÖÿß€åÿ¥ ⁄©ŸÑ€å ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ±ÿß€å ÿ±Ÿàÿ≤: {selected_day}")
            st.markdown(modern_metric_card("ÿ™ÿπÿØÿßÿØ ŸÖÿ≤ÿßÿ±ÿπ ÿØÿ± ÿß€åŸÜ ÿ±Ÿàÿ≤", f"{len(filtered_farms_df):,}", icon="fa-leaf", color="#185a9d"), unsafe_allow_html=True)
            st.caption("ÿ™ÿπÿØÿßÿØ ⁄©ŸÑ ŸÖÿ≤ÿßÿ±ÿπ ÿ´ÿ®ÿ™ ÿ¥ÿØŸá ÿ®ÿ±ÿß€å ÿ±Ÿàÿ≤ ÿßŸÜÿ™ÿÆÿßÿ® ÿ¥ÿØŸá.")

            if 'Ÿàÿßÿ±€åÿ™Ÿá' in filtered_farms_df.columns and not filtered_farms_df['Ÿàÿßÿ±€åÿ™Ÿá'].isna().all():
                variety_counts = filtered_farms_df[filtered_farms_df['Ÿàÿßÿ±€åÿ™Ÿá'].astype(str).str.lower() != 'ŸÜÿßŸÖÿ¥ÿÆÿµ']['Ÿàÿßÿ±€åÿ™Ÿá'].value_counts().sort_values(ascending=False)
                if not variety_counts.empty:
                     pie_df = pd.DataFrame({
                         'Ÿàÿßÿ±€åÿ™Ÿá': variety_counts.index,
                         'ÿ™ÿπÿØÿßÿØ ŸÖÿ≤ÿ±ÿπŸá': variety_counts.values
                     })
                     fig_pie = px.pie(pie_df, values='ÿ™ÿπÿØÿßÿØ ŸÖÿ≤ÿ±ÿπŸá', names='Ÿàÿßÿ±€åÿ™Ÿá',
                                       title=f'ÿØÿ±ÿµÿØ Ÿàÿßÿ±€åÿ™Ÿá‚ÄåŸáÿß ÿØÿ± ŸÖÿ≤ÿßÿ±ÿπ ÿ±Ÿàÿ≤ {selected_day}',
                                       hole=0.3)
                     fig_pie.update_traces(textposition='inside', textinfo='percent+label', insidetextorientation='radial')
                     fig_pie.update_layout(
                         showlegend=True,
                         height=400,
                         margin=dict(l=20, r=20, t=40, b=20),
                         paper_bgcolor='rgba(0,0,0,0)',
                         plot_bgcolor='rgba(0,0,0,0)'
                     )
                     st.plotly_chart(fig_pie, use_container_width=True)
                     st.caption("ÿØÿ±ÿµÿØ Ÿáÿ± Ÿàÿßÿ±€åÿ™Ÿá ÿßÿ≤ ⁄©ŸÑ ŸÖÿ≤ÿßÿ±ÿπ ÿ´ÿ®ÿ™ ÿ¥ÿØŸá ÿØÿ± ÿß€åŸÜ ÿ±Ÿàÿ≤.")
                else:
                    st.info("‚ö†Ô∏è ÿØÿßÿØŸá Ÿàÿßÿ±€åÿ™Ÿá ŸÖÿπÿ™ÿ®ÿ±€å ÿ®ÿ±ÿß€å ŸÜŸÖŸàÿØÿßÿ± ÿØÿ± ÿß€åŸÜ ÿ±Ÿàÿ≤ €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
            else:
                st.info("‚ö†Ô∏è ÿ≥ÿ™ŸàŸÜ Ÿàÿßÿ±€åÿ™Ÿá ÿØÿ± ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿß€åŸÜ ÿ±Ÿàÿ≤ Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ €åÿß ÿÆÿßŸÑ€å ÿßÿ≥ÿ™.")


        st.markdown("---")
        st.subheader("üó∫Ô∏è ŸÜŸÇÿ¥Ÿá Ÿàÿ∂ÿπ€åÿ™ ŸÖÿ≤ÿßÿ±ÿπ")
        st.markdown("ŸÜŸÇÿ¥Ÿáÿå ŸÖŸÇÿØÿßÿ± ÿ¥ÿßÿÆÿµ ÿßŸÜÿ™ÿÆÿßÿ®€å ÿ±ÿß ÿØÿ± ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å ŸÜŸÖÿß€åÿ¥ ŸÖ€å‚ÄåÿØŸáÿØ.")

        vis_params = {
            'NDVI': {'min': 0.1, 'max': 0.9, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
            'EVI': {'min': 0.1, 'max': 0.8, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
            'NDMI': {'min': -0.6, 'max': 0.6, 'palette': ['#b2182b', '#ef8a62', '#fddbc7', '#f7f7f7', '#d1e5f0', '#67a9cf', '#2166ac']},
            'LAI': {'min': 0, 'max': 6, 'palette': ['#f7f7f7', '#dcdcdc', '#babcba', '#8aae8b', '#5a9c5a', '#2a8a2a', '#006400']},
            'MSI': {'min': 0.6, 'max': 2.5, 'palette': ['#2166ac', '#67a9cf', '#d1e5f0', '#f7f7f7', '#fddbc7', '#ef8a62', '#b2182b']},
            'CVI_corrected_palette': {'min': 0, 'max': 20, 'palette': ['#ffffb2', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
            'SAVI': {'min': 0.1, 'max': 0.8, 'palette': ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']},
        }

        if selected_index == 'CVI':
            index_vis_params = vis_params['CVI_corrected_palette']
        else:
             index_vis_params = vis_params.get(selected_index, {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']})


        m = geemap.Map(
            location=[center_lat, center_lon],
            zoom=zoom_level,
            add_google_map=False
        )
        m.add_basemap("HYBRID")

        gee_image_current = None
        error_msg_current = None
        if gee_initialized and selected_farm_gee_geom is not None and start_date_current_str and end_date_current_str:
             with st.spinner(f"ÿØÿ± ÿ≠ÿßŸÑ ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿ™ÿµŸà€åÿ± ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ÿ¥ÿßÿÆÿµ {selected_index}..."):
                 gee_image_current, error_msg_current = get_processed_image(
                     selected_farm_gee_geom, start_date_current_str, end_date_current_str, selected_index
                 )

        if gee_image_current:
            try:
                m.addLayer(
                    gee_image_current,
                    index_vis_params,
                    f"{selected_index} ({start_date_current_str} ÿ™ÿß {end_date_current_str})"
                )

                farm_boundary_collection = ee.FeatureCollection([ee.Feature(geom) for geom in filtered_farms_df['ee_geometry'] if geom is not None])
                if not farm_boundary_collection.size().getInfo() == 0:
                     m.addLayer(
                         farm_boundary_collection,
                         {'color': 'yellow', 'fillColor': '00000000'},
                         'ŸÖÿ≠ÿØŸàÿØŸá ŸÖÿ≤ÿßÿ±ÿπ'
                     )
                else:
                     st.warning("‚ö†Ô∏è ŸáŸÜÿØÿ≥Ÿá ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ±ÿß€å ŸÜŸÖÿß€åÿ¥ ŸÑÿß€åŸá ŸÖÿ±ÿ≤€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")


                legend_title = f"ÿ±ÿßŸáŸÜŸÖÿß€å ÿ¥ÿßÿÆÿµ {selected_index}"
                legend_description = ""

                if selected_index in ['NDVI', 'EVI', 'LAI', 'CVI', 'SAVI']:
                     legend_description = "(ŸÜÿ¥ÿßŸÜ‚ÄåÿØŸáŸÜÿØŸá Ÿàÿ∂ÿπ€åÿ™ ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å/ÿ≥ŸÑÿßŸÖÿ™ÿå ŸÖŸÇÿßÿØ€åÿ± ÿ®ÿßŸÑÿßÿ™ÿ± ÿ®Ÿáÿ™ÿ± ÿßÿ≥ÿ™)"
                     palette_colors = index_vis_params.get('palette', ['red', 'yellow', 'green'])
                     color_low = palette_colors[0] if palette_colors else 'red'
                     color_mid = palette_colors[len(palette_colors)//2] if palette_colors else 'yellow'
                     color_high = palette_colors[-1] if palette_colors else 'green'
                     legend_text = f'''
                     <p style="margin: 0;"><span style="color: {color_low};">ŸÖŸÇÿØÿßÿ± ⁄©ŸÖ</span> / <span style="color: {color_mid};">ŸÖÿ™Ÿàÿ≥ÿ∑</span> / <span style="color: {color_high};">ŸÖŸÇÿØÿßÿ± ÿ≤€åÿßÿØ</span></p>
                     '''
                elif selected_index in ['NDMI']:
                     legend_description = "(ŸÜÿ¥ÿßŸÜ‚ÄåÿØŸáŸÜÿØŸá ÿ±ÿ∑Ÿàÿ®ÿ™ ÿÆÿß⁄©ÿå ŸÖŸÇÿßÿØ€åÿ± ÿ®ÿßŸÑÿßÿ™ÿ± ÿ®Ÿáÿ™ÿ± ÿßÿ≥ÿ™)"
                     palette_colors = index_vis_params.get('palette', ['brown', 'white', 'blue'])
                     color_low = palette_colors[0] if palette_colors else 'brown'
                     color_mid = palette_colors[len(palette_colors)//2] if palette_colors else 'white'
                     color_high = palette_colors[-1] if palette_colors else 'blue'
                     legend_text = f'''
                     <p style="margin: 0;"><span style="color: {color_low};">ÿÆÿ¥⁄© (⁄©ŸÖ)</span> / <span style="color: {color_mid};">ŸÖÿ™Ÿàÿ≥ÿ∑</span> / <span style="color: {color_high};">ŸÖÿ±ÿ∑Ÿàÿ® (ÿ≤€åÿßÿØ)</span></p>
                     '''
                elif selected_index in ['MSI']:
                     legend_description = "(ŸÜÿ¥ÿßŸÜ‚ÄåÿØŸáŸÜÿØŸá ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€åÿå ŸÖŸÇÿßÿØ€åÿ± Ÿæÿß€å€åŸÜ‚Äåÿ™ÿ± ÿ®Ÿáÿ™ÿ± ÿßÿ≥ÿ™)"
                     palette_colors = index_vis_params.get('palette', ['blue', 'white', 'brown'])
                     color_low = palette_colors[0] if palette_colors else 'blue'
                     color_mid = palette_colors[len(palette_colors)//2] if palette_colors else 'white'
                     color_high = palette_colors[-1] if palette_colors else 'brown'
                     legend_text = f'''
                     <p style="margin: 0;"><span style="color: {color_low};">ŸÖÿ±ÿ∑Ÿàÿ® (⁄©ŸÖ)</span> / <span style="color: {color_mid};">ŸÖÿ™Ÿàÿ≥ÿ∑</span> / <span style="color: {color_high};">ÿÆÿ¥⁄© (ÿ≤€åÿßÿØ)</span></p>
                     '''
                else:
                    legend_text = '''
                    <p style="margin: 0;">ÿ±ÿßŸáŸÜŸÖÿß€å ŸÖŸÇÿßÿØ€åÿ± ÿ¥ÿßÿÆÿµ</p>
                    '''

                legend_html = f'''
                <div style="position: fixed; bottom: 50px; right: 10px; z-index: 1000; background-color: rgba(255, 255, 255, 0.9); padding: 10px; border: 1px solid grey; border-radius: 8px; font-family: Vazirmatn, sans-serif; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                    <p style="margin: 0;"><strong>{legend_title}</strong></p>
                    {legend_text}
                    <p style="margin: 0; font-size: 0.8em; opacity: 0.8;">{legend_description}</p>
                </div>
                '''
                m.get_root().html.add_child(folium.Element(legend_html))

                ranking_df_map_popups = pd.DataFrame()
                if not is_single_farm and start_date_current_str and end_date_current_str and start_date_previous_str and end_date_previous_str:
                     with st.spinner("ÿØÿ± ÿ≠ÿßŸÑ ÿ¢ŸÖÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿßÿ∑ŸÑÿßÿπÿßÿ™ ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ±ÿß€å ŸÜŸÖÿß€åÿ¥ ÿØÿ± ŸæÿßŸæ‚Äåÿ¢Ÿæ‚ÄåŸáÿß€å ŸÜŸÇÿ¥Ÿá..."):
                         # Re-calculate indices for popups only if not single farm, to save computation
                         # This calculation is parallelized within the function if possible
                         ranking_df_map_popups, popup_calculation_errors = calculate_weekly_indices_for_table(
                              filtered_farms_df,
                              selected_index,
                              start_date_current_str,
                              end_date_current_str,
                              start_date_previous_str,
                              end_date_previous_str
                         )
                         if popup_calculation_errors:
                             st.warning("‚ö†Ô∏è ÿ®ÿ±ÿÆ€å ÿÆÿ∑ÿßŸáÿß ÿØÿ± ÿ≠€åŸÜ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß ÿ®ÿ±ÿß€å ŸæÿßŸæ‚Äåÿ¢Ÿæ‚ÄåŸáÿß€å ŸÜŸÇÿ¥Ÿá ÿ±ÿÆ ÿØÿßÿØ (ÿ™ÿß €µ ÿÆÿ∑ÿß):")
                             for error in popup_calculation_errors[:5]: st.warning(f"- {error}")


                if not filtered_farms_df.empty:
                     for idx, farm in filtered_farms_df.iterrows():
                          lat = farm.get('wgs84_centroid_lat')
                          lon = farm.get('wgs84_centroid_lon')

                          if pd.notna(lat) and pd.notna(lon):
                               farm_name = farm.get('ŸÖÿ≤ÿ±ÿπŸá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')
                               group = farm.get('⁄Øÿ±ŸàŸá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')
                               age = farm.get('ÿ≥ŸÜ', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')
                               variety = farm.get('Ÿàÿßÿ±€åÿ™Ÿá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ')

                               current_index_val = 'N/A'
                               previous_index_val = 'N/A'
                               change_val_display = 'N/A'
                               status_text = "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá"

                               # Get data for popup: use ranking_df if single farm, or ranking_df_map_popups if all farms
                               farm_data_for_popup = None
                               if is_single_farm and 'ranking_df' in locals() and not ranking_df.empty:
                                    farm_data_for_popup_list = ranking_df[ranking_df['ŸÖÿ≤ÿ±ÿπŸá'] == farm_name]
                                    if not farm_data_for_popup_list.empty:
                                         farm_data_for_popup = farm_data_for_popup_list.iloc[0]
                               elif not is_single_farm and not ranking_df_map_popups.empty:
                                    farm_data_for_popup_list = ranking_df_map_popups[ranking_df_map_popups['ŸÖÿ≤ÿ±ÿπŸá'] == farm_name]
                                    if not farm_data_for_popup_list.empty:
                                        farm_data_for_popup = farm_data_for_popup_list.iloc[0]


                               if farm_data_for_popup is not None:
                                    current_index_val_raw = farm_data_for_popup.get(f'{selected_index} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)')
                                    previous_index_val_raw = farm_data_for_popup.get(f'{selected_index} (ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ)')
                                    change_val_raw = farm_data_for_popup.get('ÿ™ÿ∫€å€åÿ±')

                                    # Format for display, handling None/N/A/nan
                                    current_index_val = f"{float(str(current_index_val_raw).replace('N/A', 'nan').replace('None', 'nan')):.3f}" if pd.notna(current_index_val_raw) and str(current_index_val_raw) != 'N/A' and str(current_index_val_raw) != 'None' else 'N/A'
                                    previous_index_val = f"{float(str(previous_index_val_raw).replace('N/A', 'nan').replace('None', 'nan')):.3f}" if pd.notna(previous_index_val_raw) and str(previous_index_val_raw) != 'N/A' and str(previous_index_val_raw) != 'None' else 'N/A'
                                    change_val_display = f"{float(str(change_val_raw).replace('N/A', 'nan').replace('None', 'nan')):.3f}" if pd.notna(change_val_raw) and str(change_val_raw) != 'N/A' and str(change_val_raw) != 'None' else 'N/A'

                                    status_text = determine_status(farm_data_for_popup, selected_index)
                               else:
                                   # If no data found for this farm in the ranking/popup df, try getting just the current value
                                   try:
                                       point_geom_single = ee.Geometry.Point([lon, lat])
                                       current_img_single, err_single = get_processed_image(point_geom_single, start_date_current_str, end_date_current_str, selected_index)
                                       if current_img_single:
                                           current_val_single = current_img_single.reduceRegion(
                                               reducer=ee.Reducer.first(),
                                               geometry=point_geom_single,
                                               scale=10,
                                               bestEffort=True
                                           ).get(selected_index).getInfo()
                                           current_index_val = f"{float(str(current_val_single).replace('None', 'nan')):.3f}" if pd.notna(current_val_single) and str(current_val_single) != 'None' else 'N/A'
                                           status_text = "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ" if pd.notna(current_val_single) else "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá"
                                       else:
                                            status_text = "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá"
                                            if err_single: print(f"Error getting single farm current index for popup ({farm_name}): {err_single}")
                                   except Exception as e:
                                       print(f"Error getting single farm current index for popup ({farm_name}): {e}")
                                       status_text = "ÿÆÿ∑ÿß ÿØÿ± ÿØÿßÿØŸá"


                               popup_html = f"""
                               <strong>ŸÖÿ≤ÿ±ÿπŸá:</strong> {farm_name}<br>
                               <strong>⁄Øÿ±ŸàŸá:</strong> {group}<br>
                               <strong>ÿ≥ŸÜ:</strong> {age}<br>
                               <strong>Ÿàÿßÿ±€åÿ™Ÿá:</strong> {variety}<br>
                               ---<br>
                               <strong>{selected_index} (ÿ¨ÿßÿ±€å):</strong> {current_index_val} <br>
                               <strong>{selected_index} (ŸÇÿ®ŸÑ€å):</strong> {previous_index_val} <br>
                               <strong>ÿ™ÿ∫€å€åÿ±:</strong> {change_val_display} <br>
                               <strong>Ÿàÿ∂ÿπ€åÿ™:</strong> {status_text}
                               """

                               marker_icon = 'info-sign'
                               marker_color = 'blue'
                               if is_single_farm:
                                    marker_icon = 'star'
                                    marker_color = 'red'

                               folium.Marker(
                                   location=[lat, lon],
                                   popup=folium.Popup(popup_html, max_width=300),
                                   tooltip=farm_name,
                                   icon=folium.Icon(color=marker_color, icon=marker_icon, prefix='fa')
                               ).add_to(m)


                m.add_layer_control()

            except Exception as map_err:
                st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿßŸÅÿ≤ŸàÿØŸÜ ŸÑÿß€åŸá GEE ÿ®Ÿá ŸÜŸÇÿ¥Ÿá: {map_err}")
                st.error(traceback.format_exc())
        else:
            st.warning(f"‚ö†Ô∏è ÿ™ÿµŸà€åÿ±€å ÿ®ÿ±ÿß€å ŸÜŸÖÿß€åÿ¥ ÿ¥ÿßÿÆÿµ {selected_index} ÿ±Ÿà€å ŸÜŸÇÿ¥Ÿá ÿØÿ± ÿ®ÿßÿ≤Ÿá ŸÅÿπŸÑ€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ({error_msg_current})")


        map_placeholder = st.empty()
        with map_placeholder:
             st_folium(m, width=None, height=500, use_container_width=True)

        st.caption("ÿ®ÿ±ÿß€å ŸÖÿ¥ÿßŸáÿØŸá ÿ¨ÿ≤ÿ¶€åÿßÿ™ ÿ±Ÿà€å ŸÖÿßÿ±⁄©ÿ±Ÿáÿß ⁄©ŸÑ€å⁄© ⁄©ŸÜ€åÿØ. ÿßÿ≤ ⁄©ŸÜÿ™ÿ±ŸÑ ŸÑÿß€åŸá‚ÄåŸáÿß ÿØÿ± ÿ≥ŸÖÿ™ ÿ±ÿßÿ≥ÿ™ ÿ®ÿßŸÑÿß ÿ®ÿ±ÿß€å ÿ™ÿ∫€å€åÿ± ŸÜŸÇÿ¥Ÿá Ÿæÿß€åŸá Ÿà ŸÑÿß€åŸá ÿ¥ÿßÿÆÿµ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ.")
        st.info("üí° ÿ®ÿ±ÿß€å ÿ∞ÿÆ€åÿ±Ÿá ŸÜŸÇÿ¥Ÿáÿå ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ÿßÿ≤ ÿßÿ®ÿ≤ÿßÿ± ÿπ⁄©ÿ≥ ⁄Øÿ±ŸÅÿ™ŸÜ ÿßÿ≤ ÿµŸÅÿ≠Ÿá (Screenshot) ŸÖÿ±Ÿàÿ±⁄Øÿ± €åÿß ÿ≥€åÿ≥ÿ™ŸÖ ÿπÿßŸÖŸÑ ÿÆŸàÿØ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ.")


        st.markdown("---")
        st.subheader(f"üìà ŸÜŸÖŸàÿØÿßÿ± ÿ±ŸàŸÜÿØ ÿ≤ŸÖÿßŸÜ€å ÿ¥ÿßÿÆÿµ {selected_index}")
        st.markdown("ÿ±ŸàŸÜÿØ ÿ™ÿ∫€å€åÿ±ÿßÿ™ ÿ¥ÿßÿÆÿµ ÿßŸÜÿ™ÿÆÿßÿ®€å ÿ®ÿ±ÿß€å ŸÖÿ≤ÿ±ÿπŸá ÿØÿ± €å⁄© ÿ≥ÿßŸÑ ⁄Øÿ∞ÿ¥ÿ™Ÿá (ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ™ÿµÿßŸà€åÿ± ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ÿ®ÿØŸàŸÜ ÿßÿ®ÿ±).")

        if not is_single_farm:
            st.info("‚ÑπÔ∏è ŸÑÿ∑ŸÅÿßŸã €å⁄© ŸÖÿ≤ÿ±ÿπŸá ÿÆÿßÿµ ÿ±ÿß ÿßÿ≤ ŸæŸÜŸÑ ⁄©ŸÜÿßÿ±€å ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ ÿ™ÿß ŸÜŸÖŸàÿØÿßÿ± ÿ±ŸàŸÜÿØ ÿ≤ŸÖÿßŸÜ€å ÿ¢ŸÜ ŸÜŸÖÿß€åÿ¥ ÿØÿßÿØŸá ÿ¥ŸàÿØ.")
        elif not gee_initialized:
             st.warning("‚ö†Ô∏è ÿßÿ™ÿµÿßŸÑ ÿ®Ÿá Google Earth Engine ÿ®ÿ±ŸÇÿ±ÿßÿ± ŸÜ€åÿ≥ÿ™. ŸÜŸÖŸàÿØÿßÿ± ÿ±ŸàŸÜÿØ ÿ≤ŸÖÿßŸÜ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜŸÖ€å‚Äåÿ®ÿßÿ¥ÿØ.")
        elif selected_farm_details is None or pd.isna(selected_farm_details.get('wgs84_centroid_lat')) or pd.isna(selected_farm_details.get('wgs84_centroid_lon')):
             st.warning(f"‚ö†Ô∏è ŸÖÿÆÿ™ÿµÿßÿ™ WGS84 ŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å ŸÖÿ≤ÿ±ÿπŸá '{selected_farm_name}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ŸÜŸÖŸàÿØÿßÿ± ÿ±ŸàŸÜÿØ ÿ≤ŸÖÿßŸÜ€å ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜ€åÿ≥ÿ™.")
        else:
             point_geom_ts = ee.Geometry.Point([selected_farm_details['wgs84_centroid_lon'], selected_farm_details['wgs84_centroid_lat']])

             timeseries_end_date = today.strftime('%Y-%m-%d')
             timeseries_start_date = (today - datetime.timedelta(days=365)).strftime('%Y-%m-%d')

             ts_df, ts_error = get_index_time_series(
                 point_geom_ts,
                 selected_index,
                 start_date=timeseries_start_date,
                 end_date=timeseries_end_date
             )

             if ts_error:
                 st.warning(f"‚ö†Ô∏è ÿÆÿ∑ÿß ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å: {ts_error}")
             elif not ts_df.empty:
                 fig_ts = px.line(ts_df, y=selected_index, title=f'ÿ±ŸàŸÜÿØ ÿ≤ŸÖÿßŸÜ€å ÿ¥ÿßÿÆÿµ {selected_index} ÿ®ÿ±ÿß€å ŸÖÿ≤ÿ±ÿπŸá {selected_farm_name}')
                 fig_ts.update_layout(
                     xaxis_title="ÿ™ÿßÿ±€åÿÆ",
                     yaxis_title=selected_index,
                     hovermode="x unified",
                     margin=dict(l=20, r=20, t=40, b=20),
                     paper_bgcolor='rgba(0,0,0,0)',
                     plot_bgcolor='rgba(0,0,0,0)'
                 )
                 st.plotly_chart(fig_ts, use_container_width=True)
                 st.caption(f"ŸÜŸÖŸàÿØÿßÿ± ÿ™ÿ∫€å€åÿ±ÿßÿ™ ÿ¥ÿßÿÆÿµ {selected_index} ÿ®ÿ±ÿß€å ŸÖÿ≤ÿ±ÿπŸá {selected_farm_name} ÿØÿ± €å⁄© ÿ≥ÿßŸÑ ⁄Øÿ∞ÿ¥ÿ™Ÿá (ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ™ÿµÿßŸà€åÿ± ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ÿ®ÿØŸàŸÜ ÿßÿ®ÿ±).")
             else:
                 st.info(f"‚ÑπÔ∏è ÿØÿßÿØŸá‚Äåÿß€å ÿ®ÿ±ÿß€å ŸÜŸÖÿß€åÿ¥ ŸÜŸÖŸàÿØÿßÿ± ÿ≥ÿ±€å ÿ≤ŸÖÿßŸÜ€å ÿ¥ÿßÿÆÿµ {selected_index} ÿØÿ± ÿ®ÿßÿ≤Ÿá ŸÖÿ¥ÿÆÿµ ÿ¥ÿØŸá €åÿßŸÅÿ™ ŸÜÿ¥ÿØ (ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ÿ®Ÿá ÿØŸÑ€åŸÑ ŸæŸàÿ¥ÿ¥ ÿßÿ®ÿ±€å ŸÖÿØÿßŸàŸÖ).")


        st.markdown("---")
        st.subheader(f"üìä ÿ¨ÿØŸàŸÑ ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ŸÖÿ≤ÿßÿ±ÿπ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ {selected_index} (ÿ±Ÿàÿ≤: {selected_day})")
        st.markdown("ŸÖŸÇÿß€åÿ≥Ÿá ŸÖŸÇÿßÿØ€åÿ± ŸÖÿ™Ÿàÿ≥ÿ∑ ÿ¥ÿßÿÆÿµ ÿØÿ± ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å ÿ®ÿß ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ Ÿà ÿ™ÿπ€å€åŸÜ Ÿàÿ∂ÿπ€åÿ™ Ÿáÿ± ŸÖÿ≤ÿ±ÿπŸá.")

        @st.cache_data(show_spinner=False, persist="disk")
        def calculate_weekly_indices_for_table(
            _farms_df, index_name, start_curr, end_curr, start_prev, end_prev
        ):
            results = []
            errors = []
            total_farms = len(_farms_df)
            progress_placeholder = st.empty()


            for i, (idx, farm) in enumerate(_farms_df.iterrows()):
                farm_name = farm.get('ŸÖÿ≤ÿ±ÿπŸá', f'ŸÖÿ≤ÿ±ÿπŸá ŸÜÿßÿ¥ŸÜÿßÿ≥ ÿ±ÿØ€åŸÅ {i+1}')
                farm_gee_geom = farm.get('ee_geometry')

                if farm_gee_geom is None:
                    errors.append(f"ŸáŸÜÿØÿ≥Ÿá GEE ŸÜÿßŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å ŸÖÿ≤ÿ±ÿπŸá '{farm_name}'. ŸÜÿßÿØ€åÿØŸá ⁄Øÿ±ŸÅÿ™Ÿá ÿ¥ÿØ.")
                    results.append({
                         'ŸÖÿ≤ÿ±ÿπŸá': farm_name,
                         '⁄Øÿ±ŸàŸá': farm.get('⁄Øÿ±ŸàŸá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ'),
                         f'{index_name} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)': None,
                         f'{index_name} (ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ)': None,
                         'ÿ™ÿ∫€å€åÿ±': None,
                         'ÿ≥ŸÜ': farm.get('ÿ≥ŸÜ', 'ŸÜÿßŸÖÿ¥ÿÆÿµ'),
                         'Ÿàÿßÿ±€åÿ™Ÿá': farm.get('Ÿàÿßÿ±€åÿ™Ÿá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ'),
                     })
                    progress = (i + 1) / total_farms
                    progress_placeholder.markdown(modern_progress_bar(progress), unsafe_allow_html=True)
                    continue

                def get_mean_value_single_index(start, end, index):
                     try:
                          image, error = get_processed_image(farm_gee_geom, start, end, index)
                          if image:
                              # Select the band explicitly before reducing to avoid projection issues
                              mean_dict = image.select(index).reduceRegion(
                                  reducer=ee.Reducer.mean(),
                                  geometry=farm_gee_geom,
                                  scale=10,
                                  bestEffort=True,
                                  maxPixels=1e8
                              ).get(index).getInfo()
                              return mean_dict, None
                          else:
                              return None, error
                     except ee.EEException as e:
                          # Check for common errors and provide more specific messages
                          error_message = f"GEE Error for {farm_name} ({start}-{end}): {e}"
                          try:
                               error_details = e.args[0] if e.args else str(e)
                               if isinstance(error_details, str) and 'computation timed out' in error_details.lower():
                                   error_message += "\n(ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ÿ®Ÿá ÿØŸÑ€åŸÑ ÿ≠ÿ¨ŸÖ ÿ®ÿßŸÑÿß€å Ÿæÿ±ÿØÿßÿ≤ÿ¥ €åÿß ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ÿ∑ŸàŸÑÿßŸÜ€å)"
                               elif isinstance(error_details, str) and 'user memory limit exceeded' in error_details.lower():
                                   error_message += "\n(ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ÿ®Ÿá ÿØŸÑ€åŸÑ Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸÖŸÜÿ∑ŸÇŸá ÿ®ÿ≤ÿ±⁄Ø €åÿß ÿπŸÖŸÑ€åÿßÿ™ Ÿæ€å⁄Ü€åÿØŸá)"
                               elif isinstance(error_details, str) and 'Image.projection: The bands of the specified image contains different projections' in error_details:
                                    error_message += "\n(ÿÆÿ∑ÿß€å Ÿæÿ±Ÿàÿ¨⁄©ÿ¥ŸÜ ÿØÿßÿÆŸÑ€å ÿØÿ± GEE. ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ®ÿß ÿ™ŸÑÿßÿ¥ ŸÖÿ¨ÿØÿØ €åÿß ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ŸÖÿ™ŸÅÿßŸàÿ™ ÿ®ÿ±ÿ∑ÿ±ŸÅ ÿ¥ŸàÿØ.)"
                          except Exception:
                               pass
                          return None, error_message
                     except Exception as e:
                          return None, f"Unknown Error for {farm_name} ({start}-{end}): {e}"


                current_val, err_curr = get_mean_value_single_index(start_curr, end_curr, index_name)
                if err_curr: errors.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}' (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å): {err_curr}")

                previous_val, err_prev = get_mean_value_single_index(start_prev, end_prev, index_name)
                if err_prev: errors.append(f"ŸÖÿ≤ÿ±ÿπŸá '{farm_name}' (ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ): {err_prev}")

                change = None
                if pd.notna(current_val) and pd.notna(previous_val):
                    try:
                        change = current_val - previous_val
                    except TypeError:
                        change = None


                results.append({
                    'ŸÖÿ≤ÿ±ÿπŸá': farm_name,
                    '⁄Øÿ±ŸàŸá': farm.get('⁄Øÿ±ŸàŸá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ'),
                    f'{index_name} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)': current_val, # Store raw numerical value here
                    f'{index_name} (ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ)': previous_val, # Store raw numerical value here
                    'ÿ™ÿ∫€å€åÿ±': change, # Store raw numerical value here
                    'ÿ≥ŸÜ': farm.get('ÿ≥ŸÜ', 'ŸÜÿßŸÖÿ¥ÿÆÿµ'),
                    'Ÿàÿßÿ±€åÿ™Ÿá': farm.get('Ÿàÿßÿ±€åÿ™Ÿá', 'ŸÜÿßŸÖÿ¥ÿÆÿµ'),
                })

                progress = (i + 1) / total_farms
                progress_placeholder.markdown(modern_progress_bar(progress), unsafe_allow_html=True)

            progress_placeholder.empty()
            return pd.DataFrame(results), errors

        ranking_df = pd.DataFrame()
        calculation_errors = []

        if gee_initialized and start_date_current_str and end_date_current_str and start_date_previous_str and end_date_previous_str and not filtered_farms_df.empty:
             ranking_df, calculation_errors = calculate_weekly_indices_for_table(
                 filtered_farms_df,
                 selected_index,
                 start_date_current_str,
                 end_date_current_str,
                 start_date_previous_str,
                 end_date_previous_str
             )
        elif not gee_initialized:
             st.warning("‚ö†Ô∏è ÿßÿ™ÿµÿßŸÑ ÿ®Ÿá Google Earth Engine ÿ®ÿ±ŸÇÿ±ÿßÿ± ŸÜ€åÿ≥ÿ™. ÿ¨ÿØŸàŸÑ ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜŸÖ€å‚Äåÿ®ÿßÿ¥ÿØ.")
        elif filtered_farms_df.empty:
             st.warning("‚ö†Ô∏è Ÿá€å⁄Ü ŸÖÿ≤ÿ±ÿπŸá‚Äåÿß€å ÿ®ÿ±ÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
        else:
             st.warning("‚ö†Ô∏è ÿ®ÿßÿ≤Ÿá‚ÄåŸáÿß€å ÿ≤ŸÖÿßŸÜ€å ŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")


        if calculation_errors:
            st.warning("‚ö†Ô∏è ÿ®ÿ±ÿÆ€å ÿÆÿ∑ÿßŸáÿß ÿØÿ± ÿ≠€åŸÜ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß ÿ®ÿ±ÿß€å ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ÿ±ÿÆ ÿØÿßÿØ (ÿ™ÿß €±€∞ ÿÆÿ∑ÿß):")
            for error in calculation_errors[:10]:
                st.warning(f"- {error}")
            if len(calculation_errors) > 10:
                st.warning(f"... Ÿà {len(calculation_errors) - 10} ÿÆÿ∑ÿß€å ÿØ€å⁄Øÿ±.")


        if not ranking_df.empty:
            ascending_sort = selected_index == 'MSI'

            sort_col_name_raw = f'{selected_index} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)'

            if sort_col_name_raw in ranking_df.columns:
                # Sort directly on the raw numerical column (which might have None/NaN)
                # Use 'na_position' to control where missing values appear
                ranking_df_sorted = ranking_df.sort_values(
                    by=sort_col_name_raw,
                    ascending=ascending_sort,
                    na_position='last' # Place missing values at the end
                ).reset_index(drop=True)
            else:
                 st.warning(f"‚ö†Ô∏è ÿ≥ÿ™ŸàŸÜ '{sort_col_name_raw}' ÿ®ÿ±ÿß€å ŸÖÿ±ÿ™ÿ®‚Äåÿ≥ÿßÿ≤€å ÿ¨ÿØŸàŸÑ €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")
                 ranking_df_sorted = ranking_df.copy()


            if not ranking_df_sorted.empty:
                 ranking_df_sorted.index = ranking_df_sorted.index + 1
                 ranking_df_sorted.index.name = 'ÿ±ÿ™ÿ®Ÿá'

                 # Calculate status AFTER sorting, based on the sorted data (which has raw numbers)
                 ranking_df_sorted['Ÿàÿ∂ÿπ€åÿ™'] = ranking_df_sorted.apply(
                     lambda row: determine_status(row, selected_index), axis=1
                 )

                 ranking_df_sorted['Ÿàÿ∂ÿπ€åÿ™_ŸÜŸÖÿß€åÿ¥'] = ranking_df_sorted['Ÿàÿ∂ÿπ€åÿ™'].apply(lambda s: status_badge(s))

                 # Format the numerical columns for display AFTER status calculation and sorting
                 cols_to_format = [f'{selected_index} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)', f'{selected_index} (ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ)', 'ÿ™ÿ∫€å€åÿ±']
                 for col in cols_to_format:
                     if col in ranking_df_sorted.columns:
                          # Convert numerical values to formatted strings, leaving None/NaN as N/A
                          ranking_df_sorted[col] = ranking_df_sorted[col].apply(lambda x: f"{x:.3f}" if pd.notna(x) else "N/A")


                 display_columns = ['ŸÖÿ≤ÿ±ÿπŸá', '⁄Øÿ±ŸàŸá', 'ÿ≥ŸÜ', 'Ÿàÿßÿ±€åÿ™Ÿá'] + cols_to_format + ['Ÿàÿ∂ÿπ€åÿ™_ŸÜŸÖÿß€åÿ¥']
                 final_display_columns = [col for col in display_columns if col in ranking_df_sorted.columns]

                 ranking_df_display = ranking_df_sorted[final_display_columns].rename(columns={'Ÿàÿ∂ÿπ€åÿ™_ŸÜŸÖÿß€åÿ¥': 'Ÿàÿ∂ÿπ€åÿ™'})

                 st.write("<style>td {vertical-align: middle !important;}</style>", unsafe_allow_html=True)
                 st.write(ranking_df_display.to_html(escape=False, index=True), unsafe_allow_html=True)

                 st.subheader("üìä ÿÆŸÑÿßÿµŸá Ÿàÿ∂ÿπ€åÿ™ ŸÖÿ≤ÿßÿ±ÿπ (ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å)")

                 status_counts = ranking_df_sorted['Ÿàÿ∂ÿπ€åÿ™'].value_counts()

                 # Define groups based on keywords
                 positive_terms = [s for s in status_counts.index if "ÿ®Ÿáÿ®ŸàÿØ" in s or "ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™" in s or "ÿßŸÅÿ≤ÿß€åÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™" in s]
                 negative_terms = [s for s in status_counts.index if any(sub in s for sub in ["ÿ™ŸÜÿ¥", "⁄©ÿßŸáÿ¥", "ÿ®ÿØÿ™ÿ±", "ŸÜ€åÿßÿ≤"])]
                 neutral_terms = [s for s in status_counts.index if any(sub in s for sub in ["ÿ´ÿßÿ®ÿ™", "ÿ±ÿ∑Ÿàÿ®ÿ™ ÿ´ÿßÿ®ÿ™", "ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿæÿß€å€åŸÜ", "ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá"])] # Added 'ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá' for NDMI decrease
                 nodata_terms = [s for s in status_counts.index if "ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá" in s or "N/A" in s] # Added N/A for completeness

                 col1, col2, col3, col4 = st.columns(4)

                 with col1:
                     pos_count = sum(status_counts.get(term, 0) for term in positive_terms)
                     st.metric("üü¢ ÿ®Ÿáÿ®ŸàÿØ", pos_count)

                 with col2:
                     neutral_count = sum(status_counts.get(term, 0) for term in neutral_terms)
                     st.metric("‚ö™ ÿ´ÿßÿ®ÿ™", neutral_count)

                 with col3:
                     neg_count = sum(status_counts.get(term, 0) for term in negative_terms)
                     st.metric("üî¥ ÿ™ŸÜÿ¥", neg_count)

                 with col4:
                      nodata_count = sum(status_counts.get(term, 0) for term in nodata_terms)
                      st.metric("üü° ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá", nodata_count)

                 st.info(f"""
                 **ÿ™Ÿàÿ∂€åÿ≠ÿßÿ™ Ÿàÿ∂ÿπ€åÿ™:**
                 - **üü¢ ÿ®Ÿáÿ®ŸàÿØ/ÿ±ÿ¥ÿØ ŸÖÿ´ÿ®ÿ™**: ŸÖÿ≤ÿßÿ±ÿπ€å ⁄©Ÿá ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ ÿ®Ÿáÿ®ŸàÿØ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá€å ÿØÿßÿ¥ÿ™Ÿá‚ÄåÿßŸÜÿØ (ÿßŸÅÿ≤ÿß€åÿ¥ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å€å ŸÖÿßŸÜŸÜÿØ NDVI €åÿß ⁄©ÿßŸáÿ¥ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å€å ŸÖÿßŸÜŸÜÿØ MSI) €åÿß ÿßŸÅÿ≤ÿß€åÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÜÿ¥ÿßŸÜ ŸÖ€å‚ÄåÿØŸáŸÜÿØ.
                 - **‚ö™ ÿ´ÿßÿ®ÿ™**: ŸÖÿ≤ÿßÿ±ÿπ€å ⁄©Ÿá ÿ™ÿ∫€å€åÿ± ŸÖÿπŸÜÿßÿØÿßÿ±€å ÿØÿ± ÿ¥ÿßÿÆÿµ ŸÜÿØÿßÿ¥ÿ™Ÿá‚ÄåÿßŸÜÿØ (ÿØÿ±ŸàŸÜ ÿ¢ÿ≥ÿ™ÿßŸÜŸá ÿ™ÿ∫€å€åÿ±) €åÿß Ÿàÿ∂ÿπ€åÿ™ Ÿæÿß€åÿØÿßÿ±€å ÿØÿßÿ±ŸÜÿØ (ŸÖÿ´ŸÑ ÿ±ÿ∑Ÿàÿ®ÿ™ ÿ´ÿßÿ®ÿ™ €åÿß ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿæÿß€å€åŸÜ ÿ®ÿØŸàŸÜ ÿ™ÿ∫€å€åÿ±). ÿ¥ÿßŸÖŸÑ ⁄©ÿßŸáÿ¥‚ÄåŸáÿß€å ÿ±ÿ∑Ÿàÿ®ÿ™ ⁄©Ÿá ÿ®Ÿá ÿ≠ÿØ ÿ™ŸÜÿ¥ ŸÜÿ±ÿ≥€åÿØŸá‚ÄåÿßŸÜÿØ.
                 - **üî¥ ÿ™ŸÜÿ¥/⁄©ÿßŸáÿ¥/ÿ®ÿØÿ™ÿ± ÿ¥ÿØŸÜ**: ŸÖÿ≤ÿßÿ±ÿπ€å ⁄©Ÿá ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ Ÿàÿ∂ÿπ€åÿ™ ŸÜÿßŸÖÿ∑ŸÑŸàÿ®‚Äåÿ™ÿ±€å ÿØÿßÿ¥ÿ™Ÿá‚ÄåÿßŸÜÿØ (⁄©ÿßŸáÿ¥ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å€å ŸÖÿßŸÜŸÜÿØ NDVI €åÿß ÿßŸÅÿ≤ÿß€åÿ¥ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å€å ŸÖÿßŸÜŸÜÿØ MSI) €åÿß ŸÜ€åÿßÿ≤ ÿ¢ÿ®€åÿßÿ±€å/⁄©ŸàÿØ€å ÿ™ÿ¥ÿÆ€åÿµ ÿØÿßÿØŸá ÿ¥ÿØŸá ÿßÿ≥ÿ™. ÿ¥ÿßŸÖŸÑ ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å €åÿß ⁄©ÿßŸáÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá.
                 - **üü° ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá**: ŸÖÿ≤ÿßÿ±ÿπ€å ⁄©Ÿá ÿ®Ÿá ÿØŸÑ€åŸÑ ÿπÿØŸÖ ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿ®Ÿá ÿ™ÿµÿßŸà€åÿ± ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ÿ®ÿØŸàŸÜ ÿßÿ®ÿ± ÿØÿ± €å⁄© €åÿß Ÿáÿ± ÿØŸà ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€åÿå ÿßŸÖ⁄©ÿßŸÜ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿ™ÿ∫€å€åÿ±ÿßÿ™ Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ¥ÿ™Ÿá ÿßÿ≥ÿ™.
                 """)

                 st.markdown("---")
                 st.subheader("ü§ñ ÿÆŸÑÿßÿµŸá ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿßÿ≤ Ÿàÿ∂ÿπ€åÿ™ ŸÖÿ≤ÿßÿ±ÿπ")
                 if gemini_model:
                      with st.spinner("ÿØÿ± ÿ≠ÿßŸÑ ÿ™ŸàŸÑ€åÿØ ÿÆŸÑÿßÿµŸá ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å..."):
                          ai_map_summary = get_ai_map_summary(gemini_model, ranking_df_sorted, selected_index, selected_day)
                      st.markdown(ai_map_summary)
                 else:
                      st.info("‚ö†Ô∏è ÿ≥ÿ±Ÿà€åÿ≥ ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å Ÿæ€å⁄©ÿ±ÿ®ŸÜÿØ€å ŸÜÿ¥ÿØŸá €åÿß ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")

                 ranking_df_clean = ranking_df_sorted.drop(columns=['Ÿàÿ∂ÿπ€åÿ™_ŸÜŸÖÿß€åÿ¥'], errors='ignore')
                 # Format numerical columns back to string for CSV export if desired, or keep as numbers
                 # Let's keep them as numbers for potential further analysis outside the app
                 csv_data = ranking_df_clean.to_csv(index=True).encode('utf-8')
                 st.download_button(
                     label="üì• ÿØÿßŸÜŸÑŸàÿØ ÿ¨ÿØŸàŸÑ ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å (CSV)",
                     data=csv_data,
                     file_name=f'ranking_{selected_index}_{selected_day}_{end_date_current_str}.csv',
                     mime='text/csv',
                 )
            else:
                 st.info("‚ö†Ô∏è ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¨ÿØŸàŸÑ ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å Ÿæÿ≥ ÿßÿ≤ ŸÖÿ±ÿ™ÿ®‚Äåÿ≥ÿßÿ≤€å ÿÆÿßŸÑ€å ÿßÿ≥ÿ™. ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ŸÖÿ¥⁄©ŸÑ€å ÿØÿ± ÿØÿßÿØŸá‚ÄåŸáÿß€å Ÿàÿ±ŸàÿØ€å €åÿß ŸÖÿ±ÿ™ÿ®‚Äåÿ≥ÿßÿ≤€å Ÿàÿ¨ŸàÿØ ÿØÿßÿ¥ÿ™Ÿá ÿ®ÿßÿ¥ÿØ.")
        else:
            st.info(f"‚ÑπÔ∏è ÿØÿßÿØŸá‚Äåÿß€å ÿ®ÿ±ÿß€å ÿ¨ÿØŸàŸÑ ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ¥ÿßÿÆÿµ {selected_index} ÿØÿ± ÿß€åŸÜ ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ (ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ÿ®Ÿá ÿØŸÑ€åŸÑ ÿπÿØŸÖ ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿ®Ÿá ÿ™ÿµÿßŸà€åÿ± ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ÿ®ÿØŸàŸÜ ÿßÿ®ÿ±).")


    st.markdown("---")


with tab2:
    st.header("üìà ÿ™ÿ≠ŸÑ€åŸÑ ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÅÿß€åŸÑ ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™")
    st.markdown("""
    <div style="text-align: justify; margin-bottom: 20px;">
    ÿØÿ± ÿß€åŸÜ ÿ®ÿÆÿ¥ ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿ¥ÿØŸá ÿßÿ≤ ŸÅÿß€åŸÑ ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ ŸÖÿ≥ÿßÿ≠ÿ™ Ÿà ÿ™ŸàŸÑ€åÿØ ÿ±ÿß ÿ®Ÿá‚ÄåÿµŸàÿ±ÿ™ ŸÜŸÖŸàÿØÿßÿ±Ÿáÿß€å ÿ™ÿπÿßŸÖŸÑ€å ŸÖÿ¥ÿßŸáÿØŸá ⁄©ŸÜ€åÿØ. ÿß€åŸÜ ŸÜŸÖŸàÿØÿßÿ±Ÿáÿß ÿ™Ÿàÿ≤€åÿπ ŸÖÿ≥ÿßÿ≠ÿ™ Ÿà ÿ™ŸàŸÑ€åÿØ ÿ±ÿß ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿßÿØÿßÿ±Ÿáÿå ÿ≥ŸÜ Ÿà Ÿàÿßÿ±€åÿ™Ÿá ŸÜŸÖÿß€åÿ¥ ŸÖ€å‚ÄåÿØŸáŸÜÿØ.
    </div>
    """, unsafe_allow_html=True)


    if analysis_area_df is None and analysis_prod_df is None:
        st.error("‚ùå ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ÿßÿ≤ ŸÅÿß€åŸÑ 'ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ 2.csv' ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å €åÿß Ÿæÿ±ÿØÿßÿ≤ÿ¥ ŸÜÿ¥ÿØŸÜÿØ. ŸÑÿ∑ŸÅÿßŸã ŸÅÿß€åŸÑ ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ.")
    else:
        available_edareh = []
        if analysis_area_df is not None and 'ÿßÿØÿßÿ±Ÿá' in analysis_area_df.index.names:
            available_edareh.extend(analysis_area_df.index.get_level_values('ÿßÿØÿßÿ±Ÿá').unique().tolist())
        if analysis_prod_df is not None and 'ÿßÿØÿßÿ±Ÿá' in analysis_prod_df.index.names:
            available_edareh.extend(analysis_prod_df.index.get_level_values('ÿßÿØÿßÿ±Ÿá').unique().tolist())

        available_edareh = sorted(list(set(e for e in available_edareh if e is not None)))

        if not available_edareh:
            st.warning("‚ö†Ô∏è Ÿá€å⁄Ü ÿßÿØÿßÿ±Ÿá‚Äåÿß€å ÿ®ÿ±ÿß€å ŸÜŸÖÿß€åÿ¥ ÿØÿ± ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ™ÿ≠ŸÑ€åŸÑ€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. ŸÑÿ∑ŸÅÿßŸã ÿ≥ÿßÿÆÿ™ÿßÿ± ŸÅÿß€åŸÑ 'ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ 2.csv' ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ.")
        else:
            selected_edareh = st.selectbox(
                "ÿßÿØÿßÿ±Ÿá ŸÖŸàÿ±ÿØ ŸÜÿ∏ÿ± ÿ±ÿß ÿ®ÿ±ÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ:",
                options=available_edareh,
                key='analysis_edareh_select'
            )

            st.subheader(f"ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿßÿØÿßÿ±Ÿá: {selected_edareh}")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### ŸÖÿ≥ÿßÿ≠ÿ™ (Ÿá⁄©ÿ™ÿßÿ±)")
                if analysis_area_df is not None and selected_edareh in analysis_area_df.index.get_level_values('ÿßÿØÿßÿ±Ÿá').unique():
                    try:
                        df_area_selected = analysis_area_df.loc[selected_edareh].copy()

                        ages = df_area_selected.index.tolist()
                        varieties = df_area_selected.columns.tolist()
                        z_data = df_area_selected.values

                        if len(ages) > 1 and len(varieties) > 1 and z_data.shape[0] > 1 and z_data.shape[1] > 1:
                             try:
                                 fig_3d_area = go.Figure(data=[go.Surface(z=z_data, x=ages, y=varieties, colorscale='Viridis')])
                                 fig_3d_area.update_layout(
                                     title=f'ŸÜŸÖŸàÿØÿßÿ± ÿ≥ÿ∑ÿ≠ ŸÖÿ≥ÿßÿ≠ÿ™ - ÿßÿØÿßÿ±Ÿá {selected_edareh}',
                                     scene=dict(
                                         xaxis_title='ÿ≥ŸÜ',
                                         yaxis_title='Ÿàÿßÿ±€åÿ™Ÿá',
                                         zaxis_title='ŸÖÿ≥ÿßÿ≠ÿ™ (Ÿá⁄©ÿ™ÿßÿ±)'),
                                     autosize=True, height=500,
                                     margin=dict(l=0, r=0, t=40, b=0),
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
                                 )
                                 st.plotly_chart(fig_3d_area, use_container_width=True)
                                 st.caption("ŸÜŸÖÿß€åÿ¥ ÿ™Ÿàÿ≤€åÿπ ŸÖÿ≥ÿßÿ≠ÿ™ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ≥ŸÜ Ÿà Ÿàÿßÿ±€åÿ™Ÿá ÿØÿ± €å⁄© ÿ≥ÿ∑ÿ≠ ÿ≥Ÿá ÿ®ÿπÿØ€å ÿ™ÿπÿßŸÖŸÑ€å.")
                             except Exception as e:
                                 st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿß€åÿ¨ÿßÿØ ŸÜŸÖŸàÿØÿßÿ± Surface Plot ŸÖÿ≥ÿßÿ≠ÿ™: {e}")
                                 st.dataframe(df_area_selected)
                        else:
                             st.info("‚ÑπÔ∏è ÿØÿßÿØŸá ⁄©ÿßŸÅ€å ÿ®ÿ±ÿß€å ÿ±ÿ≥ŸÖ ŸÜŸÖŸàÿØÿßÿ± Surface Plot ŸÖÿ≥ÿßÿ≠ÿ™ Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ (ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ®€åÿ¥ ÿßÿ≤ €å⁄© ŸÖŸÇÿØÿßÿ± ÿ≥ŸÜ Ÿà €å⁄© Ÿàÿßÿ±€åÿ™Ÿá ÿ®ÿß ÿØÿßÿØŸá).")
                             st.dataframe(df_area_selected)


                        if 'ÿ≥ŸÜ' in df_area_selected.index.names:
                             df_area_melt = df_area_selected.reset_index().melt(id_vars='ÿ≥ŸÜ', var_name='Ÿàÿßÿ±€åÿ™Ÿá', value_name='ŸÖÿ≥ÿßÿ≠ÿ™')
                        else:
                              st.warning("‚ö†Ô∏è ÿ≥ÿßÿÆÿ™ÿßÿ± ÿØÿßÿØŸá ŸÖÿ≥ÿßÿ≠ÿ™ ÿ®ÿ±ÿß€å Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ÿ∫€åÿ±ŸÖŸÜÿ™ÿ∏ÿ±Ÿá ÿßÿ≥ÿ™. ŸÜŸÖÿß€åÿ¥ Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜ€åÿ≥ÿ™.")
                              df_area_melt = pd.DataFrame()

                        df_area_melt = df_area_melt.dropna(subset=['ŸÖÿ≥ÿßÿ≠ÿ™', 'Ÿàÿßÿ±€åÿ™Ÿá', 'ÿ≥ŸÜ'])
                        df_area_melt = df_area_melt[pd.to_numeric(df_area_melt['ÿ≥ŸÜ'], errors='coerce').notna()]


                        if not df_area_melt.empty:
                            try:
                                fig_hist_area = px.histogram(df_area_melt, x='Ÿàÿßÿ±€åÿ™Ÿá', y='ŸÖÿ≥ÿßÿ≠ÿ™', color='ÿ≥ŸÜ',
                                                           title=f'Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ŸÖÿ≥ÿßÿ≠ÿ™ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ Ÿàÿßÿ±€åÿ™Ÿá Ÿà ÿ≥ŸÜ - ÿßÿØÿßÿ±Ÿá {selected_edareh}',
                                                           labels={'ŸÖÿ≥ÿßÿ≠ÿ™':'ŸÖÿ¨ŸÖŸàÿπ ŸÖÿ≥ÿßÿ≠ÿ™ (Ÿá⁄©ÿ™ÿßÿ±)'},
                                                           barmode='group',
                                                           text_auto=True)
                                fig_hist_area.update_layout(
                                     margin=dict(l=0, r=0, t=40, b=0),
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
                                )
                                st.plotly_chart(fig_hist_area, use_container_width=True)
                                st.caption("ÿ™Ÿàÿ≤€åÿπ ŸÖÿ≥ÿßÿ≠ÿ™ Ÿáÿ± Ÿàÿßÿ±€åÿ™Ÿá ÿ®Ÿá ÿ™ŸÅ⁄©€å⁄© ÿ≥ŸÜ.")
                            except Exception as e:
                                 st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿß€åÿ¨ÿßÿØ ŸÜŸÖŸàÿØÿßÿ± Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ŸÖÿ≥ÿßÿ≠ÿ™: {e}")
                                 st.dataframe(df_area_selected)
                        else:
                             st.info(f"‚ÑπÔ∏è ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ±€å ÿ®ÿ±ÿß€å Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ŸÖÿ≥ÿßÿ≠ÿ™ ÿØÿ± ÿßÿØÿßÿ±Ÿá {selected_edareh} €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")

                    except KeyError:
                        st.error(f"‚ùå ÿÆÿ∑ÿß€å ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿ®Ÿá ÿØÿßÿØŸá ÿßÿØÿßÿ±Ÿá '{selected_edareh}' ÿØÿ± ÿØÿßÿØŸá ŸÖÿ≥ÿßÿ≠ÿ™. ŸÑÿ∑ŸÅÿßŸã ÿ≥ÿ™ŸàŸÜ 'ÿßÿØÿßÿ±Ÿá' ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ.")
                    except Exception as e:
                         st.error(f"‚ùå ÿÆÿ∑ÿß€å ÿ∫€åÿ±ŸÖŸÜÿ™ÿ∏ÿ±Ÿá ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿØÿßÿØŸá ŸÖÿ≥ÿßÿ≠ÿ™ ÿ®ÿ±ÿß€å ÿßÿØÿßÿ±Ÿá '{selected_edareh}': {e}")
                         st.error(traceback.format_exc())

                else:
                    st.info(f"‚ö†Ô∏è ÿØÿßÿØŸá ŸÖÿ≥ÿßÿ≠ÿ™ ÿ®ÿ±ÿß€å ÿßÿØÿßÿ±Ÿá {selected_edareh} €åÿßŸÅÿ™ ŸÜÿ¥ÿØ €åÿß ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ŸÜÿ¥ÿØŸá ÿßÿ≥ÿ™.")

            with col2:
                st.markdown("#### ÿ™ŸàŸÑ€åÿØ (ÿ™ŸÜ)")
                if analysis_prod_df is not None and selected_edareh in analysis_prod_df.index.get_level_values('ÿßÿØÿßÿ±Ÿá').unique():
                    try:
                        df_prod_selected = analysis_prod_df.loc[selected_edareh].copy()

                        ages_prod = df_prod_selected.index.tolist()
                        varieties_prod = df_prod_selected.columns.tolist()
                        z_data_prod = df_prod_selected.values

                        if len(ages_prod) > 1 and len(varieties_prod) > 1 and z_data_prod.shape[0] > 1 and z_data_prod.shape[1] > 1:
                             try:
                                 fig_3d_prod = go.Figure(data=[go.Surface(z=z_data_prod, x=ages_prod, y=varieties_prod, colorscale='Plasma')])
                                 fig_3d_prod.update_layout(
                                     title=f'ŸÜŸÖŸàÿØÿßÿ± ÿ≥ÿ∑ÿ≠ ÿ™ŸàŸÑ€åÿØ - ÿßÿØÿßÿ±Ÿá {selected_edareh}',
                                     scene=dict(
                                         xaxis_title='ÿ≥ŸÜ',
                                         yaxis_title='Ÿàÿßÿ±€åÿ™Ÿá',
                                         zaxis_title='ÿ™ŸàŸÑ€åÿØ (ÿ™ŸÜ)'),
                                     autosize=True, height=500,
                                     margin=dict(l=0, r=0, t=40, b=0),
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
                                 )
                                 st.plotly_chart(fig_3d_prod, use_container_width=True)
                                 st.caption("ŸÜŸÖÿß€åÿ¥ ÿ™Ÿàÿ≤€åÿπ ÿ™ŸàŸÑ€åÿØ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ≥ŸÜ Ÿà Ÿàÿßÿ±€åÿ™Ÿá ÿØÿ± €å⁄© ÿ≥ÿ∑ÿ≠ ÿ≥Ÿá ÿ®ÿπÿØ€å ÿ™ÿπÿßŸÖŸÑ€å.")
                             except Exception as e:
                                  st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿß€åÿ¨ÿßÿØ ŸÜŸÖŸàÿØÿßÿ± Surface Plot ÿ™ŸàŸÑ€åÿØ: {e}")
                                  st.dataframe(df_prod_selected)
                        else:
                             st.info("‚ÑπÔ∏è ÿØÿßÿØŸá ⁄©ÿßŸÅ€å ÿ®ÿ±ÿß€å ÿ±ÿ≥ŸÖ ŸÜŸÖŸàÿØÿßÿ± Surface Plot ÿ™ŸàŸÑ€åÿØ Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ (ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ®€åÿ¥ ÿßÿ≤ €å⁄© ŸÖŸÇÿØÿßÿ± ÿ≥ŸÜ Ÿà €å⁄© Ÿàÿßÿ±€åÿ™Ÿá ÿ®ÿß ÿØÿßÿØŸá).")
                             st.dataframe(df_prod_selected)


                        if 'ÿ≥ŸÜ' in df_prod_selected.index.names:
                            df_prod_melt = df_prod_selected.reset_index().melt(id_vars='ÿ≥ŸÜ', var_name='Ÿàÿßÿ±€åÿ™Ÿá', value_name='ÿ™ŸàŸÑ€åÿØ')
                        else:
                             st.warning("‚ö†Ô∏è ÿ≥ÿßÿÆÿ™ÿßÿ± ÿØÿßÿØŸá ÿ™ŸàŸÑ€åÿØ ÿ®ÿ±ÿß€å Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ÿ∫€åÿ±ŸÖŸÜÿ™ÿ∏ÿ±Ÿá ÿßÿ≥ÿ™. ŸÜŸÖÿß€åÿ¥ Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜ€åÿ≥ÿ™.")
                             df_prod_melt = pd.DataFrame()

                        df_prod_melt = df_prod_melt.dropna(subset=['ÿ™ŸàŸÑ€åÿØ', 'Ÿàÿßÿ±€åÿ™Ÿá', 'ÿ≥ŸÜ'])
                        df_prod_melt = df_prod_melt[pd.to_numeric(df_prod_melt['ÿ≥ŸÜ'], errors='coerce').notna()]


                        if not df_prod_melt.empty:
                            try:
                                fig_hist_prod = px.histogram(df_prod_melt, x='Ÿàÿßÿ±€åÿ™Ÿá', y='ÿ™ŸàŸÑ€åÿØ', color='ÿ≥ŸÜ',
                                                           title=f'Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ÿ™ŸàŸÑ€åÿØ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ Ÿàÿßÿ±€åÿ™Ÿá Ÿà ÿ≥ŸÜ - ÿßÿØÿßÿ±Ÿá {selected_edareh}',
                                                           labels={'ÿ™ŸàŸÑ€åÿØ':'ŸÖÿ¨ŸÖŸàÿπ ÿ™ŸàŸÑ€åÿØ (ÿ™ŸÜ)'},
                                                           barmode='group',
                                                           text_auto=True)
                                fig_hist_prod.update_layout(
                                     margin=dict(l=0, r=0, t=40, b=0),
                                     paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
                                )
                                st.plotly_chart(fig_hist_prod, use_container_width=True)
                                st.caption("ÿ™Ÿàÿ≤€åÿπ ÿ™ŸàŸÑ€åÿØ Ÿáÿ± Ÿàÿßÿ±€åÿ™Ÿá ÿ®Ÿá ÿ™ŸÅ⁄©€å⁄© ÿ≥ŸÜ.")
                            except Exception as e:
                                 st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿß€åÿ¨ÿßÿØ ŸÜŸÖŸàÿØÿßÿ± Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ÿ™ŸàŸÑ€åÿØ: {e}")
                                 st.dataframe(df_prod_selected)
                        else:
                             st.info(f"‚ÑπÔ∏è ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ±€å ÿ®ÿ±ÿß€å Ÿá€åÿ≥ÿ™Ÿà⁄Øÿ±ÿßŸÖ ÿ™ŸàŸÑ€åÿØ ÿØÿ± ÿßÿØÿßÿ±Ÿá {selected_edareh} €åÿßŸÅÿ™ ŸÜÿ¥ÿØ.")

                    except KeyError:
                         st.error(f"‚ùå ÿÆÿ∑ÿß€å ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿ®Ÿá ÿØÿßÿØŸá ÿßÿØÿßÿ±Ÿá '{selected_edareh}' ÿØÿ± ÿØÿßÿØŸá ÿ™ŸàŸÑ€åÿØ. ŸÑÿ∑ŸÅÿßŸã ÿ≥ÿ™ŸàŸÜ 'ÿßÿØÿßÿ±Ÿá' ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸÜ€åÿØ.")
                    except Exception as e:
                         st.error(f"‚ùå ÿÆÿ∑ÿß€å ÿ∫€åÿ±ŸÖŸÜÿ™ÿ∏ÿ±Ÿá ÿØÿ± Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿØÿßÿØŸá ÿ™ŸàŸÑ€åÿØ ÿ®ÿ±ÿß€å ÿßÿØÿßÿ±Ÿá '{selected_edareh}': {e}")
                         st.error(traceback.format_exc())
                else:
                    st.info(f"‚ö†Ô∏è ÿØÿßÿØŸá ÿ™ŸàŸÑ€åÿØ ÿ®ÿ±ÿß€å ÿßÿØÿßÿ±Ÿá {selected_edareh} €åÿßŸÅÿ™ ŸÜÿ¥ÿØ €åÿß ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ŸÜÿ¥ÿØŸá ÿßÿ≥ÿ™.")

    st.markdown("---")


with tab3:
    st.header("üíß ÿ™ÿ≠ŸÑ€åŸÑ ŸÜ€åÿßÿ≤ ÿ¢ÿ®€åÿßÿ±€å Ÿà ⁄©ŸàÿØÿØŸá€å")
    st.markdown("""
    <div style="text-align: justify; margin-bottom: 20px;">
    ÿß€åŸÜ ÿ®ÿÆÿ¥ ÿ®Ÿá ÿ¥ŸÖÿß ⁄©ŸÖ⁄© ŸÖ€å‚Äå⁄©ŸÜÿØ ÿ™ÿß ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÖÿßŸáŸàÿßÿ±Ÿá‚Äåÿß€å ŸÖÿßŸÜŸÜÿØ NDMI (ÿ±ÿ∑Ÿàÿ®ÿ™) Ÿà NDVI (ÿ≥ŸÑÿßŸÖÿ™ ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å)ÿå ŸÜ€åÿßÿ≤Ÿáÿß€å ÿßÿ≠ÿ™ŸÖÿßŸÑ€å ÿ¢ÿ®€åÿßÿ±€å Ÿà ⁄©ŸàÿØÿØŸá€å ŸÖÿ≤ÿ±ÿπŸá ÿßŸÜÿ™ÿÆÿßÿ®€å ÿ±ÿß ÿßÿ±ÿ≤€åÿßÿ®€å ⁄©ŸÜ€åÿØ. ÿ™Ÿàÿµ€åŸá‚ÄåŸáÿß€å ÿßŸàŸÑ€åŸá ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ¢ÿ≥ÿ™ÿßŸÜŸá‚ÄåŸáÿß€å ÿßÿ≤ Ÿæ€åÿ¥ ÿ™ÿπ€å€åŸÜ ÿ¥ÿØŸá ÿßÿ±ÿßÿ¶Ÿá ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ Ÿà ÿ≥Ÿæÿ≥ ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿØ€åÿØ⁄ØÿßŸá ÿ¨ÿßŸÖÿπ‚Äåÿ™ÿ±€å ÿ±ÿß ŸÅÿ±ÿßŸáŸÖ ŸÖ€å‚Äå⁄©ŸÜÿØ.
    </div>
    """, unsafe_allow_html=True)


    is_single_farm = (selected_farm_name != "ŸáŸÖŸá ŸÖÿ≤ÿßÿ±ÿπ")

    # Need to get farm needs data only if a single farm is selected and GEE is initialized
    farm_needs_data = {'error': "ŸÑÿ∑ŸÅÿßŸã €å⁄© ŸÖÿ≤ÿ±ÿπŸá ÿÆÿßÿµ ÿ±ÿß ÿßÿ≤ ŸæŸÜŸÑ ⁄©ŸÜÿßÿ±€å ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ."}
    if is_single_farm and gee_initialized and selected_farm_details is not None and selected_farm_details.get('ee_geometry') is not None and start_date_current_str and end_date_current_str and start_date_previous_str and end_date_previous_str:
         with st.spinner("ÿØÿ± ÿ≠ÿßŸÑ ÿØÿ±€åÿßŸÅÿ™ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¥ÿßÿÆÿµ ÿ®ÿ±ÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ŸÜ€åÿßÿ≤Ÿáÿß..."):
             farm_needs_data = get_farm_needs_data(selected_farm_details.get('ee_geometry'), start_date_current_str, end_date_current_str, start_date_previous_str, end_date_previous_str)
    elif is_single_farm and gee_initialized and (selected_farm_details is None or selected_farm_details.get('ee_geometry') is None):
         farm_needs_data = {'error': f"ŸáŸÜÿØÿ≥Ÿá GEE ŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å ŸÖÿ≤ÿ±ÿπŸá '{selected_farm_name}' €åÿßŸÅÿ™ ŸÜÿ¥ÿØ."}
    elif is_single_farm and not gee_initialized:
         farm_needs_data = {'error': "Google Earth Engine ŸÖŸÇÿØÿßÿ±ÿØŸá€å ÿßŸàŸÑ€åŸá ŸÜÿ¥ÿØŸá ÿßÿ≥ÿ™."}
    elif is_single_farm and (not start_date_current_str or not end_date_current_str or not start_date_previous_str or not end_date_previous_str):
         farm_needs_data = {'error': "ÿ®ÿßÿ≤Ÿá‚ÄåŸáÿß€å ÿ≤ŸÖÿßŸÜ€å ŸÖÿπÿ™ÿ®ÿ± ÿ®ÿ±ÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ŸÜ€åÿßÿ≤Ÿáÿß ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™."}


    if not is_single_farm:
        st.info("‚ö†Ô∏è ŸÑÿ∑ŸÅÿßŸã €å⁄© ŸÖÿ≤ÿ±ÿπŸá ÿÆÿßÿµ ÿ±ÿß ÿßÿ≤ ŸæŸÜŸÑ ⁄©ŸÜÿßÿ±€å (ÿ≥ŸÖÿ™ ⁄ÜŸæ) ÿßŸÜÿ™ÿÆÿßÿ® ⁄©ŸÜ€åÿØ ÿ™ÿß ÿ™ÿ≠ŸÑ€åŸÑ ŸÜ€åÿßÿ≤Ÿáÿß€å ÿ¢ŸÜ ŸÜŸÖÿß€åÿ¥ ÿØÿßÿØŸá ÿ¥ŸàÿØ.")
    elif farm_needs_data.get('error'):
         st.error(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¥ÿßÿÆÿµ ÿ®ÿ±ÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ŸÜ€åÿßÿ≤Ÿáÿß: {farm_needs_data['error']}")
    elif pd.isna(farm_needs_data.get('NDMI_curr')) and pd.isna(farm_needs_data.get('NDVI_curr')):
        st.warning("‚ö†Ô∏è ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¥ÿßÿÆÿµ ŸÑÿßÿ≤ŸÖ (NDMI Ÿà NDVI) ÿ®ÿ±ÿß€å ÿ™ÿ≠ŸÑ€åŸÑ ÿØÿ± ÿØŸàÿ±Ÿá ŸÅÿπŸÑ€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ. (ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ®Ÿá ÿØŸÑ€åŸÑ ŸæŸàÿ¥ÿ¥ ÿßÿ®ÿ±€å €åÿß ÿÆÿ∑ÿß€å Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ®ÿßÿ¥ÿØ).")
        st.markdown("---")
        st.markdown("#### ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å")
        st.info("‚ö†Ô∏è ÿ®Ÿá ÿØŸÑ€åŸÑ ÿπÿØŸÖ ÿØÿ≥ÿ™ÿ±ÿ≥€å ÿ®Ÿá ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¥ÿßÿÆÿµÿå ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ÿßŸÖ⁄©ÿßŸÜ‚ÄåŸæÿ∞€åÿ± ŸÜ€åÿ≥ÿ™.")

    else:
        st.subheader(f"ÿ™ÿ≠ŸÑ€åŸÑ ÿ®ÿ±ÿß€å ŸÖÿ≤ÿ±ÿπŸá: {selected_farm_name}")

        st.markdown("---")
        st.markdown("#### ŸÜÿ™ÿß€åÿ¨ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å Ÿà ŸÇÿ®ŸÑ)")

        st.markdown("**ŸÖŸÇÿßÿØ€åÿ± ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß:**")
        idx_cols = st.columns(4)
        with idx_cols[0]:
            display_val = f"{farm_needs_data['NDVI_curr']:.3f}" if pd.notna(farm_needs_data.get('NDVI_curr')) else "N/A"
            st.metric("NDVI (ÿ¨ÿßÿ±€å)", display_val)
        with idx_cols[1]:
            display_val = f"{farm_needs_data['NDMI_curr']:.3f}" if pd.notna(farm_needs_data.get('NDMI_curr')) else "N/A"
            st.metric("NDMI (ÿ¨ÿßÿ±€å)", display_val)
        with idx_cols[2]:
            display_val = f"{farm_needs_data.get('EVI_curr', 'N/A'):.3f}" if pd.notna(farm_needs_data.get('EVI_curr')) else "N/A"
            st.metric("EVI (ÿ¨ÿßÿ±€å)", display_val)
        with idx_cols[3]:
            display_val = f"{farm_needs_data.get('SAVI_curr', 'N/A'):.3f}" if pd.notna(farm_needs_data.get('SAVI_curr')) else "N/A"
            st.metric("SAVI (ÿ¨ÿßÿ±€å)", display_val)


        idx_prev_cols = st.columns(4)
        with idx_prev_cols[0]:
             display_val_prev = f"{farm_needs_data['NDVI_prev']:.3f}" if pd.notna(farm_needs_data.get('NDVI_prev')) else "N/A"
             st.metric("NDVI (ŸÇÿ®ŸÑ€å)", display_val_prev)
        with idx_prev_cols[1]:
             display_val_prev = f"{farm_needs_data['NDMI_prev']:.3f}" if pd.notna(farm_needs_data.get('NDMI_prev')) else "N/A"
             st.metric("NDMI (ŸÇÿ®ŸÑ€å)", display_val_prev)
        with idx_prev_cols[2]:
             display_val_prev = f"{farm_needs_data.get('EVI_prev', 'N/A'):.3f}" if pd.notna(farm_needs_data.get('EVI_prev')) else "N/A"
             st.metric("EVI (ŸÇÿ®ŸÑ€å)", display_val_prev)
        with idx_prev_cols[3]:
             display_val_prev = f"{farm_needs_data.get('SAVI_prev', 'N/A'):.3f}" if pd.notna(farm_needs_data.get('SAVI_prev')) else "N/A"
             st.metric("SAVI (ŸÇÿ®ŸÑ€å)", display_val_prev)


        st.markdown("---")
        st.markdown("#### ÿ™Ÿàÿµ€åŸá‚ÄåŸáÿß€å ÿßŸàŸÑ€åŸá (ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ¢ÿ≥ÿ™ÿßŸÜŸá‚ÄåŸáÿß)")
        st.markdown("ÿß€åŸÜ ÿ™Ÿàÿµ€åŸá‚ÄåŸáÿß ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸÖŸÇÿßÿØ€åÿ± ÿ¥ÿßÿÆÿµ Ÿà ÿ¢ÿ≥ÿ™ÿßŸÜŸá‚ÄåŸáÿß€å ÿØÿßÿÆŸÑ€å ÿ≥€åÿ≥ÿ™ŸÖÿå ÿ®Ÿá‚ÄåÿµŸàÿ±ÿ™ ÿÆŸàÿØ⁄©ÿßÿ± ÿ™ŸàŸÑ€åÿØ ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ:")
        recommendations = []

        NDMI_IRRIGATION_THRESHOLD = 0.25
        NDVI_DROP_PERCENT_THRESHOLD = 5.0

        # Get status using the determine_status logic for consistency
        # We need the raw numerical values for determine_status
        farm_row_for_status = {
            f'{idx} (ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å)': farm_needs_data.get(f'{idx}_curr') for idx in ['NDVI', 'NDMI', 'EVI', 'SAVI']
        }
        farm_row_for_status.update({
             f'{idx} (ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ)': farm_needs_data.get(f'{idx}_prev') for idx in ['NDVI', 'NDMI', 'EVI', 'SAVI']
        })

        # Calculate change for status determination based on raw numerical values
        current_ndvi_raw = farm_needs_data.get('NDVI_curr')
        previous_ndvi_raw = farm_needs_data.get('NDVI_prev')
        ndvi_change_raw = current_ndvi_raw - previous_ndvi_raw if pd.notna(current_ndvi_raw) and pd.notna(previous_ndvi_raw) else np.nan
        farm_row_for_status['ÿ™ÿ∫€å€åÿ±'] = ndvi_change_raw # Add change for NDVI status check


        # Use determine_status for specific recommendations
        ndmi_status = determine_status(farm_row_for_status, 'NDMI')
        ndvi_status = determine_status(farm_row_for_status, 'NDVI')


        if "ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ¢ÿ®€åÿßÿ±€å ŸÅŸàÿ±€å" in ndmi_status or "ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å ÿ¥ÿØ€åÿØ" in ndmi_status:
             recommendations.append(f"üíß ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ¢ÿ®€åÿßÿ±€å ŸÅŸàÿ±€å ({ndmi_status})")
        elif "⁄©ÿßŸáÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá" in ndmi_status:
             recommendations.append(f"‚ùó ⁄©ÿßŸáÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÖÿ¥ÿßŸáÿØŸá ÿ¥ÿØŸá ÿßÿ≥ÿ™. ÿ®ÿ±ÿ±ÿ≥€å ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ¢ÿ®€åÿßÿ±€å ({ndmi_status})")
        elif "ÿßÿ≠ÿ™ŸÖÿßŸÑ ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å (ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸÇÿ®ŸÑ)" in ndmi_status:
             recommendations.append(f"‚ö†Ô∏è ÿßÿ≠ÿ™ŸÖÿßŸÑ ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ¥ÿßÿÆÿµ ÿ¨ÿßÿ±€å. (ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ ÿ®ÿ±ÿß€å ŸÖŸÇÿß€åÿ≥Ÿá)")


        if "ÿ™ŸÜÿ¥ / ⁄©ÿßŸáÿ¥" in ndvi_status:
             recommendations.append(f"‚ö†Ô∏è ⁄©ÿßŸáÿ¥ ÿØÿ± ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å/ÿ≥ŸÑÿßŸÖÿ™ ŸÖÿ¥ÿßŸáÿØŸá ÿ¥ÿØŸá ÿßÿ≥ÿ™. ÿ®ÿ±ÿ±ÿ≥€å ŸÜ€åÿßÿ≤ ÿ®Ÿá ⁄©ŸàÿØÿØŸá€å €åÿß ÿ≥ÿß€åÿ± ÿπŸàÿßŸÖŸÑ ÿ™ŸÜÿ¥‚Äåÿ≤ÿß ({ndvi_status})")
        # Check if NDVI is low when previous data is missing
        elif pd.notna(farm_needs_data.get('NDVI_curr')) and pd.isna(farm_needs_data.get('NDVI_prev')):
             LOW_NDVI_THRESHOLD = 0.3 # Example low threshold for NDVI
             if farm_needs_data['NDVI_curr'] <= LOW_NDVI_THRESHOLD:
                 recommendations.append(f"‚ö†Ô∏è ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿæÿß€å€åŸÜ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ¥ÿßÿÆÿµ ÿ¨ÿßÿ±€å ({farm_needs_data['NDVI_curr']:.3f}). (ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ ÿ®ÿ±ÿß€å ŸÖŸÇÿß€åÿ≥Ÿá). ÿ®ÿ±ÿ±ÿ≥€å ÿπŸÖŸàŸÖ€å ŸÖÿ≤ÿ±ÿπŸá.")

        # Handle cases where data is missing for NDMI or NDVI specifically
        if pd.isna(farm_needs_data.get('NDMI_curr')) and pd.notna(farm_needs_data.get('NDMI_prev')):
             recommendations.append("‚ÑπÔ∏è ÿØÿßÿØŸá ÿ±ÿ∑Ÿàÿ®ÿ™ (NDMI) ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å ÿ®ÿ±ÿß€å ÿßÿ±ÿ≤€åÿßÿ®€å Ÿàÿ∂ÿπ€åÿ™ ŸÅÿπŸÑ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")
        elif pd.notna(farm_needs_data.get('NDMI_curr')) and pd.isna(farm_needs_data.get('NDMI_prev')) and "ÿßÿ≠ÿ™ŸÖÿßŸÑ ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å (ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸÇÿ®ŸÑ)" not in recommendations:
             # If current NDMI exists but previous doesn't, and no other NDMI warning was added
              recommendations.append("‚ÑπÔ∏è ÿØÿßÿØŸá ÿ±ÿ∑Ÿàÿ®ÿ™ (NDMI) ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ ÿ®ÿ±ÿß€å ÿßÿ±ÿ≤€åÿßÿ®€å ÿ™ÿ∫€å€åÿ±ÿßÿ™ ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")


        if pd.isna(farm_needs_data.get('NDVI_curr')) and pd.notna(farm_needs_data.get('NDVI_prev')):
             recommendations.append("‚ÑπÔ∏è ÿØÿßÿØŸá ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å (NDVI) ŸáŸÅÿ™Ÿá ÿ¨ÿßÿ±€å ÿ®ÿ±ÿß€å ÿßÿ±ÿ≤€åÿßÿ®€å Ÿàÿ∂ÿπ€åÿ™ ŸÅÿπŸÑ€å ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")
        elif pd.notna(farm_needs_data.get('NDVI_curr')) and pd.isna(farm_needs_data.get('NDVI_prev')) and "ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿæÿß€å€åŸÜ (ÿ®ÿØŸàŸÜ ÿØÿßÿØŸá ŸÇÿ®ŸÑ)" not in recommendations:
             # If current NDVI exists but previous doesn't, and no other NDVI warning was added
              recommendations.append("‚ÑπÔ∏è ÿØÿßÿØŸá ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å (NDVI) ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑ ÿ®ÿ±ÿß€å ÿßÿ±ÿ≤€åÿßÿ®€å ÿ™ÿ∫€å€åÿ±ÿßÿ™ ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")


        if not recommendations:
             recommendations.append("‚úÖ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿ¥ÿßÿÆÿµ‚ÄåŸáÿß€å ŸÅÿπŸÑ€å Ÿà ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸáŸÅÿ™Ÿá ŸÇÿ®ŸÑÿå Ÿàÿ∂ÿπ€åÿ™ ŸÖÿ≤ÿ±ÿπŸá ŸÖÿ∑ŸÑŸàÿ® ÿ®Ÿá ŸÜÿ∏ÿ± ŸÖ€å‚Äåÿ±ÿ≥ÿØ €åÿß ÿØÿßÿØŸá ⁄©ÿßŸÅ€å ÿ®ÿ±ÿß€å ÿ™ÿ¥ÿÆ€åÿµ ŸÖÿ¥⁄©ŸÑ Ÿàÿßÿ∂ÿ≠ Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±ÿØ.")


        for rec in recommendations:
            if "ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ¢ÿ®€åÿßÿ±€å ŸÅŸàÿ±€å" in rec or "ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å ÿ¥ÿØ€åÿØ" in rec or "⁄©ÿßŸáÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™ ŸÇÿßÿ®ŸÑ ÿ™Ÿàÿ¨Ÿá" in rec or "ÿßÿ≠ÿ™ŸÖÿßŸÑ ÿ™ŸÜÿ¥ ÿ±ÿ∑Ÿàÿ®ÿ™€å" in rec: st.error(rec)
            elif "ŸÜ€åÿßÿ≤ ÿ®Ÿá ÿ®ÿ±ÿ±ÿ≥€å ⁄©ŸàÿØÿØŸá€å" in rec or "ŸæŸàÿ¥ÿ¥ ⁄Ø€åÿßŸá€å Ÿæÿß€å€åŸÜ" in rec: st.warning(rec)
            else: st.success(rec)

        st.markdown("---")
        st.markdown("#### ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å")
        if gemini_model:
             with st.spinner("ÿØÿ± ÿ≠ÿßŸÑ ÿ™ŸàŸÑ€åÿØ ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å..."):
                 ai_explanation = get_ai_needs_analysis(gemini_model, selected_farm_name, farm_needs_data, recommendations)
             st.markdown(ai_explanation)
        else:
             st.info("‚ö†Ô∏è ÿ≥ÿ±Ÿà€åÿ≥ ÿ™ÿ≠ŸÑ€åŸÑ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å Ÿæ€å⁄©ÿ±ÿ®ŸÜÿØ€å ŸÜÿ¥ÿØŸá €åÿß ÿØÿ± ÿØÿ≥ÿ™ÿ±ÿ≥ ŸÜ€åÿ≥ÿ™.")

    st.markdown("---")