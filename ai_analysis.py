import streamlit as st
import pandas as pd
import google.generativeai as genai
import os

# --- Configure Gemini API ---
# WARNING: Hardcoding API keys directly in code is NOT recommended for security reasons.
# It's better to use Streamlit's secrets management (st.secrets).
# However, as per user instruction, the API key is placed directly here for ease of use.

# <<< IMPORTANT: Replace "YOUR_GEMINI_API_KEY_HERE" with your actual API key >>>
api_key = "AIzaSyDzirWUubBVyjF10_JZ8UVSd6c6nnTKpLw" 

# Configure genai only if an API key is provided (even if hardcoded)
model = None # Initialize model as None
if api_key and api_key != "YOUR_GEMINI_API_KEY_HERE":
    try:
        genai.configure(api_key=api_key)
        # Use a model name appropriate for text generation, e.g., "gemini-pro"
        model = genai.GenerativeModel('gemini-pro')
        # st.success("Gemini API Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø´Ø¯.") # Optional success message
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Gemini: {e}")
        model = None # Ensure model is None if loading fails

def render_ai_analysis(farm_data_df, filters):
    """
    Renders the AI analysis section with Gemini functionality
    """
    st.title("ğŸ§  ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Gemini")
    
    if farm_data_df.empty:
        st.warning("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
        return
    
    # Check if API key is provided and model is loaded
    if not api_key or api_key == "YOUR_GEMINI_API_KEY_HERE":
         st.info("Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯ Gemini API Ø±Ø§ Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ ÙØ§ÛŒÙ„ ai_analysis.py ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ ØªØ§ Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ¹Ø§Ù„ Ø´ÙˆØ¯.")
         return

    if not model:
         st.warning("Ù…Ø¯Ù„ Gemini Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯ API Ùˆ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
         return
    
    # Filter data based on selected farm if available
    filtered_df = farm_data_df
    farm_name_col = 'farm_name' if 'farm_name' in farm_data_df.columns else 'name'
    
    selected_farm = filters.get('selected_farm')
    if selected_farm:
        filtered_df = farm_data_df[farm_data_df[farm_name_col] == selected_farm]
        if filtered_df.empty:
             st.warning(f"Ù…Ø²Ø±Ø¹Ù‡ \"{selected_farm}\" Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
             return
    
    # AI analysis section
    st.write("Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚Ø¯Ø±Øª Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ GeminiØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø±Ø¹ Ù†ÛŒØ´Ú©Ø± Ø¨Ù¾Ø±Ø³ÛŒØ¯.")
    
    # Display simplified analysis options
    st.subheader("Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø±ÛŒØ¹")
    
    option = st.selectbox(
        "Ø§Ù†ØªØ®Ø§Ø¨ Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø³Ø±ÛŒØ¹",
        ["ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø²Ø±Ø¹Ù‡", "Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³Ù„Ø§Ù…Øª Ú¯ÛŒØ§Ù‡Ø§Ù†", "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø­ØµÙˆÙ„", "ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø¨ÛŒØ§Ø±ÛŒ", "Ù¾Ø±Ø³Ø´ Ø¢Ø²Ø§Ø¯"],
        key="ai_analysis_option"
    )
    
    prompt_prefix = {
        "ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø²Ø±Ø¹Ù‡": "Ù„Ø·ÙØ§Ù‹ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ´Ú©Ø± Ø±Ø§ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯: ",
        "Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³Ù„Ø§Ù…Øª Ú¯ÛŒØ§Ù‡Ø§Ù†": "ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…Øª Ú¯ÛŒØ§Ù‡Ø§Ù† Ù†ÛŒØ´Ú©Ø± Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ NDVI Ø²ÛŒØ± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù†ÛŒØ¯: ",
        "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø­ØµÙˆÙ„": "Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ±ØŒ Ù…ÛŒØ²Ø§Ù† Ù…Ø­ØµÙˆÙ„ Ù†ÛŒØ´Ú©Ø± Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ø±Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†ÛŒØ¯: ",
        "ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø¨ÛŒØ§Ø±ÛŒ": "Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ±ØŒ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø¨ÛŒØ§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø²Ø±Ø¹Ù‡ Ù†ÛŒØ´Ú©Ø± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯: ",
        "Ù¾Ø±Ø³Ø´ Ø¢Ø²Ø§Ø¯": "Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ±ØŒ Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ù…Ù† Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯: "
    }
    
    # User input for AI query
    user_query_text = st.text_area(
        "Ø³ÙˆØ§Ù„ ÛŒØ§ Ø¯Ø³ØªÙˆØ± Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯:",
        value=prompt_prefix[option],
        height=150,
        key="ai_user_query"
    )
    
    # Create context from filtered farm data
    # Convert DataFrame to a string format suitable for the model
    if not filtered_df.empty:
         farm_data_context = filtered_df.to_markdown(index=False)
         context_prompt = f"\n\nØ¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø±Ø¹Ù‡ (ÛŒØ§ Ù…Ø²Ø§Ø±Ø¹) Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡:\n{farm_data_context}\n\n"
    else:
         farm_data_context = farm_data_df.to_markdown(index=False) # Provide all data if no farm selected
         context_prompt = f"\n\nØ¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ Ù…Ø²Ø§Ø±Ø¹:\n{farm_data_context}\n\n"
         if selected_farm:
             context_prompt += f"ØªÙˆØ¬Ù‡: Ù…Ø²Ø±Ø¹Ù‡ \"{selected_farm}\" Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø§Ø³Øª Ø§Ù…Ø§ Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯. ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n\n"

    full_prompt = user_query_text + context_prompt

    if st.button("Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Gemini", key="send_to_gemini_button"):
        if not user_query_text:
             st.warning("Ù„Ø·ÙØ§Ù‹ Ø³ÙˆØ§Ù„ ÛŒØ§ Ø¯Ø³ØªÙˆØ± Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
             return

        with st.spinner("â³ Gemini Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª..."):
            try:
                # Call the actual Gemini API
                response = model.generate_content(full_prompt)

                # Display response using enhanced styling
                st.subheader("Ù¾Ø§Ø³Ø® ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯:")

                # Check if the response has parts and display them
                if response and response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                     # Join content parts into a single string
                    response_text = "".join([part.text for part in response.candidates[0].content.parts])

                    st.markdown(f"""
                    <div class="gemini-response-report">
                    {response_text}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                     st.error("Gemini Ù¾Ø§Ø³Ø® Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ù†Ú¯Ø±Ø¯Ø§Ù†Ø¯.")
                     if response and response.prompt_feedback:
                         st.warning(f"Prompt feedback: {response.prompt_feedback}")

            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ù‚Ø±Ø§Ø±ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini API: {str(e)}")
                st.info("Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª Ú©Ù„ÛŒØ¯ API Ø®ÙˆØ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.") 